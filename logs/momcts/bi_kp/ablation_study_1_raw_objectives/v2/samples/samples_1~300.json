[
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 1,
        "algorithm": "The algorithm selects a high-potential solution from the archive (based on the sum of its two objective values) and generates a neighbor by randomly flipping items (with a 20% chance) followed by a greedy feasibility check and improvement step. It prioritizes items with higher combined marginal values when removing excess weight or adding new items, ensuring feasibility while potentially improving both objectives. The hybrid approach balances exploration (random flips) with exploitation (greedy improvements).",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., sum of objectives)\n    archive_scores = [obj[0] + obj[1] for _, obj in archive]\n    selected_idx = np.argmax(archive_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by randomly flipping items, then apply greedy improvement\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Random flip strategy\n    flip_mask = np.random.rand(n_items) < 0.2  # 20% chance to flip each item\n    new_solution = np.where(flip_mask, 1 - new_solution, new_solution)\n\n    # Ensure feasibility by removing excess weight\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        # Remove items with lowest marginal value (sum of both objectives) until feasible\n        while excess > 0 and np.sum(new_solution) > 0:\n            # Calculate marginal values for included items\n            marginal_values = (value1_lst + value2_lst) * new_solution\n            if np.max(marginal_values) == 0:\n                break  # No items can be removed further\n            # Remove the item with the smallest marginal value\n            item_to_remove = np.argmax(marginal_values)\n            if new_solution[item_to_remove] == 1:\n                new_solution[item_to_remove] = 0\n                excess -= weight_lst[item_to_remove]\n\n    # Greedy improvement step: try adding items with positive marginal value\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate marginal values for excluded items\n        marginal_values = (value1_lst + value2_lst) * (1 - new_solution)\n        # Try adding items with positive marginal value\n        for item in np.argsort(-marginal_values):\n            if marginal_values[item] > 0 and weight_lst[item] <= remaining_weight:\n                new_solution[item] = 1\n                remaining_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.4356826408397726,
            0.7961173951625824
        ],
        "raw_score": [
            36.97065483014461,
            37.2599863682192
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., sum of objectives)\n    archive_scores = [obj[0] + obj[1] for _, obj in archive]\n    selected_idx = np.argmax(archive_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by randomly flipping items, then apply greedy improvement\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Random flip strategy\n    flip_mask = np.random.rand(n_items) < 0.2  # 20% chance to flip each item\n    new_solution = np.where(flip_mask, 1 - new_solution, new_solution)\n\n    # Ensure feasibility by removing excess weight\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        # Remove items with lowest marginal value (sum of both objectives) until feasible\n        while excess > 0 and np.sum(new_solution) > 0:\n            # Calculate marginal values for included items\n            marginal_values = (value1_lst + value2_lst) * new_solution\n            if np.max(marginal_values) == 0:\n                break  # No items can be removed further\n            # Remove the item with the smallest marginal value\n            item_to_remove = np.argmax(marginal_values)\n            if new_solution[item_to_remove] == 1:\n                new_solution[item_to_remove] = 0\n                excess -= weight_lst[item_to_remove]\n\n    # Greedy improvement step: try adding items with positive marginal value\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate marginal values for excluded items\n        marginal_values = (value1_lst + value2_lst) * (1 - new_solution)\n        # Try adding items with positive marginal value\n        for item in np.argsort(-marginal_values):\n            if marginal_values[item] > 0 and weight_lst[item] <= remaining_weight:\n                new_solution[item] = 1\n                remaining_weight -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 1,
        "algorithm": "The algorithm selects a high-potential solution from the archive (based on the sum of its two objective values) and generates a neighbor by randomly flipping items (with a 20% chance) followed by a greedy feasibility check and improvement step. It prioritizes items with higher combined marginal values when removing excess weight or adding new items, ensuring feasibility while potentially improving both objectives. The hybrid approach balances exploration (random flips) with exploitation (greedy improvements).",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., sum of objectives)\n    archive_scores = [obj[0] + obj[1] for _, obj in archive]\n    selected_idx = np.argmax(archive_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by randomly flipping items, then apply greedy improvement\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Random flip strategy\n    flip_mask = np.random.rand(n_items) < 0.2  # 20% chance to flip each item\n    new_solution = np.where(flip_mask, 1 - new_solution, new_solution)\n\n    # Ensure feasibility by removing excess weight\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        # Remove items with lowest marginal value (sum of both objectives) until feasible\n        while excess > 0 and np.sum(new_solution) > 0:\n            # Calculate marginal values for included items\n            marginal_values = (value1_lst + value2_lst) * new_solution\n            if np.max(marginal_values) == 0:\n                break  # No items can be removed further\n            # Remove the item with the smallest marginal value\n            item_to_remove = np.argmax(marginal_values)\n            if new_solution[item_to_remove] == 1:\n                new_solution[item_to_remove] = 0\n                excess -= weight_lst[item_to_remove]\n\n    # Greedy improvement step: try adding items with positive marginal value\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate marginal values for excluded items\n        marginal_values = (value1_lst + value2_lst) * (1 - new_solution)\n        # Try adding items with positive marginal value\n        for item in np.argsort(-marginal_values):\n            if marginal_values[item] > 0 and weight_lst[item] <= remaining_weight:\n                new_solution[item] = 1\n                remaining_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.4356826408397726,
            0.7961173951625824
        ],
        "raw_score": [
            36.97065483014461,
            37.2599863682192
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., sum of objectives)\n    archive_scores = [obj[0] + obj[1] for _, obj in archive]\n    selected_idx = np.argmax(archive_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by randomly flipping items, then apply greedy improvement\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Random flip strategy\n    flip_mask = np.random.rand(n_items) < 0.2  # 20% chance to flip each item\n    new_solution = np.where(flip_mask, 1 - new_solution, new_solution)\n\n    # Ensure feasibility by removing excess weight\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        # Remove items with lowest marginal value (sum of both objectives) until feasible\n        while excess > 0 and np.sum(new_solution) > 0:\n            # Calculate marginal values for included items\n            marginal_values = (value1_lst + value2_lst) * new_solution\n            if np.max(marginal_values) == 0:\n                break  # No items can be removed further\n            # Remove the item with the smallest marginal value\n            item_to_remove = np.argmax(marginal_values)\n            if new_solution[item_to_remove] == 1:\n                new_solution[item_to_remove] = 0\n                excess -= weight_lst[item_to_remove]\n\n    # Greedy improvement step: try adding items with positive marginal value\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate marginal values for excluded items\n        marginal_values = (value1_lst + value2_lst) * (1 - new_solution)\n        # Try adding items with positive marginal value\n        for item in np.argsort(-marginal_values):\n            if marginal_values[item] > 0 and weight_lst[item] <= remaining_weight:\n                new_solution[item] = 1\n                remaining_weight -= weight_lst[item]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 1,
        "algorithm": "The algorithm selects a high-potential solution from the archive (based on the sum of its two objective values) and generates a neighbor by randomly flipping items (with a 20% chance) followed by a greedy feasibility check and improvement step. It prioritizes items with higher combined marginal values when removing excess weight or adding new items, ensuring feasibility while potentially improving both objectives. The hybrid approach balances exploration (random flips) with exploitation (greedy improvements).",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., sum of objectives)\n    archive_scores = [obj[0] + obj[1] for _, obj in archive]\n    selected_idx = np.argmax(archive_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by randomly flipping items, then apply greedy improvement\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Random flip strategy\n    flip_mask = np.random.rand(n_items) < 0.2  # 20% chance to flip each item\n    new_solution = np.where(flip_mask, 1 - new_solution, new_solution)\n\n    # Ensure feasibility by removing excess weight\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        # Remove items with lowest marginal value (sum of both objectives) until feasible\n        while excess > 0 and np.sum(new_solution) > 0:\n            # Calculate marginal values for included items\n            marginal_values = (value1_lst + value2_lst) * new_solution\n            if np.max(marginal_values) == 0:\n                break  # No items can be removed further\n            # Remove the item with the smallest marginal value\n            item_to_remove = np.argmax(marginal_values)\n            if new_solution[item_to_remove] == 1:\n                new_solution[item_to_remove] = 0\n                excess -= weight_lst[item_to_remove]\n\n    # Greedy improvement step: try adding items with positive marginal value\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate marginal values for excluded items\n        marginal_values = (value1_lst + value2_lst) * (1 - new_solution)\n        # Try adding items with positive marginal value\n        for item in np.argsort(-marginal_values):\n            if marginal_values[item] > 0 and weight_lst[item] <= remaining_weight:\n                new_solution[item] = 1\n                remaining_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.4356826408397726,
            0.7961173951625824
        ],
        "raw_score": [
            36.97065483014461,
            37.2599863682192
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a solution with high potential for improvement (e.g., sum of objectives)\n    archive_scores = [obj[0] + obj[1] for _, obj in archive]\n    selected_idx = np.argmax(archive_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor by randomly flipping items, then apply greedy improvement\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Random flip strategy\n    flip_mask = np.random.rand(n_items) < 0.2  # 20% chance to flip each item\n    new_solution = np.where(flip_mask, 1 - new_solution, new_solution)\n\n    # Ensure feasibility by removing excess weight\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        # Remove items with lowest marginal value (sum of both objectives) until feasible\n        while excess > 0 and np.sum(new_solution) > 0:\n            # Calculate marginal values for included items\n            marginal_values = (value1_lst + value2_lst) * new_solution\n            if np.max(marginal_values) == 0:\n                break  # No items can be removed further\n            # Remove the item with the smallest marginal value\n            item_to_remove = np.argmax(marginal_values)\n            if new_solution[item_to_remove] == 1:\n                new_solution[item_to_remove] = 0\n                excess -= weight_lst[item_to_remove]\n\n    # Greedy improvement step: try adding items with positive marginal value\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Calculate marginal values for excluded items\n        marginal_values = (value1_lst + value2_lst) * (1 - new_solution)\n        # Try adding items with positive marginal value\n        for item in np.argsort(-marginal_values):\n            if marginal_values[item] > 0 and weight_lst[item] <= remaining_weight:\n                new_solution[item] = 1\n                remaining_weight -= weight_lst[item]\n\n    return new_solution\n\n",
        "operation": "i1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 2,
        "algorithm": "The algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6616908732258407,
            0.4831783175468445
        ],
        "raw_score": [
            28.48375171154526,
            28.74721189525877
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 2,
        "algorithm": "The algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6616908732258407,
            0.4831783175468445
        ],
        "raw_score": [
            28.48375171154526,
            28.74721189525877
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 2,
        "algorithm": "The algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6616908732258407,
            0.4831783175468445
        ],
        "raw_score": [
            28.48375171154526,
            28.74721189525877
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "operation": "i1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 3,
        "algorithm": "The algorithm selects the top solution from the archive (sorted by the sum of both objectives) and performs a greedy local search by iteratively adding or removing items to improve feasibility and objective values, followed by a random swap to maintain diversity. The key design ideas are prioritizing solutions with higher combined objective values and using a hybrid approach of greedy and random exploration to generate neighbors.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(base_solution * weight_lst)\n    new_solution = base_solution.copy()\n\n    # Identify items that can be swapped or added to improve objectives\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Perform a random swap to ensure diversity\n    if len(new_solution) >= 2:\n        idx1, idx2 = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[idx1] != new_solution[idx2]:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n            temp_weight = np.sum(new_solution * weight_lst)\n            if temp_weight > capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.5244073814411324,
            0.5121272504329681
        ],
        "raw_score": [
            30.374999737717005,
            31.044817273830414
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(base_solution * weight_lst)\n    new_solution = base_solution.copy()\n\n    # Identify items that can be swapped or added to improve objectives\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Perform a random swap to ensure diversity\n    if len(new_solution) >= 2:\n        idx1, idx2 = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[idx1] != new_solution[idx2]:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n            temp_weight = np.sum(new_solution * weight_lst)\n            if temp_weight > capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\n",
        "operation": "i1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 4,
        "algorithm": "The heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9035397066548494,
            0.47091394662857056
        ],
        "raw_score": [
            27.34055461589349,
            28.03176024888062
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 4,
        "algorithm": "The heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9035397066548494,
            0.47091394662857056
        ],
        "raw_score": [
            27.34055461589349,
            28.03176024888062
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 4,
        "algorithm": "The heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9035397066548494,
            0.47091394662857056
        ],
        "raw_score": [
            27.34055461589349,
            28.03176024888062
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n",
        "operation": "i1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 5,
        "algorithm": "The algorithm intelligently selects a high-potential solution from the archive by evaluating its improvement potential (based on marginal gains and losses in both objectives) and then applies a hybrid local search combining random perturbations with targeted flips of high-value items, while ensuring feasibility through weight checks. It prioritizes items with higher marginal gains in either objective and occasionally removes low-value items to explore the solution space more effectively. The selection is driven by a normalized improvement score that balances potential gains and losses, while the local search strategically flips items to maximize both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    archive_solutions = [sol for sol, _ in archive]\n    current_weights = [np.sum(weight_lst[sol == 1]) for sol in archive_solutions]\n    current_values1 = [np.sum(value1_lst[sol == 1]) for sol in archive_solutions]\n    current_values2 = [np.sum(value2_lst[sol == 1]) for sol in archive_solutions]\n\n    # Calculate potential improvement scores (normalized)\n    improvement_scores = []\n    for i in range(len(archive_solutions)):\n        sol = archive_solutions[i]\n        total_weight = current_weights[i]\n        remaining_capacity = capacity - total_weight\n\n        # Calculate potential gains for items not in the solution\n        potential_gains1 = value1_lst[sol == 0] * (weight_lst[sol == 0] <= remaining_capacity)\n        potential_gains2 = value2_lst[sol == 0] * (weight_lst[sol == 0] <= remaining_capacity)\n\n        # Calculate potential losses for items in the solution\n        potential_losses1 = value1_lst[sol == 1]\n        potential_losses2 = value2_lst[sol == 1]\n\n        # Calculate improvement score (simplified)\n        score = (np.sum(potential_gains1) + np.sum(potential_gains2)) / (1 + np.sum(potential_losses1) + np.sum(potential_losses2))\n        improvement_scores.append(score)\n\n    # Select solution with highest improvement score\n    selected_idx = np.argmax(improvement_scores)\n    base_solution = archive_solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine random perturbation with targeted flips\n    n_items = len(weight_lst)\n    current_weight = current_weights[selected_idx]\n\n    # Step 1: Random perturbation (flip a few random items)\n    for _ in range(min(3, n_items)):\n        item = random.randint(0, n_items - 1)\n        if new_solution[item] == 1:\n            current_weight -= weight_lst[item]\n            new_solution[item] = 0\n        else:\n            if current_weight + weight_lst[item] <= capacity:\n                current_weight += weight_lst[item]\n                new_solution[item] = 1\n\n    # Step 2: Targeted flips for high-margin items\n    # Find items not in the solution with high value1\n    candidate_items = np.where(new_solution == 0)[0]\n    if len(candidate_items) > 0:\n        # Sort by value1 (descending) and value2 (descending)\n        sorted_items = sorted(candidate_items, key=lambda x: (-value1_lst[x], -value2_lst[x]))\n        for item in sorted_items[:min(2, len(sorted_items))]:\n            if current_weight + weight_lst[item] <= capacity:\n                current_weight += weight_lst[item]\n                new_solution[item] = 1\n\n    # Step 3: Optional: Flip low-value items in the solution\n    # Find items in the solution with low value1 and value2\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Sort by value1 (ascending) and value2 (ascending)\n        sorted_items = sorted(included_items, key=lambda x: (value1_lst[x], value2_lst[x]))\n        for item in sorted_items[:min(1, len(sorted_items))]:\n            current_weight -= weight_lst[item]\n            new_solution[item] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.5795017757017813,
            2.2255084812641144
        ],
        "raw_score": [
            41.60249546165841,
            36.2860970163389
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    archive_solutions = [sol for sol, _ in archive]\n    current_weights = [np.sum(weight_lst[sol == 1]) for sol in archive_solutions]\n    current_values1 = [np.sum(value1_lst[sol == 1]) for sol in archive_solutions]\n    current_values2 = [np.sum(value2_lst[sol == 1]) for sol in archive_solutions]\n\n    # Calculate potential improvement scores (normalized)\n    improvement_scores = []\n    for i in range(len(archive_solutions)):\n        sol = archive_solutions[i]\n        total_weight = current_weights[i]\n        remaining_capacity = capacity - total_weight\n\n        # Calculate potential gains for items not in the solution\n        potential_gains1 = value1_lst[sol == 0] * (weight_lst[sol == 0] <= remaining_capacity)\n        potential_gains2 = value2_lst[sol == 0] * (weight_lst[sol == 0] <= remaining_capacity)\n\n        # Calculate potential losses for items in the solution\n        potential_losses1 = value1_lst[sol == 1]\n        potential_losses2 = value2_lst[sol == 1]\n\n        # Calculate improvement score (simplified)\n        score = (np.sum(potential_gains1) + np.sum(potential_gains2)) / (1 + np.sum(potential_losses1) + np.sum(potential_losses2))\n        improvement_scores.append(score)\n\n    # Select solution with highest improvement score\n    selected_idx = np.argmax(improvement_scores)\n    base_solution = archive_solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine random perturbation with targeted flips\n    n_items = len(weight_lst)\n    current_weight = current_weights[selected_idx]\n\n    # Step 1: Random perturbation (flip a few random items)\n    for _ in range(min(3, n_items)):\n        item = random.randint(0, n_items - 1)\n        if new_solution[item] == 1:\n            current_weight -= weight_lst[item]\n            new_solution[item] = 0\n        else:\n            if current_weight + weight_lst[item] <= capacity:\n                current_weight += weight_lst[item]\n                new_solution[item] = 1\n\n    # Step 2: Targeted flips for high-margin items\n    # Find items not in the solution with high value1\n    candidate_items = np.where(new_solution == 0)[0]\n    if len(candidate_items) > 0:\n        # Sort by value1 (descending) and value2 (descending)\n        sorted_items = sorted(candidate_items, key=lambda x: (-value1_lst[x], -value2_lst[x]))\n        for item in sorted_items[:min(2, len(sorted_items))]:\n            if current_weight + weight_lst[item] <= capacity:\n                current_weight += weight_lst[item]\n                new_solution[item] = 1\n\n    # Step 3: Optional: Flip low-value items in the solution\n    # Find items in the solution with low value1 and value2\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Sort by value1 (ascending) and value2 (ascending)\n        sorted_items = sorted(included_items, key=lambda x: (value1_lst[x], value2_lst[x]))\n        for item in sorted_items[:min(1, len(sorted_items))]:\n            current_weight -= weight_lst[item]\n            new_solution[item] = 0\n\n    return new_solution\n\n",
        "operation": "i1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            \n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 6,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (near-capacity but not fully packed)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Novel local search operator: Weighted Value-Based Greedy Swap\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Calculate weighted values for both objectives (balance exploration and exploitation)\n    alpha = 0.6  # Weight for objective 1\n    beta = 0.4   # Weight for objective 2\n    weighted_values = alpha * value1_lst + beta * value2_lst\n\n    # Find the most valuable item currently in the knapsack\n    in_knapsack = np.where(new_solution == 1)[0]\n    if len(in_knapsack) > 0:\n        most_valuable_in = in_knapsack[np.argmax(weighted_values[in_knapsack])]\n\n        # Find the best candidate to replace it (consider both in and out of knapsack)\n        all_items = np.arange(n_items)\n        exclude_most_valuable = np.delete(all_items, most_valuable_in)\n        candidates = exclude_most_valuable\n\n        # Calculate potential new weights\n        current_weight = np.sum(weight_lst * new_solution)\n        potential_weights = current_weight - weight_lst[most_valuable_in] + weight_lst[candidates]\n\n        # Filter feasible candidates\n        feasible_mask = potential_weights <= capacity\n        feasible_candidates = candidates[feasible_mask]\n\n        if len(feasible_candidates) > 0:\n            # Select the candidate with highest weighted value\n            best_candidate = feasible_candidates[np.argmax(weighted_values[feasible_candidates])]\n\n            # Perform the swap\n            new_solution[most_valuable_in] = 0\n            new_solution[best_candidate] = 1\n\n    # Additional diversification: With probability 0.2, perform a random flip\n    if random.random() < 0.2:\n        flip_idx = random.randint(0, n_items - 1)\n        if new_solution[flip_idx] == 1 and np.sum(weight_lst * new_solution) - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n        elif new_solution[flip_idx] == 0 and np.sum(weight_lst * new_solution) + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6276822021074377,
            0.44365832209587097
        ],
        "raw_score": [
            28.295263699328505,
            29.17602913160117
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (near-capacity but not fully packed)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Novel local search operator: Weighted Value-Based Greedy Swap\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Calculate weighted values for both objectives (balance exploration and exploitation)\n    alpha = 0.6  # Weight for objective 1\n    beta = 0.4   # Weight for objective 2\n    weighted_values = alpha * value1_lst + beta * value2_lst\n\n    # Find the most valuable item currently in the knapsack\n    in_knapsack = np.where(new_solution == 1)[0]\n    if len(in_knapsack) > 0:\n        most_valuable_in = in_knapsack[np.argmax(weighted_values[in_knapsack])]\n\n        # Find the best candidate to replace it (consider both in and out of knapsack)\n        all_items = np.arange(n_items)\n        exclude_most_valuable = np.delete(all_items, most_valuable_in)\n        candidates = exclude_most_valuable\n\n        # Calculate potential new weights\n        current_weight = np.sum(weight_lst * new_solution)\n        potential_weights = current_weight - weight_lst[most_valuable_in] + weight_lst[candidates]\n\n        # Filter feasible candidates\n        feasible_mask = potential_weights <= capacity\n        feasible_candidates = candidates[feasible_mask]\n\n        if len(feasible_candidates) > 0:\n            # Select the candidate with highest weighted value\n            best_candidate = feasible_candidates[np.argmax(weighted_values[feasible_candidates])]\n\n            # Perform the swap\n            new_solution[most_valuable_in] = 0\n            new_solution[best_candidate] = 1\n\n    # Additional diversification: With probability 0.2, perform a random flip\n    if random.random() < 0.2:\n        flip_idx = random.randint(0, n_items - 1)\n        if new_solution[flip_idx] == 1 and np.sum(weight_lst * new_solution) - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n        elif new_solution[flip_idx] == 0 and np.sum(weight_lst * new_solution) + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            \n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 6,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (near-capacity but not fully packed)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Novel local search operator: Weighted Value-Based Greedy Swap\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Calculate weighted values for both objectives (balance exploration and exploitation)\n    alpha = 0.6  # Weight for objective 1\n    beta = 0.4   # Weight for objective 2\n    weighted_values = alpha * value1_lst + beta * value2_lst\n\n    # Find the most valuable item currently in the knapsack\n    in_knapsack = np.where(new_solution == 1)[0]\n    if len(in_knapsack) > 0:\n        most_valuable_in = in_knapsack[np.argmax(weighted_values[in_knapsack])]\n\n        # Find the best candidate to replace it (consider both in and out of knapsack)\n        all_items = np.arange(n_items)\n        exclude_most_valuable = np.delete(all_items, most_valuable_in)\n        candidates = exclude_most_valuable\n\n        # Calculate potential new weights\n        current_weight = np.sum(weight_lst * new_solution)\n        potential_weights = current_weight - weight_lst[most_valuable_in] + weight_lst[candidates]\n\n        # Filter feasible candidates\n        feasible_mask = potential_weights <= capacity\n        feasible_candidates = candidates[feasible_mask]\n\n        if len(feasible_candidates) > 0:\n            # Select the candidate with highest weighted value\n            best_candidate = feasible_candidates[np.argmax(weighted_values[feasible_candidates])]\n\n            # Perform the swap\n            new_solution[most_valuable_in] = 0\n            new_solution[best_candidate] = 1\n\n    # Additional diversification: With probability 0.2, perform a random flip\n    if random.random() < 0.2:\n        flip_idx = random.randint(0, n_items - 1)\n        if new_solution[flip_idx] == 1 and np.sum(weight_lst * new_solution) - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n        elif new_solution[flip_idx] == 0 and np.sum(weight_lst * new_solution) + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6276822021074377,
            0.44365832209587097
        ],
        "raw_score": [
            28.295263699328505,
            29.17602913160117
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (near-capacity but not fully packed)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Novel local search operator: Weighted Value-Based Greedy Swap\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Calculate weighted values for both objectives (balance exploration and exploitation)\n    alpha = 0.6  # Weight for objective 1\n    beta = 0.4   # Weight for objective 2\n    weighted_values = alpha * value1_lst + beta * value2_lst\n\n    # Find the most valuable item currently in the knapsack\n    in_knapsack = np.where(new_solution == 1)[0]\n    if len(in_knapsack) > 0:\n        most_valuable_in = in_knapsack[np.argmax(weighted_values[in_knapsack])]\n\n        # Find the best candidate to replace it (consider both in and out of knapsack)\n        all_items = np.arange(n_items)\n        exclude_most_valuable = np.delete(all_items, most_valuable_in)\n        candidates = exclude_most_valuable\n\n        # Calculate potential new weights\n        current_weight = np.sum(weight_lst * new_solution)\n        potential_weights = current_weight - weight_lst[most_valuable_in] + weight_lst[candidates]\n\n        # Filter feasible candidates\n        feasible_mask = potential_weights <= capacity\n        feasible_candidates = candidates[feasible_mask]\n\n        if len(feasible_candidates) > 0:\n            # Select the candidate with highest weighted value\n            best_candidate = feasible_candidates[np.argmax(weighted_values[feasible_candidates])]\n\n            # Perform the swap\n            new_solution[most_valuable_in] = 0\n            new_solution[best_candidate] = 1\n\n    # Additional diversification: With probability 0.2, perform a random flip\n    if random.random() < 0.2:\n        flip_idx = random.randint(0, n_items - 1)\n        if new_solution[flip_idx] == 1 and np.sum(weight_lst * new_solution) - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n        elif new_solution[flip_idx] == 0 and np.sum(weight_lst * new_solution) + weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects the top solution from the archive (sorted by the sum of both objectives) and performs a greedy local search by iteratively adding or removing items to improve feasibility and objective values, followed by a random swap to maintain diversity. The key design ideas are prioritizing solutions with higher combined objective values and using a hybrid approach of greedy and random exploration to generate neighbors.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(base_solution * weight_lst)\n    new_solution = base_solution.copy()\n\n    # Identify items that can be swapped or added to improve objectives\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Perform a random swap to ensure diversity\n    if len(new_solution) >= 2:\n        idx1, idx2 = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[idx1] != new_solution[idx2]:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n            temp_weight = np.sum(new_solution * weight_lst)\n            if temp_weight > capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            \n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 7,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Identify promising items to consider\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 3 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-3:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Perform targeted swapping with items in solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Select two items to swap based on their contribution to both objectives\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Perform random flip with probability based on current solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8179565713407433,
            0.27593129873275757
        ],
        "raw_score": [
            27.604553890686965,
            28.184297658157398
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Identify promising items to consider\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 3 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-3:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Perform targeted swapping with items in solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Select two items to swap based on their contribution to both objectives\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Perform random flip with probability based on current solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects the top solution from the archive (sorted by the sum of both objectives) and performs a greedy local search by iteratively adding or removing items to improve feasibility and objective values, followed by a random swap to maintain diversity. The key design ideas are prioritizing solutions with higher combined objective values and using a hybrid approach of greedy and random exploration to generate neighbors.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(base_solution * weight_lst)\n    new_solution = base_solution.copy()\n\n    # Identify items that can be swapped or added to improve objectives\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Perform a random swap to ensure diversity\n    if len(new_solution) >= 2:\n        idx1, idx2 = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[idx1] != new_solution[idx2]:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n            temp_weight = np.sum(new_solution * weight_lst)\n            if temp_weight > capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            \n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 7,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Identify promising items to consider\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 3 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-3:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Perform targeted swapping with items in solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Select two items to swap based on their contribution to both objectives\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Perform random flip with probability based on current solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8179565713407433,
            0.27593129873275757
        ],
        "raw_score": [
            27.604553890686965,
            28.184297658157398
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Identify promising items to consider\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 3 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-3:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Perform targeted swapping with items in solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Select two items to swap based on their contribution to both objectives\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Perform random flip with probability based on current solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 8,
        "algorithm": "The algorithm selects the most promising solution from the archive based on a weighted value metric balancing both objectives (60% value1, 40% value2) and capacity utilization, then applies a hybrid local search that first adds high-value-density items and occasionally removes low-value-density items to create a feasible neighbor solution. It prioritizes items with higher combined value-to-weight ratios while ensuring feasibility through targeted removals when necessary.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate weighted value metric for each solution\n    def weighted_value(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        # Weighted value metric combining both objectives and capacity utilization\n        return (0.6 * value1 + 0.4 * value2) * (1 - (total_weight / capacity))\n\n    # Select solution with highest weighted value\n    selected_sol, _ = max(archive, key=lambda x: weighted_value(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search operator\n    # Step 1: Replace low-value items with high-value alternatives\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Calculate value density (value per weight) for all items\n    value_density = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-value_density)  # Highest density first\n\n    # Try to add high-value items that fit\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and weight_lst[idx] <= available_weight:\n            new_solution[idx] = 1\n            available_weight -= weight_lst[idx]\n\n    # Step 2: Randomly perturb by removing items with low value density\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        low_density_items = np.where(new_solution == 1)[0]\n        if len(low_density_items) > 0:\n            # Remove items with lowest value density\n            low_density_items_sorted = sorted(low_density_items, key=lambda x: value_density[x])\n            for idx in low_density_items_sorted[:max(1, len(low_density_items)//3)]:\n                new_solution[idx] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        while total_weight > capacity:\n            # Find the item with lowest value density in the solution\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmin(value_density[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8243948490542945,
            10.670056641101837
        ],
        "raw_score": [
            28.23516013650488,
            28.37749093126734
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate weighted value metric for each solution\n    def weighted_value(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        # Weighted value metric combining both objectives and capacity utilization\n        return (0.6 * value1 + 0.4 * value2) * (1 - (total_weight / capacity))\n\n    # Select solution with highest weighted value\n    selected_sol, _ = max(archive, key=lambda x: weighted_value(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search operator\n    # Step 1: Replace low-value items with high-value alternatives\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Calculate value density (value per weight) for all items\n    value_density = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-value_density)  # Highest density first\n\n    # Try to add high-value items that fit\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and weight_lst[idx] <= available_weight:\n            new_solution[idx] = 1\n            available_weight -= weight_lst[idx]\n\n    # Step 2: Randomly perturb by removing items with low value density\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        low_density_items = np.where(new_solution == 1)[0]\n        if len(low_density_items) > 0:\n            # Remove items with lowest value density\n            low_density_items_sorted = sorted(low_density_items, key=lambda x: value_density[x])\n            for idx in low_density_items_sorted[:max(1, len(low_density_items)//3)]:\n                new_solution[idx] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        while total_weight > capacity:\n            # Find the item with lowest value density in the solution\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmin(value_density[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 9,
        "algorithm": "The algorithm selects a near-capacity solution with diverse item distributions from the archive, then applies a hybrid local search combining value-weighted item swaps and flips, prioritizing items with high value ratios while ensuring feasibility through intelligent restoration steps. It balances both objectives by considering value ratios and dynamically adjusting the solution to maintain capacity constraints. The selection prioritizes solutions close to capacity and with balanced value distributions, while the local search intelligently explores neighboring solutions by swapping high-value items and flipping low-value items when needed.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential (near-capacity with diverse items)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()\n\n    # Select solution with highest weight and most balanced value distribution\n    selected_sol = max(candidates, key=lambda x: (np.sum(weight_lst * x), np.std(value1_lst * x) + np.std(value2_lst * x)))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search operator\n    # Step 1: Value-weighted swap of two items\n    value_weights = value1_lst + value2_lst\n    probs = value_weights / np.sum(value_weights)\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False, p=probs)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Undo swap and try value-weighted flip\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Flip item with highest value ratio\n        value_ratio = (value1_lst / (value2_lst + 1e-6)) * (1 - 2 * new_solution)\n        flip_idx = np.argmax(value_ratio)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # Remove lowest value ratio item if adding would violate capacity\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Add highest value ratio item available\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    ratio = (value1_lst[available_items] + value2_lst[available_items]) / (weight_lst[available_items] + 1e-6)\n                    best_item = available_items[np.argmax(ratio)]\n                    if np.sum(weight_lst * new_solution) + weight_lst[best_item] <= capacity:\n                        new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6572029456644558,
            2.1454139351844788
        ],
        "raw_score": [
            28.894898211799664,
            29.70234149994233
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential (near-capacity with diverse items)\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()\n\n    # Select solution with highest weight and most balanced value distribution\n    selected_sol = max(candidates, key=lambda x: (np.sum(weight_lst * x), np.std(value1_lst * x) + np.std(value2_lst * x)))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search operator\n    # Step 1: Value-weighted swap of two items\n    value_weights = value1_lst + value2_lst\n    probs = value_weights / np.sum(value_weights)\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False, p=probs)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Undo swap and try value-weighted flip\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Flip item with highest value ratio\n        value_ratio = (value1_lst / (value2_lst + 1e-6)) * (1 - 2 * new_solution)\n        flip_idx = np.argmax(value_ratio)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # Remove lowest value ratio item if adding would violate capacity\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Add highest value ratio item available\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    ratio = (value1_lst[available_items] + value2_lst[available_items]) / (weight_lst[available_items] + 1e-6)\n                    best_item = available_items[np.argmax(ratio)]\n                    if np.sum(weight_lst * new_solution) + weight_lst[best_item] <= capacity:\n                        new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Identify promising items to consider\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 3 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-3:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Perform targeted swapping with items in solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Select two items to swap based on their contribution to both objectives\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Perform random flip with probability based on current solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            \n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 10,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives using a novelty-aware selection\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting with novelty factor\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) * (1 - (current_value1 / total_value1)) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) * (1 - (current_value2 / total_value2)) if total_value2 > 0 else 0.5\n\n    # Novelty-driven item selection: prioritize items that create \"novel\" value combinations\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate novelty scores based on value ratios and current solution's coverage\n        novelty_scores = []\n        for item in potential_items:\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            novelty = abs(ratio1 - ratio2) * (1 - min(ratio1, ratio2))\n            novelty_scores.append(novelty)\n\n        # Select top items with highest novelty and feasible addition\n        novelty_scores = np.array(novelty_scores)\n        top_items = potential_items[np.argsort(novelty_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Context-aware swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        if len(worst_items) == 2:\n            idx1, idx2 = worst_items\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Dynamic exploration: probabilistic flip with novelty-based probability\n    flip_prob = 0.2 + 0.6 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9117416583656477,
            0.6331888437271118
        ],
        "raw_score": [
            27.47455128805673,
            28.37877368886923
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives using a novelty-aware selection\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting with novelty factor\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) * (1 - (current_value1 / total_value1)) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) * (1 - (current_value2 / total_value2)) if total_value2 > 0 else 0.5\n\n    # Novelty-driven item selection: prioritize items that create \"novel\" value combinations\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate novelty scores based on value ratios and current solution's coverage\n        novelty_scores = []\n        for item in potential_items:\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            novelty = abs(ratio1 - ratio2) * (1 - min(ratio1, ratio2))\n            novelty_scores.append(novelty)\n\n        # Select top items with highest novelty and feasible addition\n        novelty_scores = np.array(novelty_scores)\n        top_items = potential_items[np.argsort(novelty_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Context-aware swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        if len(worst_items) == 2:\n            idx1, idx2 = worst_items\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Dynamic exploration: probabilistic flip with novelty-based probability\n    flip_prob = 0.2 + 0.6 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Identify promising items to consider\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 3 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-3:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Perform targeted swapping with items in solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Select two items to swap based on their contribution to both objectives\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Perform random flip with probability based on current solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            \n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 10,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives using a novelty-aware selection\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting with novelty factor\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) * (1 - (current_value1 / total_value1)) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) * (1 - (current_value2 / total_value2)) if total_value2 > 0 else 0.5\n\n    # Novelty-driven item selection: prioritize items that create \"novel\" value combinations\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate novelty scores based on value ratios and current solution's coverage\n        novelty_scores = []\n        for item in potential_items:\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            novelty = abs(ratio1 - ratio2) * (1 - min(ratio1, ratio2))\n            novelty_scores.append(novelty)\n\n        # Select top items with highest novelty and feasible addition\n        novelty_scores = np.array(novelty_scores)\n        top_items = potential_items[np.argsort(novelty_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Context-aware swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        if len(worst_items) == 2:\n            idx1, idx2 = worst_items\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Dynamic exploration: probabilistic flip with novelty-based probability\n    flip_prob = 0.2 + 0.6 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9117416583656477,
            0.6331888437271118
        ],
        "raw_score": [
            27.47455128805673,
            28.37877368886923
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives using a novelty-aware selection\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting with novelty factor\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) * (1 - (current_value1 / total_value1)) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) * (1 - (current_value2 / total_value2)) if total_value2 > 0 else 0.5\n\n    # Novelty-driven item selection: prioritize items that create \"novel\" value combinations\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate novelty scores based on value ratios and current solution's coverage\n        novelty_scores = []\n        for item in potential_items:\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            novelty = abs(ratio1 - ratio2) * (1 - min(ratio1, ratio2))\n            novelty_scores.append(novelty)\n\n        # Select top items with highest novelty and feasible addition\n        novelty_scores = np.array(novelty_scores)\n        top_items = potential_items[np.argsort(novelty_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Context-aware swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        if len(worst_items) == 2:\n            idx1, idx2 = worst_items\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Dynamic exploration: probabilistic flip with novelty-based probability\n    flip_prob = 0.2 + 0.6 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Identify promising items to consider\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 3 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-3:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Perform targeted swapping with items in solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Select two items to swap based on their contribution to both objectives\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Perform random flip with probability based on current solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            \n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 11,
        "algorithm": "The algorithm combines selection of high-potential solutions from the archive with a three-phase local search: probabilistic item removal/addition (prioritizing marginal contribution), targeted item swapping (focusing on high-value exchanges), and dynamic feasibility adjustment (ensuring weight constraints). It balances exploration (randomized selection) with exploitation (greedy improvement) while maintaining feasibility, with the selection strategy favoring top 30% of solutions based on combined objective values.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high dominance rank and objective diversity\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = int(len(archive) * 0.3)  # Select from top 30% to balance exploration\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Phase 1: Probabilistic item removal/addition\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Remove item with probability based on marginal contribution\n            marginal1 = current_value1 - value1_lst[i]\n            marginal2 = current_value2 - value2_lst[i]\n            prob_remove = 0.5 * (1 - (marginal1 / (np.sum(value1_lst) + 1e-8) + marginal2 / (np.sum(value2_lst) + 1e-8)))\n            if np.random.random() < prob_remove and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                current_value1 -= value1_lst[i]\n                current_value2 -= value2_lst[i]\n        else:\n            # Add item with probability based on potential contribution\n            if current_weight + weight_lst[i] <= capacity:\n                potential1 = current_value1 + value1_lst[i]\n                potential2 = current_value2 + value2_lst[i]\n                prob_add = 0.5 * (potential1 / (np.sum(value1_lst) + 1e-8) + potential2 / (np.sum(value2_lst) + 1e-8))\n                if np.random.random() < prob_add:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    current_value1 += value1_lst[i]\n                    current_value2 += value2_lst[i]\n\n    # Phase 2: Targeted item swapping\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Select best candidate to remove\n        remove_candidates = sorted(in_solution, key=lambda x: -(value1_lst[x] + value2_lst[x]))[:3]\n        # Select best candidate to add\n        add_candidates = sorted(out_solution, key=lambda x: (value1_lst[x] + value2_lst[x]))[-3:]\n\n        for i in remove_candidates:\n            for j in add_candidates:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    break\n\n    # Phase 3: Dynamic feasibility adjustment\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess = current_weight - capacity\n        items_sorted = sorted(np.where(new_solution == 1)[0], key=lambda x: weight_lst[x])\n        for i in items_sorted:\n            if excess <= 0:\n                break\n            new_solution[i] = 0\n            excess -= weight_lst[i]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.2354430486725304,
            5.821518748998642
        ],
        "raw_score": [
            49.083212030353714,
            49.17956062632942
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high dominance rank and objective diversity\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = int(len(archive) * 0.3)  # Select from top 30% to balance exploration\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Phase 1: Probabilistic item removal/addition\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Remove item with probability based on marginal contribution\n            marginal1 = current_value1 - value1_lst[i]\n            marginal2 = current_value2 - value2_lst[i]\n            prob_remove = 0.5 * (1 - (marginal1 / (np.sum(value1_lst) + 1e-8) + marginal2 / (np.sum(value2_lst) + 1e-8)))\n            if np.random.random() < prob_remove and current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                current_value1 -= value1_lst[i]\n                current_value2 -= value2_lst[i]\n        else:\n            # Add item with probability based on potential contribution\n            if current_weight + weight_lst[i] <= capacity:\n                potential1 = current_value1 + value1_lst[i]\n                potential2 = current_value2 + value2_lst[i]\n                prob_add = 0.5 * (potential1 / (np.sum(value1_lst) + 1e-8) + potential2 / (np.sum(value2_lst) + 1e-8))\n                if np.random.random() < prob_add:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    current_value1 += value1_lst[i]\n                    current_value2 += value2_lst[i]\n\n    # Phase 2: Targeted item swapping\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Select best candidate to remove\n        remove_candidates = sorted(in_solution, key=lambda x: -(value1_lst[x] + value2_lst[x]))[:3]\n        # Select best candidate to add\n        add_candidates = sorted(out_solution, key=lambda x: (value1_lst[x] + value2_lst[x]))[-3:]\n\n        for i in remove_candidates:\n            for j in add_candidates:\n                if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    break\n\n    # Phase 3: Dynamic feasibility adjustment\n    if current_weight > capacity:\n        # Remove items until feasible\n        excess = current_weight - capacity\n        items_sorted = sorted(np.where(new_solution == 1)[0], key=lambda x: weight_lst[x])\n        for i in items_sorted:\n            if excess <= 0:\n                break\n            new_solution[i] = 0\n            excess -= weight_lst[i]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        None\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Identify promising items to consider\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 3 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-3:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Perform targeted swapping with items in solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Select two items to swap based on their contribution to both objectives\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Perform random flip with probability based on current solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 12,
        "algorithm": "The algorithm selects a balanced solution from the archive (prioritizing those with high combined objective product) and applies a hybrid local search combining weighted item addition, adaptive swapping, and probabilistic flipping, while dynamically adjusting weights based on solution quality and ensuring feasibility through capacity checks. It emphasizes objective-aware selection (using weighted value metrics) and diversity maintenance (through probabilistic flips), creating a balance between exploration and exploitation. The key design focuses on adaptive weights, combined value metrics, and solution quality-aware operations to improve multi-objective performance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8522696808180721,
            0.22630241513252258
        ],
        "raw_score": [
            27.121475374476667,
            27.863057367568054
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        None\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Identify promising items to consider\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 3 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-3:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Perform targeted swapping with items in solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Select two items to swap based on their contribution to both objectives\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Perform random flip with probability based on current solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 12,
        "algorithm": "The algorithm selects a balanced solution from the archive (prioritizing those with high combined objective product) and applies a hybrid local search combining weighted item addition, adaptive swapping, and probabilistic flipping, while dynamically adjusting weights based on solution quality and ensuring feasibility through capacity checks. It emphasizes objective-aware selection (using weighted value metrics) and diversity maintenance (through probabilistic flips), creating a balance between exploration and exploitation. The key design focuses on adaptive weights, combined value metrics, and solution quality-aware operations to improve multi-objective performance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8522696808180721,
            0.22630241513252258
        ],
        "raw_score": [
            27.121475374476667,
            27.863057367568054
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        None\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Identify promising items to consider\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 3 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-3:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Perform targeted swapping with items in solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Select two items to swap based on their contribution to both objectives\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Perform random flip with probability based on current solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 13,
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid of dominance ranking and crowding distance, then applies a novel local search operator that combines adaptive item selection with probabilistic swaps and dynamic mutation to generate neighbors while ensuring feasibility. It prioritizes items with high combined efficiency scores (normalized by both objective values and weight) and uses probabilistic selection based on relative utility for swaps and mutations. The mutation rate adapts dynamically based on the solution's overall quality, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance ranking with crowding distance\n    archive.sort(key=lambda x: (x[1][0] + x[1][1], -np.linalg.norm(np.array(x[1]) - np.array([np.mean([v[0] for v in archive]), np.mean([v[1] for v in archive])]))))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current metrics\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate normalized objective weights\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    norm_value1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    norm_value2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Adaptive item selection: consider both value and weight efficiency\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined efficiency score\n        efficiency_scores = (norm_value1 * value1_lst[potential_items] + norm_value2 * value2_lst[potential_items]) / (weight_lst[potential_items] + 1e-6)\n        top_items = potential_items[np.argsort(efficiency_scores)[-2:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Probabilistic swap with adaptive temperature\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate swap probabilities based on relative utility\n        swap_utils = norm_value1 * value1_lst[in_solution] + norm_value2 * value2_lst[in_solution]\n        swap_probs = np.exp(swap_utils / (np.sum(swap_utils) + 1e-6))\n        swap_probs = swap_probs / np.sum(swap_probs)\n\n        # Select two items to swap\n        idx1, idx2 = np.random.choice(in_solution, size=2, p=swap_probs, replace=False)\n        temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n        if temp_weight <= capacity:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Dynamic mutation rate based on solution quality\n    mutation_rate = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < mutation_rate and len(new_solution) > 0:\n        # Select mutation candidates based on both value and weight\n        mutation_scores = (norm_value1 * value1_lst + norm_value2 * value2_lst) / (weight_lst + 1e-6)\n        mutation_probs = np.exp(mutation_scores / (np.sum(mutation_scores) + 1e-6))\n        mutation_probs = mutation_probs / np.sum(mutation_probs)\n\n        mutation_idx = np.random.choice(len(new_solution), p=mutation_probs)\n        if new_solution[mutation_idx] == 1:\n            if current_weight - weight_lst[mutation_idx] <= capacity:\n                new_solution[mutation_idx] = 0\n        else:\n            if current_weight + weight_lst[mutation_idx] <= capacity:\n                new_solution[mutation_idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8533480310861542,
            1.2029791176319122
        ],
        "raw_score": [
            27.01697369534874,
            27.770754145074644
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance ranking with crowding distance\n    archive.sort(key=lambda x: (x[1][0] + x[1][1], -np.linalg.norm(np.array(x[1]) - np.array([np.mean([v[0] for v in archive]), np.mean([v[1] for v in archive])]))))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current metrics\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate normalized objective weights\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    norm_value1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    norm_value2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Adaptive item selection: consider both value and weight efficiency\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined efficiency score\n        efficiency_scores = (norm_value1 * value1_lst[potential_items] + norm_value2 * value2_lst[potential_items]) / (weight_lst[potential_items] + 1e-6)\n        top_items = potential_items[np.argsort(efficiency_scores)[-2:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Probabilistic swap with adaptive temperature\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate swap probabilities based on relative utility\n        swap_utils = norm_value1 * value1_lst[in_solution] + norm_value2 * value2_lst[in_solution]\n        swap_probs = np.exp(swap_utils / (np.sum(swap_utils) + 1e-6))\n        swap_probs = swap_probs / np.sum(swap_probs)\n\n        # Select two items to swap\n        idx1, idx2 = np.random.choice(in_solution, size=2, p=swap_probs, replace=False)\n        temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n        if temp_weight <= capacity:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Dynamic mutation rate based on solution quality\n    mutation_rate = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < mutation_rate and len(new_solution) > 0:\n        # Select mutation candidates based on both value and weight\n        mutation_scores = (norm_value1 * value1_lst + norm_value2 * value2_lst) / (weight_lst + 1e-6)\n        mutation_probs = np.exp(mutation_scores / (np.sum(mutation_scores) + 1e-6))\n        mutation_probs = mutation_probs / np.sum(mutation_probs)\n\n        mutation_idx = np.random.choice(len(new_solution), p=mutation_probs)\n        if new_solution[mutation_idx] == 1:\n            if current_weight - weight_lst[mutation_idx] <= capacity:\n                new_solution[mutation_idx] = 0\n        else:\n            if current_weight + weight_lst[mutation_idx] <= capacity:\n                new_solution[mutation_idx] = 1\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Identify promising items to consider\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 3 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-3:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Perform targeted swapping with items in solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Select two items to swap based on their contribution to both objectives\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Perform random flip with probability based on current solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            \n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 14,
        "algorithm": "The heuristic selects a balanced solution from the archive, then applies a hybrid local search combining targeted swaps (prioritizing high-value items), probabilistic flips, feasibility checks, and greedy additions of valuable items. It dynamically adjusts weights based on current solution quality and ensures feasibility through intelligent item removals and additions. The approach balances exploration and exploitation while maintaining Pareto optimality potential.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Targeted swapping based on adaptive weights\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                current_weight = temp_weight\n\n    # Step 2: Random flip with probability based on solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and n_items > 0:\n        flip_idx = np.random.choice(n_items)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Step 3: Ensure feasibility by removing the least valuable items if needed\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    # Step 4: Add the most valuable available items if there's remaining capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        add_idx = available_items[np.argmax(weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8073380266351767,
            0.2613680064678192
        ],
        "raw_score": [
            27.274817832427832,
            28.08075458475086
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Targeted swapping based on adaptive weights\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                current_weight = temp_weight\n\n    # Step 2: Random flip with probability based on solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and n_items > 0:\n        flip_idx = np.random.choice(n_items)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Step 3: Ensure feasibility by removing the least valuable items if needed\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    # Step 4: Add the most valuable available items if there's remaining capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        add_idx = available_items[np.argmax(weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 2 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Identify promising items to consider\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 3 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-3:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Perform targeted swapping with items in solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Select two items to swap based on their contribution to both objectives\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Perform random flip with probability based on current solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### Ineffective Self-Reflection\n- **Keywords**: Over-reliance on rigid heuristics, lack of dynamic adaptation, static selection criteria, excessive randomness.\n- **Advice**: Prioritize adaptive weights, balance exploration/exploitation, avoid arbitrary flips, and ensure feasibility checks are non-negotiable.\n- **Avoid**: Generic swaps, blind randomness, fixed probabilities, and ignoring solution quality in selection.\n- **Explanation**: Static methods fail to navigate Pareto fronts efficiently. Dynamic trade-offs and structured randomness are critical for high-quality neighbors.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 15,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high Pareto front potential using adaptive weighting\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Phase 1: Structured item addition based on weighted value\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 2 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-2:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Phase 2: Targeted item replacement based on marginal utility\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate marginal utility of each item\n        marginal_utils = []\n        for item in in_solution:\n            temp_sol = new_solution.copy()\n            temp_sol[item] = 0\n            temp_weight = np.sum(weight_lst * temp_sol)\n            if temp_weight <= capacity:\n                # Calculate potential improvement if we remove this item\n                potential_items = np.where(temp_sol == 0)[0]\n                if len(potential_items) > 0:\n                    weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n                    best_candidate = potential_items[np.argmax(weighted_values)]\n                    if temp_weight + weight_lst[best_candidate] <= capacity:\n                        marginal_util = (value1_lst[best_candidate] + value2_lst[best_candidate]) - (value1_lst[item] + value2_lst[item])\n                        marginal_utils.append((item, marginal_util))\n                    else:\n                        marginal_utils.append((item, 0))\n                else:\n                    marginal_utils.append((item, 0))\n            else:\n                marginal_utils.append((item, 0))\n\n        # Remove item with highest positive marginal utility\n        if marginal_utils:\n            best_item, best_util = max(marginal_utils, key=lambda x: x[1])\n            if best_util > 0:\n                new_solution[best_item] = 0\n                current_weight = np.sum(weight_lst * new_solution)\n                # Add the best candidate item\n                potential_items = np.where(new_solution == 0)[0]\n                if len(potential_items) > 0:\n                    weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n                    best_candidate = potential_items[np.argmax(weighted_values)]\n                    if current_weight + weight_lst[best_candidate] <= capacity:\n                        new_solution[best_candidate] = 1\n\n    # Phase 3: Controlled randomness with quality-based probability\n    flip_prob = 0.2 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.4\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select item based on its marginal utility\n        in_solution = np.where(new_solution == 1)[0]\n        out_solution = np.where(new_solution == 0)[0]\n\n        if len(in_solution) > 0 and len(out_solution) > 0:\n            # Calculate marginal utility for removal\n            remove_utils = []\n            for item in in_solution:\n                temp_sol = new_solution.copy()\n                temp_sol[item] = 0\n                temp_weight = np.sum(weight_lst * temp_sol)\n                if temp_weight <= capacity:\n                    potential_items = np.where(temp_sol == 0)[0]\n                    if len(potential_items) > 0:\n                        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n                        best_candidate = potential_items[np.argmax(weighted_values)]\n                        if temp_weight + weight_lst[best_candidate] <= capacity:\n                            marginal_util = (value1_lst[best_candidate] + value2_lst[best_candidate]) - (value1_lst[item] + value2_lst[item])\n                            remove_utils.append((item, marginal_util))\n                        else:\n                            remove_utils.append((item, 0))\n                    else:\n                        remove_utils.append((item, 0))\n                else:\n                    remove_utils.append((item, 0))\n\n            if remove_utils:\n                # Select item with highest positive marginal utility for removal\n                best_remove, best_util = max(remove_utils, key=lambda x: x[1])\n                if best_util > 0:\n                    new_solution[best_remove] = 0\n                    current_weight = np.sum(weight_lst * new_solution)\n                    # Add the best candidate item\n                    potential_items = np.where(new_solution == 0)[0]\n                    if len(potential_items) > 0:\n                        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n                        best_candidate = potential_items[np.argmax(weighted_values)]\n                        if current_weight + weight_lst[best_candidate] <= capacity:\n                            new_solution[best_candidate] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6945480478781478,
            5.413287431001663
        ],
        "raw_score": [
            31.545589337522134,
            31.729615934250702
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high Pareto front potential using adaptive weighting\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Phase 1: Structured item addition based on weighted value\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 2 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-2:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Phase 2: Targeted item replacement based on marginal utility\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate marginal utility of each item\n        marginal_utils = []\n        for item in in_solution:\n            temp_sol = new_solution.copy()\n            temp_sol[item] = 0\n            temp_weight = np.sum(weight_lst * temp_sol)\n            if temp_weight <= capacity:\n                # Calculate potential improvement if we remove this item\n                potential_items = np.where(temp_sol == 0)[0]\n                if len(potential_items) > 0:\n                    weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n                    best_candidate = potential_items[np.argmax(weighted_values)]\n                    if temp_weight + weight_lst[best_candidate] <= capacity:\n                        marginal_util = (value1_lst[best_candidate] + value2_lst[best_candidate]) - (value1_lst[item] + value2_lst[item])\n                        marginal_utils.append((item, marginal_util))\n                    else:\n                        marginal_utils.append((item, 0))\n                else:\n                    marginal_utils.append((item, 0))\n            else:\n                marginal_utils.append((item, 0))\n\n        # Remove item with highest positive marginal utility\n        if marginal_utils:\n            best_item, best_util = max(marginal_utils, key=lambda x: x[1])\n            if best_util > 0:\n                new_solution[best_item] = 0\n                current_weight = np.sum(weight_lst * new_solution)\n                # Add the best candidate item\n                potential_items = np.where(new_solution == 0)[0]\n                if len(potential_items) > 0:\n                    weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n                    best_candidate = potential_items[np.argmax(weighted_values)]\n                    if current_weight + weight_lst[best_candidate] <= capacity:\n                        new_solution[best_candidate] = 1\n\n    # Phase 3: Controlled randomness with quality-based probability\n    flip_prob = 0.2 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.4\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select item based on its marginal utility\n        in_solution = np.where(new_solution == 1)[0]\n        out_solution = np.where(new_solution == 0)[0]\n\n        if len(in_solution) > 0 and len(out_solution) > 0:\n            # Calculate marginal utility for removal\n            remove_utils = []\n            for item in in_solution:\n                temp_sol = new_solution.copy()\n                temp_sol[item] = 0\n                temp_weight = np.sum(weight_lst * temp_sol)\n                if temp_weight <= capacity:\n                    potential_items = np.where(temp_sol == 0)[0]\n                    if len(potential_items) > 0:\n                        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n                        best_candidate = potential_items[np.argmax(weighted_values)]\n                        if temp_weight + weight_lst[best_candidate] <= capacity:\n                            marginal_util = (value1_lst[best_candidate] + value2_lst[best_candidate]) - (value1_lst[item] + value2_lst[item])\n                            remove_utils.append((item, marginal_util))\n                        else:\n                            remove_utils.append((item, 0))\n                    else:\n                        remove_utils.append((item, 0))\n                else:\n                    remove_utils.append((item, 0))\n\n            if remove_utils:\n                # Select item with highest positive marginal utility for removal\n                best_remove, best_util = max(remove_utils, key=lambda x: x[1])\n                if best_util > 0:\n                    new_solution[best_remove] = 0\n                    current_weight = np.sum(weight_lst * new_solution)\n                    # Add the best candidate item\n                    potential_items = np.where(new_solution == 0)[0]\n                    if len(potential_items) > 0:\n                        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n                        best_candidate = potential_items[np.argmax(weighted_values)]\n                        if current_weight + weight_lst[best_candidate] <= capacity:\n                            new_solution[best_candidate] = 1\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives using a novelty-aware selection\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting with novelty factor\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) * (1 - (current_value1 / total_value1)) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) * (1 - (current_value2 / total_value2)) if total_value2 > 0 else 0.5\n\n    # Novelty-driven item selection: prioritize items that create \"novel\" value combinations\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate novelty scores based on value ratios and current solution's coverage\n        novelty_scores = []\n        for item in potential_items:\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            novelty = abs(ratio1 - ratio2) * (1 - min(ratio1, ratio2))\n            novelty_scores.append(novelty)\n\n        # Select top items with highest novelty and feasible addition\n        novelty_scores = np.array(novelty_scores)\n        top_items = potential_items[np.argsort(novelty_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Context-aware swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        if len(worst_items) == 2:\n            idx1, idx2 = worst_items\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Dynamic exploration: probabilistic flip with novelty-based probability\n    flip_prob = 0.2 + 0.6 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Ineffective Self-Reflection\n- **Keywords**: Over-reliance on rigid heuristics, lack of dynamic adaptation, static selection criteria, excessive randomness.\n- **Advice**: Prioritize adaptive weights, balance exploration/exploitation, avoid arbitrary flips, and ensure feasibility checks are non-negotiable.\n- **Avoid**: Generic swaps, blind randomness, fixed probabilities, and ignoring solution quality in selection.\n- **Explanation**: Static methods fail to navigate Pareto fronts efficiently. Dynamic trade-offs and structured randomness are critical for high-quality neighbors.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 16,
        "algorithm": "The algorithm employs a hybrid selection strategy that prioritizes solutions with high value diversity, combining dynamic objective weighting with a multi-stage local search that includes value-driven item insertion, adaptive swapping, and probabilistic flipping to balance exploration and exploitation while ensuring feasibility. It dynamically adjusts flip probabilities based on the solution's Pareto dominance and focuses on improving value trade-offs through weighted value ratios and complementary item selections.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: prioritize solutions with high value diversity and potential for improvement\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 4, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item selection: prioritize items that create balanced value improvements\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-2:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:1]]\n        if len(worst_items) > 0:\n            idx = worst_items[0]\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n\n    # Dynamic exploration: probabilistic flip with value-aware probability\n    flip_prob = 0.1 + 0.4 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high value potential for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8988171251681039,
            0.5861128270626068
        ],
        "raw_score": [
            27.56373170955588,
            27.846930117034944
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: prioritize solutions with high value diversity and potential for improvement\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 4, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item selection: prioritize items that create balanced value improvements\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-2:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:1]]\n        if len(worst_items) > 0:\n            idx = worst_items[0]\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n\n    # Dynamic exploration: probabilistic flip with value-aware probability\n    flip_prob = 0.1 + 0.4 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high value potential for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe heuristic selects a balanced solution from the archive, then applies a hybrid local search combining targeted swaps (prioritizing high-value items), probabilistic flips, feasibility checks, and greedy additions of valuable items. It dynamically adjusts weights based on current solution quality and ensures feasibility through intelligent item removals and additions. The approach balances exploration and exploitation while maintaining Pareto optimality potential.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Targeted swapping based on adaptive weights\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                current_weight = temp_weight\n\n    # Step 2: Random flip with probability based on solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and n_items > 0:\n        flip_idx = np.random.choice(n_items)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Step 3: Ensure feasibility by removing the least valuable items if needed\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    # Step 4: Add the most valuable available items if there's remaining capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        add_idx = available_items[np.argmax(weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Ineffective Self-Reflection\n- **Keywords**: Over-reliance on rigid heuristics, lack of dynamic adaptation, static selection criteria, excessive randomness.\n- **Advice**: Prioritize adaptive weights, balance exploration/exploitation, avoid arbitrary flips, and ensure feasibility checks are non-negotiable.\n- **Avoid**: Generic swaps, blind randomness, fixed probabilities, and ignoring solution quality in selection.\n- **Explanation**: Static methods fail to navigate Pareto fronts efficiently. Dynamic trade-offs and structured randomness are critical for high-quality neighbors.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 17,
        "algorithm": "The algorithm combines adaptive multi-objective selection with a tiered local search that prioritizes high-impact swaps between complementary items, followed by probabilistic flips based on item contribution potential, and finally ensures feasibility through targeted removals/additions. It dynamically balances exploration and exploitation by weighting operations based on the current solution's trade-off profile, with a strong emphasis on maintaining solution quality through normalized objective diversity and weighted value calculations. The tiered approach ensures systematic improvement while preserving feasibility at every step.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate normalized objectives and diversity scores\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    normalized_solutions = []\n    for sol, obj in archive:\n        if np.sum(weight_lst * sol) > capacity:\n            continue\n        norm_obj1 = obj[0] / total_value1 if total_value1 > 0 else 0\n        norm_obj2 = obj[1] / total_value2 if total_value2 > 0 else 0\n        diversity = abs(norm_obj1 - norm_obj2)\n        normalized_solutions.append((sol, (norm_obj1, norm_obj2), diversity))\n\n    if not normalized_solutions:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest diversity (most balanced trade-off)\n    selected = max(normalized_solutions, key=lambda x: x[2])\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive weights based on current solution's trade-off\n    weight1 = current_value1 / (current_value1 + current_value2 + 1e-8)\n    weight2 = current_value2 / (current_value1 + current_value2 + 1e-8)\n\n    # Tiered local search\n    n_items = len(weight_lst)\n\n    # Phase 1: High-impact swaps between items with complementary trade-offs\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        # Sort by trade-off alignment with current solution's profile\n        tradeoff_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on how well this item's trade-off complements current solution's profile\n            score = (weight1 * val2 + weight2 * val1) / (val1 + val2 + 1e-8)\n            tradeoff_scores.append((i, score))\n\n        # Select top 2 items with most complementary trade-offs\n        tradeoff_scores.sort(key=lambda x: -x[1])\n        if len(tradeoff_scores) >= 2:\n            i1, i2 = tradeoff_scores[0][0], tradeoff_scores[1][0]\n            # Check if swap is feasible\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n                current_weight = current_weight - weight_lst[i1] + weight_lst[i2]\n\n    # Phase 2: Probabilistic flips based on item's potential contribution\n    if n_items > 0 and np.random.random() < 0.5:\n        # Calculate potential contribution scores for all items\n        potential_scores = []\n        for i in range(n_items):\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if new_solution[i] == 1:\n                # For included items, score is based on how much we might gain by removing\n                score = (weight1 * val1 + weight2 * val2) * (1 - (current_weight - weight_lst[i]) / capacity)\n            else:\n                # For excluded items, score is based on how much we might gain by adding\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                score = (weight1 * val1 + weight2 * val2) * (current_weight + weight_lst[i]) / capacity\n\n            potential_scores.append((i, score))\n\n        if potential_scores:\n            # Select item with highest potential score\n            selected_item = max(potential_scores, key=lambda x: x[1])[0]\n            if new_solution[selected_item] == 1 and current_weight - weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 0\n                current_weight -= weight_lst[selected_item]\n            elif new_solution[selected_item] == 0 and current_weight + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    # Phase 3: Feasibility preservation with targeted removals/additions\n    # Remove least valuable items first if over capacity\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Find item with lowest weighted value\n        weighted_values = weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]\n        remove_idx = in_items[np.argmin(weighted_values)]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    # Add most valuable items until no more capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        # Find item with highest weighted value\n        weighted_values = weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items]\n        add_idx = available_items[np.argmax(weighted_values)]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7091958859231042,
            7.8499915599823
        ],
        "raw_score": [
            29.208498217727623,
            28.25067809019321
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate normalized objectives and diversity scores\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    normalized_solutions = []\n    for sol, obj in archive:\n        if np.sum(weight_lst * sol) > capacity:\n            continue\n        norm_obj1 = obj[0] / total_value1 if total_value1 > 0 else 0\n        norm_obj2 = obj[1] / total_value2 if total_value2 > 0 else 0\n        diversity = abs(norm_obj1 - norm_obj2)\n        normalized_solutions.append((sol, (norm_obj1, norm_obj2), diversity))\n\n    if not normalized_solutions:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest diversity (most balanced trade-off)\n    selected = max(normalized_solutions, key=lambda x: x[2])\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive weights based on current solution's trade-off\n    weight1 = current_value1 / (current_value1 + current_value2 + 1e-8)\n    weight2 = current_value2 / (current_value1 + current_value2 + 1e-8)\n\n    # Tiered local search\n    n_items = len(weight_lst)\n\n    # Phase 1: High-impact swaps between items with complementary trade-offs\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        # Sort by trade-off alignment with current solution's profile\n        tradeoff_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on how well this item's trade-off complements current solution's profile\n            score = (weight1 * val2 + weight2 * val1) / (val1 + val2 + 1e-8)\n            tradeoff_scores.append((i, score))\n\n        # Select top 2 items with most complementary trade-offs\n        tradeoff_scores.sort(key=lambda x: -x[1])\n        if len(tradeoff_scores) >= 2:\n            i1, i2 = tradeoff_scores[0][0], tradeoff_scores[1][0]\n            # Check if swap is feasible\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n                current_weight = current_weight - weight_lst[i1] + weight_lst[i2]\n\n    # Phase 2: Probabilistic flips based on item's potential contribution\n    if n_items > 0 and np.random.random() < 0.5:\n        # Calculate potential contribution scores for all items\n        potential_scores = []\n        for i in range(n_items):\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if new_solution[i] == 1:\n                # For included items, score is based on how much we might gain by removing\n                score = (weight1 * val1 + weight2 * val2) * (1 - (current_weight - weight_lst[i]) / capacity)\n            else:\n                # For excluded items, score is based on how much we might gain by adding\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                score = (weight1 * val1 + weight2 * val2) * (current_weight + weight_lst[i]) / capacity\n\n            potential_scores.append((i, score))\n\n        if potential_scores:\n            # Select item with highest potential score\n            selected_item = max(potential_scores, key=lambda x: x[1])[0]\n            if new_solution[selected_item] == 1 and current_weight - weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 0\n                current_weight -= weight_lst[selected_item]\n            elif new_solution[selected_item] == 0 and current_weight + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    # Phase 3: Feasibility preservation with targeted removals/additions\n    # Remove least valuable items first if over capacity\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Find item with lowest weighted value\n        weighted_values = weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]\n        remove_idx = in_items[np.argmin(weighted_values)]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    # Add most valuable items until no more capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        # Find item with highest weighted value\n        weighted_values = weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items]\n        add_idx = available_items[np.argmax(weighted_values)]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 18,
        "algorithm": "The algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9296926897978155,
            0.3622717261314392
        ],
        "raw_score": [
            27.831550612136972,
            28.052400795200953
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 18,
        "algorithm": "The algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9296926897978155,
            0.3622717261314392
        ],
        "raw_score": [
            27.831550612136972,
            28.052400795200953
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 19,
        "algorithm": "The algorithm selects a promising solution from the archive based on normalized objective values, then applies a hybrid local search combining probabilistic item removal (for low-value items), strategic addition of high-value-density items, random swaps between items, and occasional random flips to explore the solution space while ensuring feasibility. The selection prioritizes solutions with higher combined normalized objectives, and the local search balances exploitation (high-value additions) with exploration (random operations) to generate diverse high-quality neighbors.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Probabilistic removal of low-value items\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        for idx in candidates:\n            if random.random() < 0.5 and total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n\n    # Strategic addition of high-value items\n    candidates = np.where(new_solution == 0)[0]\n    if len(candidates) > 0:\n        # Sort by value density (value1 + value2) / weight\n        value_density = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(value_density)[::-1]\n        for idx in sorted_indices:\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.2566695503967128,
            0.40656906366348267
        ],
        "raw_score": [
            48.990416380591356,
            48.38358173879731
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Probabilistic removal of low-value items\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        for idx in candidates:\n            if random.random() < 0.5 and total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n\n    # Strategic addition of high-value items\n    candidates = np.where(new_solution == 0)[0]\n    if len(candidates) > 0:\n        # Sort by value density (value1 + value2) / weight\n        value_density = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(value_density)[::-1]\n        for idx in sorted_indices:\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives using a novelty-aware selection\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting with novelty factor\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) * (1 - (current_value1 / total_value1)) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) * (1 - (current_value2 / total_value2)) if total_value2 > 0 else 0.5\n\n    # Novelty-driven item selection: prioritize items that create \"novel\" value combinations\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate novelty scores based on value ratios and current solution's coverage\n        novelty_scores = []\n        for item in potential_items:\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            novelty = abs(ratio1 - ratio2) * (1 - min(ratio1, ratio2))\n            novelty_scores.append(novelty)\n\n        # Select top items with highest novelty and feasible addition\n        novelty_scores = np.array(novelty_scores)\n        top_items = potential_items[np.argsort(novelty_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Context-aware swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        if len(worst_items) == 2:\n            idx1, idx2 = worst_items\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Dynamic exploration: probabilistic flip with novelty-based probability\n    flip_prob = 0.2 + 0.6 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a balanced solution from the archive (prioritizing those with high combined objective product) and applies a hybrid local search combining weighted item addition, adaptive swapping, and probabilistic flipping, while dynamically adjusting weights based on solution quality and ensuring feasibility through capacity checks. It emphasizes objective-aware selection (using weighted value metrics) and diversity maintenance (through probabilistic flips), creating a balance between exploration and exploitation. The key design focuses on adaptive weights, combined value metrics, and solution quality-aware operations to improve multi-objective performance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### Keywords:\n- **Dynamic trade-offs**, **adaptive weights**, **structured randomness**, **feasibility-aware selection**, **Pareto-front navigation**.\n\n### Advice:\n1. **Prioritize adaptive weights** to balance multi-objective exploration/exploitation.\n2. **Use novelty-aware selection** (e.g., context-based swaps) to avoid local optima.\n3. **Ensure feasibility checks** in every local search step.\n4. **Combine targeted operations** (e.g., probabilistic flips) with hybrid approaches.\n\n### Avoid:\n- **Static selection criteria**, **blind randomness**, **fixed probabilities**, **generic swaps**, **ignoring Pareto dominance**.\n\n### Explanation:\nDynamic weighting and novelty-aware selection enable efficient Pareto-front navigation, while feasibility checks and hybrid operations ensure high-quality neighbors. Avoid static methods to prevent premature convergence.\n\n---\n**Step-by-Step Design**:\n1. **Select a solution** from the archive using adaptive weights (e.g., weighted sum of normalized objectives).\n2. **Identify critical items** (e.g., those with high marginal gains in either objective).\n3. **Apply a hybrid local search**:\n   - **Novelty-driven swap**: Replace a low-marginal item with a high-marginal item from the archive.\n   - **Probabilistic flip**: Randomly flip items with a bias toward improving underrepresented objectives.\n4. **Ensure feasibility** by rejecting any swap/flip that violates capacity.\n\nThis balances exploration (novelty) and exploitation (adaptive weights) while guaranteeing feasibility.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 20,
        "algorithm": "The algorithm selects a promising solution from the archive using dynamic objective weighting, then applies a hybrid local search that removes the least novel item (based on value ratio balance) and adds the most valuable item (weighted by current objective priorities) while ensuring feasibility. It also includes probabilistic flipping of items with high potential improvement, prioritizing objectives that are currently underrepresented.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution using dynamic objective weighting to prioritize underrepresented objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -(x[1][0] / total_value1 + x[1][1] / total_value2))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: novelty-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate novelty scores for items in solution\n        novelty_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            novelty_scores.append(abs(ratio1 - ratio2))\n\n        # Select least novel item for potential removal\n        least_novel_idx = in_solution[np.argmin(novelty_scores)]\n\n        # Calculate potential additions with weighted value metric\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        best_add_idx = potential_items[np.argmax(combined_values)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[least_novel_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[least_novel_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with objective-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7727567325316299,
            0.3280051350593567
        ],
        "raw_score": [
            27.405380829461773,
            28.118865103772286
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution using dynamic objective weighting to prioritize underrepresented objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -(x[1][0] / total_value1 + x[1][1] / total_value2))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: novelty-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate novelty scores for items in solution\n        novelty_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            novelty_scores.append(abs(ratio1 - ratio2))\n\n        # Select least novel item for potential removal\n        least_novel_idx = in_solution[np.argmin(novelty_scores)]\n\n        # Calculate potential additions with weighted value metric\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        best_add_idx = potential_items[np.argmax(combined_values)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[least_novel_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[least_novel_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with objective-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects the most promising solution from the archive based on a weighted value metric balancing both objectives (60% value1, 40% value2) and capacity utilization, then applies a hybrid local search that first adds high-value-density items and occasionally removes low-value-density items to create a feasible neighbor solution. It prioritizes items with higher combined value-to-weight ratios while ensuring feasibility through targeted removals when necessary.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate weighted value metric for each solution\n    def weighted_value(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        # Weighted value metric combining both objectives and capacity utilization\n        return (0.6 * value1 + 0.4 * value2) * (1 - (total_weight / capacity))\n\n    # Select solution with highest weighted value\n    selected_sol, _ = max(archive, key=lambda x: weighted_value(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search operator\n    # Step 1: Replace low-value items with high-value alternatives\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Calculate value density (value per weight) for all items\n    value_density = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-value_density)  # Highest density first\n\n    # Try to add high-value items that fit\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and weight_lst[idx] <= available_weight:\n            new_solution[idx] = 1\n            available_weight -= weight_lst[idx]\n\n    # Step 2: Randomly perturb by removing items with low value density\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        low_density_items = np.where(new_solution == 1)[0]\n        if len(low_density_items) > 0:\n            # Remove items with lowest value density\n            low_density_items_sorted = sorted(low_density_items, key=lambda x: value_density[x])\n            for idx in low_density_items_sorted[:max(1, len(low_density_items)//3)]:\n                new_solution[idx] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        while total_weight > capacity:\n            # Find the item with lowest value density in the solution\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmin(value_density[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords:\n- **Dynamic trade-offs**, **adaptive weights**, **structured randomness**, **feasibility-aware selection**, **Pareto-front navigation**.\n\n### Advice:\n1. **Prioritize adaptive weights** to balance multi-objective exploration/exploitation.\n2. **Use novelty-aware selection** (e.g., context-based swaps) to avoid local optima.\n3. **Ensure feasibility checks** in every local search step.\n4. **Combine targeted operations** (e.g., probabilistic flips) with hybrid approaches.\n\n### Avoid:\n- **Static selection criteria**, **blind randomness**, **fixed probabilities**, **generic swaps**, **ignoring Pareto dominance**.\n\n### Explanation:\nDynamic weighting and novelty-aware selection enable efficient Pareto-front navigation, while feasibility checks and hybrid operations ensure high-quality neighbors. Avoid static methods to prevent premature convergence.\n\n---\n**Step-by-Step Design**:\n1. **Select a solution** from the archive using adaptive weights (e.g., weighted sum of normalized objectives).\n2. **Identify critical items** (e.g., those with high marginal gains in either objective).\n3. **Apply a hybrid local search**:\n   - **Novelty-driven swap**: Replace a low-marginal item with a high-marginal item from the archive.\n   - **Probabilistic flip**: Randomly flip items with a bias toward improving underrepresented objectives.\n4. **Ensure feasibility** by rejecting any swap/flip that violates capacity.\n\nThis balances exploration (novelty) and exploitation (adaptive weights) while guaranteeing feasibility.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 21,
        "algorithm": "The algorithm dynamically selects a solution from the archive by balancing objectives based on archive diversity, then applies a hybrid local search that combines probabilistic item flips biased toward high-marginal-gain items and targeted swaps of low-marginal items with high-marginal items, while ensuring feasibility through adaptive weight adjustments and marginal gain checks. The selection prioritizes solutions with higher normalized objective values, while the local search emphasizes items with combined marginal gains for both objectives, maintaining feasibility by removing low-marginal items when necessary.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest weighted value, dynamically adjusting weights based on archive diversity\n    max_value1 = max(obj[0] for _, obj in archive)\n    max_value2 = max(obj[1] for _, obj in archive)\n    if max_value1 == 0 or max_value2 == 0:\n        selected_sol, _ = archive[np.random.choice(len(archive))]\n    else:\n        # Normalize and dynamically weight objectives based on archive diversity\n        diversity_weight1 = 0.5 + 0.5 * (max_value2 / (max_value1 + max_value2))\n        diversity_weight2 = 1 - diversity_weight1\n        selected_sol, _ = max(archive, key=lambda x: (diversity_weight1 * (x[1][0] / max_value1) + diversity_weight2 * (x[1][1] / max_value2)))\n\n    new_solution = selected_sol.copy()\n    n_items = len(weight_lst)\n\n    if n_items < 2:\n        return new_solution\n\n    # Calculate marginal gains for each objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Hybrid local search with novelty-driven operations\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Step 1: Probabilistic flip biased toward objectives with marginal gains\n    flip_prob = np.zeros(n_items)\n    for i in range(n_items):\n        if new_solution[i] == 1:\n            flip_prob[i] = 0.3 * (1 - combined_gain[i] / np.max(combined_gain))\n        else:\n            flip_prob[i] = 0.7 * combined_gain[i] / np.max(combined_gain)\n    flip_prob = flip_prob / np.sum(flip_prob) if np.sum(flip_prob) > 0 else np.ones(n_items) / n_items\n    flip_idx = np.random.choice(n_items, p=flip_prob)\n    new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Ensure feasibility after flip\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest combined marginal gain until feasible\n        while total_weight > capacity:\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmin(combined_gain[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    # Step 2: Targeted swap of high-marginal items\n    if np.random.rand() < 0.5:  # 50% chance to perform swap\n        # Select a high-marginal item not in solution\n        candidate_items = np.where(new_solution == 0)[0]\n        if len(candidate_items) > 0:\n            high_marginal_items = candidate_items[np.argsort(-combined_gain[candidate_items])]\n            for idx in high_marginal_items:\n                if weight_lst[idx] <= available_weight:\n                    # Find a low-marginal item in solution to swap with\n                    in_solution = np.where(new_solution == 1)[0]\n                    if len(in_solution) > 0:\n                        low_marginal_items = in_solution[np.argsort(combined_gain[in_solution])]\n                        for swap_idx in low_marginal_items:\n                            if weight_lst[idx] - weight_lst[swap_idx] <= available_weight:\n                                new_solution[swap_idx] = 0\n                                new_solution[idx] = 1\n                                break\n                    break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.3641629117091274,
            1.439323514699936
        ],
        "raw_score": [
            49.48170136507639,
            48.197359790594795
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest weighted value, dynamically adjusting weights based on archive diversity\n    max_value1 = max(obj[0] for _, obj in archive)\n    max_value2 = max(obj[1] for _, obj in archive)\n    if max_value1 == 0 or max_value2 == 0:\n        selected_sol, _ = archive[np.random.choice(len(archive))]\n    else:\n        # Normalize and dynamically weight objectives based on archive diversity\n        diversity_weight1 = 0.5 + 0.5 * (max_value2 / (max_value1 + max_value2))\n        diversity_weight2 = 1 - diversity_weight1\n        selected_sol, _ = max(archive, key=lambda x: (diversity_weight1 * (x[1][0] / max_value1) + diversity_weight2 * (x[1][1] / max_value2)))\n\n    new_solution = selected_sol.copy()\n    n_items = len(weight_lst)\n\n    if n_items < 2:\n        return new_solution\n\n    # Calculate marginal gains for each objective\n    marginal_gain1 = value1_lst / weight_lst\n    marginal_gain2 = value2_lst / weight_lst\n    combined_gain = marginal_gain1 + marginal_gain2\n\n    # Hybrid local search with novelty-driven operations\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Step 1: Probabilistic flip biased toward objectives with marginal gains\n    flip_prob = np.zeros(n_items)\n    for i in range(n_items):\n        if new_solution[i] == 1:\n            flip_prob[i] = 0.3 * (1 - combined_gain[i] / np.max(combined_gain))\n        else:\n            flip_prob[i] = 0.7 * combined_gain[i] / np.max(combined_gain)\n    flip_prob = flip_prob / np.sum(flip_prob) if np.sum(flip_prob) > 0 else np.ones(n_items) / n_items\n    flip_idx = np.random.choice(n_items, p=flip_prob)\n    new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n    # Ensure feasibility after flip\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest combined marginal gain until feasible\n        while total_weight > capacity:\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmin(combined_gain[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    # Step 2: Targeted swap of high-marginal items\n    if np.random.rand() < 0.5:  # 50% chance to perform swap\n        # Select a high-marginal item not in solution\n        candidate_items = np.where(new_solution == 0)[0]\n        if len(candidate_items) > 0:\n            high_marginal_items = candidate_items[np.argsort(-combined_gain[candidate_items])]\n            for idx in high_marginal_items:\n                if weight_lst[idx] <= available_weight:\n                    # Find a low-marginal item in solution to swap with\n                    in_solution = np.where(new_solution == 1)[0]\n                    if len(in_solution) > 0:\n                        low_marginal_items = in_solution[np.argsort(combined_gain[in_solution])]\n                        for swap_idx in low_marginal_items:\n                            if weight_lst[idx] - weight_lst[swap_idx] <= available_weight:\n                                new_solution[swap_idx] = 0\n                                new_solution[idx] = 1\n                                break\n                    break\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive based on normalized objective values, then applies a hybrid local search combining probabilistic item removal (for low-value items), strategic addition of high-value-density items, random swaps between items, and occasional random flips to explore the solution space while ensuring feasibility. The selection prioritizes solutions with higher combined normalized objectives, and the local search balances exploitation (high-value additions) with exploration (random operations) to generate diverse high-quality neighbors.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Probabilistic removal of low-value items\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        for idx in candidates:\n            if random.random() < 0.5 and total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                total_weight -= weight_lst[idx]\n\n    # Strategic addition of high-value items\n    candidates = np.where(new_solution == 0)[0]\n    if len(candidates) > 0:\n        # Sort by value density (value1 + value2) / weight\n        value_density = (value1_lst + value2_lst) / weight_lst\n        sorted_indices = np.argsort(value_density)[::-1]\n        for idx in sorted_indices:\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                total_weight += weight_lst[idx]\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects the most promising solution from the archive based on a weighted value metric balancing both objectives (60% value1, 40% value2) and capacity utilization, then applies a hybrid local search that first adds high-value-density items and occasionally removes low-value-density items to create a feasible neighbor solution. It prioritizes items with higher combined value-to-weight ratios while ensuring feasibility through targeted removals when necessary.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate weighted value metric for each solution\n    def weighted_value(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        # Weighted value metric combining both objectives and capacity utilization\n        return (0.6 * value1 + 0.4 * value2) * (1 - (total_weight / capacity))\n\n    # Select solution with highest weighted value\n    selected_sol, _ = max(archive, key=lambda x: weighted_value(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search operator\n    # Step 1: Replace low-value items with high-value alternatives\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Calculate value density (value per weight) for all items\n    value_density = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-value_density)  # Highest density first\n\n    # Try to add high-value items that fit\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and weight_lst[idx] <= available_weight:\n            new_solution[idx] = 1\n            available_weight -= weight_lst[idx]\n\n    # Step 2: Randomly perturb by removing items with low value density\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        low_density_items = np.where(new_solution == 1)[0]\n        if len(low_density_items) > 0:\n            # Remove items with lowest value density\n            low_density_items_sorted = sorted(low_density_items, key=lambda x: value_density[x])\n            for idx in low_density_items_sorted[:max(1, len(low_density_items)//3)]:\n                new_solution[idx] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        while total_weight > capacity:\n            # Find the item with lowest value density in the solution\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmin(value_density[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords:\n- **Dynamic trade-offs**, **adaptive weights**, **structured randomness**, **feasibility-aware selection**, **Pareto-front navigation**.\n\n### Advice:\n1. **Prioritize adaptive weights** to balance multi-objective exploration/exploitation.\n2. **Use novelty-aware selection** (e.g., context-based swaps) to avoid local optima.\n3. **Ensure feasibility checks** in every local search step.\n4. **Combine targeted operations** (e.g., probabilistic flips) with hybrid approaches.\n\n### Avoid:\n- **Static selection criteria**, **blind randomness**, **fixed probabilities**, **generic swaps**, **ignoring Pareto dominance**.\n\n### Explanation:\nDynamic weighting and novelty-aware selection enable efficient Pareto-front navigation, while feasibility checks and hybrid operations ensure high-quality neighbors. Avoid static methods to prevent premature convergence.\n\n---\n**Step-by-Step Design**:\n1. **Select a solution** from the archive using adaptive weights (e.g., weighted sum of normalized objectives).\n2. **Identify critical items** (e.g., those with high marginal gains in either objective).\n3. **Apply a hybrid local search**:\n   - **Novelty-driven swap**: Replace a low-marginal item with a high-marginal item from the archive.\n   - **Probabilistic flip**: Randomly flip items with a bias toward improving underrepresented objectives.\n4. **Ensure feasibility** by rejecting any swap/flip that violates capacity.\n\nThis balances exploration (novelty) and exploitation (adaptive weights) while guaranteeing feasibility.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 22,
        "algorithm": "The algorithm dynamically selects a promising solution from the archive by adaptively weighting based on objective dominance and capacity utilization, then applies a novelty-aware local search that strategically swaps low-marginal items with high-marginal candidates while probabilistically flipping items to balance underrepresented objectives, all while ensuring feasibility through marginal-gain-based adjustments. The selection prioritizes solutions with higher combined weighted values and capacity-efficient item combinations, while the local search focuses on improving marginal gains in both objectives with probabilistic bias toward balancing underrepresented dimensions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic weighting based on Pareto-front distribution\n    def dynamic_weight(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        # Weight adaptively based on objective dominance\n        weight1 = 0.5 + 0.5 * (value1 / (np.sum(value1_lst) + 1e-8))\n        weight2 = 0.5 + 0.5 * (value2 / (np.sum(value2_lst) + 1e-8))\n        return (weight1 * value1 + weight2 * value2) * (1 - (total_weight / capacity))\n\n    # Select solution with highest dynamic weight\n    selected_sol, _ = max(archive, key=lambda x: dynamic_weight(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Calculate marginal gains for each objective\n    marginal_gain1 = (value1_lst + 1e-8) / (weight_lst + 1e-8)\n    marginal_gain2 = (value2_lst + 1e-8) / (weight_lst + 1e-8)\n\n    # Novelty-aware swap: replace low-marginal items with high-marginal items\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Find items with lowest marginal gains in the solution\n        low_marginal_in = in_solution[np.argsort(marginal_gain1[in_solution] + marginal_gain2[in_solution])[:max(1, len(in_solution)//3)]]\n        # Find items with highest marginal gains not in the solution\n        high_marginal_out = out_solution[np.argsort(-(marginal_gain1[out_solution] + marginal_gain2[out_solution]))[:max(1, len(out_solution)//3)]]\n\n        for i in low_marginal_in:\n            for j in high_marginal_out:\n                if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    total_weight = total_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    # Probabilistic flip biased toward improving underrepresented objectives\n    if np.random.rand() < 0.4:  # 40% chance to flip\n        # Calculate objective dominance\n        total_value1 = np.sum(value1_lst * new_solution)\n        total_value2 = np.sum(value2_lst * new_solution)\n        dominance = total_value1 / (total_value2 + 1e-8)\n\n        # Bias flip toward underrepresented objective\n        if dominance > 1.2:  # Over-representing objective 1\n            candidates = np.where(new_solution == 1)[0]\n            if len(candidates) > 0:\n                idx = candidates[np.argmin(marginal_gain2[candidates])]\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n        elif dominance < 0.8:  # Over-representing objective 2\n            candidates = np.where(new_solution == 1)[0]\n            if len(candidates) > 0:\n                idx = candidates[np.argmin(marginal_gain1[candidates])]\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n        else:  # Balanced, random flip\n            idx = np.random.randint(0, n_items)\n            if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n            elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest marginal gains until feasible\n        while total_weight > capacity:\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmin(marginal_gain1[in_solution] + marginal_gain2[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6847411986377774,
            0.9575352966785431
        ],
        "raw_score": [
            27.408185274632515,
            28.07902952177133
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic weighting based on Pareto-front distribution\n    def dynamic_weight(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        # Weight adaptively based on objective dominance\n        weight1 = 0.5 + 0.5 * (value1 / (np.sum(value1_lst) + 1e-8))\n        weight2 = 0.5 + 0.5 * (value2 / (np.sum(value2_lst) + 1e-8))\n        return (weight1 * value1 + weight2 * value2) * (1 - (total_weight / capacity))\n\n    # Select solution with highest dynamic weight\n    selected_sol, _ = max(archive, key=lambda x: dynamic_weight(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Calculate marginal gains for each objective\n    marginal_gain1 = (value1_lst + 1e-8) / (weight_lst + 1e-8)\n    marginal_gain2 = (value2_lst + 1e-8) / (weight_lst + 1e-8)\n\n    # Novelty-aware swap: replace low-marginal items with high-marginal items\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Find items with lowest marginal gains in the solution\n        low_marginal_in = in_solution[np.argsort(marginal_gain1[in_solution] + marginal_gain2[in_solution])[:max(1, len(in_solution)//3)]]\n        # Find items with highest marginal gains not in the solution\n        high_marginal_out = out_solution[np.argsort(-(marginal_gain1[out_solution] + marginal_gain2[out_solution]))[:max(1, len(out_solution)//3)]]\n\n        for i in low_marginal_in:\n            for j in high_marginal_out:\n                if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    total_weight = total_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    # Probabilistic flip biased toward improving underrepresented objectives\n    if np.random.rand() < 0.4:  # 40% chance to flip\n        # Calculate objective dominance\n        total_value1 = np.sum(value1_lst * new_solution)\n        total_value2 = np.sum(value2_lst * new_solution)\n        dominance = total_value1 / (total_value2 + 1e-8)\n\n        # Bias flip toward underrepresented objective\n        if dominance > 1.2:  # Over-representing objective 1\n            candidates = np.where(new_solution == 1)[0]\n            if len(candidates) > 0:\n                idx = candidates[np.argmin(marginal_gain2[candidates])]\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n        elif dominance < 0.8:  # Over-representing objective 2\n            candidates = np.where(new_solution == 1)[0]\n            if len(candidates) > 0:\n                idx = candidates[np.argmin(marginal_gain1[candidates])]\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n        else:  # Balanced, random flip\n            idx = np.random.randint(0, n_items)\n            if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n            elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest marginal gains until feasible\n        while total_weight > capacity:\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmin(marginal_gain1[in_solution] + marginal_gain2[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects the most promising solution from the archive based on a weighted value metric balancing both objectives (60% value1, 40% value2) and capacity utilization, then applies a hybrid local search that first adds high-value-density items and occasionally removes low-value-density items to create a feasible neighbor solution. It prioritizes items with higher combined value-to-weight ratios while ensuring feasibility through targeted removals when necessary.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate weighted value metric for each solution\n    def weighted_value(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        # Weighted value metric combining both objectives and capacity utilization\n        return (0.6 * value1 + 0.4 * value2) * (1 - (total_weight / capacity))\n\n    # Select solution with highest weighted value\n    selected_sol, _ = max(archive, key=lambda x: weighted_value(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search operator\n    # Step 1: Replace low-value items with high-value alternatives\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Calculate value density (value per weight) for all items\n    value_density = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-value_density)  # Highest density first\n\n    # Try to add high-value items that fit\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and weight_lst[idx] <= available_weight:\n            new_solution[idx] = 1\n            available_weight -= weight_lst[idx]\n\n    # Step 2: Randomly perturb by removing items with low value density\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        low_density_items = np.where(new_solution == 1)[0]\n        if len(low_density_items) > 0:\n            # Remove items with lowest value density\n            low_density_items_sorted = sorted(low_density_items, key=lambda x: value_density[x])\n            for idx in low_density_items_sorted[:max(1, len(low_density_items)//3)]:\n                new_solution[idx] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        while total_weight > capacity:\n            # Find the item with lowest value density in the solution\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmin(value_density[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 23,
        "algorithm": "The algorithm selects a solution from the archive using dynamic objective weighting based on diversity, then applies a hybrid local search combining value-density improvements, strategic item swaps, capacity balancing, and occasional random perturbations to generate feasible neighbor solutions. It prioritizes items with higher combined value density while ensuring feasibility through a capacity-balancing step, and occasionally perturbs the solution to escape local optima. The weighted value metric guides the selection of promising solutions for further improvement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dynamic objective weights based on archive diversity\n    obj1_values = np.array([obj[0] for _, obj in archive])\n    obj2_values = np.array([obj[1] for _, obj in archive])\n    obj1_range = np.max(obj1_values) - np.min(obj1_values)\n    obj2_range = np.max(obj2_values) - np.min(obj2_values)\n\n    # Dynamic weighting based on archive diversity\n    if obj1_range > 0 and obj2_range > 0:\n        weight1 = obj2_range / (obj1_range + obj2_range)\n        weight2 = 1 - weight1\n    else:\n        weight1, weight2 = 0.5, 0.5\n\n    # Calculate weighted value metric\n    def weighted_value(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        return (weight1 * value1 + weight2 * value2) * (1 - (total_weight / capacity))\n\n    # Select solution with highest weighted value\n    selected_sol, _ = max(archive, key=lambda x: weighted_value(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search operator\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Calculate combined value density\n    combined_value = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-combined_value)\n\n    # Step 1: Add high-value items that fit\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and weight_lst[idx] <= available_weight:\n            new_solution[idx] = 1\n            available_weight -= weight_lst[idx]\n\n    # Step 2: Strategic item swaps\n    if np.random.rand() < 0.4:\n        in_solution = np.where(new_solution == 1)[0]\n        out_solution = np.where(new_solution == 0)[0]\n\n        if len(in_solution) > 0 and len(out_solution) > 0:\n            # Find best item to remove (lowest value density)\n            remove_idx = in_solution[np.argmin(combined_value[in_solution])]\n            # Find best item to add (highest value density among available)\n            add_idx = out_solution[np.argmax(combined_value[out_solution])]\n\n            # Check if swap is feasible\n            if weight_lst[add_idx] - weight_lst[remove_idx] <= available_weight:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n\n    # Step 3: Capacity balancing\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        in_solution = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(in_solution) > 0:\n            remove_idx = in_solution[np.argmin(combined_value[in_solution])]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            in_solution = np.where(new_solution == 1)[0]\n\n    # Step 4: Random perturbation\n    if np.random.rand() < 0.2:\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) > 1:\n            # Randomly select 1-2 items to flip\n            flip_count = min(2, len(in_solution))\n            flip_indices = np.random.choice(in_solution, flip_count, replace=False)\n            for idx in flip_indices:\n                new_solution[idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9205943145787344,
            4.148276001214981
        ],
        "raw_score": [
            31.081209053454582,
            31.173129640220836
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dynamic objective weights based on archive diversity\n    obj1_values = np.array([obj[0] for _, obj in archive])\n    obj2_values = np.array([obj[1] for _, obj in archive])\n    obj1_range = np.max(obj1_values) - np.min(obj1_values)\n    obj2_range = np.max(obj2_values) - np.min(obj2_values)\n\n    # Dynamic weighting based on archive diversity\n    if obj1_range > 0 and obj2_range > 0:\n        weight1 = obj2_range / (obj1_range + obj2_range)\n        weight2 = 1 - weight1\n    else:\n        weight1, weight2 = 0.5, 0.5\n\n    # Calculate weighted value metric\n    def weighted_value(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        return (weight1 * value1 + weight2 * value2) * (1 - (total_weight / capacity))\n\n    # Select solution with highest weighted value\n    selected_sol, _ = max(archive, key=lambda x: weighted_value(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search operator\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Calculate combined value density\n    combined_value = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-combined_value)\n\n    # Step 1: Add high-value items that fit\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and weight_lst[idx] <= available_weight:\n            new_solution[idx] = 1\n            available_weight -= weight_lst[idx]\n\n    # Step 2: Strategic item swaps\n    if np.random.rand() < 0.4:\n        in_solution = np.where(new_solution == 1)[0]\n        out_solution = np.where(new_solution == 0)[0]\n\n        if len(in_solution) > 0 and len(out_solution) > 0:\n            # Find best item to remove (lowest value density)\n            remove_idx = in_solution[np.argmin(combined_value[in_solution])]\n            # Find best item to add (highest value density among available)\n            add_idx = out_solution[np.argmax(combined_value[out_solution])]\n\n            # Check if swap is feasible\n            if weight_lst[add_idx] - weight_lst[remove_idx] <= available_weight:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n\n    # Step 3: Capacity balancing\n    current_weight = np.sum(weight_lst * new_solution)\n    if current_weight > capacity:\n        # Remove items until feasible\n        in_solution = np.where(new_solution == 1)[0]\n        while current_weight > capacity and len(in_solution) > 0:\n            remove_idx = in_solution[np.argmin(combined_value[in_solution])]\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n            in_solution = np.where(new_solution == 1)[0]\n\n    # Step 4: Random perturbation\n    if np.random.rand() < 0.2:\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) > 1:\n            # Randomly select 1-2 items to flip\n            flip_count = min(2, len(in_solution))\n            flip_indices = np.random.choice(in_solution, flip_count, replace=False)\n            for idx in flip_indices:\n                new_solution[idx] = 0\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects the most promising solution from the archive based on a weighted value metric balancing both objectives (60% value1, 40% value2) and capacity utilization, then applies a hybrid local search that first adds high-value-density items and occasionally removes low-value-density items to create a feasible neighbor solution. It prioritizes items with higher combined value-to-weight ratios while ensuring feasibility through targeted removals when necessary.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate weighted value metric for each solution\n    def weighted_value(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        # Weighted value metric combining both objectives and capacity utilization\n        return (0.6 * value1 + 0.4 * value2) * (1 - (total_weight / capacity))\n\n    # Select solution with highest weighted value\n    selected_sol, _ = max(archive, key=lambda x: weighted_value(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search operator\n    # Step 1: Replace low-value items with high-value alternatives\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Calculate value density (value per weight) for all items\n    value_density = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-value_density)  # Highest density first\n\n    # Try to add high-value items that fit\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and weight_lst[idx] <= available_weight:\n            new_solution[idx] = 1\n            available_weight -= weight_lst[idx]\n\n    # Step 2: Randomly perturb by removing items with low value density\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        low_density_items = np.where(new_solution == 1)[0]\n        if len(low_density_items) > 0:\n            # Remove items with lowest value density\n            low_density_items_sorted = sorted(low_density_items, key=lambda x: value_density[x])\n            for idx in low_density_items_sorted[:max(1, len(low_density_items)//3)]:\n                new_solution[idx] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        while total_weight > capacity:\n            # Find the item with lowest value density in the solution\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmin(value_density[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 24,
        "algorithm": "The algorithm selects the most promising solution from the archive based on a weighted metric favoring value2 (60%) over value1 (40%), adjusted by capacity utilization. It then applies a hybrid local search that first removes low-value-density items and occasionally adds high-value-density items, ensuring feasibility by prioritizing high-value items when necessary. The weighted metric and density-based selection prioritize items with better overall value-to-weight ratios while balancing the two objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate weighted value metric for each solution\n    def weighted_value(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        # Dynamically adjusted weighted value metric (40% value1, 60% value2)\n        return (0.4 * value1 + 0.6 * value2) * (1 - (total_weight / capacity))\n\n    # Select solution with highest weighted value\n    selected_sol, _ = max(archive, key=lambda x: weighted_value(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search operator\n    # Step 1: Remove high-value items that might be redundant\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Calculate value density (value per weight) for all items\n    value_density = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_density)  # Lowest density first\n\n    # Try to remove low-value items\n    for idx in sorted_indices:\n        if new_solution[idx] == 1 and (total_weight - weight_lst[idx]) <= capacity:\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n            available_weight += weight_lst[idx]\n\n    # Step 2: Randomly perturb by adding items with low value density\n    if np.random.rand() < 0.4:  # 40% chance to perturb\n        low_density_items = np.where(new_solution == 0)[0]\n        if len(low_density_items) > 0:\n            # Add items with lowest value density\n            low_density_items_sorted = sorted(low_density_items, key=lambda x: value_density[x])\n            for idx in low_density_items_sorted[:max(1, len(low_density_items)//4)]:\n                if weight_lst[idx] <= available_weight:\n                    new_solution[idx] = 1\n                    available_weight -= weight_lst[idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        while total_weight > capacity:\n            # Find the item with highest value density in the solution\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmax(value_density[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.81955396626454,
            0.859280526638031
        ],
        "raw_score": [
            27.303342198361328,
            28.018638664958154
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate weighted value metric for each solution\n    def weighted_value(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        # Dynamically adjusted weighted value metric (40% value1, 60% value2)\n        return (0.4 * value1 + 0.6 * value2) * (1 - (total_weight / capacity))\n\n    # Select solution with highest weighted value\n    selected_sol, _ = max(archive, key=lambda x: weighted_value(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search operator\n    # Step 1: Remove high-value items that might be redundant\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Calculate value density (value per weight) for all items\n    value_density = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(value_density)  # Lowest density first\n\n    # Try to remove low-value items\n    for idx in sorted_indices:\n        if new_solution[idx] == 1 and (total_weight - weight_lst[idx]) <= capacity:\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n            available_weight += weight_lst[idx]\n\n    # Step 2: Randomly perturb by adding items with low value density\n    if np.random.rand() < 0.4:  # 40% chance to perturb\n        low_density_items = np.where(new_solution == 0)[0]\n        if len(low_density_items) > 0:\n            # Add items with lowest value density\n            low_density_items_sorted = sorted(low_density_items, key=lambda x: value_density[x])\n            for idx in low_density_items_sorted[:max(1, len(low_density_items)//4)]:\n                if weight_lst[idx] <= available_weight:\n                    new_solution[idx] = 1\n                    available_weight -= weight_lst[idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        while total_weight > capacity:\n            # Find the item with highest value density in the solution\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmax(value_density[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects the most promising solution from the archive based on a weighted value metric balancing both objectives (60% value1, 40% value2) and capacity utilization, then applies a hybrid local search that first adds high-value-density items and occasionally removes low-value-density items to create a feasible neighbor solution. It prioritizes items with higher combined value-to-weight ratios while ensuring feasibility through targeted removals when necessary.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate weighted value metric for each solution\n    def weighted_value(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        # Weighted value metric combining both objectives and capacity utilization\n        return (0.6 * value1 + 0.4 * value2) * (1 - (total_weight / capacity))\n\n    # Select solution with highest weighted value\n    selected_sol, _ = max(archive, key=lambda x: weighted_value(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search operator\n    # Step 1: Replace low-value items with high-value alternatives\n    total_weight = np.sum(weight_lst * new_solution)\n    available_weight = capacity - total_weight\n\n    # Calculate value density (value per weight) for all items\n    value_density = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-value_density)  # Highest density first\n\n    # Try to add high-value items that fit\n    for idx in sorted_indices:\n        if new_solution[idx] == 0 and weight_lst[idx] <= available_weight:\n            new_solution[idx] = 1\n            available_weight -= weight_lst[idx]\n\n    # Step 2: Randomly perturb by removing items with low value density\n    if np.random.rand() < 0.3:  # 30% chance to perturb\n        low_density_items = np.where(new_solution == 1)[0]\n        if len(low_density_items) > 0:\n            # Remove items with lowest value density\n            low_density_items_sorted = sorted(low_density_items, key=lambda x: value_density[x])\n            for idx in low_density_items_sorted[:max(1, len(low_density_items)//3)]:\n                new_solution[idx] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items until feasible\n        while total_weight > capacity:\n            # Find the item with lowest value density in the solution\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmin(value_density[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe heuristic selects a near-capacity solution from the archive, then applies a hybrid local search combining item swapping and random flipping, with targeted replacement for feasibility, prioritizing solutions with high potential for multi-objective improvement while ensuring all generated neighbors remain feasible. It intelligently handles infeasibility by undoing operations and adding/removing the most valuable items, with a focus on balancing both objectives through weighted value considerations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    candidates = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight < capacity:\n            candidates.append(sol)\n\n    if not candidates:\n        return archive[0][0].copy()  # Fallback to first solution if no candidates\n\n    # Select a solution with high potential (e.g., near-capacity but not fully packed)\n    selected_sol = max(candidates, key=lambda x: np.sum(weight_lst * x))\n    new_solution = selected_sol.copy()\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Randomly swap two items\n    idx1, idx2 = np.random.choice(n_items, size=2, replace=False)\n    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Ensure feasibility after swap\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If swap violates capacity, undo it and try another approach\n        new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n        # Step 2: Randomly flip one item\n        flip_idx = np.random.choice(n_items)\n        new_solution[flip_idx] = 1 - new_solution[flip_idx]\n\n        # Ensure feasibility after flip\n        total_weight = np.sum(weight_lst * new_solution)\n        if total_weight > capacity:\n            # If flip violates capacity, remove the most expensive item\n            if new_solution[flip_idx] == 1:\n                new_solution[flip_idx] = 0\n            else:\n                # Find the most expensive item to add\n                available_items = np.where(new_solution == 0)[0]\n                if len(available_items) > 0:\n                    expensive_item = available_items[np.argmax(value1_lst[available_items] + value2_lst[available_items])]\n                    if np.sum(weight_lst * new_solution) + weight_lst[expensive_item] <= capacity:\n                        new_solution[expensive_item] = 1\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords:\n- **Dynamic trade-offs**, **adaptive weights**, **structured randomness**, **feasibility-aware selection**, **Pareto-front navigation**.\n\n### Advice:\n1. **Prioritize adaptive weights** to balance multi-objective exploration/exploitation.\n2. **Use novelty-aware selection** (e.g., context-based swaps) to avoid local optima.\n3. **Ensure feasibility checks** in every local search step.\n4. **Combine targeted operations** (e.g., probabilistic flips) with hybrid approaches.\n\n### Avoid:\n- **Static selection criteria**, **blind randomness**, **fixed probabilities**, **generic swaps**, **ignoring Pareto dominance**.\n\n### Explanation:\nDynamic weighting and novelty-aware selection enable efficient Pareto-front navigation, while feasibility checks and hybrid operations ensure high-quality neighbors. Avoid static methods to prevent premature convergence.\n\n---\n**Step-by-Step Design**:\n1. **Select a solution** from the archive using adaptive weights (e.g., weighted sum of normalized objectives).\n2. **Identify critical items** (e.g., those with high marginal gains in either objective).\n3. **Apply a hybrid local search**:\n   - **Novelty-driven swap**: Replace a low-marginal item with a high-marginal item from the archive.\n   - **Probabilistic flip**: Randomly flip items with a bias toward improving underrepresented objectives.\n4. **Ensure feasibility** by rejecting any swap/flip that violates capacity.\n\nThis balances exploration (novelty) and exploitation (adaptive weights) while guaranteeing feasibility.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 25,
        "algorithm": "The algorithm selects the most promising solution from the archive using an adaptive weighting scheme (prioritizing value1 60% and value2 40% while considering capacity utilization), then applies a hybrid local search: first performing a novelty-driven swap between low-marginal and high-marginal items, followed by probabilistic flips biased toward improving underrepresented objectives, and finally ensuring feasibility by removing low-value-density items if needed. The approach dynamically balances exploration and exploitation by prioritizing high-density items while probabilistically exploring novel regions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate adaptive weights for selection\n    def adaptive_weight(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        # Dynamic weights: prioritize solutions near the Pareto front\n        return (0.6 * value1 + 0.4 * value2) * (1 - (total_weight / capacity))\n\n    # Select the most promising solution\n    selected_sol, _ = max(archive, key=lambda x: adaptive_weight(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Calculate value density for all items\n    value_density = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-value_density)  # Highest density first\n\n    # Hybrid local search\n    # Step 1: Novelty-driven swap (replace low-marginal item with high-marginal item from archive)\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Find the lowest-marginal item in the solution\n        low_marginal_idx = in_solution[np.argmin(value_density[in_solution])]\n        # Find the highest-marginal item not in the solution\n        high_marginal_idx = out_solution[np.argmax(value_density[out_solution])]\n\n        # Check if swap is feasible\n        if (np.sum(weight_lst * new_solution) - weight_lst[low_marginal_idx] + weight_lst[high_marginal_idx]) <= capacity:\n            new_solution[low_marginal_idx] = 0\n            new_solution[high_marginal_idx] = 1\n\n    # Step 2: Probabilistic flip with bias toward improving underrepresented objectives\n    if np.random.rand() < 0.4:  # 40% chance to flip\n        # Calculate current objective ratios\n        current_value1 = np.sum(value1_lst * new_solution)\n        current_value2 = np.sum(value2_lst * new_solution)\n        if current_value1 + current_value2 > 0:\n            ratio1 = current_value1 / (current_value1 + current_value2)\n            ratio2 = current_value2 / (current_value1 + current_value2)\n        else:\n            ratio1, ratio2 = 0.5, 0.5\n\n        # Flip items with probability biased toward underrepresented objective\n        for idx in range(n_items):\n            if np.random.rand() < 0.2:  # 20% chance to consider flipping\n                if (ratio1 < ratio2 and value2_lst[idx] > value1_lst[idx]) or (ratio2 < ratio1 and value1_lst[idx] > value2_lst[idx]):\n                    new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest value density until feasible\n        while total_weight > capacity:\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmin(value_density[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.3096803149461915,
            0.36819663643836975
        ],
        "raw_score": [
            50.81222206962897,
            49.950939880268315
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate adaptive weights for selection\n    def adaptive_weight(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        # Dynamic weights: prioritize solutions near the Pareto front\n        return (0.6 * value1 + 0.4 * value2) * (1 - (total_weight / capacity))\n\n    # Select the most promising solution\n    selected_sol, _ = max(archive, key=lambda x: adaptive_weight(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Calculate value density for all items\n    value_density = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-value_density)  # Highest density first\n\n    # Hybrid local search\n    # Step 1: Novelty-driven swap (replace low-marginal item with high-marginal item from archive)\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Find the lowest-marginal item in the solution\n        low_marginal_idx = in_solution[np.argmin(value_density[in_solution])]\n        # Find the highest-marginal item not in the solution\n        high_marginal_idx = out_solution[np.argmax(value_density[out_solution])]\n\n        # Check if swap is feasible\n        if (np.sum(weight_lst * new_solution) - weight_lst[low_marginal_idx] + weight_lst[high_marginal_idx]) <= capacity:\n            new_solution[low_marginal_idx] = 0\n            new_solution[high_marginal_idx] = 1\n\n    # Step 2: Probabilistic flip with bias toward improving underrepresented objectives\n    if np.random.rand() < 0.4:  # 40% chance to flip\n        # Calculate current objective ratios\n        current_value1 = np.sum(value1_lst * new_solution)\n        current_value2 = np.sum(value2_lst * new_solution)\n        if current_value1 + current_value2 > 0:\n            ratio1 = current_value1 / (current_value1 + current_value2)\n            ratio2 = current_value2 / (current_value1 + current_value2)\n        else:\n            ratio1, ratio2 = 0.5, 0.5\n\n        # Flip items with probability biased toward underrepresented objective\n        for idx in range(n_items):\n            if np.random.rand() < 0.2:  # 20% chance to consider flipping\n                if (ratio1 < ratio2 and value2_lst[idx] > value1_lst[idx]) or (ratio2 < ratio1 and value1_lst[idx] > value2_lst[idx]):\n                    new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest value density until feasible\n        while total_weight > capacity:\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmin(value_density[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 2 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a balanced solution from the archive (prioritizing those with high combined objective product) and applies a hybrid local search combining weighted item addition, adaptive swapping, and probabilistic flipping, while dynamically adjusting weights based on solution quality and ensuring feasibility through capacity checks. It emphasizes objective-aware selection (using weighted value metrics) and diversity maintenance (through probabilistic flips), creating a balance between exploration and exploitation. The key design focuses on adaptive weights, combined value metrics, and solution quality-aware operations to improve multi-objective performance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### **Heuristic Design for BI-KP Local Search**\n\n**Keywords**:\n- **Adaptive weighting**, **novelty-aware selection**, **feasibility-aware operations**, **Pareto-front navigation**.\n\n**Advice**:\n1. **Use dynamic weights** to balance objectives during selection (e.g., weighted sum of normalized values).\n2. **Prioritize high-marginal items** in swaps/flips to maximize objective improvements.\n3. **Combine novelty-driven swaps** (e.g., replace low-marginal items with high-marginal ones) with probabilistic flips.\n4. **Strictly enforce feasibility** at every step to avoid invalid solutions.\n\n**Avoid**:\n- Static selection criteria, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or violating capacity constraints.\n\n**Explanation**:\nAdaptive weights guide selection toward high-potential regions, while novelty-aware swaps ensure diverse exploration. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 26,
        "algorithm": "The algorithm selects a promising solution from the archive by sorting solutions based on the product of their objective values and choosing a middle-tier solution (to balance exploration and exploitation). It then performs a hybrid local search: first swapping the least marginal item in the solution with the most promising item outside, then probabilistically flipping items with a bias toward higher-quality solutions, while always ensuring feasibility. The dynamic weights for objectives and adaptive flip probabilities enhance multi-objective optimization.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with adaptive weights\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search\n    # Phase 1: Novelty-aware swaps\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Calculate marginal values for items in solution\n        marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / (weight_lst[in_solution] + 1e-8)\n        least_marginal = in_solution[np.argmin(marginal_values)]\n\n        # Calculate marginal values for items out of solution\n        marginal_values_out = (weight1 * value1_lst[out_solution] + weight2 * value2_lst[out_solution]) / (weight_lst[out_solution] + 1e-8)\n        best_candidate = out_solution[np.argmax(marginal_values_out)]\n\n        # Swap if feasible\n        if current_weight - weight_lst[least_marginal] + weight_lst[best_candidate] <= capacity:\n            new_solution[least_marginal] = 0\n            new_solution[best_candidate] = 1\n            current_weight = current_weight - weight_lst[least_marginal] + weight_lst[best_candidate]\n\n    # Phase 2: Probabilistic flips with objective bias\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.5\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6734280274055893,
            1.4722109138965607
        ],
        "raw_score": [
            37.58087758233144,
            37.68216771165489
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with adaptive weights\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search\n    # Phase 1: Novelty-aware swaps\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Calculate marginal values for items in solution\n        marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / (weight_lst[in_solution] + 1e-8)\n        least_marginal = in_solution[np.argmin(marginal_values)]\n\n        # Calculate marginal values for items out of solution\n        marginal_values_out = (weight1 * value1_lst[out_solution] + weight2 * value2_lst[out_solution]) / (weight_lst[out_solution] + 1e-8)\n        best_candidate = out_solution[np.argmax(marginal_values_out)]\n\n        # Swap if feasible\n        if current_weight - weight_lst[least_marginal] + weight_lst[best_candidate] <= capacity:\n            new_solution[least_marginal] = 0\n            new_solution[best_candidate] = 1\n            current_weight = current_weight - weight_lst[least_marginal] + weight_lst[best_candidate]\n\n    # Phase 2: Probabilistic flips with objective bias\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.5\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe heuristic selects a balanced solution from the archive, then applies a hybrid local search combining targeted swaps (prioritizing high-value items), probabilistic flips, feasibility checks, and greedy additions of valuable items. It dynamically adjusts weights based on current solution quality and ensures feasibility through intelligent item removals and additions. The approach balances exploration and exploitation while maintaining Pareto optimality potential.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Targeted swapping based on adaptive weights\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                current_weight = temp_weight\n\n    # Step 2: Random flip with probability based on solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and n_items > 0:\n        flip_idx = np.random.choice(n_items)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Step 3: Ensure feasibility by removing the least valuable items if needed\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    # Step 4: Add the most valuable available items if there's remaining capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        add_idx = available_items[np.argmax(weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects the top solution from the archive (sorted by the sum of both objectives) and performs a greedy local search by iteratively adding or removing items to improve feasibility and objective values, followed by a random swap to maintain diversity. The key design ideas are prioritizing solutions with higher combined objective values and using a hybrid approach of greedy and random exploration to generate neighbors.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(base_solution * weight_lst)\n    new_solution = base_solution.copy()\n\n    # Identify items that can be swapped or added to improve objectives\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Perform a random swap to ensure diversity\n    if len(new_solution) >= 2:\n        idx1, idx2 = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[idx1] != new_solution[idx2]:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n            temp_weight = np.sum(new_solution * weight_lst)\n            if temp_weight > capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Heuristic Design for BI-KP Local Search**\n\n**Keywords**:\n- **Adaptive weighting**, **novelty-aware selection**, **feasibility-aware operations**, **Pareto-front navigation**.\n\n**Advice**:\n1. **Use dynamic weights** to balance objectives during selection (e.g., weighted sum of normalized values).\n2. **Prioritize high-marginal items** in swaps/flips to maximize objective improvements.\n3. **Combine novelty-driven swaps** (e.g., replace low-marginal items with high-marginal ones) with probabilistic flips.\n4. **Strictly enforce feasibility** at every step to avoid invalid solutions.\n\n**Avoid**:\n- Static selection criteria, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or violating capacity constraints.\n\n**Explanation**:\nAdaptive weights guide selection toward high-potential regions, while novelty-aware swaps ensure diverse exploration. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 27,
        "algorithm": "The algorithm combines adaptive objective weighting, novelty-driven local search, and feasibility-preserving operations. It first selects a promising solution from the archive, then applies a hybrid approach of targeted item replacements (based on marginal value) and probabilistic flips to generate neighbors while dynamically adjusting probabilities based on solution quality. The method strictly maintains feasibility through a two-phase adjustment process that removes low-marginal items and greedily adds high-marginal items, prioritizing items with higher combined weighted values (weighted by current solution value proportions) to balance both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(1, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Novelty-driven local search\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Replace low-marginal items with high-marginal items\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Find the lowest marginal item in the solution\n        marginal_values = weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]\n        remove_idx = in_solution[np.argmin(marginal_values)]\n\n        # Find the highest marginal available item\n        marginal_values_out = weight1 * value1_lst[out_solution] + weight2 * value2_lst[out_solution]\n        add_idx = out_solution[np.argmax(marginal_values_out)]\n\n        # Try to replace\n        temp_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n        if temp_weight <= capacity:\n            new_solution[remove_idx] = 0\n            new_solution[add_idx] = 1\n            current_weight = temp_weight\n\n    # Step 2: Probabilistic flip with dynamic probability\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and n_items > 0:\n        flip_idx = np.random.choice(n_items)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Step 3: Feasibility adjustment\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    # Step 4: Greedy addition of high-marginal items\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        add_idx = available_items[np.argmax(weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.4146092961328173,
            4.235156267881393
        ],
        "raw_score": [
            37.40593160754378,
            39.78121888180131
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(1, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Novelty-driven local search\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Replace low-marginal items with high-marginal items\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Find the lowest marginal item in the solution\n        marginal_values = weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]\n        remove_idx = in_solution[np.argmin(marginal_values)]\n\n        # Find the highest marginal available item\n        marginal_values_out = weight1 * value1_lst[out_solution] + weight2 * value2_lst[out_solution]\n        add_idx = out_solution[np.argmax(marginal_values_out)]\n\n        # Try to replace\n        temp_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n        if temp_weight <= capacity:\n            new_solution[remove_idx] = 0\n            new_solution[add_idx] = 1\n            current_weight = temp_weight\n\n    # Step 2: Probabilistic flip with dynamic probability\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and n_items > 0:\n        flip_idx = np.random.choice(n_items)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Step 3: Feasibility adjustment\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    # Step 4: Greedy addition of high-marginal items\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        add_idx = available_items[np.argmax(weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects the most promising solution from the archive using an adaptive weighting scheme (prioritizing value1 60% and value2 40% while considering capacity utilization), then applies a hybrid local search: first performing a novelty-driven swap between low-marginal and high-marginal items, followed by probabilistic flips biased toward improving underrepresented objectives, and finally ensuring feasibility by removing low-value-density items if needed. The approach dynamically balances exploration and exploitation by prioritizing high-density items while probabilistically exploring novel regions.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate adaptive weights for selection\n    def adaptive_weight(sol):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        value1 = np.sum(value1_lst * sol)\n        value2 = np.sum(value2_lst * sol)\n        # Dynamic weights: prioritize solutions near the Pareto front\n        return (0.6 * value1 + 0.4 * value2) * (1 - (total_weight / capacity))\n\n    # Select the most promising solution\n    selected_sol, _ = max(archive, key=lambda x: adaptive_weight(x[0]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Calculate value density for all items\n    value_density = (value1_lst + value2_lst) / weight_lst\n    sorted_indices = np.argsort(-value_density)  # Highest density first\n\n    # Hybrid local search\n    # Step 1: Novelty-driven swap (replace low-marginal item with high-marginal item from archive)\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Find the lowest-marginal item in the solution\n        low_marginal_idx = in_solution[np.argmin(value_density[in_solution])]\n        # Find the highest-marginal item not in the solution\n        high_marginal_idx = out_solution[np.argmax(value_density[out_solution])]\n\n        # Check if swap is feasible\n        if (np.sum(weight_lst * new_solution) - weight_lst[low_marginal_idx] + weight_lst[high_marginal_idx]) <= capacity:\n            new_solution[low_marginal_idx] = 0\n            new_solution[high_marginal_idx] = 1\n\n    # Step 2: Probabilistic flip with bias toward improving underrepresented objectives\n    if np.random.rand() < 0.4:  # 40% chance to flip\n        # Calculate current objective ratios\n        current_value1 = np.sum(value1_lst * new_solution)\n        current_value2 = np.sum(value2_lst * new_solution)\n        if current_value1 + current_value2 > 0:\n            ratio1 = current_value1 / (current_value1 + current_value2)\n            ratio2 = current_value2 / (current_value1 + current_value2)\n        else:\n            ratio1, ratio2 = 0.5, 0.5\n\n        # Flip items with probability biased toward underrepresented objective\n        for idx in range(n_items):\n            if np.random.rand() < 0.2:  # 20% chance to consider flipping\n                if (ratio1 < ratio2 and value2_lst[idx] > value1_lst[idx]) or (ratio2 < ratio1 and value1_lst[idx] > value2_lst[idx]):\n                    new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest value density until feasible\n        while total_weight > capacity:\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            remove_idx = in_solution[np.argmin(value_density[in_solution])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects the top solution from the archive (sorted by the sum of both objectives) and performs a greedy local search by iteratively adding or removing items to improve feasibility and objective values, followed by a random swap to maintain diversity. The key design ideas are prioritizing solutions with higher combined objective values and using a hybrid approach of greedy and random exploration to generate neighbors.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(base_solution * weight_lst)\n    new_solution = base_solution.copy()\n\n    # Identify items that can be swapped or added to improve objectives\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Perform a random swap to ensure diversity\n    if len(new_solution) >= 2:\n        idx1, idx2 = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[idx1] != new_solution[idx2]:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n            temp_weight = np.sum(new_solution * weight_lst)\n            if temp_weight > capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### **Heuristic Design for BI-KP Local Search**\n\n**Keywords**:\n- **Adaptive weighting**, **novelty-aware selection**, **feasibility-aware operations**, **Pareto-front navigation**.\n\n**Advice**:\n1. **Use dynamic weights** to balance objectives during selection (e.g., weighted sum of normalized values).\n2. **Prioritize high-marginal items** in swaps/flips to maximize objective improvements.\n3. **Combine novelty-driven swaps** (e.g., replace low-marginal items with high-marginal ones) with probabilistic flips.\n4. **Strictly enforce feasibility** at every step to avoid invalid solutions.\n\n**Avoid**:\n- Static selection criteria, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or violating capacity constraints.\n\n**Explanation**:\nAdaptive weights guide selection toward high-potential regions, while novelty-aware swaps ensure diverse exploration. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 28,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic Pareto-front aware selection with adaptive weights\n    def pareto_weight(sol, obj1, obj2):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        # Normalize objectives to [0,1] range\n        max_obj1 = max(o[1][0] for o in archive) if archive else 1\n        max_obj2 = max(o[1][1] for o in archive) if archive else 1\n        norm_obj1 = obj1 / max_obj1 if max_obj1 > 0 else 0\n        norm_obj2 = obj2 / max_obj2 if max_obj2 > 0 else 0\n        # Adaptive weight based on current solution's position in Pareto space\n        alpha = 0.7 if norm_obj1 > norm_obj2 else 0.3  # Bias toward underrepresented objective\n        return alpha * norm_obj1 + (1 - alpha) * norm_obj2\n\n    # Select solution with highest weighted score\n    selected_sol, (obj1, obj2) = max(archive, key=lambda x: pareto_weight(x[0], x[1][0], x[1][1]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search\n    # Step 1: Novelty-driven swap between extreme items\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Find item with maximum value in underrepresented objective\n        current_ratio = obj1 / (obj1 + obj2) if (obj1 + obj2) > 0 else 0.5\n        if current_ratio > 0.5:\n            target_obj = value2_lst\n        else:\n            target_obj = value1_lst\n\n        # Find best candidate to swap out (lowest value in target objective)\n        swap_out = in_items[np.argmin(target_obj[in_items])]\n        # Find best candidate to swap in (highest value in target objective)\n        swap_in = out_items[np.argmax(target_obj[out_items])]\n\n        # Check feasibility\n        if np.sum(weight_lst * new_solution) - weight_lst[swap_out] + weight_lst[swap_in] <= capacity:\n            new_solution[swap_out] = 0\n            new_solution[swap_in] = 1\n\n    # Step 2: Objective-biased flips with dynamic probability\n    flip_prob = min(0.5, 0.1 + 0.4 * abs(obj1 - obj2) / (obj1 + obj2 + 1e-6))  # Higher when objectives are imbalanced\n    for idx in range(n_items):\n        if np.random.rand() < flip_prob:\n            # Flip based on which objective is underrepresented\n            if (obj1 < obj2 and value1_lst[idx] > value2_lst[idx]) or (obj2 < obj1 and value2_lst[idx] > value1_lst[idx]):\n                new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest value per weight until feasible\n        in_items = np.where(new_solution == 1)[0]\n        value_density = (value1_lst + value2_lst) / weight_lst\n        while total_weight > capacity and len(in_items) > 0:\n            remove_idx = in_items[np.argmin(value_density[in_items])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n            in_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.3378537145606971,
            0.5421881377696991
        ],
        "raw_score": [
            53.447280571759634,
            53.34023832951784
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic Pareto-front aware selection with adaptive weights\n    def pareto_weight(sol, obj1, obj2):\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            return -np.inf\n        # Normalize objectives to [0,1] range\n        max_obj1 = max(o[1][0] for o in archive) if archive else 1\n        max_obj2 = max(o[1][1] for o in archive) if archive else 1\n        norm_obj1 = obj1 / max_obj1 if max_obj1 > 0 else 0\n        norm_obj2 = obj2 / max_obj2 if max_obj2 > 0 else 0\n        # Adaptive weight based on current solution's position in Pareto space\n        alpha = 0.7 if norm_obj1 > norm_obj2 else 0.3  # Bias toward underrepresented objective\n        return alpha * norm_obj1 + (1 - alpha) * norm_obj2\n\n    # Select solution with highest weighted score\n    selected_sol, (obj1, obj2) = max(archive, key=lambda x: pareto_weight(x[0], x[1][0], x[1][1]))\n    new_solution = selected_sol.copy()\n\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Hybrid local search\n    # Step 1: Novelty-driven swap between extreme items\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Find item with maximum value in underrepresented objective\n        current_ratio = obj1 / (obj1 + obj2) if (obj1 + obj2) > 0 else 0.5\n        if current_ratio > 0.5:\n            target_obj = value2_lst\n        else:\n            target_obj = value1_lst\n\n        # Find best candidate to swap out (lowest value in target objective)\n        swap_out = in_items[np.argmin(target_obj[in_items])]\n        # Find best candidate to swap in (highest value in target objective)\n        swap_in = out_items[np.argmax(target_obj[out_items])]\n\n        # Check feasibility\n        if np.sum(weight_lst * new_solution) - weight_lst[swap_out] + weight_lst[swap_in] <= capacity:\n            new_solution[swap_out] = 0\n            new_solution[swap_in] = 1\n\n    # Step 2: Objective-biased flips with dynamic probability\n    flip_prob = min(0.5, 0.1 + 0.4 * abs(obj1 - obj2) / (obj1 + obj2 + 1e-6))  # Higher when objectives are imbalanced\n    for idx in range(n_items):\n        if np.random.rand() < flip_prob:\n            # Flip based on which objective is underrepresented\n            if (obj1 < obj2 and value1_lst[idx] > value2_lst[idx]) or (obj2 < obj1 and value2_lst[idx] > value1_lst[idx]):\n                new_solution[idx] = 1 - new_solution[idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Remove items with lowest value per weight until feasible\n        in_items = np.where(new_solution == 1)[0]\n        value_density = (value1_lst + value2_lst) / weight_lst\n        while total_weight > capacity and len(in_items) > 0:\n            remove_idx = in_items[np.argmin(value_density[in_items])]\n            new_solution[remove_idx] = 0\n            total_weight -= weight_lst[remove_idx]\n            in_items = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects the top solution from the archive (sorted by the sum of both objectives) and performs a greedy local search by iteratively adding or removing items to improve feasibility and objective values, followed by a random swap to maintain diversity. The key design ideas are prioritizing solutions with higher combined objective values and using a hybrid approach of greedy and random exploration to generate neighbors.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(base_solution * weight_lst)\n    new_solution = base_solution.copy()\n\n    # Identify items that can be swapped or added to improve objectives\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Perform a random swap to ensure diversity\n    if len(new_solution) >= 2:\n        idx1, idx2 = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[idx1] != new_solution[idx2]:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n            temp_weight = np.sum(new_solution * weight_lst)\n            if temp_weight > capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 29,
        "algorithm": "The algorithm selects a promising solution from the archive using a weighted sum of objectives, then applies a hybrid local search combining greedy improvement for objective 1 with probabilistic item swaps, ensuring feasibility, followed by a randomized perturbation to maintain diversity. The selection prioritizes solutions with higher combined weighted values, while the local search intelligently explores the solution space by both improving and diversifying the neighborhood.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    weights = np.random.uniform(0.3, 0.7)\n    archive.sort(key=lambda x: -(weights * x[1][0] + (1 - weights) * x[1][1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Greedy local search for objective 1\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Probabilistic item swaps\n    for i in range(len(new_solution)):\n        if np.random.random() < 0.3:  # 30% chance to consider swapping\n            if new_solution[i] == 1:\n                # Try to replace with another item\n                candidates = [j for j in range(len(new_solution)) if new_solution[j] == 0 and\n                            (current_weight - weight_lst[i] + weight_lst[j]) <= capacity]\n                if candidates:\n                    j = np.random.choice(candidates)\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n\n    # Random perturbation to maintain diversity\n    if len(new_solution) >= 2:\n        idx1, idx2 = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[idx1] != new_solution[idx2]:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n            temp_weight = np.sum(new_solution * weight_lst)\n            if temp_weight > capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.4032986865624445,
            4.209409922361374
        ],
        "raw_score": [
            32.16927109612095,
            32.57268638334989
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    weights = np.random.uniform(0.3, 0.7)\n    archive.sort(key=lambda x: -(weights * x[1][0] + (1 - weights) * x[1][1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Greedy local search for objective 1\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Probabilistic item swaps\n    for i in range(len(new_solution)):\n        if np.random.random() < 0.3:  # 30% chance to consider swapping\n            if new_solution[i] == 1:\n                # Try to replace with another item\n                candidates = [j for j in range(len(new_solution)) if new_solution[j] == 0 and\n                            (current_weight - weight_lst[i] + weight_lst[j]) <= capacity]\n                if candidates:\n                    j = np.random.choice(candidates)\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n\n    # Random perturbation to maintain diversity\n    if len(new_solution) >= 2:\n        idx1, idx2 = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[idx1] != new_solution[idx2]:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n            temp_weight = np.sum(new_solution * weight_lst)\n            if temp_weight > capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects the top solution from the archive (sorted by the sum of both objectives) and performs a greedy local search by iteratively adding or removing items to improve feasibility and objective values, followed by a random swap to maintain diversity. The key design ideas are prioritizing solutions with higher combined objective values and using a hybrid approach of greedy and random exploration to generate neighbors.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    current_weight = np.sum(base_solution * weight_lst)\n    new_solution = base_solution.copy()\n\n    # Identify items that can be swapped or added to improve objectives\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Try removing the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 0\n            temp_weight = current_weight - weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n        else:\n            # Try adding the item\n            temp_solution = new_solution.copy()\n            temp_solution[i] = 1\n            temp_weight = current_weight + weight_lst[i]\n            if temp_weight <= capacity:\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    # Perform a random swap to ensure diversity\n    if len(new_solution) >= 2:\n        idx1, idx2 = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[idx1] != new_solution[idx2]:\n            new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n            temp_weight = np.sum(new_solution * weight_lst)\n            if temp_weight > capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 30,
        "algorithm": "The algorithm selects the highest-priority solution from the archive (weighted 70% on the first objective), then performs a targeted item replacement strategy prioritizing items with higher combined efficiency (weighted 70% on efficiency1 and 30% on efficiency2), while maintaining feasibility through probabilistic swaps that favor more efficient items. The solution is progressively improved by replacing less efficient items with more efficient ones, and a final probabilistic swap further refines the solution.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(0.7*x[1][0] + 0.3*x[1][1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Calculate item efficiency for both objectives\n    efficiency1 = value1_lst / weight_lst\n    efficiency2 = value2_lst / weight_lst\n    combined_efficiency = 0.7 * efficiency1 + 0.3 * efficiency2\n\n    # Try replacing items with higher efficiency\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Find best item to replace with (not in solution)\n            candidates = np.where(new_solution == 0)[0]\n            if len(candidates) > 0:\n                best_candidate = candidates[np.argmax(combined_efficiency[candidates])]\n                temp_weight = current_weight - weight_lst[i] + weight_lst[best_candidate]\n                if temp_weight <= capacity:\n                    new_solution[i] = 0\n                    new_solution[best_candidate] = 1\n                    current_weight = temp_weight\n        else:\n            # Find best item to add (higher efficiency)\n            candidates = np.where(new_solution == 1)[0]\n            if len(candidates) > 0:\n                worst_item = candidates[np.argmin(combined_efficiency[candidates])]\n                temp_weight = current_weight + weight_lst[i] - weight_lst[worst_item]\n                if temp_weight <= capacity:\n                    new_solution[i] = 1\n                    new_solution[worst_item] = 0\n                    current_weight = temp_weight\n\n    # Probabilistic swap based on efficiency difference\n    if len(new_solution) >= 2:\n        idx1, idx2 = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[idx1] == 1 and new_solution[idx2] == 0:\n            efficiency_diff = combined_efficiency[idx2] - combined_efficiency[idx1]\n            if np.random.rand() < 0.3 + 0.7 * (efficiency_diff / np.max(combined_efficiency)):\n                temp_weight = current_weight + weight_lst[idx2] - weight_lst[idx1]\n                if temp_weight <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.31153252707626367,
            2.021637886762619
        ],
        "raw_score": [
            38.00906903682558,
            33.97037578249417
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    archive.sort(key=lambda x: -(0.7*x[1][0] + 0.3*x[1][1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n\n    # Calculate item efficiency for both objectives\n    efficiency1 = value1_lst / weight_lst\n    efficiency2 = value2_lst / weight_lst\n    combined_efficiency = 0.7 * efficiency1 + 0.3 * efficiency2\n\n    # Try replacing items with higher efficiency\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Find best item to replace with (not in solution)\n            candidates = np.where(new_solution == 0)[0]\n            if len(candidates) > 0:\n                best_candidate = candidates[np.argmax(combined_efficiency[candidates])]\n                temp_weight = current_weight - weight_lst[i] + weight_lst[best_candidate]\n                if temp_weight <= capacity:\n                    new_solution[i] = 0\n                    new_solution[best_candidate] = 1\n                    current_weight = temp_weight\n        else:\n            # Find best item to add (higher efficiency)\n            candidates = np.where(new_solution == 1)[0]\n            if len(candidates) > 0:\n                worst_item = candidates[np.argmin(combined_efficiency[candidates])]\n                temp_weight = current_weight + weight_lst[i] - weight_lst[worst_item]\n                if temp_weight <= capacity:\n                    new_solution[i] = 1\n                    new_solution[worst_item] = 0\n                    current_weight = temp_weight\n\n    # Probabilistic swap based on efficiency difference\n    if len(new_solution) >= 2:\n        idx1, idx2 = np.random.choice(len(new_solution), 2, replace=False)\n        if new_solution[idx1] == 1 and new_solution[idx2] == 0:\n            efficiency_diff = combined_efficiency[idx2] - combined_efficiency[idx1]\n            if np.random.rand() < 0.3 + 0.7 * (efficiency_diff / np.max(combined_efficiency)):\n                temp_weight = current_weight + weight_lst[idx2] - weight_lst[idx1]\n                if temp_weight <= capacity:\n                    new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 2 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a balanced solution from the archive (prioritizing those with high combined objective product) and applies a hybrid local search combining weighted item addition, adaptive swapping, and probabilistic flipping, while dynamically adjusting weights based on solution quality and ensuring feasibility through capacity checks. It emphasizes objective-aware selection (using weighted value metrics) and diversity maintenance (through probabilistic flips), creating a balance between exploration and exploitation. The key design focuses on adaptive weights, combined value metrics, and solution quality-aware operations to improve multi-objective performance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: **Keywords**:\n- **Adaptive weighting**, **novelty-aware selection**, **feasibility-aware operations**, **Pareto-front navigation**.\n\n**Advice**:\n1. Use dynamic weights to balance objectives during selection.\n2. Prioritize high-marginal items in swaps/flips to maximize improvements.\n3. Combine novelty-driven swaps with probabilistic flips.\n4. Strictly enforce feasibility at every step.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or violating capacity constraints.\n\n**Explanation**:\nAdaptive weights guide selection toward high-potential regions, while novelty-aware swaps ensure diverse exploration. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 31,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high marginal potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1] / (np.sum(weight_lst * x[0]) + 1e-8)))\n    selected_idx = min(len(archive) // 4, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights based on marginal contributions\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Novelty-aware swap: prioritize items with high marginal gain\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Calculate marginal gains for in-items\n        marginal_gain1_in = value1_lst[in_items] / (weight_lst[in_items] + 1e-8)\n        marginal_gain2_in = value2_lst[in_items] / (weight_lst[in_items] + 1e-8)\n        combined_gain_in = weight1 * marginal_gain1_in + weight2 * marginal_gain2_in\n\n        # Calculate marginal gains for out-items\n        marginal_gain1_out = value1_lst[out_items] / (weight_lst[out_items] + 1e-8)\n        marginal_gain2_out = value2_lst[out_items] / (weight_lst[out_items] + 1e-8)\n        combined_gain_out = weight1 * marginal_gain1_out + weight2 * marginal_gain2_out\n\n        # Select best in-item to remove and best out-item to add\n        best_in = in_items[np.argmin(combined_gain_in)]\n        best_out = out_items[np.argmax(combined_gain_out)]\n\n        # Check if swap maintains feasibility\n        if current_weight - weight_lst[best_in] + weight_lst[best_out] <= capacity:\n            new_solution[best_in] = 0\n            new_solution[best_out] = 1\n\n    # Probabilistic flip with adaptive probability\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.5\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    # Additional novelty: swap two items if they show high complementary potential\n    if len(in_items) >= 2 and np.random.random() < 0.4:\n        i, j = np.random.choice(in_items, 2, replace=False)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8318701054426578,
            0.4706156551837921
        ],
        "raw_score": [
            34.285522532194804,
            34.835229201877596
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high marginal potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1] / (np.sum(weight_lst * x[0]) + 1e-8)))\n    selected_idx = min(len(archive) // 4, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights based on marginal contributions\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Novelty-aware swap: prioritize items with high marginal gain\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Calculate marginal gains for in-items\n        marginal_gain1_in = value1_lst[in_items] / (weight_lst[in_items] + 1e-8)\n        marginal_gain2_in = value2_lst[in_items] / (weight_lst[in_items] + 1e-8)\n        combined_gain_in = weight1 * marginal_gain1_in + weight2 * marginal_gain2_in\n\n        # Calculate marginal gains for out-items\n        marginal_gain1_out = value1_lst[out_items] / (weight_lst[out_items] + 1e-8)\n        marginal_gain2_out = value2_lst[out_items] / (weight_lst[out_items] + 1e-8)\n        combined_gain_out = weight1 * marginal_gain1_out + weight2 * marginal_gain2_out\n\n        # Select best in-item to remove and best out-item to add\n        best_in = in_items[np.argmin(combined_gain_in)]\n        best_out = out_items[np.argmax(combined_gain_out)]\n\n        # Check if swap maintains feasibility\n        if current_weight - weight_lst[best_in] + weight_lst[best_out] <= capacity:\n            new_solution[best_in] = 0\n            new_solution[best_out] = 1\n\n    # Probabilistic flip with adaptive probability\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.5\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    # Additional novelty: swap two items if they show high complementary potential\n    if len(in_items) >= 2 and np.random.random() < 0.4:\n        i, j = np.random.choice(in_items, 2, replace=False)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe heuristic selects a balanced solution from the archive, then applies a hybrid local search combining targeted swaps (prioritizing high-value items), probabilistic flips, feasibility checks, and greedy additions of valuable items. It dynamically adjusts weights based on current solution quality and ensures feasibility through intelligent item removals and additions. The approach balances exploration and exploitation while maintaining Pareto optimality potential.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Targeted swapping based on adaptive weights\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                current_weight = temp_weight\n\n    # Step 2: Random flip with probability based on solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and n_items > 0:\n        flip_idx = np.random.choice(n_items)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Step 3: Ensure feasibility by removing the least valuable items if needed\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    # Step 4: Add the most valuable available items if there's remaining capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        add_idx = available_items[np.argmax(weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm employs a hybrid selection strategy that prioritizes solutions with high value diversity, combining dynamic objective weighting with a multi-stage local search that includes value-driven item insertion, adaptive swapping, and probabilistic flipping to balance exploration and exploitation while ensuring feasibility. It dynamically adjusts flip probabilities based on the solution's Pareto dominance and focuses on improving value trade-offs through weighted value ratios and complementary item selections.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: prioritize solutions with high value diversity and potential for improvement\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 4, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item selection: prioritize items that create balanced value improvements\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-2:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:1]]\n        if len(worst_items) > 0:\n            idx = worst_items[0]\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n\n    # Dynamic exploration: probabilistic flip with value-aware probability\n    flip_prob = 0.1 + 0.4 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high value potential for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            **Keywords**:\n- **Adaptive weighting**, **novelty-aware selection**, **feasibility-aware operations**, **Pareto-front navigation**.\n\n**Advice**:\n1. Use dynamic weights to balance objectives during selection.\n2. Prioritize high-marginal items in swaps/flips to maximize improvements.\n3. Combine novelty-driven swaps with probabilistic flips.\n4. Strictly enforce feasibility at every step.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or violating capacity constraints.\n\n**Explanation**:\nAdaptive weights guide selection toward high-potential regions, while novelty-aware swaps ensure diverse exploration. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 32,
        "algorithm": "The algorithm combines dynamic Pareto-front navigation with a hybrid local search strategy, prioritizing items with high marginal improvements in both objectives while strictly enforcing capacity constraints. It selects solutions from the archive based on their combined objective values, then applies probabilistic flipping, feasibility-preserving swaps, and greedy additions of high-value items, using adaptive objective weights to balance the two objectives. The method ensures feasibility at every step while aiming to improve Pareto optimality through value-aware selection and marginal improvement scoring.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest Pareto-front potential\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on Pareto dominance\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / (total_value1 + 1e-6)\n    weight2 = current_value2 / (total_value2 + 1e-6)\n    norm_factor = weight1 + weight2 + 1e-6\n    weight1 /= norm_factor\n    weight2 /= norm_factor\n\n    # Novelty-aware item selection\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    # Step 1: Probabilistic flipping with value-aware probabilities\n    flip_prob = 0.2 + 0.6 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(in_solution) > 0:\n        flip_candidates = in_solution[np.argsort(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])[:2]]\n        for idx in flip_candidates:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Step 2: Feasibility-preserving swaps with high marginal improvement\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Calculate marginal improvement scores\n        marginal_scores = []\n        for out_idx in out_solution:\n            if current_weight + weight_lst[out_idx] > capacity:\n                marginal_scores.append(-1)\n                continue\n            for in_idx in in_solution:\n                if current_weight - weight_lst[in_idx] + weight_lst[out_idx] > capacity:\n                    continue\n                score = (weight1 * (value1_lst[out_idx] - value1_lst[in_idx]) +\n                         weight2 * (value2_lst[out_idx] - value2_lst[in_idx]))\n                marginal_scores.append(score)\n\n        if marginal_scores and max(marginal_scores) > 0:\n            best_swap = np.argmax(marginal_scores)\n            out_idx = out_solution[best_swap % len(out_solution)]\n            in_idx = in_solution[best_swap // len(out_solution)]\n            new_solution[out_idx] = 1\n            new_solution[in_idx] = 0\n            current_weight = current_weight - weight_lst[in_idx] + weight_lst[out_idx]\n\n    # Step 3: Add most valuable items if capacity allows\n    while current_weight < capacity and len(out_solution) > 0:\n        add_idx = out_solution[np.argmax(weight1 * value1_lst[out_solution] + weight2 * value2_lst[out_solution])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            out_solution = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8044055373617649,
            10.368222415447235
        ],
        "raw_score": [
            28.984090062303395,
            29.691416268189226
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest Pareto-front potential\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on Pareto dominance\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / (total_value1 + 1e-6)\n    weight2 = current_value2 / (total_value2 + 1e-6)\n    norm_factor = weight1 + weight2 + 1e-6\n    weight1 /= norm_factor\n    weight2 /= norm_factor\n\n    # Novelty-aware item selection\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    # Step 1: Probabilistic flipping with value-aware probabilities\n    flip_prob = 0.2 + 0.6 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(in_solution) > 0:\n        flip_candidates = in_solution[np.argsort(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])[:2]]\n        for idx in flip_candidates:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Step 2: Feasibility-preserving swaps with high marginal improvement\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Calculate marginal improvement scores\n        marginal_scores = []\n        for out_idx in out_solution:\n            if current_weight + weight_lst[out_idx] > capacity:\n                marginal_scores.append(-1)\n                continue\n            for in_idx in in_solution:\n                if current_weight - weight_lst[in_idx] + weight_lst[out_idx] > capacity:\n                    continue\n                score = (weight1 * (value1_lst[out_idx] - value1_lst[in_idx]) +\n                         weight2 * (value2_lst[out_idx] - value2_lst[in_idx]))\n                marginal_scores.append(score)\n\n        if marginal_scores and max(marginal_scores) > 0:\n            best_swap = np.argmax(marginal_scores)\n            out_idx = out_solution[best_swap % len(out_solution)]\n            in_idx = in_solution[best_swap // len(out_solution)]\n            new_solution[out_idx] = 1\n            new_solution[in_idx] = 0\n            current_weight = current_weight - weight_lst[in_idx] + weight_lst[out_idx]\n\n    # Step 3: Add most valuable items if capacity allows\n    while current_weight < capacity and len(out_solution) > 0:\n        add_idx = out_solution[np.argmax(weight1 * value1_lst[out_solution] + weight2 * value2_lst[out_solution])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            out_solution = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a balanced solution from the archive (prioritizing those with high combined objective product) and applies a hybrid local search combining weighted item addition, adaptive swapping, and probabilistic flipping, while dynamically adjusting weights based on solution quality and ensuring feasibility through capacity checks. It emphasizes objective-aware selection (using weighted value metrics) and diversity maintenance (through probabilistic flips), creating a balance between exploration and exploitation. The key design focuses on adaptive weights, combined value metrics, and solution quality-aware operations to improve multi-objective performance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm employs a hybrid selection strategy that prioritizes solutions with high value diversity, combining dynamic objective weighting with a multi-stage local search that includes value-driven item insertion, adaptive swapping, and probabilistic flipping to balance exploration and exploitation while ensuring feasibility. It dynamically adjusts flip probabilities based on the solution's Pareto dominance and focuses on improving value trade-offs through weighted value ratios and complementary item selections.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: prioritize solutions with high value diversity and potential for improvement\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 4, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item selection: prioritize items that create balanced value improvements\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-2:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:1]]\n        if len(worst_items) > 0:\n            idx = worst_items[0]\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n\n    # Dynamic exploration: probabilistic flip with value-aware probability\n    flip_prob = 0.1 + 0.4 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high value potential for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            **Keywords**:\n- **Adaptive weighting**, **novelty-aware selection**, **feasibility-aware operations**, **Pareto-front navigation**.\n\n**Advice**:\n1. Use dynamic weights to balance objectives during selection.\n2. Prioritize high-marginal items in swaps/flips to maximize improvements.\n3. Combine novelty-driven swaps with probabilistic flips.\n4. Strictly enforce feasibility at every step.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or violating capacity constraints.\n\n**Explanation**:\nAdaptive weights guide selection toward high-potential regions, while novelty-aware swaps ensure diverse exploration. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 33,
        "algorithm": "The algorithm prioritizes high-marginal item insertions (weighted by adaptive objective trade-offs) and dynamic swaps of poorly trading items, while occasionally flipping low-novelty items probabilistically to balance exploration and exploitation, all while strictly maintaining feasibility. It selects promising solutions from the archive based on combined value diversity and Pareto dominance, dynamically adjusting weights to guide search toward high-quality regions of the objective space.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Novelty-aware selection: prioritize solutions with high Pareto dominance and value diversity\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 4, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting based on marginal improvements\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # High-marginal item insertion\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate marginal improvement scores\n        marginal_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                marginal_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            marginal_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest marginal scores\n        top_items = potential_items[np.argsort(marginal_scores)[-2:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Dynamic trade-off swapping\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:1]]\n        if len(worst_items) > 0:\n            idx = worst_items[0]\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n\n    # Novelty-driven probabilistic flip\n    flip_prob = 0.1 + 0.4 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with low novelty for flipping\n        novelty_scores = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                novelty = (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n                novelty_scores.append(novelty)\n            else:\n                novelty_scores.append(0)\n\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = flip_candidates[np.argmin(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8878045321651186,
            0.5914353430271149
        ],
        "raw_score": [
            27.693213380810533,
            27.794824871374686
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Novelty-aware selection: prioritize solutions with high Pareto dominance and value diversity\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 4, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting based on marginal improvements\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # High-marginal item insertion\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate marginal improvement scores\n        marginal_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                marginal_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            marginal_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest marginal scores\n        top_items = potential_items[np.argsort(marginal_scores)[-2:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Dynamic trade-off swapping\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:1]]\n        if len(worst_items) > 0:\n            idx = worst_items[0]\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n\n    # Novelty-driven probabilistic flip\n    flip_prob = 0.1 + 0.4 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with low novelty for flipping\n        novelty_scores = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                novelty = (value1_lst[i] + value2_lst[i]) / (weight_lst[i] + 1e-6)\n                novelty_scores.append(novelty)\n            else:\n                novelty_scores.append(0)\n\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            flip_idx = flip_candidates[np.argmin(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm employs a hybrid selection strategy that prioritizes solutions with high value diversity, combining dynamic objective weighting with a multi-stage local search that includes value-driven item insertion, adaptive swapping, and probabilistic flipping to balance exploration and exploitation while ensuring feasibility. It dynamically adjusts flip probabilities based on the solution's Pareto dominance and focuses on improving value trade-offs through weighted value ratios and complementary item selections.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: prioritize solutions with high value diversity and potential for improvement\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 4, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item selection: prioritize items that create balanced value improvements\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-2:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:1]]\n        if len(worst_items) > 0:\n            idx = worst_items[0]\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n\n    # Dynamic exploration: probabilistic flip with value-aware probability\n    flip_prob = 0.1 + 0.4 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high value potential for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 34,
        "algorithm": "This algorithm implements a multi-phase local search for the bi-objective knapsack problem, combining value-balanced insertion, complementary item swapping, and probabilistic diversification while dynamically adjusting objective weights based on solution value ratios. It prioritizes items with higher normalized value scores (weighted by current value balance) and selectively removes low-contribution items to maintain feasibility and explore diverse solutions. The adaptive weighting and phased approach ensure both objectives are considered while preserving solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection based on value diversity and dominance\n    archive.sort(key=lambda x: -(x[1][0] * 0.7 + x[1][1] * 0.3))\n    selection_index = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selection_index][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting based on solution's value balance\n    value_ratio = current_value1 / (current_value2 + 1e-6)\n    weight1 = 1 / (1 + np.exp(-value_ratio + 1))\n    weight2 = 1 - weight1\n\n    # Phase 1: Value-balanced insertion\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate normalized value scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            norm_value1 = value1_lst[item] / (np.max(value1_lst) + 1e-6)\n            norm_value2 = value2_lst[item] / (np.max(value2_lst) + 1e-6)\n            value_scores.append(weight1 * norm_value1 + weight2 * norm_value2)\n\n        # Select top 3 items\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Phase 2: Complementary item swapping\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate complementarity scores\n        complement_scores = []\n        for i in in_solution:\n            comp_score = (value1_lst[i] * value2_lst[i]) / (current_value1 * current_value2 + 1e-6)\n            complement_scores.append(comp_score)\n\n        # Select items with lowest complementarity\n        worst_items = in_solution[np.argsort(complement_scores)[:2]]\n        for idx in worst_items:\n            # Find best complementary item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    comp_score = (value1_lst[item] * value2_lst[item]) / (current_value1 * current_value2 + 1e-6)\n                    if comp_score > best_score:\n                        best_score = comp_score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n\n    # Phase 3: Probabilistic diversification\n    div_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (np.sum(value1_lst) + np.sum(value2_lst)))\n    if np.random.random() < div_prob and len(new_solution) > 0:\n        # Select items for potential removal based on value contribution\n        removal_candidates = np.where(new_solution == 1)[0]\n        if len(removal_candidates) > 0:\n            contrib_scores = []\n            for i in removal_candidates:\n                contrib = (value1_lst[i] + value2_lst[i]) / (current_value1 + current_value2 + 1e-6)\n                contrib_scores.append(contrib)\n\n            remove_idx = removal_candidates[np.argmin(contrib_scores)]\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8475144332840423,
            1.2942690551280975
        ],
        "raw_score": [
            31.811325687687617,
            32.37180155520954
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection based on value diversity and dominance\n    archive.sort(key=lambda x: -(x[1][0] * 0.7 + x[1][1] * 0.3))\n    selection_index = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selection_index][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting based on solution's value balance\n    value_ratio = current_value1 / (current_value2 + 1e-6)\n    weight1 = 1 / (1 + np.exp(-value_ratio + 1))\n    weight2 = 1 - weight1\n\n    # Phase 1: Value-balanced insertion\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate normalized value scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            norm_value1 = value1_lst[item] / (np.max(value1_lst) + 1e-6)\n            norm_value2 = value2_lst[item] / (np.max(value2_lst) + 1e-6)\n            value_scores.append(weight1 * norm_value1 + weight2 * norm_value2)\n\n        # Select top 3 items\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Phase 2: Complementary item swapping\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate complementarity scores\n        complement_scores = []\n        for i in in_solution:\n            comp_score = (value1_lst[i] * value2_lst[i]) / (current_value1 * current_value2 + 1e-6)\n            complement_scores.append(comp_score)\n\n        # Select items with lowest complementarity\n        worst_items = in_solution[np.argsort(complement_scores)[:2]]\n        for idx in worst_items:\n            # Find best complementary item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    comp_score = (value1_lst[item] * value2_lst[item]) / (current_value1 * current_value2 + 1e-6)\n                    if comp_score > best_score:\n                        best_score = comp_score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n\n    # Phase 3: Probabilistic diversification\n    div_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (np.sum(value1_lst) + np.sum(value2_lst)))\n    if np.random.random() < div_prob and len(new_solution) > 0:\n        # Select items for potential removal based on value contribution\n        removal_candidates = np.where(new_solution == 1)[0]\n        if len(removal_candidates) > 0:\n            contrib_scores = []\n            for i in removal_candidates:\n                contrib = (value1_lst[i] + value2_lst[i]) / (current_value1 + current_value2 + 1e-6)\n                contrib_scores.append(contrib)\n\n            remove_idx = removal_candidates[np.argmin(contrib_scores)]\n            new_solution[remove_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm employs a hybrid selection strategy that prioritizes solutions with high value diversity, combining dynamic objective weighting with a multi-stage local search that includes value-driven item insertion, adaptive swapping, and probabilistic flipping to balance exploration and exploitation while ensuring feasibility. It dynamically adjusts flip probabilities based on the solution's Pareto dominance and focuses on improving value trade-offs through weighted value ratios and complementary item selections.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: prioritize solutions with high value diversity and potential for improvement\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 4, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item selection: prioritize items that create balanced value improvements\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-2:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:1]]\n        if len(worst_items) > 0:\n            idx = worst_items[0]\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n\n    # Dynamic exploration: probabilistic flip with value-aware probability\n    flip_prob = 0.1 + 0.4 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high value potential for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 35,
        "algorithm": "The algorithm implements a multi-stage local search strategy that prioritizes value-driven item addition using dynamic objective weighting, removes dominated items to improve solution quality, and incorporates probabilistic exploration to maintain diversity while ensuring feasibility. It balances exploitation and exploration by adaptively adjusting flip probabilities based on current solution value ratios and contributions. The approach ensures solutions remain feasible by checking capacity constraints during item additions and removals.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined value\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's value ratios\n    ratio1 = current_value1 / (np.sum(value1_lst) + 1e-6)\n    ratio2 = current_value2 / (np.sum(value2_lst) + 1e-6)\n    weight1 = ratio1 * (1 - ratio1)\n    weight2 = ratio2 * (1 - ratio2)\n\n    # Value-driven item addition: prioritize items that maximize weighted value sum\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(-np.inf)\n                continue\n            weighted_value = weight1 * value1_lst[item] + weight2 * value2_lst[item]\n            value_scores.append(weighted_value)\n\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Dominance-aware item removal: remove items that are dominated in value space\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        dominated_items = []\n        for i in in_solution:\n            dominated = False\n            for j in in_solution:\n                if i != j and value1_lst[i] <= value1_lst[j] and value2_lst[i] <= value2_lst[j] and (value1_lst[i] < value1_lst[j] or value2_lst[i] < value2_lst[j]):\n                    dominated = True\n                    break\n            if dominated:\n                dominated_items.append(i)\n\n        if dominated_items:\n            remove_idx = np.random.choice(dominated_items)\n            new_solution[remove_idx] = 0\n\n    # Probabilistic exploration: flip items with low value contribution\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (np.sum(value1_lst) + np.sum(value2_lst) + 1e-6))\n    if np.random.random() < flip_prob and len(in_solution) > 0:\n        value_contributions = []\n        for i in in_solution:\n            contrib1 = value1_lst[i] / (current_value1 + 1e-6)\n            contrib2 = value2_lst[i] / (current_value2 + 1e-6)\n            value_contributions.append(weight1 * contrib1 + weight2 * contrib2)\n\n        flip_candidates = in_solution[np.argsort(value_contributions)[:2]]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8310383235613157,
            0.9968627393245697
        ],
        "raw_score": [
            27.28744862354839,
            28.254693526369042
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined value\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's value ratios\n    ratio1 = current_value1 / (np.sum(value1_lst) + 1e-6)\n    ratio2 = current_value2 / (np.sum(value2_lst) + 1e-6)\n    weight1 = ratio1 * (1 - ratio1)\n    weight2 = ratio2 * (1 - ratio2)\n\n    # Value-driven item addition: prioritize items that maximize weighted value sum\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(-np.inf)\n                continue\n            weighted_value = weight1 * value1_lst[item] + weight2 * value2_lst[item]\n            value_scores.append(weighted_value)\n\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Dominance-aware item removal: remove items that are dominated in value space\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        dominated_items = []\n        for i in in_solution:\n            dominated = False\n            for j in in_solution:\n                if i != j and value1_lst[i] <= value1_lst[j] and value2_lst[i] <= value2_lst[j] and (value1_lst[i] < value1_lst[j] or value2_lst[i] < value2_lst[j]):\n                    dominated = True\n                    break\n            if dominated:\n                dominated_items.append(i)\n\n        if dominated_items:\n            remove_idx = np.random.choice(dominated_items)\n            new_solution[remove_idx] = 0\n\n    # Probabilistic exploration: flip items with low value contribution\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (np.sum(value1_lst) + np.sum(value2_lst) + 1e-6))\n    if np.random.random() < flip_prob and len(in_solution) > 0:\n        value_contributions = []\n        for i in in_solution:\n            contrib1 = value1_lst[i] / (current_value1 + 1e-6)\n            contrib2 = value2_lst[i] / (current_value2 + 1e-6)\n            value_contributions.append(weight1 * contrib1 + weight2 * contrib2)\n\n        flip_candidates = in_solution[np.argsort(value_contributions)[:2]]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm employs a hybrid selection strategy that prioritizes solutions with high value diversity, combining dynamic objective weighting with a multi-stage local search that includes value-driven item insertion, adaptive swapping, and probabilistic flipping to balance exploration and exploitation while ensuring feasibility. It dynamically adjusts flip probabilities based on the solution's Pareto dominance and focuses on improving value trade-offs through weighted value ratios and complementary item selections.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: prioritize solutions with high value diversity and potential for improvement\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 4, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item selection: prioritize items that create balanced value improvements\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-2:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:1]]\n        if len(worst_items) > 0:\n            idx = worst_items[0]\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n\n    # Dynamic exploration: probabilistic flip with value-aware probability\n    flip_prob = 0.1 + 0.4 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high value potential for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            **Keywords**:\n- **Adaptive weighting**, **novelty-aware selection**, **feasibility-aware operations**, **Pareto-front navigation**.\n\n**Advice**:\n1. Use dynamic weights to balance objectives during selection.\n2. Prioritize high-marginal items in swaps/flips to maximize improvements.\n3. Combine novelty-driven swaps with probabilistic flips.\n4. Strictly enforce feasibility at every step.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or violating capacity constraints.\n\n**Explanation**:\nAdaptive weights guide selection toward high-potential regions, while novelty-aware swaps ensure diverse exploration. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 36,
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with high potential for improvement, calculated as the sum of normalized objectives while considering Pareto dominance. It then applies a hybrid local search operator that combines value-driven item insertion, adaptive swapping based on trade-off scores, and probabilistic flips to maintain diversity, while strictly enforcing feasibility constraints. The method dynamically adjusts flip probabilities and prioritizes items with high marginal improvement, ensuring the generated neighbor solution is always valid and potentially Pareto-optimal.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance scores for each solution\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] > obj[0] and other_obj[1] >= obj[1]:\n                dominated += 1\n            elif other_obj[0] >= obj[0] and other_obj[1] > obj[1]:\n                dominated += 1\n        dominance_scores.append(-dominated)  # Negative for sorting\n\n    # Select solution with best balance of high potential and low dominance\n    archive_with_scores = list(zip(archive, dominance_scores))\n    archive_with_scores.sort(key=lambda x: (x[1], -(x[0][1][0] + x[0][1][1])))\n    base_solution = archive_with_scores[0][0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item insertion: prioritize items with high marginal improvement\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items to improve value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select worst items for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        for idx in worst_items:\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n                current_weight = current_weight - weight_lst[idx] + weight_lst[best_swap]\n\n    # Novelty-aware probabilistic flip\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with lowest value contribution for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Random swap for additional exploration\n    if np.random.random() < 0.3 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8365705891906257,
            0.9932917952537537
        ],
        "raw_score": [
            27.295871231883734,
            27.95607664413201
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance scores for each solution\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] > obj[0] and other_obj[1] >= obj[1]:\n                dominated += 1\n            elif other_obj[0] >= obj[0] and other_obj[1] > obj[1]:\n                dominated += 1\n        dominance_scores.append(-dominated)  # Negative for sorting\n\n    # Select solution with best balance of high potential and low dominance\n    archive_with_scores = list(zip(archive, dominance_scores))\n    archive_with_scores.sort(key=lambda x: (x[1], -(x[0][1][0] + x[0][1][1])))\n    base_solution = archive_with_scores[0][0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item insertion: prioritize items with high marginal improvement\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items to improve value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select worst items for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        for idx in worst_items:\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n                current_weight = current_weight - weight_lst[idx] + weight_lst[best_swap]\n\n    # Novelty-aware probabilistic flip\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with lowest value contribution for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Random swap for additional exploration\n    if np.random.random() < 0.3 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 2 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a balanced solution from the archive (prioritizing those with high combined objective product) and applies a hybrid local search combining weighted item addition, adaptive swapping, and probabilistic flipping, while dynamically adjusting weights based on solution quality and ensuring feasibility through capacity checks. It emphasizes objective-aware selection (using weighted value metrics) and diversity maintenance (through probabilistic flips), creating a balance between exploration and exploitation. The key design focuses on adaptive weights, combined value metrics, and solution quality-aware operations to improve multi-objective performance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: **Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 37,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined normalized potential\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with adaptive weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with adaptive local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Marginal item replacement\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Calculate marginal contributions\n        in_marginals = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n        out_marginals = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n\n        # Replace worst in-item with best out-item if feasible\n        worst_in = in_items[np.argmin(in_marginals)]\n        best_out = out_items[np.argmax(out_marginals)]\n\n        if total_weight - weight_lst[worst_in] + weight_lst[best_out] <= capacity:\n            new_solution[worst_in] = 0\n            new_solution[best_out] = 1\n            total_weight = total_weight - weight_lst[worst_in] + weight_lst[best_out]\n\n    # Phase 2: Objective-biased swaps\n    if len(in_items) >= 2 and random.random() < 0.6:\n        # Calculate objective-specific marginals\n        value1_marginals = value1_lst[in_items] / weight_lst[in_items]\n        value2_marginals = value2_lst[in_items] / weight_lst[in_items]\n\n        # Select items with low marginals in one objective\n        if random.random() < 0.5:\n            # Focus on value1 improvement\n            low_value1 = in_items[np.argsort(value1_marginals)[:2]]\n        else:\n            # Focus on value2 improvement\n            low_value1 = in_items[np.argsort(value2_marginals)[:2]]\n\n        # Find best out-item for swap\n        if len(out_items) > 0:\n            out_marginals = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n            best_out = out_items[np.argmax(out_marginals)]\n\n            # Perform swap if feasible\n            if total_weight - weight_lst[low_value1[0]] + weight_lst[best_out] <= capacity:\n                new_solution[low_value1[0]] = 0\n                new_solution[best_out] = 1\n                total_weight = total_weight - weight_lst[low_value1[0]] + weight_lst[best_out]\n\n    # Phase 3: Probabilistic flips with objective bias\n    flip_prob = 0.3 if (np.sum(value1_lst * new_solution) + np.sum(value2_lst * new_solution)) / (max_value1 + max_value2) > 0.7 else 0.5\n    if random.random() < flip_prob:\n        if random.random() < 0.5 and len(in_items) > 0:\n            # Remove low-marginal item\n            marginals = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n            idx = in_items[np.argmin(marginals)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        elif len(out_items) > 0:\n            # Add high-marginal item\n            marginals = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n            idx = out_items[np.argmax(marginals)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9019376134198027,
            0.39216312766075134
        ],
        "raw_score": [
            27.423485354036217,
            27.702511738711678
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined normalized potential\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with adaptive weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with adaptive local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Marginal item replacement\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Calculate marginal contributions\n        in_marginals = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n        out_marginals = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n\n        # Replace worst in-item with best out-item if feasible\n        worst_in = in_items[np.argmin(in_marginals)]\n        best_out = out_items[np.argmax(out_marginals)]\n\n        if total_weight - weight_lst[worst_in] + weight_lst[best_out] <= capacity:\n            new_solution[worst_in] = 0\n            new_solution[best_out] = 1\n            total_weight = total_weight - weight_lst[worst_in] + weight_lst[best_out]\n\n    # Phase 2: Objective-biased swaps\n    if len(in_items) >= 2 and random.random() < 0.6:\n        # Calculate objective-specific marginals\n        value1_marginals = value1_lst[in_items] / weight_lst[in_items]\n        value2_marginals = value2_lst[in_items] / weight_lst[in_items]\n\n        # Select items with low marginals in one objective\n        if random.random() < 0.5:\n            # Focus on value1 improvement\n            low_value1 = in_items[np.argsort(value1_marginals)[:2]]\n        else:\n            # Focus on value2 improvement\n            low_value1 = in_items[np.argsort(value2_marginals)[:2]]\n\n        # Find best out-item for swap\n        if len(out_items) > 0:\n            out_marginals = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n            best_out = out_items[np.argmax(out_marginals)]\n\n            # Perform swap if feasible\n            if total_weight - weight_lst[low_value1[0]] + weight_lst[best_out] <= capacity:\n                new_solution[low_value1[0]] = 0\n                new_solution[best_out] = 1\n                total_weight = total_weight - weight_lst[low_value1[0]] + weight_lst[best_out]\n\n    # Phase 3: Probabilistic flips with objective bias\n    flip_prob = 0.3 if (np.sum(value1_lst * new_solution) + np.sum(value2_lst * new_solution)) / (max_value1 + max_value2) > 0.7 else 0.5\n    if random.random() < flip_prob:\n        if random.random() < 0.5 and len(in_items) > 0:\n            # Remove low-marginal item\n            marginals = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n            idx = in_items[np.argmin(marginals)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        elif len(out_items) > 0:\n            # Add high-marginal item\n            marginals = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n            idx = out_items[np.argmax(marginals)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives using a novelty-aware selection\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting with novelty factor\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) * (1 - (current_value1 / total_value1)) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) * (1 - (current_value2 / total_value2)) if total_value2 > 0 else 0.5\n\n    # Novelty-driven item selection: prioritize items that create \"novel\" value combinations\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate novelty scores based on value ratios and current solution's coverage\n        novelty_scores = []\n        for item in potential_items:\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            novelty = abs(ratio1 - ratio2) * (1 - min(ratio1, ratio2))\n            novelty_scores.append(novelty)\n\n        # Select top items with highest novelty and feasible addition\n        novelty_scores = np.array(novelty_scores)\n        top_items = potential_items[np.argsort(novelty_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Context-aware swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        if len(worst_items) == 2:\n            idx1, idx2 = worst_items\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Dynamic exploration: probabilistic flip with novelty-based probability\n    flip_prob = 0.2 + 0.6 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using dynamic objective weighting, then applies a hybrid local search that removes the least novel item (based on value ratio balance) and adds the most valuable item (weighted by current objective priorities) while ensuring feasibility. It also includes probabilistic flipping of items with high potential improvement, prioritizing objectives that are currently underrepresented.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution using dynamic objective weighting to prioritize underrepresented objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -(x[1][0] / total_value1 + x[1][1] / total_value2))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: novelty-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate novelty scores for items in solution\n        novelty_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            novelty_scores.append(abs(ratio1 - ratio2))\n\n        # Select least novel item for potential removal\n        least_novel_idx = in_solution[np.argmin(novelty_scores)]\n\n        # Calculate potential additions with weighted value metric\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        best_add_idx = potential_items[np.argmax(combined_values)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[least_novel_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[least_novel_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with objective-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            **Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 38,
        "algorithm": "The algorithm combines dynamic objective weighting with cluster-based local search and novelty-aware flips to generate high-quality neighbors in the BI-KP. It prioritizes solutions with underrepresented objectives, identifies item clusters with balanced trade-offs, and replaces them with high-marginal-value items from the archive, while probabilistically flipping items based on novelty scores to explore promising regions of the search space. The method ensures feasibility through adaptive capacity checks and maintains diversity by favoring less-explored solution regions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using dynamic objective weighting to prioritize underrepresented objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -(x[1][0] / total_value1 + x[1][1] / total_value2))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Cluster-based local search: identify item clusters with balanced trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            tradeoff_scores.append(abs(ratio1 - ratio2))\n\n        # Identify clusters of items with similar trade-offs\n        from sklearn.cluster import KMeans\n        if len(in_solution) >= 3:\n            k = min(3, len(in_solution) // 2)\n            clusters = KMeans(n_clusters=k).fit_predict(np.array(tradeoff_scores).reshape(-1, 1))\n            cluster_sizes = np.bincount(clusters)\n\n            # Select largest cluster for potential replacement\n            target_cluster = np.argmax(cluster_sizes)\n            cluster_items = in_solution[clusters == target_cluster]\n\n            # Calculate potential replacements from archive\n            archive_items = np.where(np.logical_and.reduce([archive[selected_idx][0] == 1, new_solution == 0]))[0]\n            if len(archive_items) > 0:\n                combined_values = (weight1 * value1_lst[archive_items] + weight2 * value2_lst[archive_items]) / weight_lst[archive_items]\n                best_add_idx = archive_items[np.argmax(combined_values)]\n\n                # Replace entire cluster if feasible\n                cluster_weight = np.sum(weight_lst[cluster_items])\n                temp_weight = current_weight - cluster_weight + weight_lst[best_add_idx]\n                if temp_weight <= capacity:\n                    new_solution[cluster_items] = 0\n                    new_solution[best_add_idx] = 1\n                    current_weight = temp_weight\n\n    # Probabilistic flip with novelty-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9335947603633915,
            2.247350037097931
        ],
        "raw_score": [
            27.71830632631996,
            27.980116193784617
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using dynamic objective weighting to prioritize underrepresented objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -(x[1][0] / total_value1 + x[1][1] / total_value2))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Cluster-based local search: identify item clusters with balanced trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            tradeoff_scores.append(abs(ratio1 - ratio2))\n\n        # Identify clusters of items with similar trade-offs\n        from sklearn.cluster import KMeans\n        if len(in_solution) >= 3:\n            k = min(3, len(in_solution) // 2)\n            clusters = KMeans(n_clusters=k).fit_predict(np.array(tradeoff_scores).reshape(-1, 1))\n            cluster_sizes = np.bincount(clusters)\n\n            # Select largest cluster for potential replacement\n            target_cluster = np.argmax(cluster_sizes)\n            cluster_items = in_solution[clusters == target_cluster]\n\n            # Calculate potential replacements from archive\n            archive_items = np.where(np.logical_and.reduce([archive[selected_idx][0] == 1, new_solution == 0]))[0]\n            if len(archive_items) > 0:\n                combined_values = (weight1 * value1_lst[archive_items] + weight2 * value2_lst[archive_items]) / weight_lst[archive_items]\n                best_add_idx = archive_items[np.argmax(combined_values)]\n\n                # Replace entire cluster if feasible\n                cluster_weight = np.sum(weight_lst[cluster_items])\n                temp_weight = current_weight - cluster_weight + weight_lst[best_add_idx]\n                if temp_weight <= capacity:\n                    new_solution[cluster_items] = 0\n                    new_solution[best_add_idx] = 1\n                    current_weight = temp_weight\n\n    # Probabilistic flip with novelty-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives using a novelty-aware selection\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting with novelty factor\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) * (1 - (current_value1 / total_value1)) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) * (1 - (current_value2 / total_value2)) if total_value2 > 0 else 0.5\n\n    # Novelty-driven item selection: prioritize items that create \"novel\" value combinations\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate novelty scores based on value ratios and current solution's coverage\n        novelty_scores = []\n        for item in potential_items:\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            novelty = abs(ratio1 - ratio2) * (1 - min(ratio1, ratio2))\n            novelty_scores.append(novelty)\n\n        # Select top items with highest novelty and feasible addition\n        novelty_scores = np.array(novelty_scores)\n        top_items = potential_items[np.argsort(novelty_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Context-aware swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        if len(worst_items) == 2:\n            idx1, idx2 = worst_items\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Dynamic exploration: probabilistic flip with novelty-based probability\n    flip_prob = 0.2 + 0.6 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using dynamic objective weighting, then applies a hybrid local search that removes the least novel item (based on value ratio balance) and adds the most valuable item (weighted by current objective priorities) while ensuring feasibility. It also includes probabilistic flipping of items with high potential improvement, prioritizing objectives that are currently underrepresented.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution using dynamic objective weighting to prioritize underrepresented objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -(x[1][0] / total_value1 + x[1][1] / total_value2))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: novelty-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate novelty scores for items in solution\n        novelty_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            novelty_scores.append(abs(ratio1 - ratio2))\n\n        # Select least novel item for potential removal\n        least_novel_idx = in_solution[np.argmin(novelty_scores)]\n\n        # Calculate potential additions with weighted value metric\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        best_add_idx = potential_items[np.argmax(combined_values)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[least_novel_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[least_novel_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with objective-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            **Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 38,
        "algorithm": "The algorithm combines dynamic objective weighting with cluster-based local search and novelty-aware flips to generate high-quality neighbors in the BI-KP. It prioritizes solutions with underrepresented objectives, identifies item clusters with balanced trade-offs, and replaces them with high-marginal-value items from the archive, while probabilistically flipping items based on novelty scores to explore promising regions of the search space. The method ensures feasibility through adaptive capacity checks and maintains diversity by favoring less-explored solution regions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using dynamic objective weighting to prioritize underrepresented objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -(x[1][0] / total_value1 + x[1][1] / total_value2))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Cluster-based local search: identify item clusters with balanced trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            tradeoff_scores.append(abs(ratio1 - ratio2))\n\n        # Identify clusters of items with similar trade-offs\n        from sklearn.cluster import KMeans\n        if len(in_solution) >= 3:\n            k = min(3, len(in_solution) // 2)\n            clusters = KMeans(n_clusters=k).fit_predict(np.array(tradeoff_scores).reshape(-1, 1))\n            cluster_sizes = np.bincount(clusters)\n\n            # Select largest cluster for potential replacement\n            target_cluster = np.argmax(cluster_sizes)\n            cluster_items = in_solution[clusters == target_cluster]\n\n            # Calculate potential replacements from archive\n            archive_items = np.where(np.logical_and.reduce([archive[selected_idx][0] == 1, new_solution == 0]))[0]\n            if len(archive_items) > 0:\n                combined_values = (weight1 * value1_lst[archive_items] + weight2 * value2_lst[archive_items]) / weight_lst[archive_items]\n                best_add_idx = archive_items[np.argmax(combined_values)]\n\n                # Replace entire cluster if feasible\n                cluster_weight = np.sum(weight_lst[cluster_items])\n                temp_weight = current_weight - cluster_weight + weight_lst[best_add_idx]\n                if temp_weight <= capacity:\n                    new_solution[cluster_items] = 0\n                    new_solution[best_add_idx] = 1\n                    current_weight = temp_weight\n\n    # Probabilistic flip with novelty-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9335947603633915,
            2.247350037097931
        ],
        "raw_score": [
            27.71830632631996,
            27.980116193784617
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using dynamic objective weighting to prioritize underrepresented objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -(x[1][0] / total_value1 + x[1][1] / total_value2))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Cluster-based local search: identify item clusters with balanced trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            tradeoff_scores.append(abs(ratio1 - ratio2))\n\n        # Identify clusters of items with similar trade-offs\n        from sklearn.cluster import KMeans\n        if len(in_solution) >= 3:\n            k = min(3, len(in_solution) // 2)\n            clusters = KMeans(n_clusters=k).fit_predict(np.array(tradeoff_scores).reshape(-1, 1))\n            cluster_sizes = np.bincount(clusters)\n\n            # Select largest cluster for potential replacement\n            target_cluster = np.argmax(cluster_sizes)\n            cluster_items = in_solution[clusters == target_cluster]\n\n            # Calculate potential replacements from archive\n            archive_items = np.where(np.logical_and.reduce([archive[selected_idx][0] == 1, new_solution == 0]))[0]\n            if len(archive_items) > 0:\n                combined_values = (weight1 * value1_lst[archive_items] + weight2 * value2_lst[archive_items]) / weight_lst[archive_items]\n                best_add_idx = archive_items[np.argmax(combined_values)]\n\n                # Replace entire cluster if feasible\n                cluster_weight = np.sum(weight_lst[cluster_items])\n                temp_weight = current_weight - cluster_weight + weight_lst[best_add_idx]\n                if temp_weight <= capacity:\n                    new_solution[cluster_items] = 0\n                    new_solution[best_add_idx] = 1\n                    current_weight = temp_weight\n\n    # Probabilistic flip with novelty-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined normalized potential\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with adaptive weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with adaptive local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Marginal item replacement\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Calculate marginal contributions\n        in_marginals = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n        out_marginals = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n\n        # Replace worst in-item with best out-item if feasible\n        worst_in = in_items[np.argmin(in_marginals)]\n        best_out = out_items[np.argmax(out_marginals)]\n\n        if total_weight - weight_lst[worst_in] + weight_lst[best_out] <= capacity:\n            new_solution[worst_in] = 0\n            new_solution[best_out] = 1\n            total_weight = total_weight - weight_lst[worst_in] + weight_lst[best_out]\n\n    # Phase 2: Objective-biased swaps\n    if len(in_items) >= 2 and random.random() < 0.6:\n        # Calculate objective-specific marginals\n        value1_marginals = value1_lst[in_items] / weight_lst[in_items]\n        value2_marginals = value2_lst[in_items] / weight_lst[in_items]\n\n        # Select items with low marginals in one objective\n        if random.random() < 0.5:\n            # Focus on value1 improvement\n            low_value1 = in_items[np.argsort(value1_marginals)[:2]]\n        else:\n            # Focus on value2 improvement\n            low_value1 = in_items[np.argsort(value2_marginals)[:2]]\n\n        # Find best out-item for swap\n        if len(out_items) > 0:\n            out_marginals = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n            best_out = out_items[np.argmax(out_marginals)]\n\n            # Perform swap if feasible\n            if total_weight - weight_lst[low_value1[0]] + weight_lst[best_out] <= capacity:\n                new_solution[low_value1[0]] = 0\n                new_solution[best_out] = 1\n                total_weight = total_weight - weight_lst[low_value1[0]] + weight_lst[best_out]\n\n    # Phase 3: Probabilistic flips with objective bias\n    flip_prob = 0.3 if (np.sum(value1_lst * new_solution) + np.sum(value2_lst * new_solution)) / (max_value1 + max_value2) > 0.7 else 0.5\n    if random.random() < flip_prob:\n        if random.random() < 0.5 and len(in_items) > 0:\n            # Remove low-marginal item\n            marginals = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n            idx = in_items[np.argmin(marginals)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n        elif len(out_items) > 0:\n            # Add high-marginal item\n            marginals = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n            idx = out_items[np.argmax(marginals)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using dynamic objective weighting, then applies a hybrid local search that removes the least novel item (based on value ratio balance) and adds the most valuable item (weighted by current objective priorities) while ensuring feasibility. It also includes probabilistic flipping of items with high potential improvement, prioritizing objectives that are currently underrepresented.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution using dynamic objective weighting to prioritize underrepresented objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -(x[1][0] / total_value1 + x[1][1] / total_value2))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: novelty-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate novelty scores for items in solution\n        novelty_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            novelty_scores.append(abs(ratio1 - ratio2))\n\n        # Select least novel item for potential removal\n        least_novel_idx = in_solution[np.argmin(novelty_scores)]\n\n        # Calculate potential additions with weighted value metric\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        best_add_idx = potential_items[np.argmax(combined_values)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[least_novel_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[least_novel_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with objective-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            **Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 39,
        "algorithm": "The algorithm combines adaptive objective weighting with a three-phase local search strategy. It first selects a solution from the archive using a dynamic weighting scheme that prioritizes underrepresented objectives, then applies a hybrid approach that removes least balanced items, adds most promising items based on current objective balance, and performs probabilistic flips of high-potential items. The method ensures feasibility through rigorous capacity checks at every step, dynamically adjusting exploration based on the current solution's objective balance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate total possible values for normalization\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n\n    # Select solution using adaptive objective weighting\n    weighted_scores = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        if current_weight > capacity:\n            continue\n\n        # Calculate normalized objective values\n        norm_value1 = obj[0] / (total_value1 + 1e-8)\n        norm_value2 = obj[1] / (total_value2 + 1e-8)\n\n        # Dynamic weighting based on current balance\n        balance = norm_value1 / (norm_value2 + 1e-8)\n        weight1 = 1 - balance if balance < 1 else 0.5\n        weight2 = balance if balance < 1 else 0.5\n\n        weighted_score = weight1 * norm_value1 + weight2 * norm_value2\n        weighted_scores.append((sol, weighted_score))\n\n    if not weighted_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    weighted_scores.sort(key=lambda x: -x[1])\n    base_solution = weighted_scores[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Multi-phase local search\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    # Phase 1: Remove least balanced item\n    if len(in_items) > 1:\n        balance_scores = []\n        for i in in_items:\n            ratio = (value1_lst[i] / (current_value1 + 1e-8)) / (value2_lst[i] / (current_value2 + 1e-8))\n            balance_scores.append(abs(ratio - 1))\n\n        least_balanced = in_items[np.argmax(balance_scores)]\n        if current_weight - weight_lst[least_balanced] <= capacity:\n            new_solution[least_balanced] = 0\n            current_weight -= weight_lst[least_balanced]\n\n    # Phase 2: Add most promising item\n    if len(out_items) > 0:\n        # Calculate objective-specific marginals\n        marginal1 = value1_lst[out_items] / weight_lst[out_items]\n        marginal2 = value2_lst[out_items] / weight_lst[out_items]\n\n        # Dynamic selection based on current balance\n        if current_value1 > current_value2:\n            candidates = out_items[np.argsort(marginal2)[-3:]]  # Prioritize value2 improvement\n        else:\n            candidates = out_items[np.argsort(marginal1)[-3:]]  # Prioritize value1 improvement\n\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Phase 3: Probabilistic flips\n    flip_prob = 0.4 + 0.4 * (1 - (current_value1 / (total_value1 + 1e-8) + current_value2 / (total_value2 + 1e-8)) / 2)\n    if random.random() < flip_prob and len(in_items) > 0:\n        # Select items with high potential improvement\n        improvement_scores = []\n        for i in in_items:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-8)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-8)\n            improvement_scores.append(ratio1 + ratio2)\n\n        flip_candidate = in_items[np.argmax(improvement_scores)]\n        if current_weight - weight_lst[flip_candidate] <= capacity:\n            new_solution[flip_candidate] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.3902157649598306,
            3.3427036106586456
        ],
        "raw_score": [
            31.164307199993722,
            33.83062424175053
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate total possible values for normalization\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n\n    # Select solution using adaptive objective weighting\n    weighted_scores = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        if current_weight > capacity:\n            continue\n\n        # Calculate normalized objective values\n        norm_value1 = obj[0] / (total_value1 + 1e-8)\n        norm_value2 = obj[1] / (total_value2 + 1e-8)\n\n        # Dynamic weighting based on current balance\n        balance = norm_value1 / (norm_value2 + 1e-8)\n        weight1 = 1 - balance if balance < 1 else 0.5\n        weight2 = balance if balance < 1 else 0.5\n\n        weighted_score = weight1 * norm_value1 + weight2 * norm_value2\n        weighted_scores.append((sol, weighted_score))\n\n    if not weighted_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    weighted_scores.sort(key=lambda x: -x[1])\n    base_solution = weighted_scores[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Multi-phase local search\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    # Phase 1: Remove least balanced item\n    if len(in_items) > 1:\n        balance_scores = []\n        for i in in_items:\n            ratio = (value1_lst[i] / (current_value1 + 1e-8)) / (value2_lst[i] / (current_value2 + 1e-8))\n            balance_scores.append(abs(ratio - 1))\n\n        least_balanced = in_items[np.argmax(balance_scores)]\n        if current_weight - weight_lst[least_balanced] <= capacity:\n            new_solution[least_balanced] = 0\n            current_weight -= weight_lst[least_balanced]\n\n    # Phase 2: Add most promising item\n    if len(out_items) > 0:\n        # Calculate objective-specific marginals\n        marginal1 = value1_lst[out_items] / weight_lst[out_items]\n        marginal2 = value2_lst[out_items] / weight_lst[out_items]\n\n        # Dynamic selection based on current balance\n        if current_value1 > current_value2:\n            candidates = out_items[np.argsort(marginal2)[-3:]]  # Prioritize value2 improvement\n        else:\n            candidates = out_items[np.argsort(marginal1)[-3:]]  # Prioritize value1 improvement\n\n        for candidate in candidates:\n            if current_weight + weight_lst[candidate] <= capacity:\n                new_solution[candidate] = 1\n                current_weight += weight_lst[candidate]\n                break\n\n    # Phase 3: Probabilistic flips\n    flip_prob = 0.4 + 0.4 * (1 - (current_value1 / (total_value1 + 1e-8) + current_value2 / (total_value2 + 1e-8)) / 2)\n    if random.random() < flip_prob and len(in_items) > 0:\n        # Select items with high potential improvement\n        improvement_scores = []\n        for i in in_items:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-8)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-8)\n            improvement_scores.append(ratio1 + ratio2)\n\n        flip_candidate = in_items[np.argmax(improvement_scores)]\n        if current_weight - weight_lst[flip_candidate] <= capacity:\n            new_solution[flip_candidate] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using dynamic objective weighting, then applies a hybrid local search that removes the least novel item (based on value ratio balance) and adds the most valuable item (weighted by current objective priorities) while ensuring feasibility. It also includes probabilistic flipping of items with high potential improvement, prioritizing objectives that are currently underrepresented.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution using dynamic objective weighting to prioritize underrepresented objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -(x[1][0] / total_value1 + x[1][1] / total_value2))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: novelty-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate novelty scores for items in solution\n        novelty_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            novelty_scores.append(abs(ratio1 - ratio2))\n\n        # Select least novel item for potential removal\n        least_novel_idx = in_solution[np.argmin(novelty_scores)]\n\n        # Calculate potential additions with weighted value metric\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        best_add_idx = potential_items[np.argmax(combined_values)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[least_novel_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[least_novel_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with objective-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 40,
        "algorithm": "The algorithm selects a solution from the archive based on diversity in objective contributions, then applies a hybrid local search that prioritizes removing items with extreme value imbalances and adding items with highest dynamic objective-weighted value density, while periodically flipping low-contribution items to maintain solution quality and diversity. The dynamic objective weights (weight1 and weight2) adjust based on the current solution's balance, and the flip probability increases when solutions are less balanced.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest diversity in objective contributions\n    diversity_scores = []\n    for sol, _ in archive:\n        in_items = np.where(sol == 1)[0]\n        if len(in_items) == 0:\n            diversity_scores.append(0)\n            continue\n        v1 = np.sum(value1_lst[in_items])\n        v2 = np.sum(value2_lst[in_items])\n        diversity_scores.append(abs(v1 - v2) / (v1 + v2 + 1e-6))\n\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's balance\n    total_v1 = np.sum(value1_lst)\n    total_v2 = np.sum(value2_lst)\n    weight1 = 0.5 + 0.5 * (1 - current_value1 / total_v1) if total_v1 > 0 else 0.5\n    weight2 = 0.5 + 0.5 * (1 - current_value2 / total_v2) if total_v2 > 0 else 0.5\n\n    # Hybrid local search: contribution-aware replacement\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 1 and len(out_items) > 0:\n        # Calculate contribution imbalance for items in solution\n        imbalance_scores = []\n        for i in in_items:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            imbalance_scores.append(abs(ratio1 - ratio2))\n\n        # Select item with most extreme imbalance for potential removal\n        remove_idx = in_items[np.argmax(imbalance_scores)]\n\n        # Calculate value density for potential additions\n        density_scores = (weight1 * value1_lst[out_items] + weight2 * value2_lst[out_items]) / (weight_lst[out_items] + 1e-6)\n        add_idx = out_items[np.argmax(density_scores)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n        if temp_weight <= capacity:\n            new_solution[remove_idx] = 0\n            new_solution[add_idx] = 1\n            current_weight = temp_weight\n\n    # Periodic diversification through probabilistic flipping\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 / total_v1 + current_value2 / total_v2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential for improving underrepresented objective\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8531484000452234,
            0.6412076354026794
        ],
        "raw_score": [
            27.740423312406165,
            27.881736142017175
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest diversity in objective contributions\n    diversity_scores = []\n    for sol, _ in archive:\n        in_items = np.where(sol == 1)[0]\n        if len(in_items) == 0:\n            diversity_scores.append(0)\n            continue\n        v1 = np.sum(value1_lst[in_items])\n        v2 = np.sum(value2_lst[in_items])\n        diversity_scores.append(abs(v1 - v2) / (v1 + v2 + 1e-6))\n\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's balance\n    total_v1 = np.sum(value1_lst)\n    total_v2 = np.sum(value2_lst)\n    weight1 = 0.5 + 0.5 * (1 - current_value1 / total_v1) if total_v1 > 0 else 0.5\n    weight2 = 0.5 + 0.5 * (1 - current_value2 / total_v2) if total_v2 > 0 else 0.5\n\n    # Hybrid local search: contribution-aware replacement\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 1 and len(out_items) > 0:\n        # Calculate contribution imbalance for items in solution\n        imbalance_scores = []\n        for i in in_items:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            imbalance_scores.append(abs(ratio1 - ratio2))\n\n        # Select item with most extreme imbalance for potential removal\n        remove_idx = in_items[np.argmax(imbalance_scores)]\n\n        # Calculate value density for potential additions\n        density_scores = (weight1 * value1_lst[out_items] + weight2 * value2_lst[out_items]) / (weight_lst[out_items] + 1e-6)\n        add_idx = out_items[np.argmax(density_scores)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[remove_idx] + weight_lst[add_idx]\n        if temp_weight <= capacity:\n            new_solution[remove_idx] = 0\n            new_solution[add_idx] = 1\n            current_weight = temp_weight\n\n    # Periodic diversification through probabilistic flipping\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 / total_v1 + current_value2 / total_v2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential for improving underrepresented objective\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using dynamic objective weighting, then applies a hybrid local search that removes the least novel item (based on value ratio balance) and adds the most valuable item (weighted by current objective priorities) while ensuring feasibility. It also includes probabilistic flipping of items with high potential improvement, prioritizing objectives that are currently underrepresented.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution using dynamic objective weighting to prioritize underrepresented objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -(x[1][0] / total_value1 + x[1][1] / total_value2))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: novelty-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate novelty scores for items in solution\n        novelty_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            novelty_scores.append(abs(ratio1 - ratio2))\n\n        # Select least novel item for potential removal\n        least_novel_idx = in_solution[np.argmin(novelty_scores)]\n\n        # Calculate potential additions with weighted value metric\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        best_add_idx = potential_items[np.argmax(combined_values)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[least_novel_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[least_novel_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with objective-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 41,
        "algorithm": "The algorithm selects a solution from the archive using crowding distance to prioritize underrepresented regions of the Pareto front, then applies a hybrid local search that removes low-marginal-contribution items and adds high-weighted-marginal-contribution items, while ensuring feasibility through a probabilistic flip mechanism based on crowding distance. The selection process dynamically adjusts objective weights to balance exploration of both objectives, and the local search prioritizes items with higher potential for improvement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using crowding distance to prioritize underrepresented regions\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                continue\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: marginal contribution-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate marginal contributions for items in solution\n        marginal_contributions = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_weight + 1e-6)\n            ratio2 = value2_lst[i] / (current_weight + 1e-6)\n            marginal_contributions.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select item with lowest marginal contribution for potential removal\n        worst_idx = in_solution[np.argmin(marginal_contributions)]\n\n        # Calculate potential additions with weighted marginal contribution\n        combined_marginals = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / (weight_lst[potential_items] + 1e-6)\n        best_add_idx = potential_items[np.argmax(combined_marginals)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with crowding-aware probability\n    flip_prob = 0.2 + 0.6 * (crowding_distances[selected_idx] / (np.max(crowding_distances) + 1e-6))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential marginal improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_weight + 1e-6)\n                ratio2 = value2_lst[i] / (current_weight + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8640257281258411,
            0.4674264192581177
        ],
        "raw_score": [
            27.295348945520054,
            27.80626950593772
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using crowding distance to prioritize underrepresented regions\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                continue\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: marginal contribution-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate marginal contributions for items in solution\n        marginal_contributions = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_weight + 1e-6)\n            ratio2 = value2_lst[i] / (current_weight + 1e-6)\n            marginal_contributions.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select item with lowest marginal contribution for potential removal\n        worst_idx = in_solution[np.argmin(marginal_contributions)]\n\n        # Calculate potential additions with weighted marginal contribution\n        combined_marginals = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / (weight_lst[potential_items] + 1e-6)\n        best_add_idx = potential_items[np.argmax(combined_marginals)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with crowding-aware probability\n    flip_prob = 0.2 + 0.6 * (crowding_distances[selected_idx] / (np.max(crowding_distances) + 1e-6))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential marginal improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_weight + 1e-6)\n                ratio2 = value2_lst[i] / (current_weight + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using dynamic objective weighting, then applies a hybrid local search that removes the least novel item (based on value ratio balance) and adds the most valuable item (weighted by current objective priorities) while ensuring feasibility. It also includes probabilistic flipping of items with high potential improvement, prioritizing objectives that are currently underrepresented.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution using dynamic objective weighting to prioritize underrepresented objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -(x[1][0] / total_value1 + x[1][1] / total_value2))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: novelty-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate novelty scores for items in solution\n        novelty_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            novelty_scores.append(abs(ratio1 - ratio2))\n\n        # Select least novel item for potential removal\n        least_novel_idx = in_solution[np.argmin(novelty_scores)]\n\n        # Calculate potential additions with weighted value metric\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        best_add_idx = potential_items[np.argmax(combined_values)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[least_novel_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[least_novel_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with objective-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            **Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 42,
        "algorithm": "The algorithm selects a promising solution from the archive by dynamically weighting objectives based on underrepresentation, then applies a hybrid local search combining novelty-driven swaps (removing least balanced items) with high-marginal additions, followed by probabilistic flips biased toward improving underrepresented objectives, while ensuring feasibility through capacity checks. The selection prioritizes solutions with higher normalized objective sums and underrepresented objectives, while the local search strategically balances exploration and exploitation through weighted marginal evaluations and targeted swaps.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate total possible values\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n\n    # Select a solution using dynamic objective weighting and potential for improvement\n    archive_with_scores = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        if current_weight > capacity:\n            continue\n\n        # Calculate dynamic weights based on current solution's underrepresentation\n        weight1 = 1 - (obj[0] / total_value1) if total_value1 > 0 else 0.5\n        weight2 = 1 - (obj[1] / total_value2) if total_value2 > 0 else 0.5\n\n        # Calculate potential score combining normalized objectives and dynamic weights\n        normalized_obj1 = obj[0] / (total_value1 + 1e-8)\n        normalized_obj2 = obj[1] / (total_value2 + 1e-8)\n        potential_score = weight1 * normalized_obj1 + weight2 * normalized_obj2\n\n        archive_with_scores.append((sol, obj, potential_score))\n\n    if not archive_with_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by potential score and select top 30% with highest scores\n    archive_with_scores.sort(key=lambda x: -x[2])\n    selected_idx = min(len(archive_with_scores) // 3, len(archive_with_scores) - 1)\n    base_solution = archive_with_scores[selected_idx][0].copy()\n    current_obj = archive_with_scores[selected_idx][1]\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = current_obj[0]\n    current_value2 = current_obj[1]\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: novelty-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate novelty scores for items in solution\n        novelty_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            novelty_scores.append(abs(ratio1 - ratio2))\n\n        # Select least novel item for potential removal\n        least_novel_idx = in_solution[np.argmin(novelty_scores)]\n\n        # Calculate potential additions with weighted value metric\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        best_add_idx = potential_items[np.argmax(combined_values)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[least_novel_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[least_novel_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n            current_value1 = current_value1 - value1_lst[least_novel_idx] + value1_lst[best_add_idx]\n            current_value2 = current_value2 - value2_lst[least_novel_idx] + value2_lst[best_add_idx]\n\n    # Probabilistic flip with objective-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Additional exploration: random swap between high-marginal items\n    if len(in_solution) > 1 and np.random.random() < 0.2:\n        # Calculate marginal values for items in solution\n        marginal_values = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            marginal_values.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top 2 items with highest marginal values\n        if len(marginal_values) >= 2:\n            top_indices = np.argsort(marginal_values)[-2:]\n            i, j = in_solution[top_indices[0]], in_solution[top_indices[1]]\n\n            # Check if swap is feasible\n            if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8255394181840705,
            0.5206159353256226
        ],
        "raw_score": [
            27.006815313049852,
            27.641527679712578
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate total possible values\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n\n    # Select a solution using dynamic objective weighting and potential for improvement\n    archive_with_scores = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        if current_weight > capacity:\n            continue\n\n        # Calculate dynamic weights based on current solution's underrepresentation\n        weight1 = 1 - (obj[0] / total_value1) if total_value1 > 0 else 0.5\n        weight2 = 1 - (obj[1] / total_value2) if total_value2 > 0 else 0.5\n\n        # Calculate potential score combining normalized objectives and dynamic weights\n        normalized_obj1 = obj[0] / (total_value1 + 1e-8)\n        normalized_obj2 = obj[1] / (total_value2 + 1e-8)\n        potential_score = weight1 * normalized_obj1 + weight2 * normalized_obj2\n\n        archive_with_scores.append((sol, obj, potential_score))\n\n    if not archive_with_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by potential score and select top 30% with highest scores\n    archive_with_scores.sort(key=lambda x: -x[2])\n    selected_idx = min(len(archive_with_scores) // 3, len(archive_with_scores) - 1)\n    base_solution = archive_with_scores[selected_idx][0].copy()\n    current_obj = archive_with_scores[selected_idx][1]\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = current_obj[0]\n    current_value2 = current_obj[1]\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: novelty-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate novelty scores for items in solution\n        novelty_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            novelty_scores.append(abs(ratio1 - ratio2))\n\n        # Select least novel item for potential removal\n        least_novel_idx = in_solution[np.argmin(novelty_scores)]\n\n        # Calculate potential additions with weighted value metric\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        best_add_idx = potential_items[np.argmax(combined_values)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[least_novel_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[least_novel_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n            current_value1 = current_value1 - value1_lst[least_novel_idx] + value1_lst[best_add_idx]\n            current_value2 = current_value2 - value2_lst[least_novel_idx] + value2_lst[best_add_idx]\n\n    # Probabilistic flip with objective-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Additional exploration: random swap between high-marginal items\n    if len(in_solution) > 1 and np.random.random() < 0.2:\n        # Calculate marginal values for items in solution\n        marginal_values = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            marginal_values.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top 2 items with highest marginal values\n        if len(marginal_values) >= 2:\n            top_indices = np.argsort(marginal_values)[-2:]\n            i, j = in_solution[top_indices[0]], in_solution[top_indices[1]]\n\n            # Check if swap is feasible\n            if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 2 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a balanced solution from the archive (prioritizing those with high combined objective product) and applies a hybrid local search combining weighted item addition, adaptive swapping, and probabilistic flipping, while dynamically adjusting weights based on solution quality and ensuring feasibility through capacity checks. It emphasizes objective-aware selection (using weighted value metrics) and diversity maintenance (through probabilistic flips), creating a balance between exploration and exploitation. The key design focuses on adaptive weights, combined value metrics, and solution quality-aware operations to improve multi-objective performance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 43,
        "algorithm": "The algorithm dynamically selects a promising solution from the archive by balancing objective potential and diversity, then applies a hybrid local search combining novelty-driven swaps (prioritizing items with low marginal improvement), probabilistic flips (biased toward feasible changes), and marginal improvement additions (prioritizing high-value items) while strictly enforcing capacity constraints. The selection prioritizes solutions with greater room for improvement in both objectives and higher diversity, while the local search focuses on both targeted and exploratory moves to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dynamic weights based on objective potential and diversity\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    weighted_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with diversity measure\n        diversity = np.sum(sol != archive[0][0]) / len(sol)\n        score = (potential1 + potential2) * (1 + diversity)\n        weighted_scores.append((sol, score))\n\n    if not weighted_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest weighted score\n    weighted_scores.sort(key=lambda x: -x[1])\n    base_solution = weighted_scores[0][0].copy()\n\n    # Generate neighbor with hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Novelty-driven swap\n    if np.sum(new_solution) > 1:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Calculate marginal improvements for potential swaps\n            in_marginals = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n            out_marginals = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n\n            best_in = in_items[np.argmin(in_marginals)]\n            best_out = out_items[np.argmax(out_marginals)]\n\n            if total_weight - weight_lst[best_in] + weight_lst[best_out] <= capacity:\n                new_solution[best_in] = 0\n                new_solution[best_out] = 1\n\n    # Phase 2: Probabilistic flip with objective bias\n    flip_prob = 0.5\n    if np.random.random() < flip_prob:\n        idx = np.random.randint(0, len(new_solution))\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    # Phase 3: Marginal improvement addition\n    if np.random.random() < 0.3:\n        out_items = np.where(new_solution == 0)[0]\n        if len(out_items) > 0:\n            # Calculate combined marginal improvement\n            marginals = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n            best_item = out_items[np.argmax(marginals)]\n\n            if total_weight + weight_lst[best_item] <= capacity:\n                new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8418687404797867,
            0.5221823155879974
        ],
        "raw_score": [
            27.04787871384466,
            27.912277291311042
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dynamic weights based on objective potential and diversity\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    weighted_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with diversity measure\n        diversity = np.sum(sol != archive[0][0]) / len(sol)\n        score = (potential1 + potential2) * (1 + diversity)\n        weighted_scores.append((sol, score))\n\n    if not weighted_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest weighted score\n    weighted_scores.sort(key=lambda x: -x[1])\n    base_solution = weighted_scores[0][0].copy()\n\n    # Generate neighbor with hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Novelty-driven swap\n    if np.sum(new_solution) > 1:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) > 0 and len(out_items) > 0:\n            # Calculate marginal improvements for potential swaps\n            in_marginals = (value1_lst[in_items] + value2_lst[in_items]) / weight_lst[in_items]\n            out_marginals = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n\n            best_in = in_items[np.argmin(in_marginals)]\n            best_out = out_items[np.argmax(out_marginals)]\n\n            if total_weight - weight_lst[best_in] + weight_lst[best_out] <= capacity:\n                new_solution[best_in] = 0\n                new_solution[best_out] = 1\n\n    # Phase 2: Probabilistic flip with objective bias\n    flip_prob = 0.5\n    if np.random.random() < flip_prob:\n        idx = np.random.randint(0, len(new_solution))\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    # Phase 3: Marginal improvement addition\n    if np.random.random() < 0.3:\n        out_items = np.where(new_solution == 0)[0]\n        if len(out_items) > 0:\n            # Calculate combined marginal improvement\n            marginals = (value1_lst[out_items] + value2_lst[out_items]) / weight_lst[out_items]\n            best_item = out_items[np.argmax(marginals)]\n\n            if total_weight + weight_lst[best_item] <= capacity:\n                new_solution[best_item] = 1\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe heuristic selects a balanced solution from the archive, then applies a hybrid local search combining targeted swaps (prioritizing high-value items), probabilistic flips, feasibility checks, and greedy additions of valuable items. It dynamically adjusts weights based on current solution quality and ensures feasibility through intelligent item removals and additions. The approach balances exploration and exploitation while maintaining Pareto optimality potential.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Targeted swapping based on adaptive weights\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                current_weight = temp_weight\n\n    # Step 2: Random flip with probability based on solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and n_items > 0:\n        flip_idx = np.random.choice(n_items)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Step 3: Ensure feasibility by removing the least valuable items if needed\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    # Step 4: Add the most valuable available items if there's remaining capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        add_idx = available_items[np.argmax(weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 44,
        "algorithm": "The algorithm combines adaptive objective weighting with a hybrid local search that prioritizes high-marginal items, using dynamic weights to balance objectives, and employs probabilistic item removals/additions while ensuring feasibility. It selects promising solutions based on their potential for improvement in both objectives and applies a three-phase local search (swap, remove, add) with objective-biased marginal contributions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate adaptive weights for selection\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    selection_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with dynamic weights based on potential\n        combined_score = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        selection_scores.append((sol, combined_score))\n\n    if not selection_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest combined score\n    selection_scores.sort(key=lambda x: -x[1])\n    base_solution = selection_scores[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n    weight1 = total_value1 / (total_value1 + total_value2 + 1e-8)\n    weight2 = 1 - weight1\n\n    # Phase 1: Replace low-marginal items with high-marginal ones\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Calculate marginal contributions\n        in_marginals = (weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]) / (weight_lst[in_items] + 1e-8)\n        out_marginals = (weight1 * value1_lst[out_items] + weight2 * value2_lst[out_items]) / (weight_lst[out_items] + 1e-8)\n\n        # Find worst in-item and best out-item\n        worst_in = in_items[np.argmin(in_marginals)]\n        best_out = out_items[np.argmax(out_marginals)]\n\n        # Check if swap maintains feasibility\n        if weight_lst[best_out] <= weight_lst[worst_in] + (capacity - current_weight):\n            new_solution[worst_in] = 0\n            new_solution[best_out] = 1\n            current_weight = current_weight - weight_lst[worst_in] + weight_lst[best_out]\n\n    # Phase 2: Probabilistic item removal with objective bias\n    if np.random.random() < 0.4 and len(in_items) > 0:\n        # Remove item with lowest weighted marginal contribution\n        in_marginals = (weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]) / (weight_lst[in_items] + 1e-8)\n        remove_idx = in_items[np.argmin(in_marginals)]\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Phase 3: Targeted item addition with objective bias\n    if np.random.random() < 0.5 and current_weight < capacity:\n        out_items = np.where(new_solution == 0)[0]\n        if len(out_items) > 0:\n            # Add item with highest weighted marginal contribution\n            out_marginals = (weight1 * value1_lst[out_items] + weight2 * value2_lst[out_items]) / (weight_lst[out_items] + 1e-8)\n            add_idx = out_items[np.argmax(out_marginals)]\n            if current_weight + weight_lst[add_idx] <= capacity:\n                new_solution[add_idx] = 1\n                current_weight += weight_lst[add_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9350819388673721,
            0.41082093119621277
        ],
        "raw_score": [
            27.61992255945934,
            27.960503075216337
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate adaptive weights for selection\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    selection_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with dynamic weights based on potential\n        combined_score = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        selection_scores.append((sol, combined_score))\n\n    if not selection_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest combined score\n    selection_scores.sort(key=lambda x: -x[1])\n    base_solution = selection_scores[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n    weight1 = total_value1 / (total_value1 + total_value2 + 1e-8)\n    weight2 = 1 - weight1\n\n    # Phase 1: Replace low-marginal items with high-marginal ones\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Calculate marginal contributions\n        in_marginals = (weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]) / (weight_lst[in_items] + 1e-8)\n        out_marginals = (weight1 * value1_lst[out_items] + weight2 * value2_lst[out_items]) / (weight_lst[out_items] + 1e-8)\n\n        # Find worst in-item and best out-item\n        worst_in = in_items[np.argmin(in_marginals)]\n        best_out = out_items[np.argmax(out_marginals)]\n\n        # Check if swap maintains feasibility\n        if weight_lst[best_out] <= weight_lst[worst_in] + (capacity - current_weight):\n            new_solution[worst_in] = 0\n            new_solution[best_out] = 1\n            current_weight = current_weight - weight_lst[worst_in] + weight_lst[best_out]\n\n    # Phase 2: Probabilistic item removal with objective bias\n    if np.random.random() < 0.4 and len(in_items) > 0:\n        # Remove item with lowest weighted marginal contribution\n        in_marginals = (weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]) / (weight_lst[in_items] + 1e-8)\n        remove_idx = in_items[np.argmin(in_marginals)]\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Phase 3: Targeted item addition with objective bias\n    if np.random.random() < 0.5 and current_weight < capacity:\n        out_items = np.where(new_solution == 0)[0]\n        if len(out_items) > 0:\n            # Add item with highest weighted marginal contribution\n            out_marginals = (weight1 * value1_lst[out_items] + weight2 * value2_lst[out_items]) / (weight_lst[out_items] + 1e-8)\n            add_idx = out_items[np.argmax(out_marginals)]\n            if current_weight + weight_lst[add_idx] <= capacity:\n                new_solution[add_idx] = 1\n                current_weight += weight_lst[add_idx]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe heuristic selects a balanced solution from the archive, then applies a hybrid local search combining targeted swaps (prioritizing high-value items), probabilistic flips, feasibility checks, and greedy additions of valuable items. It dynamically adjusts weights based on current solution quality and ensures feasibility through intelligent item removals and additions. The approach balances exploration and exploitation while maintaining Pareto optimality potential.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Targeted swapping based on adaptive weights\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                current_weight = temp_weight\n\n    # Step 2: Random flip with probability based on solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and n_items > 0:\n        flip_idx = np.random.choice(n_items)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Step 3: Ensure feasibility by removing the least valuable items if needed\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    # Step 4: Add the most valuable available items if there's remaining capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        add_idx = available_items[np.argmax(weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 44,
        "algorithm": "The algorithm combines adaptive objective weighting with a hybrid local search that prioritizes high-marginal items, using dynamic weights to balance objectives, and employs probabilistic item removals/additions while ensuring feasibility. It selects promising solutions based on their potential for improvement in both objectives and applies a three-phase local search (swap, remove, add) with objective-biased marginal contributions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate adaptive weights for selection\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    selection_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with dynamic weights based on potential\n        combined_score = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        selection_scores.append((sol, combined_score))\n\n    if not selection_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest combined score\n    selection_scores.sort(key=lambda x: -x[1])\n    base_solution = selection_scores[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n    weight1 = total_value1 / (total_value1 + total_value2 + 1e-8)\n    weight2 = 1 - weight1\n\n    # Phase 1: Replace low-marginal items with high-marginal ones\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Calculate marginal contributions\n        in_marginals = (weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]) / (weight_lst[in_items] + 1e-8)\n        out_marginals = (weight1 * value1_lst[out_items] + weight2 * value2_lst[out_items]) / (weight_lst[out_items] + 1e-8)\n\n        # Find worst in-item and best out-item\n        worst_in = in_items[np.argmin(in_marginals)]\n        best_out = out_items[np.argmax(out_marginals)]\n\n        # Check if swap maintains feasibility\n        if weight_lst[best_out] <= weight_lst[worst_in] + (capacity - current_weight):\n            new_solution[worst_in] = 0\n            new_solution[best_out] = 1\n            current_weight = current_weight - weight_lst[worst_in] + weight_lst[best_out]\n\n    # Phase 2: Probabilistic item removal with objective bias\n    if np.random.random() < 0.4 and len(in_items) > 0:\n        # Remove item with lowest weighted marginal contribution\n        in_marginals = (weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]) / (weight_lst[in_items] + 1e-8)\n        remove_idx = in_items[np.argmin(in_marginals)]\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Phase 3: Targeted item addition with objective bias\n    if np.random.random() < 0.5 and current_weight < capacity:\n        out_items = np.where(new_solution == 0)[0]\n        if len(out_items) > 0:\n            # Add item with highest weighted marginal contribution\n            out_marginals = (weight1 * value1_lst[out_items] + weight2 * value2_lst[out_items]) / (weight_lst[out_items] + 1e-8)\n            add_idx = out_items[np.argmax(out_marginals)]\n            if current_weight + weight_lst[add_idx] <= capacity:\n                new_solution[add_idx] = 1\n                current_weight += weight_lst[add_idx]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9350819388673721,
            0.41082093119621277
        ],
        "raw_score": [
            27.61992255945934,
            27.960503075216337
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate adaptive weights for selection\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    selection_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with dynamic weights based on potential\n        combined_score = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        selection_scores.append((sol, combined_score))\n\n    if not selection_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest combined score\n    selection_scores.sort(key=lambda x: -x[1])\n    base_solution = selection_scores[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst * new_solution)\n    total_value2 = np.sum(value2_lst * new_solution)\n    weight1 = total_value1 / (total_value1 + total_value2 + 1e-8)\n    weight2 = 1 - weight1\n\n    # Phase 1: Replace low-marginal items with high-marginal ones\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Calculate marginal contributions\n        in_marginals = (weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]) / (weight_lst[in_items] + 1e-8)\n        out_marginals = (weight1 * value1_lst[out_items] + weight2 * value2_lst[out_items]) / (weight_lst[out_items] + 1e-8)\n\n        # Find worst in-item and best out-item\n        worst_in = in_items[np.argmin(in_marginals)]\n        best_out = out_items[np.argmax(out_marginals)]\n\n        # Check if swap maintains feasibility\n        if weight_lst[best_out] <= weight_lst[worst_in] + (capacity - current_weight):\n            new_solution[worst_in] = 0\n            new_solution[best_out] = 1\n            current_weight = current_weight - weight_lst[worst_in] + weight_lst[best_out]\n\n    # Phase 2: Probabilistic item removal with objective bias\n    if np.random.random() < 0.4 and len(in_items) > 0:\n        # Remove item with lowest weighted marginal contribution\n        in_marginals = (weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]) / (weight_lst[in_items] + 1e-8)\n        remove_idx = in_items[np.argmin(in_marginals)]\n        if current_weight - weight_lst[remove_idx] <= capacity:\n            new_solution[remove_idx] = 0\n            current_weight -= weight_lst[remove_idx]\n\n    # Phase 3: Targeted item addition with objective bias\n    if np.random.random() < 0.5 and current_weight < capacity:\n        out_items = np.where(new_solution == 0)[0]\n        if len(out_items) > 0:\n            # Add item with highest weighted marginal contribution\n            out_marginals = (weight1 * value1_lst[out_items] + weight2 * value2_lst[out_items]) / (weight_lst[out_items] + 1e-8)\n            add_idx = out_items[np.argmax(out_marginals)]\n            if current_weight + weight_lst[add_idx] <= capacity:\n                new_solution[add_idx] = 1\n                current_weight += weight_lst[add_idx]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives using a novelty-aware selection\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting with novelty factor\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) * (1 - (current_value1 / total_value1)) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) * (1 - (current_value2 / total_value2)) if total_value2 > 0 else 0.5\n\n    # Novelty-driven item selection: prioritize items that create \"novel\" value combinations\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate novelty scores based on value ratios and current solution's coverage\n        novelty_scores = []\n        for item in potential_items:\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            novelty = abs(ratio1 - ratio2) * (1 - min(ratio1, ratio2))\n            novelty_scores.append(novelty)\n\n        # Select top items with highest novelty and feasible addition\n        novelty_scores = np.array(novelty_scores)\n        top_items = potential_items[np.argsort(novelty_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Context-aware swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        if len(worst_items) == 2:\n            idx1, idx2 = worst_items\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Dynamic exploration: probabilistic flip with novelty-based probability\n    flip_prob = 0.2 + 0.6 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 45,
        "algorithm": "The algorithm combines adaptive objective weighting with novelty-aware selection to prioritize solutions with high potential for improvement, followed by a hybrid local search that integrates biased item replacement, dynamic swaps, and probabilistic flips, all while ensuring feasibility. It dynamically balances exploration and exploitation by favoring solutions with diverse value ratios and high marginal gains, using context-sensitive operations that probabilistically target underrepresented objectives. The method emphasizes novelty in item selection, prioritizes trade-off improvements in swaps, and probabilistically flips items based on their marginal contributions to both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate adaptive weights and select solution with highest potential\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate adaptive weights based on current solution's coverage\n        coverage1 = obj[0] / max_value1 if max_value1 > 0 else 0.5\n        coverage2 = obj[1] / max_value2 if max_value2 > 0 else 0.5\n        weight1 = 1 - coverage1\n        weight2 = 1 - coverage2\n\n        # Calculate normalized potential with adaptive weights\n        potential = (weight1 * (max_value1 - obj[0]) + weight2 * (max_value2 - obj[1])) / (max_value1 + max_value2 + 1e-8)\n        potential_scores.append((sol, potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Phase 1: Novelty-aware biased replacement\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Calculate novelty scores for in-items (low marginal value)\n        novelty_scores_in = []\n        for i in in_items:\n            marginal1 = value1_lst[i] / (current_value1 + 1e-6)\n            marginal2 = value2_lst[i] / (current_value2 + 1e-6)\n            novelty_scores_in.append(abs(marginal1 - marginal2))\n\n        # Calculate novelty scores for out-items (high potential)\n        novelty_scores_out = []\n        for j in out_items:\n            if current_weight + weight_lst[j] > capacity:\n                novelty_scores_out.append(-1)  # Infeasible\n                continue\n            marginal1 = value1_lst[j] / max_value1 if max_value1 > 0 else 0\n            marginal2 = value2_lst[j] / max_value2 if max_value2 > 0 else 0\n            novelty_scores_out.append(abs(marginal1 - marginal2))\n\n        # Find best replacement pair\n        if any(n > 0 for n in novelty_scores_out):\n            best_in = in_items[np.argmin(novelty_scores_in)]\n            best_out = out_items[np.argmax(novelty_scores_out)]\n            if novelty_scores_out[np.argmax(novelty_scores_out)] > 0:\n                new_solution[best_in] = 0\n                new_solution[best_out] = 1\n\n    # Phase 2: Dynamic swaps with objective bias\n    if np.sum(new_solution) > 1 and np.random.random() < 0.6:\n        in_items = np.where(new_solution == 1)[0]\n        i, j = np.random.choice(in_items, 2, replace=False)\n\n        # Calculate swap impact\n        delta_weight = weight_lst[j] - weight_lst[i]\n        temp_weight = current_weight + delta_weight\n\n        if temp_weight <= capacity:\n            # Calculate trade-off before and after swap\n            before_tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            after_tradeoff = abs((value1_lst[j] - (current_value1 - value1_lst[i] + value1_lst[j])) /\n                               (value2_lst[j] - (current_value2 - value2_lst[i] + value2_lst[j]) + 1e-6))\n\n            # Perform swap if it improves trade-off\n            if after_tradeoff < before_tradeoff:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 3: Probabilistic flips with novelty bias\n    flip_prob = 0.3 + 0.4 * (1 - (current_value1 + current_value2) / (max_value1 + max_value2))\n    if np.random.random() < flip_prob:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        # Calculate novelty scores for flips\n        novelty_scores = []\n        for i in in_items:\n            marginal1 = value1_lst[i] / (current_value1 + 1e-6)\n            marginal2 = value2_lst[i] / (current_value2 + 1e-6)\n            novelty_scores.append(abs(marginal1 - marginal2))\n\n        if len(novelty_scores) > 0:\n            flip_idx = in_items[np.argmin(novelty_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8639361322487982,
            0.5879537463188171
        ],
        "raw_score": [
            27.519281736075754,
            28.131976466534326
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate adaptive weights and select solution with highest potential\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate adaptive weights based on current solution's coverage\n        coverage1 = obj[0] / max_value1 if max_value1 > 0 else 0.5\n        coverage2 = obj[1] / max_value2 if max_value2 > 0 else 0.5\n        weight1 = 1 - coverage1\n        weight2 = 1 - coverage2\n\n        # Calculate normalized potential with adaptive weights\n        potential = (weight1 * (max_value1 - obj[0]) + weight2 * (max_value2 - obj[1])) / (max_value1 + max_value2 + 1e-8)\n        potential_scores.append((sol, potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Phase 1: Novelty-aware biased replacement\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    if len(in_items) > 0 and len(out_items) > 0:\n        # Calculate novelty scores for in-items (low marginal value)\n        novelty_scores_in = []\n        for i in in_items:\n            marginal1 = value1_lst[i] / (current_value1 + 1e-6)\n            marginal2 = value2_lst[i] / (current_value2 + 1e-6)\n            novelty_scores_in.append(abs(marginal1 - marginal2))\n\n        # Calculate novelty scores for out-items (high potential)\n        novelty_scores_out = []\n        for j in out_items:\n            if current_weight + weight_lst[j] > capacity:\n                novelty_scores_out.append(-1)  # Infeasible\n                continue\n            marginal1 = value1_lst[j] / max_value1 if max_value1 > 0 else 0\n            marginal2 = value2_lst[j] / max_value2 if max_value2 > 0 else 0\n            novelty_scores_out.append(abs(marginal1 - marginal2))\n\n        # Find best replacement pair\n        if any(n > 0 for n in novelty_scores_out):\n            best_in = in_items[np.argmin(novelty_scores_in)]\n            best_out = out_items[np.argmax(novelty_scores_out)]\n            if novelty_scores_out[np.argmax(novelty_scores_out)] > 0:\n                new_solution[best_in] = 0\n                new_solution[best_out] = 1\n\n    # Phase 2: Dynamic swaps with objective bias\n    if np.sum(new_solution) > 1 and np.random.random() < 0.6:\n        in_items = np.where(new_solution == 1)[0]\n        i, j = np.random.choice(in_items, 2, replace=False)\n\n        # Calculate swap impact\n        delta_weight = weight_lst[j] - weight_lst[i]\n        temp_weight = current_weight + delta_weight\n\n        if temp_weight <= capacity:\n            # Calculate trade-off before and after swap\n            before_tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            after_tradeoff = abs((value1_lst[j] - (current_value1 - value1_lst[i] + value1_lst[j])) /\n                               (value2_lst[j] - (current_value2 - value2_lst[i] + value2_lst[j]) + 1e-6))\n\n            # Perform swap if it improves trade-off\n            if after_tradeoff < before_tradeoff:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 3: Probabilistic flips with novelty bias\n    flip_prob = 0.3 + 0.4 * (1 - (current_value1 + current_value2) / (max_value1 + max_value2))\n    if np.random.random() < flip_prob:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        # Calculate novelty scores for flips\n        novelty_scores = []\n        for i in in_items:\n            marginal1 = value1_lst[i] / (current_value1 + 1e-6)\n            marginal2 = value2_lst[i] / (current_value2 + 1e-6)\n            novelty_scores.append(abs(marginal1 - marginal2))\n\n        if len(novelty_scores) > 0:\n            flip_idx = in_items[np.argmin(novelty_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 46,
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid objective potential score that combines normalized improvement potential with diversity-aware selection, then applies a multi-phase local search combining adaptive item removal, objective-biased addition, balanced swaps, and probabilistic flips, while dynamically adjusting operation probabilities based on the current solution's characteristics to ensure feasibility. It prioritizes objective 1 (60%) over objective 2 (40%) in the initial selection but dynamically balances contributions during the local search phases, with higher probabilities for operations when packing density is moderate.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate hybrid objective potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential with diversity factor\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n        diversity = np.sum(sol) / len(sol)  # Packing density\n\n        # Hybrid potential score with dynamic weights\n        combined_potential = (0.6 * potential1 + 0.4 * potential2) * (1 + 0.3 * diversity)\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest hybrid potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current solution characteristics\n    total_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n    packing_density = np.sum(new_solution) / len(new_solution)\n\n    # Phase 1: Adaptive item removal\n    if packing_density > 0.6 and random.random() < 0.4:\n        # Remove items with lowest marginal contribution\n        marginal1 = value1_lst / (weight_lst + 1e-8)\n        marginal2 = value2_lst / (weight_lst + 1e-8)\n        combined_marginal = 0.5 * marginal1 + 0.5 * marginal2\n        candidates = np.where(new_solution == 1)[0]\n\n        if len(candidates) > 0:\n            # Remove items below 50th percentile\n            threshold = np.percentile(combined_marginal[candidates], 50)\n            remove_candidates = candidates[combined_marginal[candidates] < threshold]\n\n            for idx in remove_candidates:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n\n    # Phase 2: Objective-biased addition with dynamic probability\n    add_prob = 0.5 if packing_density < 0.4 else 0.3\n    if random.random() < add_prob:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            # Dynamic objective weighting based on current solution\n            obj_weight = current_value1 / (current_value1 + current_value2 + 1e-8)\n            ratios = (obj_weight * value1_lst + (1 - obj_weight) * value2_lst) / (weight_lst + 1e-8)\n\n            # Add top 20% of candidates\n            threshold = np.percentile(ratios[candidates], 80)\n            add_candidates = candidates[ratios[candidates] >= threshold]\n\n            for idx in add_candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    # Phase 3: Balanced swaps with diversity consideration\n    if packing_density > 0.3 and random.random() < 0.4:\n        items = np.where(new_solution == 1)[0]\n        if len(items) > 1:\n            # Select two items for swap\n            i, j = random.sample(list(items), 2)\n\n            # Check if swap maintains feasibility and improves diversity\n            if (total_weight - weight_lst[i] + weight_lst[j] <= capacity and\n                abs((value1_lst[i] - value1_lst[j]) / (max_value1 + 1e-8)) > 0.2 and\n                abs((value2_lst[i] - value2_lst[j]) / (max_value2 + 1e-8)) > 0.2):\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with adaptive probability\n    flip_prob = 0.2 if packing_density < 0.5 else 0.3\n    if random.random() < flip_prob:\n        idx = random.randint(0, len(new_solution) - 1)\n\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            # Remove item with probability based on marginal contribution\n            marginal = 0.5 * (value1_lst[idx] / (weight_lst[idx] + 1e-8)) + 0.5 * (value2_lst[idx] / (weight_lst[idx] + 1e-8))\n            if random.random() < 0.5 * marginal:\n                new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            # Add item with probability based on marginal contribution\n            marginal = 0.5 * (value1_lst[idx] / (weight_lst[idx] + 1e-8)) + 0.5 * (value2_lst[idx] / (weight_lst[idx] + 1e-8))\n            if random.random() < 0.7 * marginal:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7798497456656739,
            0.5490481853485107
        ],
        "raw_score": [
            27.47587318036346,
            28.09584465121344
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate hybrid objective potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential with diversity factor\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n        diversity = np.sum(sol) / len(sol)  # Packing density\n\n        # Hybrid potential score with dynamic weights\n        combined_potential = (0.6 * potential1 + 0.4 * potential2) * (1 + 0.3 * diversity)\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest hybrid potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current solution characteristics\n    total_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n    packing_density = np.sum(new_solution) / len(new_solution)\n\n    # Phase 1: Adaptive item removal\n    if packing_density > 0.6 and random.random() < 0.4:\n        # Remove items with lowest marginal contribution\n        marginal1 = value1_lst / (weight_lst + 1e-8)\n        marginal2 = value2_lst / (weight_lst + 1e-8)\n        combined_marginal = 0.5 * marginal1 + 0.5 * marginal2\n        candidates = np.where(new_solution == 1)[0]\n\n        if len(candidates) > 0:\n            # Remove items below 50th percentile\n            threshold = np.percentile(combined_marginal[candidates], 50)\n            remove_candidates = candidates[combined_marginal[candidates] < threshold]\n\n            for idx in remove_candidates:\n                if total_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    total_weight -= weight_lst[idx]\n\n    # Phase 2: Objective-biased addition with dynamic probability\n    add_prob = 0.5 if packing_density < 0.4 else 0.3\n    if random.random() < add_prob:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            # Dynamic objective weighting based on current solution\n            obj_weight = current_value1 / (current_value1 + current_value2 + 1e-8)\n            ratios = (obj_weight * value1_lst + (1 - obj_weight) * value2_lst) / (weight_lst + 1e-8)\n\n            # Add top 20% of candidates\n            threshold = np.percentile(ratios[candidates], 80)\n            add_candidates = candidates[ratios[candidates] >= threshold]\n\n            for idx in add_candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    total_weight += weight_lst[idx]\n\n    # Phase 3: Balanced swaps with diversity consideration\n    if packing_density > 0.3 and random.random() < 0.4:\n        items = np.where(new_solution == 1)[0]\n        if len(items) > 1:\n            # Select two items for swap\n            i, j = random.sample(list(items), 2)\n\n            # Check if swap maintains feasibility and improves diversity\n            if (total_weight - weight_lst[i] + weight_lst[j] <= capacity and\n                abs((value1_lst[i] - value1_lst[j]) / (max_value1 + 1e-8)) > 0.2 and\n                abs((value2_lst[i] - value2_lst[j]) / (max_value2 + 1e-8)) > 0.2):\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with adaptive probability\n    flip_prob = 0.2 if packing_density < 0.5 else 0.3\n    if random.random() < flip_prob:\n        idx = random.randint(0, len(new_solution) - 1)\n\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            # Remove item with probability based on marginal contribution\n            marginal = 0.5 * (value1_lst[idx] / (weight_lst[idx] + 1e-8)) + 0.5 * (value2_lst[idx] / (weight_lst[idx] + 1e-8))\n            if random.random() < 0.5 * marginal:\n                new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            # Add item with probability based on marginal contribution\n            marginal = 0.5 * (value1_lst[idx] / (weight_lst[idx] + 1e-8)) + 0.5 * (value2_lst[idx] / (weight_lst[idx] + 1e-8))\n            if random.random() < 0.7 * marginal:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 47,
        "algorithm": "The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a hybrid local search that prioritizes high-value-to-weight items, uses biased removal/addition, performs balanced swaps, and includes probabilistic flips\u2014with increased probabilities for swaps and flips to explore diverse regions while maintaining feasibility. It focuses on improving either objective 1 or 2 with a 40% bias, and uses value-to-weight ratios to guide item selection, ensuring the neighbor solution stays within capacity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection with higher value-to-weight focus\n    objective_bias = random.random()\n    if objective_bias < 0.4:\n        # Focus on value1 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias and higher probability\n    if random.random() < 0.5:  # Increased from 0.4\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.4:\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with higher probability and diversity focus\n    if np.sum(new_solution) > 1 and random.random() < 0.6:  # Increased from 0.5\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with higher probability and different bias\n    if random.random() < 0.4:  # Increased from 0.3\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9696108699777306,
            0.3680013418197632
        ],
        "raw_score": [
            27.531472102636563,
            27.722940598702838
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection with higher value-to-weight focus\n    objective_bias = random.random()\n    if objective_bias < 0.4:\n        # Focus on value1 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias and higher probability\n    if random.random() < 0.5:  # Increased from 0.4\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.4:\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with higher probability and diversity focus\n    if np.sum(new_solution) > 1 and random.random() < 0.6:  # Increased from 0.5\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with higher probability and different bias\n    if random.random() < 0.4:  # Increased from 0.3\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 47,
        "algorithm": "The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a hybrid local search that prioritizes high-value-to-weight items, uses biased removal/addition, performs balanced swaps, and includes probabilistic flips\u2014with increased probabilities for swaps and flips to explore diverse regions while maintaining feasibility. It focuses on improving either objective 1 or 2 with a 40% bias, and uses value-to-weight ratios to guide item selection, ensuring the neighbor solution stays within capacity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection with higher value-to-weight focus\n    objective_bias = random.random()\n    if objective_bias < 0.4:\n        # Focus on value1 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias and higher probability\n    if random.random() < 0.5:  # Increased from 0.4\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.4:\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with higher probability and diversity focus\n    if np.sum(new_solution) > 1 and random.random() < 0.6:  # Increased from 0.5\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with higher probability and different bias\n    if random.random() < 0.4:  # Increased from 0.3\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9696108699777306,
            0.3680013418197632
        ],
        "raw_score": [
            27.531472102636563,
            27.722940598702838
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection with higher value-to-weight focus\n    objective_bias = random.random()\n    if objective_bias < 0.4:\n        # Focus on value1 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias and higher probability\n    if random.random() < 0.5:  # Increased from 0.4\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.4:\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with higher probability and diversity focus\n    if np.sum(new_solution) > 1 and random.random() < 0.6:  # Increased from 0.5\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with higher probability and different bias\n    if random.random() < 0.4:  # Increased from 0.3\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 48,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate adaptive weights and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    weighted_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate adaptive weights based on current potential\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n        weight1 = 0.5 + 0.5 * potential1 / (potential1 + potential2 + 1e-8)\n        weight2 = 1 - weight1\n\n        # Calculate weighted score\n        score = weight1 * potential1 + weight2 * potential2\n        weighted_scores.append((sol, score))\n\n    if not weighted_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest weighted score\n    weighted_scores.sort(key=lambda x: -x[1])\n    base_solution = weighted_scores[0][0].copy()\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Novelty-driven item replacement\n    if np.sum(new_solution) > 0:\n        # Identify items with lowest marginal contribution\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        # Calculate marginal ratios for included items\n        if len(included) > 0:\n            ratios1 = value1_lst[included] / (weight_lst[included] + 1e-8)\n            ratios2 = value2_lst[included] / (weight_lst[included] + 1e-8)\n            combined_ratios = (ratios1 + ratios2) / 2\n\n            # Remove item with lowest combined ratio\n            remove_idx = included[np.argmin(combined_ratios)]\n            if total_weight - weight_lst[remove_idx] <= capacity:\n                new_solution[remove_idx] = 0\n                total_weight -= weight_lst[remove_idx]\n\n        # Add novel item with highest potential ratio\n        if len(excluded) > 0:\n            # Calculate potential ratios for excluded items\n            ratios1 = value1_lst[excluded] / (weight_lst[excluded] + 1e-8)\n            ratios2 = value2_lst[excluded] / (weight_lst[excluded] + 1e-8)\n\n            # Use adaptive weights to select which objective to prioritize\n            if random.random() < 0.5:\n                # Prioritize value1 improvement\n                add_idx = excluded[np.argmax(ratios1)]\n            else:\n                # Prioritize value2 improvement\n                add_idx = excluded[np.argmax(ratios2)]\n\n            if total_weight + weight_lst[add_idx] <= capacity:\n                new_solution[add_idx] = 1\n                total_weight += weight_lst[add_idx]\n\n    # Phase 2: Targeted swaps with objective awareness\n    if np.sum(new_solution) > 1 and random.random() < 0.6:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n\n        # Calculate potential improvement for each objective\n        delta1 = (value1_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-8)\n        delta2 = (value2_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-8)\n\n        # Only perform swap if it improves at least one objective\n        if (delta1 > 0 or delta2 > 0) and (total_weight - weight_lst[i] + weight_lst[j] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 3: Probabilistic flips with objective bias\n    if random.random() < 0.4:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            # Remove item with probability based on its marginal contribution\n            ratios1 = value1_lst[idx] / (weight_lst[idx] + 1e-8)\n            ratios2 = value2_lst[idx] / (weight_lst[idx] + 1e-8)\n            remove_prob = 0.2 + 0.8 * min(ratios1, ratios2)  # Higher probability to remove low-marginal items\n            if random.random() < remove_prob:\n                new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            # Add item with probability based on its potential\n            ratios1 = value1_lst[idx] / (weight_lst[idx] + 1e-8)\n            ratios2 = value2_lst[idx] / (weight_lst[idx] + 1e-8)\n            add_prob = 0.2 + 0.8 * max(ratios1, ratios2)  # Higher probability to add high-potential items\n            if random.random() < add_prob:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8397007649262349,
            0.4094524383544922
        ],
        "raw_score": [
            27.34483576347231,
            27.986275325397013
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate adaptive weights and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    weighted_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate adaptive weights based on current potential\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n        weight1 = 0.5 + 0.5 * potential1 / (potential1 + potential2 + 1e-8)\n        weight2 = 1 - weight1\n\n        # Calculate weighted score\n        score = weight1 * potential1 + weight2 * potential2\n        weighted_scores.append((sol, score))\n\n    if not weighted_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest weighted score\n    weighted_scores.sort(key=lambda x: -x[1])\n    base_solution = weighted_scores[0][0].copy()\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Novelty-driven item replacement\n    if np.sum(new_solution) > 0:\n        # Identify items with lowest marginal contribution\n        included = np.where(new_solution == 1)[0]\n        excluded = np.where(new_solution == 0)[0]\n\n        # Calculate marginal ratios for included items\n        if len(included) > 0:\n            ratios1 = value1_lst[included] / (weight_lst[included] + 1e-8)\n            ratios2 = value2_lst[included] / (weight_lst[included] + 1e-8)\n            combined_ratios = (ratios1 + ratios2) / 2\n\n            # Remove item with lowest combined ratio\n            remove_idx = included[np.argmin(combined_ratios)]\n            if total_weight - weight_lst[remove_idx] <= capacity:\n                new_solution[remove_idx] = 0\n                total_weight -= weight_lst[remove_idx]\n\n        # Add novel item with highest potential ratio\n        if len(excluded) > 0:\n            # Calculate potential ratios for excluded items\n            ratios1 = value1_lst[excluded] / (weight_lst[excluded] + 1e-8)\n            ratios2 = value2_lst[excluded] / (weight_lst[excluded] + 1e-8)\n\n            # Use adaptive weights to select which objective to prioritize\n            if random.random() < 0.5:\n                # Prioritize value1 improvement\n                add_idx = excluded[np.argmax(ratios1)]\n            else:\n                # Prioritize value2 improvement\n                add_idx = excluded[np.argmax(ratios2)]\n\n            if total_weight + weight_lst[add_idx] <= capacity:\n                new_solution[add_idx] = 1\n                total_weight += weight_lst[add_idx]\n\n    # Phase 2: Targeted swaps with objective awareness\n    if np.sum(new_solution) > 1 and random.random() < 0.6:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n\n        # Calculate potential improvement for each objective\n        delta1 = (value1_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-8)\n        delta2 = (value2_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-8)\n\n        # Only perform swap if it improves at least one objective\n        if (delta1 > 0 or delta2 > 0) and (total_weight - weight_lst[i] + weight_lst[j] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 3: Probabilistic flips with objective bias\n    if random.random() < 0.4:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            # Remove item with probability based on its marginal contribution\n            ratios1 = value1_lst[idx] / (weight_lst[idx] + 1e-8)\n            ratios2 = value2_lst[idx] / (weight_lst[idx] + 1e-8)\n            remove_prob = 0.2 + 0.8 * min(ratios1, ratios2)  # Higher probability to remove low-marginal items\n            if random.random() < remove_prob:\n                new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            # Add item with probability based on its potential\n            ratios1 = value1_lst[idx] / (weight_lst[idx] + 1e-8)\n            ratios2 = value2_lst[idx] / (weight_lst[idx] + 1e-8)\n            add_prob = 0.2 + 0.8 * max(ratios1, ratios2)  # Higher probability to add high-potential items\n            if random.random() < add_prob:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a balanced solution from the archive (prioritizing those with high combined objective product) and applies a hybrid local search combining weighted item addition, adaptive swapping, and probabilistic flipping, while dynamically adjusting weights based on solution quality and ensuring feasibility through capacity checks. It emphasizes objective-aware selection (using weighted value metrics) and diversity maintenance (through probabilistic flips), creating a balance between exploration and exploitation. The key design focuses on adaptive weights, combined value metrics, and solution quality-aware operations to improve multi-objective performance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines dynamic objective weighting with cluster-based local search and novelty-aware flips to generate high-quality neighbors in the BI-KP. It prioritizes solutions with underrepresented objectives, identifies item clusters with balanced trade-offs, and replaces them with high-marginal-value items from the archive, while probabilistically flipping items based on novelty scores to explore promising regions of the search space. The method ensures feasibility through adaptive capacity checks and maintains diversity by favoring less-explored solution regions.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using dynamic objective weighting to prioritize underrepresented objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -(x[1][0] / total_value1 + x[1][1] / total_value2))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Cluster-based local search: identify item clusters with balanced trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            tradeoff_scores.append(abs(ratio1 - ratio2))\n\n        # Identify clusters of items with similar trade-offs\n        from sklearn.cluster import KMeans\n        if len(in_solution) >= 3:\n            k = min(3, len(in_solution) // 2)\n            clusters = KMeans(n_clusters=k).fit_predict(np.array(tradeoff_scores).reshape(-1, 1))\n            cluster_sizes = np.bincount(clusters)\n\n            # Select largest cluster for potential replacement\n            target_cluster = np.argmax(cluster_sizes)\n            cluster_items = in_solution[clusters == target_cluster]\n\n            # Calculate potential replacements from archive\n            archive_items = np.where(np.logical_and.reduce([archive[selected_idx][0] == 1, new_solution == 0]))[0]\n            if len(archive_items) > 0:\n                combined_values = (weight1 * value1_lst[archive_items] + weight2 * value2_lst[archive_items]) / weight_lst[archive_items]\n                best_add_idx = archive_items[np.argmax(combined_values)]\n\n                # Replace entire cluster if feasible\n                cluster_weight = np.sum(weight_lst[cluster_items])\n                temp_weight = current_weight - cluster_weight + weight_lst[best_add_idx]\n                if temp_weight <= capacity:\n                    new_solution[cluster_items] = 0\n                    new_solution[best_add_idx] = 1\n                    current_weight = temp_weight\n\n    # Probabilistic flip with novelty-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 49,
        "algorithm": "The algorithm selects the best solution from the archive based on combined normalized objective scores, then applies a three-phase local search: first removing low-marginal items, then adding high-marginal items, and finally performing a novelty-aware probabilistic flip to potentially improve the solution further while ensuring feasibility. The method dynamically adjusts weights based on underrepresented objectives and incorporates probabilistic exploration to balance exploitation and diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined normalized objective score\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -((x[1][0] / total_value1) + (x[1][1] / total_value2)))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic weights based on underrepresented objectives\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Remove low-marginal items\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        worst_idx = in_solution[np.argmin(marginal_values)]\n        if current_weight - weight_lst[worst_idx] <= capacity:\n            new_solution[worst_idx] = 0\n\n    # Phase 2: Add high-marginal items from archive\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        marginal_values = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        best_idx = excluded_items[np.argmax(marginal_values)]\n        if current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n\n    # Phase 3: Novelty-aware probabilistic flip\n    flip_prob = 0.4 + 0.4 * (1 - ((current_value1 / total_value1) + (current_value2 / total_value2)) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            novelty_scores = (abs((value1_lst[candidates] / (current_value1 + 1e-6)) - (value2_lst[candidates] / (current_value2 + 1e-6))))\n            flip_idx = candidates[np.argmax(novelty_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8205218409832766,
            0.207279771566391
        ],
        "raw_score": [
            27.117276071697262,
            27.68502992495774
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined normalized objective score\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -((x[1][0] / total_value1) + (x[1][1] / total_value2)))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic weights based on underrepresented objectives\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Remove low-marginal items\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        worst_idx = in_solution[np.argmin(marginal_values)]\n        if current_weight - weight_lst[worst_idx] <= capacity:\n            new_solution[worst_idx] = 0\n\n    # Phase 2: Add high-marginal items from archive\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        marginal_values = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        best_idx = excluded_items[np.argmax(marginal_values)]\n        if current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n\n    # Phase 3: Novelty-aware probabilistic flip\n    flip_prob = 0.4 + 0.4 * (1 - ((current_value1 / total_value1) + (current_value2 / total_value2)) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            novelty_scores = (abs((value1_lst[candidates] / (current_value1 + 1e-6)) - (value2_lst[candidates] / (current_value2 + 1e-6))))\n            flip_idx = candidates[np.argmax(novelty_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a balanced solution from the archive (prioritizing those with high combined objective product) and applies a hybrid local search combining weighted item addition, adaptive swapping, and probabilistic flipping, while dynamically adjusting weights based on solution quality and ensuring feasibility through capacity checks. It emphasizes objective-aware selection (using weighted value metrics) and diversity maintenance (through probabilistic flips), creating a balance between exploration and exploitation. The key design focuses on adaptive weights, combined value metrics, and solution quality-aware operations to improve multi-objective performance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines dynamic objective weighting with cluster-based local search and novelty-aware flips to generate high-quality neighbors in the BI-KP. It prioritizes solutions with underrepresented objectives, identifies item clusters with balanced trade-offs, and replaces them with high-marginal-value items from the archive, while probabilistically flipping items based on novelty scores to explore promising regions of the search space. The method ensures feasibility through adaptive capacity checks and maintains diversity by favoring less-explored solution regions.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using dynamic objective weighting to prioritize underrepresented objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -(x[1][0] / total_value1 + x[1][1] / total_value2))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Cluster-based local search: identify item clusters with balanced trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            tradeoff_scores.append(abs(ratio1 - ratio2))\n\n        # Identify clusters of items with similar trade-offs\n        from sklearn.cluster import KMeans\n        if len(in_solution) >= 3:\n            k = min(3, len(in_solution) // 2)\n            clusters = KMeans(n_clusters=k).fit_predict(np.array(tradeoff_scores).reshape(-1, 1))\n            cluster_sizes = np.bincount(clusters)\n\n            # Select largest cluster for potential replacement\n            target_cluster = np.argmax(cluster_sizes)\n            cluster_items = in_solution[clusters == target_cluster]\n\n            # Calculate potential replacements from archive\n            archive_items = np.where(np.logical_and.reduce([archive[selected_idx][0] == 1, new_solution == 0]))[0]\n            if len(archive_items) > 0:\n                combined_values = (weight1 * value1_lst[archive_items] + weight2 * value2_lst[archive_items]) / weight_lst[archive_items]\n                best_add_idx = archive_items[np.argmax(combined_values)]\n\n                # Replace entire cluster if feasible\n                cluster_weight = np.sum(weight_lst[cluster_items])\n                temp_weight = current_weight - cluster_weight + weight_lst[best_add_idx]\n                if temp_weight <= capacity:\n                    new_solution[cluster_items] = 0\n                    new_solution[best_add_idx] = 1\n                    current_weight = temp_weight\n\n    # Probabilistic flip with novelty-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest novelty for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            novelty_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                novelty_scores.append(abs(ratio1 - ratio2))\n\n            flip_idx = flip_candidates[np.argmax(novelty_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 49,
        "algorithm": "The algorithm selects the best solution from the archive based on combined normalized objective scores, then applies a three-phase local search: first removing low-marginal items, then adding high-marginal items, and finally performing a novelty-aware probabilistic flip to potentially improve the solution further while ensuring feasibility. The method dynamically adjusts weights based on underrepresented objectives and incorporates probabilistic exploration to balance exploitation and diversity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined normalized objective score\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -((x[1][0] / total_value1) + (x[1][1] / total_value2)))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic weights based on underrepresented objectives\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Remove low-marginal items\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        worst_idx = in_solution[np.argmin(marginal_values)]\n        if current_weight - weight_lst[worst_idx] <= capacity:\n            new_solution[worst_idx] = 0\n\n    # Phase 2: Add high-marginal items from archive\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        marginal_values = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        best_idx = excluded_items[np.argmax(marginal_values)]\n        if current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n\n    # Phase 3: Novelty-aware probabilistic flip\n    flip_prob = 0.4 + 0.4 * (1 - ((current_value1 / total_value1) + (current_value2 / total_value2)) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            novelty_scores = (abs((value1_lst[candidates] / (current_value1 + 1e-6)) - (value2_lst[candidates] / (current_value2 + 1e-6))))\n            flip_idx = candidates[np.argmax(novelty_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8205218409832766,
            0.207279771566391
        ],
        "raw_score": [
            27.117276071697262,
            27.68502992495774
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined normalized objective score\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -((x[1][0] / total_value1) + (x[1][1] / total_value2)))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic weights based on underrepresented objectives\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Remove low-marginal items\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        worst_idx = in_solution[np.argmin(marginal_values)]\n        if current_weight - weight_lst[worst_idx] <= capacity:\n            new_solution[worst_idx] = 0\n\n    # Phase 2: Add high-marginal items from archive\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        marginal_values = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        best_idx = excluded_items[np.argmax(marginal_values)]\n        if current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n\n    # Phase 3: Novelty-aware probabilistic flip\n    flip_prob = 0.4 + 0.4 * (1 - ((current_value1 / total_value1) + (current_value2 / total_value2)) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            novelty_scores = (abs((value1_lst[candidates] / (current_value1 + 1e-6)) - (value2_lst[candidates] / (current_value2 + 1e-6))))\n            flip_idx = candidates[np.argmax(novelty_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a hybrid local search that prioritizes high-value-to-weight items, uses biased removal/addition, performs balanced swaps, and includes probabilistic flips\u2014with increased probabilities for swaps and flips to explore diverse regions while maintaining feasibility. It focuses on improving either objective 1 or 2 with a 40% bias, and uses value-to-weight ratios to guide item selection, ensuring the neighbor solution stays within capacity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection with higher value-to-weight focus\n    objective_bias = random.random()\n    if objective_bias < 0.4:\n        # Focus on value1 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias and higher probability\n    if random.random() < 0.5:  # Increased from 0.4\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.4:\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with higher probability and diversity focus\n    if np.sum(new_solution) > 1 and random.random() < 0.6:  # Increased from 0.5\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with higher probability and different bias\n    if random.random() < 0.4:  # Increased from 0.3\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 50,
        "algorithm": "The algorithm selects a promising solution from the archive by dynamically weighting objective potentials (prioritizing underrepresented objectives) and generates neighbors through two phases: first replacing low-marginal items with high-marginal ones from the archive while ensuring feasibility, then probabilistically flipping items to bias improvement toward underrepresented objectives. The selection process uses adaptive weights based on objective dominance, while the local search combines marginal value analysis with probabilistic flips to explore high-potential regions efficiently.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Dynamic weighting based on objective dominance\n        if potential1 > potential2:\n            weight1, weight2 = 0.7, 0.3\n        else:\n            weight1, weight2 = 0.3, 0.7\n\n        combined_potential = weight1 * potential1 + weight2 * potential2\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novelty-driven local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Replace low-marginal items with high-marginal ones from archive\n    for sol, _ in archive:\n        if np.sum(sol) == 0:\n            continue\n\n        # Calculate marginal values\n        marginal1 = value1_lst[sol == 1] / (weight_lst[sol == 1] + 1e-8)\n        marginal2 = value2_lst[sol == 1] / (weight_lst[sol == 1] + 1e-8)\n\n        # Find items to replace\n        current_marginal1 = value1_lst[new_solution == 1] / (weight_lst[new_solution == 1] + 1e-8)\n        current_marginal2 = value2_lst[new_solution == 1] / (weight_lst[new_solution == 1] + 1e-8)\n\n        if len(current_marginal1) > 0 and len(marginal1) > 0:\n            # Replace worst current item with best archive item if beneficial\n            worst_idx = np.where(new_solution == 1)[0][np.argmin(current_marginal1)]\n            best_idx = np.where(sol == 1)[0][np.argmax(marginal1)]\n\n            if (current_marginal1.min() < marginal1.max() and\n                total_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity):\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n                total_weight = total_weight - weight_lst[worst_idx] + weight_lst[best_idx]\n\n    # Phase 2: Probabilistic flips biased toward underrepresented objectives\n    if random.random() < 0.5:\n        current_obj1 = np.sum(value1_lst * new_solution)\n        current_obj2 = np.sum(value2_lst * new_solution)\n        total_obj1 = np.sum(value1_lst)\n        total_obj2 = np.sum(value2_lst)\n\n        # Calculate objective dominance\n        dominance1 = (total_obj1 - current_obj1) / (total_obj1 + 1e-8)\n        dominance2 = (total_obj2 - current_obj2) / (total_obj2 + 1e-8)\n\n        # Bias flips toward underrepresented objective\n        if dominance1 > dominance2:\n            # Focus on value1 improvement\n            candidates = np.where(new_solution == 0)[0]\n            if len(candidates) > 0:\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n                idx = candidates[np.argmax(ratios)]\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n        else:\n            # Focus on value2 improvement\n            candidates = np.where(new_solution == 0)[0]\n            if len(candidates) > 0:\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n                idx = candidates[np.argmax(ratios)]\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8913958697339112,
            1.9730267226696014
        ],
        "raw_score": [
            27.273684756325743,
            28.02966492767029
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Dynamic weighting based on objective dominance\n        if potential1 > potential2:\n            weight1, weight2 = 0.7, 0.3\n        else:\n            weight1, weight2 = 0.3, 0.7\n\n        combined_potential = weight1 * potential1 + weight2 * potential2\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novelty-driven local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Replace low-marginal items with high-marginal ones from archive\n    for sol, _ in archive:\n        if np.sum(sol) == 0:\n            continue\n\n        # Calculate marginal values\n        marginal1 = value1_lst[sol == 1] / (weight_lst[sol == 1] + 1e-8)\n        marginal2 = value2_lst[sol == 1] / (weight_lst[sol == 1] + 1e-8)\n\n        # Find items to replace\n        current_marginal1 = value1_lst[new_solution == 1] / (weight_lst[new_solution == 1] + 1e-8)\n        current_marginal2 = value2_lst[new_solution == 1] / (weight_lst[new_solution == 1] + 1e-8)\n\n        if len(current_marginal1) > 0 and len(marginal1) > 0:\n            # Replace worst current item with best archive item if beneficial\n            worst_idx = np.where(new_solution == 1)[0][np.argmin(current_marginal1)]\n            best_idx = np.where(sol == 1)[0][np.argmax(marginal1)]\n\n            if (current_marginal1.min() < marginal1.max() and\n                total_weight - weight_lst[worst_idx] + weight_lst[best_idx] <= capacity):\n                new_solution[worst_idx] = 0\n                new_solution[best_idx] = 1\n                total_weight = total_weight - weight_lst[worst_idx] + weight_lst[best_idx]\n\n    # Phase 2: Probabilistic flips biased toward underrepresented objectives\n    if random.random() < 0.5:\n        current_obj1 = np.sum(value1_lst * new_solution)\n        current_obj2 = np.sum(value2_lst * new_solution)\n        total_obj1 = np.sum(value1_lst)\n        total_obj2 = np.sum(value2_lst)\n\n        # Calculate objective dominance\n        dominance1 = (total_obj1 - current_obj1) / (total_obj1 + 1e-8)\n        dominance2 = (total_obj2 - current_obj2) / (total_obj2 + 1e-8)\n\n        # Bias flips toward underrepresented objective\n        if dominance1 > dominance2:\n            # Focus on value1 improvement\n            candidates = np.where(new_solution == 0)[0]\n            if len(candidates) > 0:\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n                idx = candidates[np.argmax(ratios)]\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n        else:\n            # Focus on value2 improvement\n            candidates = np.where(new_solution == 0)[0]\n            if len(candidates) > 0:\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n                idx = candidates[np.argmax(ratios)]\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Identify promising items to consider\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate weighted values for potential items\n        weighted_values = weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]\n        # Select top 3 items with highest weighted value\n        top_items = potential_items[np.argsort(weighted_values)[-3:]]\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Perform targeted swapping with items in solution\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Select two items to swap based on their contribution to both objectives\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Perform random flip with probability based on current solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a hybrid local search that prioritizes high-value-to-weight items, uses biased removal/addition, performs balanced swaps, and includes probabilistic flips\u2014with increased probabilities for swaps and flips to explore diverse regions while maintaining feasibility. It focuses on improving either objective 1 or 2 with a 40% bias, and uses value-to-weight ratios to guide item selection, ensuring the neighbor solution stays within capacity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection with higher value-to-weight focus\n    objective_bias = random.random()\n    if objective_bias < 0.4:\n        # Focus on value1 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias and higher probability\n    if random.random() < 0.5:  # Increased from 0.4\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.4:\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with higher probability and diversity focus\n    if np.sum(new_solution) > 1 and random.random() < 0.6:  # Increased from 0.5\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with higher probability and different bias\n    if random.random() < 0.4:  # Increased from 0.3\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 51,
        "algorithm": "The algorithm selects a solution from the archive using adaptive weights based on objective diversity, then applies a hybrid local search that combines novelty-driven item replacement, probabilistic flips biased toward underrepresented objectives, and an objective-balancing swap to improve solution quality while ensuring feasibility. It prioritizes items with high marginal value for the underrepresented objective and swaps complementary items to balance objectives, with dynamic capacity checks maintaining feasibility throughout.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate adaptive weights based on archive diversity and non-dominated front\n    obj1_values = np.array([obj[0] for _, obj in archive])\n    obj2_values = np.array([obj[1] for _, obj in archive])\n    max_obj1, min_obj1 = np.max(obj1_values), np.min(obj1_values)\n    max_obj2, min_obj2 = np.max(obj2_values), np.min(obj2_values)\n\n    # Normalize and calculate adaptive weights\n    if max_obj1 != min_obj1 and max_obj2 != min_obj2:\n        norm_obj1 = (obj1_values - min_obj1) / (max_obj1 - min_obj1)\n        norm_obj2 = (obj2_values - min_obj2) / (max_obj2 - min_obj2)\n        weights = norm_obj1 + norm_obj2\n        weights = weights / np.sum(weights)\n    else:\n        weights = np.ones(len(archive)) / len(archive)\n\n    # Select solution with adaptive probability\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and objective values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_obj1 = np.sum(value1_lst * new_solution)\n    current_obj2 = np.sum(value2_lst * new_solution)\n\n    # Identify underrepresented objective\n    total_obj1 = np.sum(value1_lst)\n    total_obj2 = np.sum(value2_lst)\n    obj1_ratio = current_obj1 / total_obj1 if total_obj1 > 0 else 0.5\n    obj2_ratio = current_obj2 / total_obj2 if total_obj2 > 0 else 0.5\n    underrepresented_obj = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Novelty-driven item replacement\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    # Remove items with low marginal value for the underrepresented objective\n    if len(in_solution) > 0:\n        if underrepresented_obj == 1:\n            marginal_values = value1_lst[in_solution] / (weight_lst[in_solution] + 1e-8)\n        else:\n            marginal_values = value2_lst[in_solution] / (weight_lst[in_solution] + 1e-8)\n\n        worst_item = in_solution[np.argmin(marginal_values)]\n        if current_weight - weight_lst[worst_item] <= capacity:\n            new_solution[worst_item] = 0\n            current_weight -= weight_lst[worst_item]\n\n    # Add items with high marginal value for the underrepresented objective\n    if len(out_solution) > 0:\n        if underrepresented_obj == 1:\n            marginal_values = value1_lst[out_solution] / (weight_lst[out_solution] + 1e-8)\n        else:\n            marginal_values = value2_lst[out_solution] / (weight_lst[out_solution] + 1e-8)\n\n        best_item = out_solution[np.argmax(marginal_values)]\n        if current_weight + weight_lst[best_item] <= capacity:\n            new_solution[best_item] = 1\n\n    # Objective-balancing swap\n    if len(in_solution) >= 2:\n        # Find two items with complementary marginal values\n        obj1_marginals = value1_lst[in_solution] / (weight_lst[in_solution] + 1e-8)\n        obj2_marginals = value2_lst[in_solution] / (weight_lst[in_solution] + 1e-8)\n\n        # Calculate balance scores (items that complement each other)\n        balance_scores = []\n        for i in range(len(in_solution)):\n            for j in range(i+1, len(in_solution)):\n                # Score based on how well one item compensates for the other's weakness\n                score = abs(obj1_marginals[i] - obj2_marginals[j]) + abs(obj2_marginals[i] - obj1_marginals[j])\n                balance_scores.append((i, j, score))\n\n        if balance_scores:\n            # Select the pair with highest balance score\n            i, j, _ = max(balance_scores, key=lambda x: x[2])\n            idx1, idx2 = in_solution[i], in_solution[j]\n\n            # Check if swap is feasible\n            if current_weight - weight_lst[idx1] + weight_lst[idx2] <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Probabilistic flip biased toward underrepresented objective\n    flip_prob = 0.4 if underrepresented_obj == 1 else 0.6\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.5639873193260272,
            4.7034153044223785
        ],
        "raw_score": [
            39.29980012385682,
            39.69755998637706
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate adaptive weights based on archive diversity and non-dominated front\n    obj1_values = np.array([obj[0] for _, obj in archive])\n    obj2_values = np.array([obj[1] for _, obj in archive])\n    max_obj1, min_obj1 = np.max(obj1_values), np.min(obj1_values)\n    max_obj2, min_obj2 = np.max(obj2_values), np.min(obj2_values)\n\n    # Normalize and calculate adaptive weights\n    if max_obj1 != min_obj1 and max_obj2 != min_obj2:\n        norm_obj1 = (obj1_values - min_obj1) / (max_obj1 - min_obj1)\n        norm_obj2 = (obj2_values - min_obj2) / (max_obj2 - min_obj2)\n        weights = norm_obj1 + norm_obj2\n        weights = weights / np.sum(weights)\n    else:\n        weights = np.ones(len(archive)) / len(archive)\n\n    # Select solution with adaptive probability\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and objective values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_obj1 = np.sum(value1_lst * new_solution)\n    current_obj2 = np.sum(value2_lst * new_solution)\n\n    # Identify underrepresented objective\n    total_obj1 = np.sum(value1_lst)\n    total_obj2 = np.sum(value2_lst)\n    obj1_ratio = current_obj1 / total_obj1 if total_obj1 > 0 else 0.5\n    obj2_ratio = current_obj2 / total_obj2 if total_obj2 > 0 else 0.5\n    underrepresented_obj = 1 if obj1_ratio < obj2_ratio else 2\n\n    # Novelty-driven item replacement\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    # Remove items with low marginal value for the underrepresented objective\n    if len(in_solution) > 0:\n        if underrepresented_obj == 1:\n            marginal_values = value1_lst[in_solution] / (weight_lst[in_solution] + 1e-8)\n        else:\n            marginal_values = value2_lst[in_solution] / (weight_lst[in_solution] + 1e-8)\n\n        worst_item = in_solution[np.argmin(marginal_values)]\n        if current_weight - weight_lst[worst_item] <= capacity:\n            new_solution[worst_item] = 0\n            current_weight -= weight_lst[worst_item]\n\n    # Add items with high marginal value for the underrepresented objective\n    if len(out_solution) > 0:\n        if underrepresented_obj == 1:\n            marginal_values = value1_lst[out_solution] / (weight_lst[out_solution] + 1e-8)\n        else:\n            marginal_values = value2_lst[out_solution] / (weight_lst[out_solution] + 1e-8)\n\n        best_item = out_solution[np.argmax(marginal_values)]\n        if current_weight + weight_lst[best_item] <= capacity:\n            new_solution[best_item] = 1\n\n    # Objective-balancing swap\n    if len(in_solution) >= 2:\n        # Find two items with complementary marginal values\n        obj1_marginals = value1_lst[in_solution] / (weight_lst[in_solution] + 1e-8)\n        obj2_marginals = value2_lst[in_solution] / (weight_lst[in_solution] + 1e-8)\n\n        # Calculate balance scores (items that complement each other)\n        balance_scores = []\n        for i in range(len(in_solution)):\n            for j in range(i+1, len(in_solution)):\n                # Score based on how well one item compensates for the other's weakness\n                score = abs(obj1_marginals[i] - obj2_marginals[j]) + abs(obj2_marginals[i] - obj1_marginals[j])\n                balance_scores.append((i, j, score))\n\n        if balance_scores:\n            # Select the pair with highest balance score\n            i, j, _ = max(balance_scores, key=lambda x: x[2])\n            idx1, idx2 = in_solution[i], in_solution[j]\n\n            # Check if swap is feasible\n            if current_weight - weight_lst[idx1] + weight_lst[idx2] <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n\n    # Probabilistic flip biased toward underrepresented objective\n    flip_prob = 0.4 if underrepresented_obj == 1 else 0.6\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a hybrid local search that prioritizes high-value-to-weight items, uses biased removal/addition, performs balanced swaps, and includes probabilistic flips\u2014with increased probabilities for swaps and flips to explore diverse regions while maintaining feasibility. It focuses on improving either objective 1 or 2 with a 40% bias, and uses value-to-weight ratios to guide item selection, ensuring the neighbor solution stays within capacity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection with higher value-to-weight focus\n    objective_bias = random.random()\n    if objective_bias < 0.4:\n        # Focus on value1 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias and higher probability\n    if random.random() < 0.5:  # Increased from 0.4\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.4:\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with higher probability and diversity focus\n    if np.sum(new_solution) > 1 and random.random() < 0.6:  # Increased from 0.5\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with higher probability and different bias\n    if random.random() < 0.4:  # Increased from 0.3\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 52,
        "algorithm": "This algorithm selects a promising solution from an archive based on dominance scores and applies a multi-phase local search: Phase 1 prioritizes Pareto-optimal item selection with adaptive value-to-weight ratios, Phase 2 performs probabilistic swaps biased toward improving either objective, and Phase 3 introduces diversification with probabilistic flips. The method intelligently balances exploration and exploitation while maintaining feasibility by always checking weight constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance scores and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    dominance_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate dominance score based on Pareto front approximation\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] > obj[0] and other_obj[1] >= obj[1]) or (other_obj[0] >= obj[0] and other_obj[1] > obj[1]):\n                dominated += 1\n        dominance_scores.append((sol, -dominated))  # Negative for sorting\n\n    if not dominance_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest dominance score\n    dominance_scores.sort(key=lambda x: x[1])\n    base_solution = dominance_scores[0][0].copy()\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Pareto-optimal item selection with adaptive value-to-weight prioritization\n    objective_ratio = np.sum(value1_lst) / (np.sum(value2_lst) + 1e-8)\n    if random.random() < 0.5:\n        # Select items based on combined value-to-weight ratio\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            combined_ratios = (value1_lst[candidates] * objective_ratio + value2_lst[candidates]) / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(combined_ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n    else:\n        # Remove items with lowest marginal contribution\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            marginal_contributions = (value1_lst[candidates] * objective_ratio + value2_lst[candidates]) / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(marginal_contributions)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Probabilistic swaps with objective-specific biases\n    if np.sum(new_solution) > 1 and random.random() < 0.6:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n\n        # Calculate swap impact based on objective bias\n        if random.random() < objective_ratio:\n            # Favor value1 improvement\n            delta_value1 = (value1_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-8)\n            if delta_value1 > 0 and total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Favor value2 improvement\n            delta_value2 = (value2_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-8)\n            if delta_value2 > 0 and total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 3: Diversification with probabilistic flips\n    if random.random() < 0.4:\n        # Flip items based on their potential contribution\n        for idx in range(len(new_solution)):\n            if random.random() < 0.3:  # 30% chance to consider each item\n                if new_solution[idx] == 0:\n                    if total_weight + weight_lst[idx] <= capacity:\n                        new_solution[idx] = 1\n                else:\n                    if total_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.857001948634718,
            0.46937957406044006
        ],
        "raw_score": [
            27.444118668601828,
            28.184058854585402
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance scores and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    dominance_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate dominance score based on Pareto front approximation\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if (other_obj[0] > obj[0] and other_obj[1] >= obj[1]) or (other_obj[0] >= obj[0] and other_obj[1] > obj[1]):\n                dominated += 1\n        dominance_scores.append((sol, -dominated))  # Negative for sorting\n\n    if not dominance_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest dominance score\n    dominance_scores.sort(key=lambda x: x[1])\n    base_solution = dominance_scores[0][0].copy()\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Pareto-optimal item selection with adaptive value-to-weight prioritization\n    objective_ratio = np.sum(value1_lst) / (np.sum(value2_lst) + 1e-8)\n    if random.random() < 0.5:\n        # Select items based on combined value-to-weight ratio\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            combined_ratios = (value1_lst[candidates] * objective_ratio + value2_lst[candidates]) / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(combined_ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n    else:\n        # Remove items with lowest marginal contribution\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            marginal_contributions = (value1_lst[candidates] * objective_ratio + value2_lst[candidates]) / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(marginal_contributions)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Probabilistic swaps with objective-specific biases\n    if np.sum(new_solution) > 1 and random.random() < 0.6:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n\n        # Calculate swap impact based on objective bias\n        if random.random() < objective_ratio:\n            # Favor value1 improvement\n            delta_value1 = (value1_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-8)\n            if delta_value1 > 0 and total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        else:\n            # Favor value2 improvement\n            delta_value2 = (value2_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-8)\n            if delta_value2 > 0 and total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 3: Diversification with probabilistic flips\n    if random.random() < 0.4:\n        # Flip items based on their potential contribution\n        for idx in range(len(new_solution)):\n            if random.random() < 0.3:  # 30% chance to consider each item\n                if new_solution[idx] == 0:\n                    if total_weight + weight_lst[idx] <= capacity:\n                        new_solution[idx] = 1\n                else:\n                    if total_weight - weight_lst[idx] <= capacity:\n                        new_solution[idx] = 0\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a hybrid local search that prioritizes high-value-to-weight items, uses biased removal/addition, performs balanced swaps, and includes probabilistic flips\u2014with increased probabilities for swaps and flips to explore diverse regions while maintaining feasibility. It focuses on improving either objective 1 or 2 with a 40% bias, and uses value-to-weight ratios to guide item selection, ensuring the neighbor solution stays within capacity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection with higher value-to-weight focus\n    objective_bias = random.random()\n    if objective_bias < 0.4:\n        # Focus on value1 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias and higher probability\n    if random.random() < 0.5:  # Increased from 0.4\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.4:\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with higher probability and diversity focus\n    if np.sum(new_solution) > 1 and random.random() < 0.6:  # Increased from 0.5\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with higher probability and different bias\n    if random.random() < 0.4:  # Increased from 0.3\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 53,
        "algorithm": "The algorithm selects a promising solution from the archive based on its potential for improvement in both objectives, then applies a hybrid local search that prioritizes high-value-to-weight items, adaptively removes/adds items, performs guided swaps, and includes probabilistic flips\u2014all while dynamically adjusting the bias between objectives to balance improvement in both value dimensions. The bias factor is derived from the current solution's objective values, guiding the search toward regions with better potential for multi-objective improvement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with equal objective weights\n        combined_potential = (potential1 + potential2) / 2\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Dynamic bias factor based on current solution's objective values\n    current_obj1 = np.sum(value1_lst * new_solution)\n    current_obj2 = np.sum(value2_lst * new_solution)\n    bias_factor = current_obj1 / (current_obj1 + current_obj2 + 1e-8)\n\n    # Phase 1: Adaptive removal with dynamic bias\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        # Calculate adaptive ratios based on bias factor\n        ratios = (bias_factor * value1_lst[candidates] + (1 - bias_factor) * value2_lst[candidates]) / (weight_lst[candidates] + 1e-8)\n        idx = candidates[np.argmax(ratios)]\n        if total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n\n    # Phase 2: Random addition with dynamic bias\n    if random.random() < 0.6:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            ratios = (bias_factor * value1_lst[candidates] + (1 - bias_factor) * value2_lst[candidates]) / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Guided swaps with dynamic bias\n    if np.sum(new_solution) > 1 and random.random() < 0.7:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Calculate swap gain based on dynamic bias\n        gain1 = value1_lst[j] - value1_lst[i]\n        gain2 = value2_lst[j] - value2_lst[i]\n        weighted_gain = bias_factor * gain1 + (1 - bias_factor) * gain2\n        if weighted_gain > 0 and total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with dynamic bias\n    if random.random() < 0.5:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8137554180243284,
            0.38788527250289917
        ],
        "raw_score": [
            27.534955684827445,
            28.064208119837758
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with equal objective weights\n        combined_potential = (potential1 + potential2) / 2\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Dynamic bias factor based on current solution's objective values\n    current_obj1 = np.sum(value1_lst * new_solution)\n    current_obj2 = np.sum(value2_lst * new_solution)\n    bias_factor = current_obj1 / (current_obj1 + current_obj2 + 1e-8)\n\n    # Phase 1: Adaptive removal with dynamic bias\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        # Calculate adaptive ratios based on bias factor\n        ratios = (bias_factor * value1_lst[candidates] + (1 - bias_factor) * value2_lst[candidates]) / (weight_lst[candidates] + 1e-8)\n        idx = candidates[np.argmax(ratios)]\n        if total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n\n    # Phase 2: Random addition with dynamic bias\n    if random.random() < 0.6:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            ratios = (bias_factor * value1_lst[candidates] + (1 - bias_factor) * value2_lst[candidates]) / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Guided swaps with dynamic bias\n    if np.sum(new_solution) > 1 and random.random() < 0.7:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Calculate swap gain based on dynamic bias\n        gain1 = value1_lst[j] - value1_lst[i]\n        gain2 = value2_lst[j] - value2_lst[i]\n        weighted_gain = bias_factor * gain1 + (1 - bias_factor) * gain2\n        if weighted_gain > 0 and total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with dynamic bias\n    if random.random() < 0.5:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 3 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a hybrid local search that prioritizes high-value-to-weight items, uses biased removal/addition, performs balanced swaps, and includes probabilistic flips\u2014with increased probabilities for swaps and flips to explore diverse regions while maintaining feasibility. It focuses on improving either objective 1 or 2 with a 40% bias, and uses value-to-weight ratios to guide item selection, ensuring the neighbor solution stays within capacity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection with higher value-to-weight focus\n    objective_bias = random.random()\n    if objective_bias < 0.4:\n        # Focus on value1 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias and higher probability\n    if random.random() < 0.5:  # Increased from 0.4\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.4:\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with higher probability and diversity focus\n    if np.sum(new_solution) > 1 and random.random() < 0.6:  # Increased from 0.5\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with higher probability and different bias\n    if random.random() < 0.4:  # Increased from 0.3\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 54,
        "algorithm": "The algorithm selects a promising solution from the archive using adaptive weights that combine normalized objective values and improvement potentials, then applies a hybrid local search with four phases: objective-biased removal of low-value-to-weight items, addition of high-value-to-weight items, novelty-driven swaps between high-marginal-gain items, and probabilistic flips biased toward improving underrepresented objectives, all while ensuring feasibility. The selection prioritizes solutions with balanced objectives and high improvement potential, while the local search dynamically adapts to the current solution's objective ratios and explore diverse neighborhoods.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate adaptive weights and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    weighted_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized objectives and improvement potentials\n        norm_obj1 = obj[0] / (max_value1 + 1e-8)\n        norm_obj2 = obj[1] / (max_value2 + 1e-8)\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Adaptive weight combining normalized objectives and potentials\n        weight = (norm_obj1 + norm_obj2) * (1 + abs(potential1 - potential2))\n        weighted_scores.append((sol, weight))\n\n    if not weighted_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest weighted score\n    weighted_scores.sort(key=lambda x: -x[1])\n    base_solution = weighted_scores[0][0].copy()\n\n    # Generate neighbor with hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate current objective ratios\n    current_obj1 = np.sum(value1_lst * new_solution)\n    current_obj2 = np.sum(value2_lst * new_solution)\n    obj_ratio = current_obj1 / (current_obj2 + 1e-8)\n\n    # Phase 1: Objective-biased removal of low-value-to-weight items\n    objective_bias = random.random()\n    candidates = np.where(new_solution == 1)[0]\n\n    if len(candidates) > 0:\n        if objective_bias < obj_ratio:\n            # Focus on value1 improvement\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n        else:\n            # Focus on value2 improvement\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n\n        if total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    # Phase 2: Addition of high-value-to-weight items\n    candidates = np.where(new_solution == 0)[0]\n    if len(candidates) > 0:\n        if objective_bias < obj_ratio:\n            # Add highest value1/weight item\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n        else:\n            # Add highest value2/weight item\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n\n        idx = candidates[np.argmax(ratios)]\n        if total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            total_weight += weight_lst[idx]\n\n    # Phase 3: Novelty-driven swaps between items with high marginal gains\n    if np.sum(new_solution) > 1 and random.random() < 0.7:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n\n        # Calculate marginal gains for each objective\n        marginal1 = (value1_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-8)\n        marginal2 = (value2_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-8)\n\n        # Only swap if it improves either objective\n        if (marginal1 > 0 or marginal2 > 0) and total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flips biased toward improving underrepresented objective\n    if random.random() < 0.5:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.23583484855861622,
            5.924146950244904
        ],
        "raw_score": [
            58.48314903037817,
            45.2807555728389
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate adaptive weights and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    weighted_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized objectives and improvement potentials\n        norm_obj1 = obj[0] / (max_value1 + 1e-8)\n        norm_obj2 = obj[1] / (max_value2 + 1e-8)\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Adaptive weight combining normalized objectives and potentials\n        weight = (norm_obj1 + norm_obj2) * (1 + abs(potential1 - potential2))\n        weighted_scores.append((sol, weight))\n\n    if not weighted_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest weighted score\n    weighted_scores.sort(key=lambda x: -x[1])\n    base_solution = weighted_scores[0][0].copy()\n\n    # Generate neighbor with hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate current objective ratios\n    current_obj1 = np.sum(value1_lst * new_solution)\n    current_obj2 = np.sum(value2_lst * new_solution)\n    obj_ratio = current_obj1 / (current_obj2 + 1e-8)\n\n    # Phase 1: Objective-biased removal of low-value-to-weight items\n    objective_bias = random.random()\n    candidates = np.where(new_solution == 1)[0]\n\n    if len(candidates) > 0:\n        if objective_bias < obj_ratio:\n            # Focus on value1 improvement\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n        else:\n            # Focus on value2 improvement\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n\n        if total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    # Phase 2: Addition of high-value-to-weight items\n    candidates = np.where(new_solution == 0)[0]\n    if len(candidates) > 0:\n        if objective_bias < obj_ratio:\n            # Add highest value1/weight item\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n        else:\n            # Add highest value2/weight item\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n\n        idx = candidates[np.argmax(ratios)]\n        if total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n            total_weight += weight_lst[idx]\n\n    # Phase 3: Novelty-driven swaps between items with high marginal gains\n    if np.sum(new_solution) > 1 and random.random() < 0.7:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n\n        # Calculate marginal gains for each objective\n        marginal1 = (value1_lst[j] - value1_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-8)\n        marginal2 = (value2_lst[j] - value2_lst[i]) / (weight_lst[j] - weight_lst[i] + 1e-8)\n\n        # Only swap if it improves either objective\n        if (marginal1 > 0 or marginal2 > 0) and total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flips biased toward improving underrepresented objective\n    if random.random() < 0.5:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a balanced solution from the archive (prioritizing those with high combined objective product) and applies a hybrid local search combining weighted item addition, adaptive swapping, and probabilistic flipping, while dynamically adjusting weights based on solution quality and ensuring feasibility through capacity checks. It emphasizes objective-aware selection (using weighted value metrics) and diversity maintenance (through probabilistic flips), creating a balance between exploration and exploitation. The key design focuses on adaptive weights, combined value metrics, and solution quality-aware operations to improve multi-objective performance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a hybrid local search that prioritizes high-value-to-weight items, uses biased removal/addition, performs balanced swaps, and includes probabilistic flips\u2014with increased probabilities for swaps and flips to explore diverse regions while maintaining feasibility. It focuses on improving either objective 1 or 2 with a 40% bias, and uses value-to-weight ratios to guide item selection, ensuring the neighbor solution stays within capacity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection with higher value-to-weight focus\n    objective_bias = random.random()\n    if objective_bias < 0.4:\n        # Focus on value1 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias and higher probability\n    if random.random() < 0.5:  # Increased from 0.4\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.4:\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with higher probability and diversity focus\n    if np.sum(new_solution) > 1 and random.random() < 0.6:  # Increased from 0.5\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with higher probability and different bias\n    if random.random() < 0.4:  # Increased from 0.3\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects the best solution from the archive based on combined normalized objective scores, then applies a three-phase local search: first removing low-marginal items, then adding high-marginal items, and finally performing a novelty-aware probabilistic flip to potentially improve the solution further while ensuring feasibility. The method dynamically adjusts weights based on underrepresented objectives and incorporates probabilistic exploration to balance exploitation and diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined normalized objective score\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -((x[1][0] / total_value1) + (x[1][1] / total_value2)))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic weights based on underrepresented objectives\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Remove low-marginal items\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        worst_idx = in_solution[np.argmin(marginal_values)]\n        if current_weight - weight_lst[worst_idx] <= capacity:\n            new_solution[worst_idx] = 0\n\n    # Phase 2: Add high-marginal items from archive\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        marginal_values = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        best_idx = excluded_items[np.argmax(marginal_values)]\n        if current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n\n    # Phase 3: Novelty-aware probabilistic flip\n    flip_prob = 0.4 + 0.4 * (1 - ((current_value1 / total_value1) + (current_value2 / total_value2)) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            novelty_scores = (abs((value1_lst[candidates] / (current_value1 + 1e-6)) - (value2_lst[candidates] / (current_value2 + 1e-6))))\n            flip_idx = candidates[np.argmax(novelty_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 55,
        "algorithm": "This algorithm selects a solution from the archive by prioritizing those with high Pareto dominance and objective diversity, then applies a hybrid local search combining novelty-driven swaps, marginal improvement steps, and probabilistic flips biased toward underrepresented objectives, while dynamically adjusting weights to balance exploration and exploitation. The selection process favors solutions with high combined objective values and diversity, while the local search prioritizes items with high novelty scores and marginal improvements, with probabilistic flips to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest Pareto dominance and objective diversity\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1] * (1 + abs(x[1][0] - x[1][1]))))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic weights based on objective diversity\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Novelty-driven swaps\n    in_solution = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(excluded_items) > 0:\n        # Calculate novelty scores for included items\n        novelty_scores = (abs((value1_lst[in_solution] / (current_value1 + 1e-6)) - (value2_lst[in_solution] / (current_value2 + 1e-6))))\n        swap_candidate = in_solution[np.argmax(novelty_scores)]\n\n        # Find best excluded item to swap with\n        marginal_values = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        best_excluded = excluded_items[np.argmax(marginal_values)]\n\n        # Perform swap if feasible\n        if current_weight - weight_lst[swap_candidate] + weight_lst[best_excluded] <= capacity:\n            new_solution[swap_candidate] = 0\n            new_solution[best_excluded] = 1\n\n    # Phase 2: Marginal improvement\n    if np.random.random() < 0.5:\n        # Remove low-marginal item\n        if len(in_solution) > 0:\n            marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n            worst_idx = in_solution[np.argmin(marginal_values)]\n            if current_weight - weight_lst[worst_idx] <= capacity:\n                new_solution[worst_idx] = 0\n\n        # Add high-marginal item\n        if len(excluded_items) > 0:\n            marginal_values = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n            best_idx = excluded_items[np.argmax(marginal_values)]\n            if current_weight + weight_lst[best_idx] <= capacity:\n                new_solution[best_idx] = 1\n\n    # Phase 3: Probabilistic flip biased toward underrepresented objective\n    flip_prob = 0.3 + 0.5 * (1 - ((current_value1 / total_value1) + (current_value2 / total_value2)) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6686071864147365,
            0.9605536460876465
        ],
        "raw_score": [
            31.189272267103604,
            32.829893704096186
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest Pareto dominance and objective diversity\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1] * (1 + abs(x[1][0] - x[1][1]))))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic weights based on objective diversity\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Novelty-driven swaps\n    in_solution = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(excluded_items) > 0:\n        # Calculate novelty scores for included items\n        novelty_scores = (abs((value1_lst[in_solution] / (current_value1 + 1e-6)) - (value2_lst[in_solution] / (current_value2 + 1e-6))))\n        swap_candidate = in_solution[np.argmax(novelty_scores)]\n\n        # Find best excluded item to swap with\n        marginal_values = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        best_excluded = excluded_items[np.argmax(marginal_values)]\n\n        # Perform swap if feasible\n        if current_weight - weight_lst[swap_candidate] + weight_lst[best_excluded] <= capacity:\n            new_solution[swap_candidate] = 0\n            new_solution[best_excluded] = 1\n\n    # Phase 2: Marginal improvement\n    if np.random.random() < 0.5:\n        # Remove low-marginal item\n        if len(in_solution) > 0:\n            marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n            worst_idx = in_solution[np.argmin(marginal_values)]\n            if current_weight - weight_lst[worst_idx] <= capacity:\n                new_solution[worst_idx] = 0\n\n        # Add high-marginal item\n        if len(excluded_items) > 0:\n            marginal_values = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n            best_idx = excluded_items[np.argmax(marginal_values)]\n            if current_weight + weight_lst[best_idx] <= capacity:\n                new_solution[best_idx] = 1\n\n    # Phase 3: Probabilistic flip biased toward underrepresented objective\n    flip_prob = 0.3 + 0.5 * (1 - ((current_value1 / total_value1) + (current_value2 / total_value2)) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm combines adaptive multi-objective selection with a tiered local search that prioritizes high-impact swaps between complementary items, followed by probabilistic flips based on item contribution potential, and finally ensures feasibility through targeted removals/additions. It dynamically balances exploration and exploitation by weighting operations based on the current solution's trade-off profile, with a strong emphasis on maintaining solution quality through normalized objective diversity and weighted value calculations. The tiered approach ensures systematic improvement while preserving feasibility at every step.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate normalized objectives and diversity scores\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    normalized_solutions = []\n    for sol, obj in archive:\n        if np.sum(weight_lst * sol) > capacity:\n            continue\n        norm_obj1 = obj[0] / total_value1 if total_value1 > 0 else 0\n        norm_obj2 = obj[1] / total_value2 if total_value2 > 0 else 0\n        diversity = abs(norm_obj1 - norm_obj2)\n        normalized_solutions.append((sol, (norm_obj1, norm_obj2), diversity))\n\n    if not normalized_solutions:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest diversity (most balanced trade-off)\n    selected = max(normalized_solutions, key=lambda x: x[2])\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive weights based on current solution's trade-off\n    weight1 = current_value1 / (current_value1 + current_value2 + 1e-8)\n    weight2 = current_value2 / (current_value1 + current_value2 + 1e-8)\n\n    # Tiered local search\n    n_items = len(weight_lst)\n\n    # Phase 1: High-impact swaps between items with complementary trade-offs\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        # Sort by trade-off alignment with current solution's profile\n        tradeoff_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on how well this item's trade-off complements current solution's profile\n            score = (weight1 * val2 + weight2 * val1) / (val1 + val2 + 1e-8)\n            tradeoff_scores.append((i, score))\n\n        # Select top 2 items with most complementary trade-offs\n        tradeoff_scores.sort(key=lambda x: -x[1])\n        if len(tradeoff_scores) >= 2:\n            i1, i2 = tradeoff_scores[0][0], tradeoff_scores[1][0]\n            # Check if swap is feasible\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n                current_weight = current_weight - weight_lst[i1] + weight_lst[i2]\n\n    # Phase 2: Probabilistic flips based on item's potential contribution\n    if n_items > 0 and np.random.random() < 0.5:\n        # Calculate potential contribution scores for all items\n        potential_scores = []\n        for i in range(n_items):\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if new_solution[i] == 1:\n                # For included items, score is based on how much we might gain by removing\n                score = (weight1 * val1 + weight2 * val2) * (1 - (current_weight - weight_lst[i]) / capacity)\n            else:\n                # For excluded items, score is based on how much we might gain by adding\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                score = (weight1 * val1 + weight2 * val2) * (current_weight + weight_lst[i]) / capacity\n\n            potential_scores.append((i, score))\n\n        if potential_scores:\n            # Select item with highest potential score\n            selected_item = max(potential_scores, key=lambda x: x[1])[0]\n            if new_solution[selected_item] == 1 and current_weight - weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 0\n                current_weight -= weight_lst[selected_item]\n            elif new_solution[selected_item] == 0 and current_weight + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    # Phase 3: Feasibility preservation with targeted removals/additions\n    # Remove least valuable items first if over capacity\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Find item with lowest weighted value\n        weighted_values = weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]\n        remove_idx = in_items[np.argmin(weighted_values)]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    # Add most valuable items until no more capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        # Find item with highest weighted value\n        weighted_values = weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items]\n        add_idx = available_items[np.argmax(weighted_values)]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 56,
        "algorithm": "The algorithm combines dynamic objective prioritization with a tiered local search that first removes low-marginal items, probabilistically flips items based on potential improvement to underrepresented objectives, and performs targeted swaps between complementary items to systematically explore the solution space while maintaining feasibility and Pareto dominance. It prioritizes objectives based on the current solution's trade-off profile and uses weighted scores to guide item selection and swaps.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate normalized objectives and identify the most balanced solution\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    balanced_solution = None\n    max_diversity = -1\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n        norm_obj1 = obj[0] / total_value1 if total_value1 > 0 else 0\n        norm_obj2 = obj[1] / total_value2 if total_value2 > 0 else 0\n        diversity = abs(norm_obj1 - norm_obj2)\n        if diversity > max_diversity:\n            max_diversity = diversity\n            balanced_solution = sol\n\n    if balanced_solution is None:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    base_solution = balanced_solution.copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Determine objective weights based on current trade-off\n    weight1 = current_value1 / (current_value1 + current_value2 + 1e-8)\n    weight2 = current_value2 / (current_value1 + current_value2 + 1e-8)\n\n    # Phase 1: Remove least marginal items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        marginal_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on marginal contribution to current solution's trade-off\n            score = weight1 * val1 + weight2 * val2\n            marginal_scores.append((i, score))\n\n        marginal_scores.sort(key=lambda x: x[1])\n        for i, score in marginal_scores:\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                break\n\n    # Phase 2: Probabilistic flips based on potential improvement\n    if random.random() < 0.6:\n        out_items = np.where(new_solution == 0)[0]\n        if len(out_items) > 0:\n            potential_scores = []\n            for i in out_items:\n                val1 = value1_lst[i]\n                val2 = value2_lst[i]\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                # Score based on potential improvement to underrepresented objective\n                if weight1 > weight2:\n                    score = val2 / (weight_lst[i] + 1e-8)\n                else:\n                    score = val1 / (weight_lst[i] + 1e-8)\n                potential_scores.append((i, score))\n\n            if potential_scores:\n                selected_item = max(potential_scores, key=lambda x: x[1])[0]\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    # Phase 3: Targeted swaps between complementary items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        swap_candidates = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on how well this item's trade-off complements current solution's profile\n            score = (weight1 * val2 + weight2 * val1) / (val1 + val2 + 1e-8)\n            swap_candidates.append((i, score))\n\n        swap_candidates.sort(key=lambda x: -x[1])\n        if len(swap_candidates) >= 2:\n            i1, i2 = swap_candidates[0][0], swap_candidates[1][0]\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.5223694478163956,
            4.147333860397339
        ],
        "raw_score": [
            29.20351811092516,
            29.72176531388474
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate normalized objectives and identify the most balanced solution\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    balanced_solution = None\n    max_diversity = -1\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n        norm_obj1 = obj[0] / total_value1 if total_value1 > 0 else 0\n        norm_obj2 = obj[1] / total_value2 if total_value2 > 0 else 0\n        diversity = abs(norm_obj1 - norm_obj2)\n        if diversity > max_diversity:\n            max_diversity = diversity\n            balanced_solution = sol\n\n    if balanced_solution is None:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    base_solution = balanced_solution.copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Determine objective weights based on current trade-off\n    weight1 = current_value1 / (current_value1 + current_value2 + 1e-8)\n    weight2 = current_value2 / (current_value1 + current_value2 + 1e-8)\n\n    # Phase 1: Remove least marginal items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) > 0:\n        marginal_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on marginal contribution to current solution's trade-off\n            score = weight1 * val1 + weight2 * val2\n            marginal_scores.append((i, score))\n\n        marginal_scores.sort(key=lambda x: x[1])\n        for i, score in marginal_scores:\n            if current_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                break\n\n    # Phase 2: Probabilistic flips based on potential improvement\n    if random.random() < 0.6:\n        out_items = np.where(new_solution == 0)[0]\n        if len(out_items) > 0:\n            potential_scores = []\n            for i in out_items:\n                val1 = value1_lst[i]\n                val2 = value2_lst[i]\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                # Score based on potential improvement to underrepresented objective\n                if weight1 > weight2:\n                    score = val2 / (weight_lst[i] + 1e-8)\n                else:\n                    score = val1 / (weight_lst[i] + 1e-8)\n                potential_scores.append((i, score))\n\n            if potential_scores:\n                selected_item = max(potential_scores, key=lambda x: x[1])[0]\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    # Phase 3: Targeted swaps between complementary items\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        swap_candidates = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on how well this item's trade-off complements current solution's profile\n            score = (weight1 * val2 + weight2 * val1) / (val1 + val2 + 1e-8)\n            swap_candidates.append((i, score))\n\n        swap_candidates.sort(key=lambda x: -x[1])\n        if len(swap_candidates) >= 2:\n            i1, i2 = swap_candidates[0][0], swap_candidates[1][0]\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe heuristic selects a balanced solution from the archive, then applies a hybrid local search combining targeted swaps (prioritizing high-value items), probabilistic flips, feasibility checks, and greedy additions of valuable items. It dynamically adjusts weights based on current solution quality and ensures feasibility through intelligent item removals and additions. The approach balances exploration and exploitation while maintaining Pareto optimality potential.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Targeted swapping based on adaptive weights\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                current_weight = temp_weight\n\n    # Step 2: Random flip with probability based on solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and n_items > 0:\n        flip_idx = np.random.choice(n_items)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Step 3: Ensure feasibility by removing the least valuable items if needed\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    # Step 4: Add the most valuable available items if there's remaining capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        add_idx = available_items[np.argmax(weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm combines adaptive multi-objective selection with a tiered local search that prioritizes high-impact swaps between complementary items, followed by probabilistic flips based on item contribution potential, and finally ensures feasibility through targeted removals/additions. It dynamically balances exploration and exploitation by weighting operations based on the current solution's trade-off profile, with a strong emphasis on maintaining solution quality through normalized objective diversity and weighted value calculations. The tiered approach ensures systematic improvement while preserving feasibility at every step.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate normalized objectives and diversity scores\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    normalized_solutions = []\n    for sol, obj in archive:\n        if np.sum(weight_lst * sol) > capacity:\n            continue\n        norm_obj1 = obj[0] / total_value1 if total_value1 > 0 else 0\n        norm_obj2 = obj[1] / total_value2 if total_value2 > 0 else 0\n        diversity = abs(norm_obj1 - norm_obj2)\n        normalized_solutions.append((sol, (norm_obj1, norm_obj2), diversity))\n\n    if not normalized_solutions:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest diversity (most balanced trade-off)\n    selected = max(normalized_solutions, key=lambda x: x[2])\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive weights based on current solution's trade-off\n    weight1 = current_value1 / (current_value1 + current_value2 + 1e-8)\n    weight2 = current_value2 / (current_value1 + current_value2 + 1e-8)\n\n    # Tiered local search\n    n_items = len(weight_lst)\n\n    # Phase 1: High-impact swaps between items with complementary trade-offs\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        # Sort by trade-off alignment with current solution's profile\n        tradeoff_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on how well this item's trade-off complements current solution's profile\n            score = (weight1 * val2 + weight2 * val1) / (val1 + val2 + 1e-8)\n            tradeoff_scores.append((i, score))\n\n        # Select top 2 items with most complementary trade-offs\n        tradeoff_scores.sort(key=lambda x: -x[1])\n        if len(tradeoff_scores) >= 2:\n            i1, i2 = tradeoff_scores[0][0], tradeoff_scores[1][0]\n            # Check if swap is feasible\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n                current_weight = current_weight - weight_lst[i1] + weight_lst[i2]\n\n    # Phase 2: Probabilistic flips based on item's potential contribution\n    if n_items > 0 and np.random.random() < 0.5:\n        # Calculate potential contribution scores for all items\n        potential_scores = []\n        for i in range(n_items):\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if new_solution[i] == 1:\n                # For included items, score is based on how much we might gain by removing\n                score = (weight1 * val1 + weight2 * val2) * (1 - (current_weight - weight_lst[i]) / capacity)\n            else:\n                # For excluded items, score is based on how much we might gain by adding\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                score = (weight1 * val1 + weight2 * val2) * (current_weight + weight_lst[i]) / capacity\n\n            potential_scores.append((i, score))\n\n        if potential_scores:\n            # Select item with highest potential score\n            selected_item = max(potential_scores, key=lambda x: x[1])[0]\n            if new_solution[selected_item] == 1 and current_weight - weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 0\n                current_weight -= weight_lst[selected_item]\n            elif new_solution[selected_item] == 0 and current_weight + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    # Phase 3: Feasibility preservation with targeted removals/additions\n    # Remove least valuable items first if over capacity\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Find item with lowest weighted value\n        weighted_values = weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]\n        remove_idx = in_items[np.argmin(weighted_values)]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    # Add most valuable items until no more capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        # Find item with highest weighted value\n        weighted_values = weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items]\n        add_idx = available_items[np.argmax(weighted_values)]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 57,
        "algorithm": "The algorithm combines adaptive multi-objective selection with a tiered local search, prioritizing solutions in underrepresented regions of the objective space. It first identifies the most promising solution based on objective diversity, then performs targeted swaps between complementary items, followed by probabilistic flips based on item contribution potential, and finally ensures feasibility through marginal removal/addition of items. The approach dynamically adjusts weights and focuses on improving the underrepresented objective while maintaining Pareto optimality through systematic feasibility checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective ranges and identify underrepresented regions\n    all_values1 = [obj[0] for _, obj in archive]\n    all_values2 = [obj[1] for _, obj in archive]\n    min_val1, max_val1 = min(all_values1), max(all_values1)\n    min_val2, max_val2 = min(all_values2), max(all_values2)\n\n    # Identify underrepresented regions in the objective space\n    underrepresented_region = None\n    if max_val1 - min_val1 > max_val2 - min_val2:\n        underrepresented_region = 'value2'\n    elif max_val2 - min_val2 > max_val1 - min_val1:\n        underrepresented_region = 'value1'\n    else:\n        underrepresented_region = 'balanced'\n\n    # Select solution with highest potential for improvement in underrepresented region\n    if underrepresented_region == 'value1':\n        selected = max(archive, key=lambda x: x[1][1] - x[1][0])\n    elif underrepresented_region == 'value2':\n        selected = max(archive, key=lambda x: x[1][0] - x[1][1])\n    else:\n        selected = max(archive, key=lambda x: x[1][0] + x[1][1])\n\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive weights based on underrepresented region\n    if underrepresented_region == 'value1':\n        weight1, weight2 = 0.7, 0.3\n    elif underrepresented_region == 'value2':\n        weight1, weight2 = 0.3, 0.7\n    else:\n        weight1, weight2 = 0.5, 0.5\n\n    # Tiered local search\n    n_items = len(weight_lst)\n\n    # Phase 1: Targeted swaps between items with complementary trade-offs\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        # Calculate trade-off scores based on current underrepresented region\n        tradeoff_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if underrepresented_region == 'value1':\n                score = val2 - val1\n            elif underrepresented_region == 'value2':\n                score = val1 - val2\n            else:\n                score = val1 + val2\n            tradeoff_scores.append((i, score))\n\n        # Select top 2 items with most complementary trade-offs\n        tradeoff_scores.sort(key=lambda x: -x[1])\n        if len(tradeoff_scores) >= 2:\n            i1, i2 = tradeoff_scores[0][0], tradeoff_scores[1][0]\n            # Check if swap is feasible\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n                current_weight = current_weight - weight_lst[i1] + weight_lst[i2]\n\n    # Phase 2: Probabilistic flips based on item contribution potential\n    if n_items > 0 and np.random.random() < 0.6:\n        # Calculate potential contribution scores for all items\n        potential_scores = []\n        for i in range(n_items):\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if new_solution[i] == 1:\n                # For included items, score is based on how much we might gain by removing\n                if underrepresented_region == 'value1':\n                    score = val2 - val1\n                elif underrepresented_region == 'value2':\n                    score = val1 - val2\n                else:\n                    score = val1 + val2\n                score *= (1 - (current_weight - weight_lst[i]) / capacity)\n            else:\n                # For excluded items, score is based on how much we might gain by adding\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                if underrepresented_region == 'value1':\n                    score = val2 - val1\n                elif underrepresented_region == 'value2':\n                    score = val1 - val2\n                else:\n                    score = val1 + val2\n                score *= (current_weight + weight_lst[i]) / capacity\n\n            potential_scores.append((i, score))\n\n        if potential_scores:\n            # Select item with highest potential score\n            selected_item = max(potential_scores, key=lambda x: x[1])[0]\n            if new_solution[selected_item] == 1 and current_weight - weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 0\n                current_weight -= weight_lst[selected_item]\n            elif new_solution[selected_item] == 0 and current_weight + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    # Phase 3: Feasibility preservation with targeted removals/additions\n    # Remove items with lowest marginal value first if over capacity\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Calculate marginal values\n        marginal_values = []\n        for i in in_items:\n            if underrepresented_region == 'value1':\n                marginal_value = value2_lst[i] - value1_lst[i]\n            elif underrepresented_region == 'value2':\n                marginal_value = value1_lst[i] - value2_lst[i]\n            else:\n                marginal_value = value1_lst[i] + value2_lst[i]\n            marginal_values.append((i, marginal_value))\n\n        # Remove item with lowest marginal value\n        remove_idx = min(marginal_values, key=lambda x: x[1])[0]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    # Add items with highest marginal value until no more capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        # Calculate marginal values for available items\n        marginal_values = []\n        for i in available_items:\n            if current_weight + weight_lst[i] > capacity:\n                continue\n            if underrepresented_region == 'value1':\n                marginal_value = value2_lst[i] - value1_lst[i]\n            elif underrepresented_region == 'value2':\n                marginal_value = value1_lst[i] - value2_lst[i]\n            else:\n                marginal_value = value1_lst[i] + value2_lst[i]\n            marginal_values.append((i, marginal_value))\n\n        if not marginal_values:\n            break\n\n        # Add item with highest marginal value\n        add_idx = max(marginal_values, key=lambda x: x[1])[0]\n        new_solution[add_idx] = 1\n        current_weight += weight_lst[add_idx]\n        available_items = np.where(new_solution == 0)[0]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8605774523796688,
            2.189105659723282
        ],
        "raw_score": [
            28.1447991347077,
            29.515567482461247
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective ranges and identify underrepresented regions\n    all_values1 = [obj[0] for _, obj in archive]\n    all_values2 = [obj[1] for _, obj in archive]\n    min_val1, max_val1 = min(all_values1), max(all_values1)\n    min_val2, max_val2 = min(all_values2), max(all_values2)\n\n    # Identify underrepresented regions in the objective space\n    underrepresented_region = None\n    if max_val1 - min_val1 > max_val2 - min_val2:\n        underrepresented_region = 'value2'\n    elif max_val2 - min_val2 > max_val1 - min_val1:\n        underrepresented_region = 'value1'\n    else:\n        underrepresented_region = 'balanced'\n\n    # Select solution with highest potential for improvement in underrepresented region\n    if underrepresented_region == 'value1':\n        selected = max(archive, key=lambda x: x[1][1] - x[1][0])\n    elif underrepresented_region == 'value2':\n        selected = max(archive, key=lambda x: x[1][0] - x[1][1])\n    else:\n        selected = max(archive, key=lambda x: x[1][0] + x[1][1])\n\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive weights based on underrepresented region\n    if underrepresented_region == 'value1':\n        weight1, weight2 = 0.7, 0.3\n    elif underrepresented_region == 'value2':\n        weight1, weight2 = 0.3, 0.7\n    else:\n        weight1, weight2 = 0.5, 0.5\n\n    # Tiered local search\n    n_items = len(weight_lst)\n\n    # Phase 1: Targeted swaps between items with complementary trade-offs\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        # Calculate trade-off scores based on current underrepresented region\n        tradeoff_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if underrepresented_region == 'value1':\n                score = val2 - val1\n            elif underrepresented_region == 'value2':\n                score = val1 - val2\n            else:\n                score = val1 + val2\n            tradeoff_scores.append((i, score))\n\n        # Select top 2 items with most complementary trade-offs\n        tradeoff_scores.sort(key=lambda x: -x[1])\n        if len(tradeoff_scores) >= 2:\n            i1, i2 = tradeoff_scores[0][0], tradeoff_scores[1][0]\n            # Check if swap is feasible\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n                current_weight = current_weight - weight_lst[i1] + weight_lst[i2]\n\n    # Phase 2: Probabilistic flips based on item contribution potential\n    if n_items > 0 and np.random.random() < 0.6:\n        # Calculate potential contribution scores for all items\n        potential_scores = []\n        for i in range(n_items):\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if new_solution[i] == 1:\n                # For included items, score is based on how much we might gain by removing\n                if underrepresented_region == 'value1':\n                    score = val2 - val1\n                elif underrepresented_region == 'value2':\n                    score = val1 - val2\n                else:\n                    score = val1 + val2\n                score *= (1 - (current_weight - weight_lst[i]) / capacity)\n            else:\n                # For excluded items, score is based on how much we might gain by adding\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                if underrepresented_region == 'value1':\n                    score = val2 - val1\n                elif underrepresented_region == 'value2':\n                    score = val1 - val2\n                else:\n                    score = val1 + val2\n                score *= (current_weight + weight_lst[i]) / capacity\n\n            potential_scores.append((i, score))\n\n        if potential_scores:\n            # Select item with highest potential score\n            selected_item = max(potential_scores, key=lambda x: x[1])[0]\n            if new_solution[selected_item] == 1 and current_weight - weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 0\n                current_weight -= weight_lst[selected_item]\n            elif new_solution[selected_item] == 0 and current_weight + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    # Phase 3: Feasibility preservation with targeted removals/additions\n    # Remove items with lowest marginal value first if over capacity\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Calculate marginal values\n        marginal_values = []\n        for i in in_items:\n            if underrepresented_region == 'value1':\n                marginal_value = value2_lst[i] - value1_lst[i]\n            elif underrepresented_region == 'value2':\n                marginal_value = value1_lst[i] - value2_lst[i]\n            else:\n                marginal_value = value1_lst[i] + value2_lst[i]\n            marginal_values.append((i, marginal_value))\n\n        # Remove item with lowest marginal value\n        remove_idx = min(marginal_values, key=lambda x: x[1])[0]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    # Add items with highest marginal value until no more capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        # Calculate marginal values for available items\n        marginal_values = []\n        for i in available_items:\n            if current_weight + weight_lst[i] > capacity:\n                continue\n            if underrepresented_region == 'value1':\n                marginal_value = value2_lst[i] - value1_lst[i]\n            elif underrepresented_region == 'value2':\n                marginal_value = value1_lst[i] - value2_lst[i]\n            else:\n                marginal_value = value1_lst[i] + value2_lst[i]\n            marginal_values.append((i, marginal_value))\n\n        if not marginal_values:\n            break\n\n        # Add item with highest marginal value\n        add_idx = max(marginal_values, key=lambda x: x[1])[0]\n        new_solution[add_idx] = 1\n        current_weight += weight_lst[add_idx]\n        available_items = np.where(new_solution == 0)[0]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines adaptive multi-objective selection with a tiered local search that prioritizes high-impact swaps between complementary items, followed by probabilistic flips based on item contribution potential, and finally ensures feasibility through targeted removals/additions. It dynamically balances exploration and exploitation by weighting operations based on the current solution's trade-off profile, with a strong emphasis on maintaining solution quality through normalized objective diversity and weighted value calculations. The tiered approach ensures systematic improvement while preserving feasibility at every step.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate normalized objectives and diversity scores\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    normalized_solutions = []\n    for sol, obj in archive:\n        if np.sum(weight_lst * sol) > capacity:\n            continue\n        norm_obj1 = obj[0] / total_value1 if total_value1 > 0 else 0\n        norm_obj2 = obj[1] / total_value2 if total_value2 > 0 else 0\n        diversity = abs(norm_obj1 - norm_obj2)\n        normalized_solutions.append((sol, (norm_obj1, norm_obj2), diversity))\n\n    if not normalized_solutions:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest diversity (most balanced trade-off)\n    selected = max(normalized_solutions, key=lambda x: x[2])\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive weights based on current solution's trade-off\n    weight1 = current_value1 / (current_value1 + current_value2 + 1e-8)\n    weight2 = current_value2 / (current_value1 + current_value2 + 1e-8)\n\n    # Tiered local search\n    n_items = len(weight_lst)\n\n    # Phase 1: High-impact swaps between items with complementary trade-offs\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        # Sort by trade-off alignment with current solution's profile\n        tradeoff_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on how well this item's trade-off complements current solution's profile\n            score = (weight1 * val2 + weight2 * val1) / (val1 + val2 + 1e-8)\n            tradeoff_scores.append((i, score))\n\n        # Select top 2 items with most complementary trade-offs\n        tradeoff_scores.sort(key=lambda x: -x[1])\n        if len(tradeoff_scores) >= 2:\n            i1, i2 = tradeoff_scores[0][0], tradeoff_scores[1][0]\n            # Check if swap is feasible\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n                current_weight = current_weight - weight_lst[i1] + weight_lst[i2]\n\n    # Phase 2: Probabilistic flips based on item's potential contribution\n    if n_items > 0 and np.random.random() < 0.5:\n        # Calculate potential contribution scores for all items\n        potential_scores = []\n        for i in range(n_items):\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if new_solution[i] == 1:\n                # For included items, score is based on how much we might gain by removing\n                score = (weight1 * val1 + weight2 * val2) * (1 - (current_weight - weight_lst[i]) / capacity)\n            else:\n                # For excluded items, score is based on how much we might gain by adding\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                score = (weight1 * val1 + weight2 * val2) * (current_weight + weight_lst[i]) / capacity\n\n            potential_scores.append((i, score))\n\n        if potential_scores:\n            # Select item with highest potential score\n            selected_item = max(potential_scores, key=lambda x: x[1])[0]\n            if new_solution[selected_item] == 1 and current_weight - weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 0\n                current_weight -= weight_lst[selected_item]\n            elif new_solution[selected_item] == 0 and current_weight + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    # Phase 3: Feasibility preservation with targeted removals/additions\n    # Remove least valuable items first if over capacity\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Find item with lowest weighted value\n        weighted_values = weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]\n        remove_idx = in_items[np.argmin(weighted_values)]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    # Add most valuable items until no more capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        # Find item with highest weighted value\n        weighted_values = weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items]\n        add_idx = available_items[np.argmax(weighted_values)]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 58,
        "algorithm": "The algorithm combines diversity-aware selection with a hybrid local search that first performs targeted swaps based on item complementarity, then applies adaptive flips weighted by objective-specific contributions, and finally refines the solution through multi-phase feasibility adjustments. It prioritizes solutions with higher diversity in their normalized objective values, uses adaptive weights to balance value contributions from both objectives, and employs a three-phase refinement process to ensure feasibility while improving trade-offs. The selection process emphasizes solutions with complementary trade-offs, while the local search phases systematically explore value-weighted swaps and additions to optimize both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate diversity-aware selection scores\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    selection_scores = []\n    for sol, obj in archive:\n        if np.sum(weight_lst * sol) > capacity:\n            continue\n        norm_obj1 = obj[0] / total_value1 if total_value1 > 0 else 0\n        norm_obj2 = obj[1] / total_value2 if total_value2 > 0 else 0\n        diversity = abs(norm_obj1 - norm_obj2)\n        # Weight diversity by current solution's trade-off\n        weight1 = obj[0] / (obj[0] + obj[1] + 1e-8)\n        weight2 = obj[1] / (obj[0] + obj[1] + 1e-8)\n        score = diversity * (weight1 * norm_obj1 + weight2 * norm_obj2)\n        selection_scores.append((sol, score))\n\n    if not selection_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest adaptive score\n    selected = max(selection_scores, key=lambda x: x[1])\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive weights based on current solution's trade-off\n    weight1 = current_value1 / (current_value1 + current_value2 + 1e-8)\n    weight2 = current_value2 / (current_value1 + current_value2 + 1e-8)\n\n    # Hybrid local search\n    n_items = len(weight_lst)\n\n    # Phase 1: Targeted swaps based on item complementarity\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        # Calculate item trade-off alignment\n        tradeoff_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on how well this item's trade-off complements current solution's profile\n            score = (weight1 * val1 + weight2 * val2) / (val1 + val2 + 1e-8)\n            tradeoff_scores.append((i, score))\n\n        # Select top 3 items with most complementary trade-offs\n        tradeoff_scores.sort(key=lambda x: -x[1])\n        if len(tradeoff_scores) >= 3:\n            i1, i2 = tradeoff_scores[0][0], tradeoff_scores[1][0]\n            i3 = tradeoff_scores[2][0]\n            # Check if swap is feasible\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n                current_weight = current_weight - weight_lst[i1] + weight_lst[i2]\n            if current_weight - weight_lst[i2] + weight_lst[i3] <= capacity:\n                new_solution[i2], new_solution[i3] = new_solution[i3], new_solution[i2]\n                current_weight = current_weight - weight_lst[i2] + weight_lst[i3]\n\n    # Phase 2: Adaptive flips weighted by objective contributions\n    if n_items > 0 and np.random.random() < 0.7:\n        # Calculate potential contribution scores\n        potential_scores = []\n        for i in range(n_items):\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if new_solution[i] == 1:\n                # For included items, score is based on how much we might gain by removing\n                score = (weight1 * val1 + weight2 * val2) * (1 - (current_weight - weight_lst[i]) / capacity)\n            else:\n                # For excluded items, score is based on how much we might gain by adding\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                score = (weight1 * val1 + weight2 * val2) * (current_weight + weight_lst[i]) / capacity\n            potential_scores.append((i, score))\n\n        if potential_scores:\n            # Select top 2 items with highest potential scores\n            potential_scores.sort(key=lambda x: -x[1])\n            for i, score in potential_scores[:2]:\n                if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Phase 3: Multi-phase feasibility adjustment\n    # Phase 3.1: Remove least valuable items if over capacity\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Find item with lowest weighted value\n        weighted_values = weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]\n        remove_idx = in_items[np.argmin(weighted_values)]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    # Phase 3.2: Add most valuable items until no more capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        # Find item with highest weighted value\n        weighted_values = weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items]\n        add_idx = available_items[np.argmax(weighted_values)]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    # Phase 3.3: Final balance adjustment\n    if current_weight < capacity and np.random.random() < 0.3:\n        # Try to add a medium-value item to improve trade-off\n        available_items = np.where(new_solution == 0)[0]\n        if len(available_items) > 0:\n            # Calculate value-to-weight ratios\n            ratios = (weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items]) / weight_lst[available_items]\n            # Select item with medium ratio\n            sorted_indices = np.argsort(ratios)\n            if len(sorted_indices) > 2:\n                # Select from middle 50% to avoid extremes\n                middle_idx = sorted_indices[len(sorted_indices)//4 : 3*len(sorted_indices)//4]\n                if len(middle_idx) > 0:\n                    selected_idx = available_items[np.random.choice(middle_idx)]\n                    if current_weight + weight_lst[selected_idx] <= capacity:\n                        new_solution[selected_idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6947725815632491,
            5.260686218738556
        ],
        "raw_score": [
            29.222494389330556,
            29.889434511734976
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate diversity-aware selection scores\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    selection_scores = []\n    for sol, obj in archive:\n        if np.sum(weight_lst * sol) > capacity:\n            continue\n        norm_obj1 = obj[0] / total_value1 if total_value1 > 0 else 0\n        norm_obj2 = obj[1] / total_value2 if total_value2 > 0 else 0\n        diversity = abs(norm_obj1 - norm_obj2)\n        # Weight diversity by current solution's trade-off\n        weight1 = obj[0] / (obj[0] + obj[1] + 1e-8)\n        weight2 = obj[1] / (obj[0] + obj[1] + 1e-8)\n        score = diversity * (weight1 * norm_obj1 + weight2 * norm_obj2)\n        selection_scores.append((sol, score))\n\n    if not selection_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest adaptive score\n    selected = max(selection_scores, key=lambda x: x[1])\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive weights based on current solution's trade-off\n    weight1 = current_value1 / (current_value1 + current_value2 + 1e-8)\n    weight2 = current_value2 / (current_value1 + current_value2 + 1e-8)\n\n    # Hybrid local search\n    n_items = len(weight_lst)\n\n    # Phase 1: Targeted swaps based on item complementarity\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        # Calculate item trade-off alignment\n        tradeoff_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on how well this item's trade-off complements current solution's profile\n            score = (weight1 * val1 + weight2 * val2) / (val1 + val2 + 1e-8)\n            tradeoff_scores.append((i, score))\n\n        # Select top 3 items with most complementary trade-offs\n        tradeoff_scores.sort(key=lambda x: -x[1])\n        if len(tradeoff_scores) >= 3:\n            i1, i2 = tradeoff_scores[0][0], tradeoff_scores[1][0]\n            i3 = tradeoff_scores[2][0]\n            # Check if swap is feasible\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n                current_weight = current_weight - weight_lst[i1] + weight_lst[i2]\n            if current_weight - weight_lst[i2] + weight_lst[i3] <= capacity:\n                new_solution[i2], new_solution[i3] = new_solution[i3], new_solution[i2]\n                current_weight = current_weight - weight_lst[i2] + weight_lst[i3]\n\n    # Phase 2: Adaptive flips weighted by objective contributions\n    if n_items > 0 and np.random.random() < 0.7:\n        # Calculate potential contribution scores\n        potential_scores = []\n        for i in range(n_items):\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if new_solution[i] == 1:\n                # For included items, score is based on how much we might gain by removing\n                score = (weight1 * val1 + weight2 * val2) * (1 - (current_weight - weight_lst[i]) / capacity)\n            else:\n                # For excluded items, score is based on how much we might gain by adding\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                score = (weight1 * val1 + weight2 * val2) * (current_weight + weight_lst[i]) / capacity\n            potential_scores.append((i, score))\n\n        if potential_scores:\n            # Select top 2 items with highest potential scores\n            potential_scores.sort(key=lambda x: -x[1])\n            for i, score in potential_scores[:2]:\n                if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Phase 3: Multi-phase feasibility adjustment\n    # Phase 3.1: Remove least valuable items if over capacity\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Find item with lowest weighted value\n        weighted_values = weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]\n        remove_idx = in_items[np.argmin(weighted_values)]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    # Phase 3.2: Add most valuable items until no more capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        # Find item with highest weighted value\n        weighted_values = weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items]\n        add_idx = available_items[np.argmax(weighted_values)]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    # Phase 3.3: Final balance adjustment\n    if current_weight < capacity and np.random.random() < 0.3:\n        # Try to add a medium-value item to improve trade-off\n        available_items = np.where(new_solution == 0)[0]\n        if len(available_items) > 0:\n            # Calculate value-to-weight ratios\n            ratios = (weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items]) / weight_lst[available_items]\n            # Select item with medium ratio\n            sorted_indices = np.argsort(ratios)\n            if len(sorted_indices) > 2:\n                # Select from middle 50% to avoid extremes\n                middle_idx = sorted_indices[len(sorted_indices)//4 : 3*len(sorted_indices)//4]\n                if len(middle_idx) > 0:\n                    selected_idx = available_items[np.random.choice(middle_idx)]\n                    if current_weight + weight_lst[selected_idx] <= capacity:\n                        new_solution[selected_idx] = 1\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines adaptive multi-objective selection with a tiered local search that prioritizes high-impact swaps between complementary items, followed by probabilistic flips based on item contribution potential, and finally ensures feasibility through targeted removals/additions. It dynamically balances exploration and exploitation by weighting operations based on the current solution's trade-off profile, with a strong emphasis on maintaining solution quality through normalized objective diversity and weighted value calculations. The tiered approach ensures systematic improvement while preserving feasibility at every step.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate normalized objectives and diversity scores\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    normalized_solutions = []\n    for sol, obj in archive:\n        if np.sum(weight_lst * sol) > capacity:\n            continue\n        norm_obj1 = obj[0] / total_value1 if total_value1 > 0 else 0\n        norm_obj2 = obj[1] / total_value2 if total_value2 > 0 else 0\n        diversity = abs(norm_obj1 - norm_obj2)\n        normalized_solutions.append((sol, (norm_obj1, norm_obj2), diversity))\n\n    if not normalized_solutions:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest diversity (most balanced trade-off)\n    selected = max(normalized_solutions, key=lambda x: x[2])\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive weights based on current solution's trade-off\n    weight1 = current_value1 / (current_value1 + current_value2 + 1e-8)\n    weight2 = current_value2 / (current_value1 + current_value2 + 1e-8)\n\n    # Tiered local search\n    n_items = len(weight_lst)\n\n    # Phase 1: High-impact swaps between items with complementary trade-offs\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        # Sort by trade-off alignment with current solution's profile\n        tradeoff_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on how well this item's trade-off complements current solution's profile\n            score = (weight1 * val2 + weight2 * val1) / (val1 + val2 + 1e-8)\n            tradeoff_scores.append((i, score))\n\n        # Select top 2 items with most complementary trade-offs\n        tradeoff_scores.sort(key=lambda x: -x[1])\n        if len(tradeoff_scores) >= 2:\n            i1, i2 = tradeoff_scores[0][0], tradeoff_scores[1][0]\n            # Check if swap is feasible\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n                current_weight = current_weight - weight_lst[i1] + weight_lst[i2]\n\n    # Phase 2: Probabilistic flips based on item's potential contribution\n    if n_items > 0 and np.random.random() < 0.5:\n        # Calculate potential contribution scores for all items\n        potential_scores = []\n        for i in range(n_items):\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if new_solution[i] == 1:\n                # For included items, score is based on how much we might gain by removing\n                score = (weight1 * val1 + weight2 * val2) * (1 - (current_weight - weight_lst[i]) / capacity)\n            else:\n                # For excluded items, score is based on how much we might gain by adding\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                score = (weight1 * val1 + weight2 * val2) * (current_weight + weight_lst[i]) / capacity\n\n            potential_scores.append((i, score))\n\n        if potential_scores:\n            # Select item with highest potential score\n            selected_item = max(potential_scores, key=lambda x: x[1])[0]\n            if new_solution[selected_item] == 1 and current_weight - weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 0\n                current_weight -= weight_lst[selected_item]\n            elif new_solution[selected_item] == 0 and current_weight + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    # Phase 3: Feasibility preservation with targeted removals/additions\n    # Remove least valuable items first if over capacity\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Find item with lowest weighted value\n        weighted_values = weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]\n        remove_idx = in_items[np.argmin(weighted_values)]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    # Add most valuable items until no more capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        # Find item with highest weighted value\n        weighted_values = weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items]\n        add_idx = available_items[np.argmax(weighted_values)]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 59,
        "algorithm": "The algorithm combines adaptive multi-objective selection with a tiered local search approach, prioritizing high-impact swaps between complementary items, followed by probabilistic flips based on item contribution potential, and finally ensuring feasibility through targeted removals/additions. It dynamically balances exploration and exploitation by weighting operations based on the current solution's trade-off profile, with a strong emphasis on maintaining solution quality through normalized objective diversity and weighted value calculations. The tiered structure ensures systematic improvement while preserving feasibility at every step.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate normalized objectives and diversity scores\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    normalized_solutions = []\n    for sol, obj in archive:\n        if np.sum(weight_lst * sol) > capacity:\n            continue\n        norm_obj1 = obj[0] / total_value1 if total_value1 > 0 else 0\n        norm_obj2 = obj[1] / total_value2 if total_value2 > 0 else 0\n        diversity = abs(norm_obj1 - norm_obj2)\n        normalized_solutions.append((sol, (norm_obj1, norm_obj2), diversity))\n\n    if not normalized_solutions:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest diversity (most balanced trade-off)\n    selected = max(normalized_solutions, key=lambda x: x[2])\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive weights based on current solution's trade-off\n    weight1 = current_value1 / (current_value1 + current_value2 + 1e-8)\n    weight2 = current_value2 / (current_value1 + current_value2 + 1e-8)\n\n    # Tiered local search\n    n_items = len(weight_lst)\n\n    # Phase 1: High-impact swaps between items with complementary trade-offs\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        # Sort by trade-off alignment with current solution's profile\n        tradeoff_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on how well this item's trade-off complements current solution's profile\n            score = (weight1 * val2 + weight2 * val1) / (val1 + val2 + 1e-8)\n            tradeoff_scores.append((i, score))\n\n        # Select top 2 items with most complementary trade-offs\n        tradeoff_scores.sort(key=lambda x: -x[1])\n        if len(tradeoff_scores) >= 2:\n            i1, i2 = tradeoff_scores[0][0], tradeoff_scores[1][0]\n            # Check if swap is feasible\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n                current_weight = current_weight - weight_lst[i1] + weight_lst[i2]\n\n    # Phase 2: Probabilistic flips based on item's potential contribution\n    if n_items > 0 and np.random.random() < 0.5:\n        # Calculate potential contribution scores for all items\n        potential_scores = []\n        for i in range(n_items):\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if new_solution[i] == 1:\n                # For included items, score is based on how much we might gain by removing\n                score = (weight1 * val1 + weight2 * val2) * (1 - (current_weight - weight_lst[i]) / capacity)\n            else:\n                # For excluded items, score is based on how much we might gain by adding\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                score = (weight1 * val1 + weight2 * val2) * (current_weight + weight_lst[i]) / capacity\n\n            potential_scores.append((i, score))\n\n        if potential_scores:\n            # Select item with highest potential score\n            selected_item = max(potential_scores, key=lambda x: x[1])[0]\n            if new_solution[selected_item] == 1 and current_weight - weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 0\n                current_weight -= weight_lst[selected_item]\n            elif new_solution[selected_item] == 0 and current_weight + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    # Phase 3: Feasibility preservation with targeted removals/additions\n    # Remove least valuable items first if over capacity\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Find item with lowest weighted value\n        weighted_values = weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]\n        remove_idx = in_items[np.argmin(weighted_values)]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    # Add most valuable items until no more capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        # Find item with highest weighted value\n        weighted_values = weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items]\n        add_idx = available_items[np.argmax(weighted_values)]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7107524362610459,
            5.79396390914917
        ],
        "raw_score": [
            28.75836671788094,
            28.855178596237423
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate normalized objectives and diversity scores\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    normalized_solutions = []\n    for sol, obj in archive:\n        if np.sum(weight_lst * sol) > capacity:\n            continue\n        norm_obj1 = obj[0] / total_value1 if total_value1 > 0 else 0\n        norm_obj2 = obj[1] / total_value2 if total_value2 > 0 else 0\n        diversity = abs(norm_obj1 - norm_obj2)\n        normalized_solutions.append((sol, (norm_obj1, norm_obj2), diversity))\n\n    if not normalized_solutions:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest diversity (most balanced trade-off)\n    selected = max(normalized_solutions, key=lambda x: x[2])\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive weights based on current solution's trade-off\n    weight1 = current_value1 / (current_value1 + current_value2 + 1e-8)\n    weight2 = current_value2 / (current_value1 + current_value2 + 1e-8)\n\n    # Tiered local search\n    n_items = len(weight_lst)\n\n    # Phase 1: High-impact swaps between items with complementary trade-offs\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        # Sort by trade-off alignment with current solution's profile\n        tradeoff_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on how well this item's trade-off complements current solution's profile\n            score = (weight1 * val2 + weight2 * val1) / (val1 + val2 + 1e-8)\n            tradeoff_scores.append((i, score))\n\n        # Select top 2 items with most complementary trade-offs\n        tradeoff_scores.sort(key=lambda x: -x[1])\n        if len(tradeoff_scores) >= 2:\n            i1, i2 = tradeoff_scores[0][0], tradeoff_scores[1][0]\n            # Check if swap is feasible\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n                current_weight = current_weight - weight_lst[i1] + weight_lst[i2]\n\n    # Phase 2: Probabilistic flips based on item's potential contribution\n    if n_items > 0 and np.random.random() < 0.5:\n        # Calculate potential contribution scores for all items\n        potential_scores = []\n        for i in range(n_items):\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if new_solution[i] == 1:\n                # For included items, score is based on how much we might gain by removing\n                score = (weight1 * val1 + weight2 * val2) * (1 - (current_weight - weight_lst[i]) / capacity)\n            else:\n                # For excluded items, score is based on how much we might gain by adding\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                score = (weight1 * val1 + weight2 * val2) * (current_weight + weight_lst[i]) / capacity\n\n            potential_scores.append((i, score))\n\n        if potential_scores:\n            # Select item with highest potential score\n            selected_item = max(potential_scores, key=lambda x: x[1])[0]\n            if new_solution[selected_item] == 1 and current_weight - weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 0\n                current_weight -= weight_lst[selected_item]\n            elif new_solution[selected_item] == 0 and current_weight + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    # Phase 3: Feasibility preservation with targeted removals/additions\n    # Remove least valuable items first if over capacity\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Find item with lowest weighted value\n        weighted_values = weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]\n        remove_idx = in_items[np.argmin(weighted_values)]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    # Add most valuable items until no more capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        # Find item with highest weighted value\n        weighted_values = weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items]\n        add_idx = available_items[np.argmax(weighted_values)]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive multi-objective selection with a tiered local search that prioritizes high-impact swaps between complementary items, followed by probabilistic flips based on item contribution potential, and finally ensures feasibility through targeted removals/additions. It dynamically balances exploration and exploitation by weighting operations based on the current solution's trade-off profile, with a strong emphasis on maintaining solution quality through normalized objective diversity and weighted value calculations. The tiered approach ensures systematic improvement while preserving feasibility at every step.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate normalized objectives and diversity scores\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    normalized_solutions = []\n    for sol, obj in archive:\n        if np.sum(weight_lst * sol) > capacity:\n            continue\n        norm_obj1 = obj[0] / total_value1 if total_value1 > 0 else 0\n        norm_obj2 = obj[1] / total_value2 if total_value2 > 0 else 0\n        diversity = abs(norm_obj1 - norm_obj2)\n        normalized_solutions.append((sol, (norm_obj1, norm_obj2), diversity))\n\n    if not normalized_solutions:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest diversity (most balanced trade-off)\n    selected = max(normalized_solutions, key=lambda x: x[2])\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive weights based on current solution's trade-off\n    weight1 = current_value1 / (current_value1 + current_value2 + 1e-8)\n    weight2 = current_value2 / (current_value1 + current_value2 + 1e-8)\n\n    # Tiered local search\n    n_items = len(weight_lst)\n\n    # Phase 1: High-impact swaps between items with complementary trade-offs\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        # Sort by trade-off alignment with current solution's profile\n        tradeoff_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on how well this item's trade-off complements current solution's profile\n            score = (weight1 * val2 + weight2 * val1) / (val1 + val2 + 1e-8)\n            tradeoff_scores.append((i, score))\n\n        # Select top 2 items with most complementary trade-offs\n        tradeoff_scores.sort(key=lambda x: -x[1])\n        if len(tradeoff_scores) >= 2:\n            i1, i2 = tradeoff_scores[0][0], tradeoff_scores[1][0]\n            # Check if swap is feasible\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n                current_weight = current_weight - weight_lst[i1] + weight_lst[i2]\n\n    # Phase 2: Probabilistic flips based on item's potential contribution\n    if n_items > 0 and np.random.random() < 0.5:\n        # Calculate potential contribution scores for all items\n        potential_scores = []\n        for i in range(n_items):\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if new_solution[i] == 1:\n                # For included items, score is based on how much we might gain by removing\n                score = (weight1 * val1 + weight2 * val2) * (1 - (current_weight - weight_lst[i]) / capacity)\n            else:\n                # For excluded items, score is based on how much we might gain by adding\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                score = (weight1 * val1 + weight2 * val2) * (current_weight + weight_lst[i]) / capacity\n\n            potential_scores.append((i, score))\n\n        if potential_scores:\n            # Select item with highest potential score\n            selected_item = max(potential_scores, key=lambda x: x[1])[0]\n            if new_solution[selected_item] == 1 and current_weight - weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 0\n                current_weight -= weight_lst[selected_item]\n            elif new_solution[selected_item] == 0 and current_weight + weight_lst[selected_item] <= capacity:\n                new_solution[selected_item] = 1\n                current_weight += weight_lst[selected_item]\n\n    # Phase 3: Feasibility preservation with targeted removals/additions\n    # Remove least valuable items first if over capacity\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Find item with lowest weighted value\n        weighted_values = weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]\n        remove_idx = in_items[np.argmin(weighted_values)]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    # Add most valuable items until no more capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        # Find item with highest weighted value\n        weighted_values = weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items]\n        add_idx = available_items[np.argmax(weighted_values)]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive weights**, **novelty-driven swaps**, **probabilistic flips**, **feasibility checks**.\n\n**Advice**:\n1. Select solutions using dynamic weights (e.g., weighted sum of normalized objectives).\n2. Replace low-marginal items with high-marginal ones from the archive.\n3. Apply probabilistic flips biased toward improving underrepresented objectives.\n4. Reject any operation violating capacity constraints.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance or capacity violations.\n\n**Explanation**:\nAdaptive weights guide selection toward promising regions, while novelty-driven swaps ensure exploration. Probabilistic flips balance exploitation, and feasibility checks guarantee valid neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 60,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate total possible values for normalization\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n\n    # Select solutions with high potential for improvement (top 20% by normalized objective sum)\n    feasible_solutions = []\n    for sol, obj in archive:\n        if np.sum(weight_lst * sol) > capacity:\n            continue\n        norm_obj1 = obj[0] / (total_value1 + 1e-8)\n        norm_obj2 = obj[1] / (total_value2 + 1e-8)\n        feasible_solutions.append((sol, norm_obj1, norm_obj2, norm_obj1 + norm_obj2))\n\n    if not feasible_solutions:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives and select top 20%\n    feasible_solutions.sort(key=lambda x: -x[3])\n    selection_pool = feasible_solutions[:max(1, len(feasible_solutions) // 5)]\n\n    # Select solution with highest diversity (most balanced trade-off)\n    selected = max(selection_pool, key=lambda x: abs(x[1] - x[2]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive weights based on current solution's trade-off\n    weight1 = current_value1 / (current_value1 + current_value2 + 1e-8)\n    weight2 = current_value2 / (current_value1 + current_value2 + 1e-8)\n\n    # Phase 1: High-impact swaps between items with complementary trade-offs\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        # Calculate trade-off scores for all included items\n        tradeoff_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on how well this item's trade-off complements current solution's profile\n            score = (weight1 * val2 + weight2 * val1) / (val1 + val2 + 1e-8)\n            tradeoff_scores.append((i, score))\n\n        # Select top 2 items with most complementary trade-offs\n        tradeoff_scores.sort(key=lambda x: -x[1])\n        if len(tradeoff_scores) >= 2:\n            i1, i2 = tradeoff_scores[0][0], tradeoff_scores[1][0]\n            # Check if swap is feasible\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n                current_weight = current_weight - weight_lst[i1] + weight_lst[i2]\n\n    # Phase 2: Novelty-driven flips based on item's potential contribution\n    n_items = len(weight_lst)\n    if n_items > 0:\n        # Calculate potential contribution scores for all items\n        potential_scores = []\n        for i in range(n_items):\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if new_solution[i] == 1:\n                # For included items, score is based on how much we might gain by removing\n                score = (weight1 * val1 + weight2 * val2) * (1 - (current_weight - weight_lst[i]) / capacity)\n            else:\n                # For excluded items, score is based on how much we might gain by adding\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                score = (weight1 * val1 + weight2 * val2) * (current_weight + weight_lst[i]) / capacity\n\n            potential_scores.append((i, score))\n\n        if potential_scores:\n            # Select top 3 items with highest potential scores\n            potential_scores.sort(key=lambda x: -x[1])\n            for i, score in potential_scores[:3]:\n                if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Phase 3: Feasibility preservation with targeted removals/additions\n    # Remove least valuable items first if over capacity\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Find item with lowest weighted value\n        weighted_values = weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]\n        remove_idx = in_items[np.argmin(weighted_values)]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    # Add most valuable items until no more capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        # Find item with highest weighted value\n        weighted_values = weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items]\n        add_idx = available_items[np.argmax(weighted_values)]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    # Phase 4: Probabilistic flips biased toward improving underrepresented objectives\n    if np.random.random() < 0.4:\n        # Calculate which objective is underrepresented\n        if current_value1 < current_value2:\n            # Focus on improving value1\n            candidates = np.where(new_solution == 0)[0]\n            if len(candidates) > 0:\n                # Select item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n                idx = candidates[np.argmax(ratios)]\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n        else:\n            # Focus on improving value2\n            candidates = np.where(new_solution == 0)[0]\n            if len(candidates) > 0:\n                # Select item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n                idx = candidates[np.argmax(ratios)]\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "metric_score": [
            -0.5284245563329447,
            7.979265660047531
        ],
        "raw_score": [
            30.823621303052875,
            31.603392452794324
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate total possible values for normalization\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n\n    # Select solutions with high potential for improvement (top 20% by normalized objective sum)\n    feasible_solutions = []\n    for sol, obj in archive:\n        if np.sum(weight_lst * sol) > capacity:\n            continue\n        norm_obj1 = obj[0] / (total_value1 + 1e-8)\n        norm_obj2 = obj[1] / (total_value2 + 1e-8)\n        feasible_solutions.append((sol, norm_obj1, norm_obj2, norm_obj1 + norm_obj2))\n\n    if not feasible_solutions:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives and select top 20%\n    feasible_solutions.sort(key=lambda x: -x[3])\n    selection_pool = feasible_solutions[:max(1, len(feasible_solutions) // 5)]\n\n    # Select solution with highest diversity (most balanced trade-off)\n    selected = max(selection_pool, key=lambda x: abs(x[1] - x[2]))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive weights based on current solution's trade-off\n    weight1 = current_value1 / (current_value1 + current_value2 + 1e-8)\n    weight2 = current_value2 / (current_value1 + current_value2 + 1e-8)\n\n    # Phase 1: High-impact swaps between items with complementary trade-offs\n    in_items = np.where(new_solution == 1)[0]\n    if len(in_items) >= 2:\n        # Calculate trade-off scores for all included items\n        tradeoff_scores = []\n        for i in in_items:\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            # Score based on how well this item's trade-off complements current solution's profile\n            score = (weight1 * val2 + weight2 * val1) / (val1 + val2 + 1e-8)\n            tradeoff_scores.append((i, score))\n\n        # Select top 2 items with most complementary trade-offs\n        tradeoff_scores.sort(key=lambda x: -x[1])\n        if len(tradeoff_scores) >= 2:\n            i1, i2 = tradeoff_scores[0][0], tradeoff_scores[1][0]\n            # Check if swap is feasible\n            if current_weight - weight_lst[i1] + weight_lst[i2] <= capacity:\n                new_solution[i1], new_solution[i2] = new_solution[i2], new_solution[i1]\n                current_weight = current_weight - weight_lst[i1] + weight_lst[i2]\n\n    # Phase 2: Novelty-driven flips based on item's potential contribution\n    n_items = len(weight_lst)\n    if n_items > 0:\n        # Calculate potential contribution scores for all items\n        potential_scores = []\n        for i in range(n_items):\n            val1 = value1_lst[i]\n            val2 = value2_lst[i]\n            if new_solution[i] == 1:\n                # For included items, score is based on how much we might gain by removing\n                score = (weight1 * val1 + weight2 * val2) * (1 - (current_weight - weight_lst[i]) / capacity)\n            else:\n                # For excluded items, score is based on how much we might gain by adding\n                if current_weight + weight_lst[i] > capacity:\n                    continue\n                score = (weight1 * val1 + weight2 * val2) * (current_weight + weight_lst[i]) / capacity\n\n            potential_scores.append((i, score))\n\n        if potential_scores:\n            # Select top 3 items with highest potential scores\n            potential_scores.sort(key=lambda x: -x[1])\n            for i, score in potential_scores[:3]:\n                if new_solution[i] == 1 and current_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                elif new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Phase 3: Feasibility preservation with targeted removals/additions\n    # Remove least valuable items first if over capacity\n    while current_weight > capacity:\n        in_items = np.where(new_solution == 1)[0]\n        if len(in_items) == 0:\n            break\n        # Find item with lowest weighted value\n        weighted_values = weight1 * value1_lst[in_items] + weight2 * value2_lst[in_items]\n        remove_idx = in_items[np.argmin(weighted_values)]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n\n    # Add most valuable items until no more capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        # Find item with highest weighted value\n        weighted_values = weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items]\n        add_idx = available_items[np.argmax(weighted_values)]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    # Phase 4: Probabilistic flips biased toward improving underrepresented objectives\n    if np.random.random() < 0.4:\n        # Calculate which objective is underrepresented\n        if current_value1 < current_value2:\n            # Focus on improving value1\n            candidates = np.where(new_solution == 0)[0]\n            if len(candidates) > 0:\n                # Select item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n                idx = candidates[np.argmax(ratios)]\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n        else:\n            # Focus on improving value2\n            candidates = np.where(new_solution == 0)[0]\n            if len(candidates) > 0:\n                # Select item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n                idx = candidates[np.argmax(ratios)]\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a balanced solution from the archive (prioritizing those with high combined objective product) and applies a hybrid local search combining weighted item addition, adaptive swapping, and probabilistic flipping, while dynamically adjusting weights based on solution quality and ensuring feasibility through capacity checks. It emphasizes objective-aware selection (using weighted value metrics) and diversity maintenance (through probabilistic flips), creating a balance between exploration and exploitation. The key design focuses on adaptive weights, combined value metrics, and solution quality-aware operations to improve multi-objective performance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a hybrid local search that prioritizes high-value-to-weight items, uses biased removal/addition, performs balanced swaps, and includes probabilistic flips\u2014with increased probabilities for swaps and flips to explore diverse regions while maintaining feasibility. It focuses on improving either objective 1 or 2 with a 40% bias, and uses value-to-weight ratios to guide item selection, ensuring the neighbor solution stays within capacity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection with higher value-to-weight focus\n    objective_bias = random.random()\n    if objective_bias < 0.4:\n        # Focus on value1 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias and higher probability\n    if random.random() < 0.5:  # Increased from 0.4\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.4:\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with higher probability and diversity focus\n    if np.sum(new_solution) > 1 and random.random() < 0.6:  # Increased from 0.5\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with higher probability and different bias\n    if random.random() < 0.4:  # Increased from 0.3\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects the best solution from the archive based on combined normalized objective scores, then applies a three-phase local search: first removing low-marginal items, then adding high-marginal items, and finally performing a novelty-aware probabilistic flip to potentially improve the solution further while ensuring feasibility. The method dynamically adjusts weights based on underrepresented objectives and incorporates probabilistic exploration to balance exploitation and diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined normalized objective score\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -((x[1][0] / total_value1) + (x[1][1] / total_value2)))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic weights based on underrepresented objectives\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Remove low-marginal items\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        worst_idx = in_solution[np.argmin(marginal_values)]\n        if current_weight - weight_lst[worst_idx] <= capacity:\n            new_solution[worst_idx] = 0\n\n    # Phase 2: Add high-marginal items from archive\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        marginal_values = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        best_idx = excluded_items[np.argmax(marginal_values)]\n        if current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n\n    # Phase 3: Novelty-aware probabilistic flip\n    flip_prob = 0.4 + 0.4 * (1 - ((current_value1 / total_value1) + (current_value2 / total_value2)) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            novelty_scores = (abs((value1_lst[candidates] / (current_value1 + 1e-6)) - (value2_lst[candidates] / (current_value2 + 1e-6))))\n            flip_idx = candidates[np.argmax(novelty_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: **Keywords**:\n- **Adaptive dominance-aware selection**, **objective-biased novelty swaps**, **probabilistic feasibility-aware flips**, **Pareto-constrained exploration**.\n\n**Advice**:\n1. Select solutions via dynamic weights (e.g., weighted sum of normalized objectives) while prioritizing Pareto dominance.\n2. Replace low-marginal items with high-marginal ones from the archive, biased toward underrepresented objectives.\n3. Apply probabilistic flips, favoring items that improve underperforming objectives while respecting capacity.\n4. Enforce feasibility at every step via marginal contribution checks.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance, violating capacity constraints, or overfocusing on single objectives.\n\n**Explanation**:\nAdaptive dominance-aware selection balances exploration/exploitation, while objective-biased swaps ensure multi-objective progress. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 61,
        "algorithm": "The algorithm selects a high-quality base solution from the archive (sorted by combined objective scores) and applies a four-phase hybrid local search: (1) removing low-marginal-value items, (2) adding high-marginal-value items with novelty bias, (3) swapping items to improve objective balance, and (4) probabilistically flipping items based on feasibility and novelty. All operations ensure feasibility by checking weight constraints, with dynamic weights prioritizing underrepresented objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance-aware selection\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -((x[1][0] / total_value1) + (x[1][1] / total_value2)))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic weights based on underrepresented objectives\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Remove low-marginal items with Pareto-constrained exploration\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        worst_idx = in_solution[np.argmin(marginal_values)]\n        if current_weight - weight_lst[worst_idx] <= capacity:\n            new_solution[worst_idx] = 0\n\n    # Phase 2: Add high-marginal items from archive with novelty bias\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        novelty_scores = abs((value1_lst[excluded_items] / (current_value1 + 1e-6)) - (value2_lst[excluded_items] / (current_value2 + 1e-6)))\n        marginal_values = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        combined_scores = marginal_values * novelty_scores\n        best_idx = excluded_items[np.argmax(combined_scores)]\n        if current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n\n    # Phase 3: Objective-biased novelty swaps\n    if np.sum(new_solution) > 1 and np.random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        novelty_diff = abs((value1_lst[i] / (current_value1 + 1e-6)) - (value2_lst[i] / (current_value2 + 1e-6))) - \\\n                       abs((value1_lst[j] / (current_value1 + 1e-6)) - (value2_lst[j] / (current_value2 + 1e-6)))\n        if (novelty_diff > 0 and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic feasibility-aware flips\n    flip_prob = 0.4 + 0.4 * (1 - ((current_value1 / total_value1) + (current_value2 / total_value2)) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            novelty_scores = abs((value1_lst[candidates] / (current_value1 + 1e-6)) - (value2_lst[candidates] / (current_value2 + 1e-6)))\n            flip_idx = candidates[np.argmax(novelty_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7727160107799509,
            0.23587819933891296
        ],
        "raw_score": [
            27.119469702377444,
            27.959461267434055
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance-aware selection\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -((x[1][0] / total_value1) + (x[1][1] / total_value2)))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic weights based on underrepresented objectives\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Remove low-marginal items with Pareto-constrained exploration\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        worst_idx = in_solution[np.argmin(marginal_values)]\n        if current_weight - weight_lst[worst_idx] <= capacity:\n            new_solution[worst_idx] = 0\n\n    # Phase 2: Add high-marginal items from archive with novelty bias\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        novelty_scores = abs((value1_lst[excluded_items] / (current_value1 + 1e-6)) - (value2_lst[excluded_items] / (current_value2 + 1e-6)))\n        marginal_values = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        combined_scores = marginal_values * novelty_scores\n        best_idx = excluded_items[np.argmax(combined_scores)]\n        if current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n\n    # Phase 3: Objective-biased novelty swaps\n    if np.sum(new_solution) > 1 and np.random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        novelty_diff = abs((value1_lst[i] / (current_value1 + 1e-6)) - (value2_lst[i] / (current_value2 + 1e-6))) - \\\n                       abs((value1_lst[j] / (current_value1 + 1e-6)) - (value2_lst[j] / (current_value2 + 1e-6)))\n        if (novelty_diff > 0 and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic feasibility-aware flips\n    flip_prob = 0.4 + 0.4 * (1 - ((current_value1 / total_value1) + (current_value2 / total_value2)) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            novelty_scores = abs((value1_lst[candidates] / (current_value1 + 1e-6)) - (value2_lst[candidates] / (current_value2 + 1e-6)))\n            flip_idx = candidates[np.argmax(novelty_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a high-quality base solution from the archive (sorted by combined objective scores) and applies a four-phase hybrid local search: (1) removing low-marginal-value items, (2) adding high-marginal-value items with novelty bias, (3) swapping items to improve objective balance, and (4) probabilistically flipping items based on feasibility and novelty. All operations ensure feasibility by checking weight constraints, with dynamic weights prioritizing underrepresented objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance-aware selection\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -((x[1][0] / total_value1) + (x[1][1] / total_value2)))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic weights based on underrepresented objectives\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Remove low-marginal items with Pareto-constrained exploration\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        worst_idx = in_solution[np.argmin(marginal_values)]\n        if current_weight - weight_lst[worst_idx] <= capacity:\n            new_solution[worst_idx] = 0\n\n    # Phase 2: Add high-marginal items from archive with novelty bias\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        novelty_scores = abs((value1_lst[excluded_items] / (current_value1 + 1e-6)) - (value2_lst[excluded_items] / (current_value2 + 1e-6)))\n        marginal_values = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        combined_scores = marginal_values * novelty_scores\n        best_idx = excluded_items[np.argmax(combined_scores)]\n        if current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n\n    # Phase 3: Objective-biased novelty swaps\n    if np.sum(new_solution) > 1 and np.random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        novelty_diff = abs((value1_lst[i] / (current_value1 + 1e-6)) - (value2_lst[i] / (current_value2 + 1e-6))) - \\\n                       abs((value1_lst[j] / (current_value1 + 1e-6)) - (value2_lst[j] / (current_value2 + 1e-6)))\n        if (novelty_diff > 0 and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic feasibility-aware flips\n    flip_prob = 0.4 + 0.4 * (1 - ((current_value1 / total_value1) + (current_value2 / total_value2)) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            novelty_scores = abs((value1_lst[candidates] / (current_value1 + 1e-6)) - (value2_lst[candidates] / (current_value2 + 1e-6)))\n            flip_idx = candidates[np.argmax(novelty_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive using crowding distance to prioritize underrepresented regions of the Pareto front, then applies a hybrid local search that removes low-marginal-contribution items and adds high-weighted-marginal-contribution items, while ensuring feasibility through a probabilistic flip mechanism based on crowding distance. The selection process dynamically adjusts objective weights to balance exploration of both objectives, and the local search prioritizes items with higher potential for improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using crowding distance to prioritize underrepresented regions\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                continue\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: marginal contribution-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate marginal contributions for items in solution\n        marginal_contributions = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_weight + 1e-6)\n            ratio2 = value2_lst[i] / (current_weight + 1e-6)\n            marginal_contributions.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select item with lowest marginal contribution for potential removal\n        worst_idx = in_solution[np.argmin(marginal_contributions)]\n\n        # Calculate potential additions with weighted marginal contribution\n        combined_marginals = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / (weight_lst[potential_items] + 1e-6)\n        best_add_idx = potential_items[np.argmax(combined_marginals)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with crowding-aware probability\n    flip_prob = 0.2 + 0.6 * (crowding_distances[selected_idx] / (np.max(crowding_distances) + 1e-6))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential marginal improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_weight + 1e-6)\n                ratio2 = value2_lst[i] / (current_weight + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            **Keywords**:\n- **Adaptive dominance-aware selection**, **objective-biased novelty swaps**, **probabilistic feasibility-aware flips**, **Pareto-constrained exploration**.\n\n**Advice**:\n1. Select solutions via dynamic weights (e.g., weighted sum of normalized objectives) while prioritizing Pareto dominance.\n2. Replace low-marginal items with high-marginal ones from the archive, biased toward underrepresented objectives.\n3. Apply probabilistic flips, favoring items that improve underperforming objectives while respecting capacity.\n4. Enforce feasibility at every step via marginal contribution checks.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance, violating capacity constraints, or overfocusing on single objectives.\n\n**Explanation**:\nAdaptive dominance-aware selection balances exploration/exploitation, while objective-biased swaps ensure multi-objective progress. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 62,
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid of dominance and crowding distance, then applies a three-phase local search: first removing underperforming items based on marginal contribution and novelty, then adaptively adding high-marginal items with balanced objective bias, and finally probabilistically flipping items to improve the most underrepresented objective, all while dynamically adjusting objective weights and ensuring feasibility. The selection prioritizes solutions with high dominance and crowding distances while penalizing those close to the total possible values, and the local search phases progressively refine the solution by balancing exploitation of high-marginal items with exploration of novel trade-offs.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    dominance_scores = np.sum(objectives / (np.max(objectives, axis=0) + 1e-6), axis=1)\n\n    # Calculate crowding distances\n    crowding_distances = np.zeros(len(archive))\n    for i in range(2):\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                continue\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    # Combine scores with adaptive weights\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    selection_scores = (0.6 * dominance_scores + 0.4 * crowding_distances) * (1 - (objectives[:, 0] / total_value1 + objectives[:, 1] / total_value2) / 2)\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's position\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Novelty-driven removal of underperforming items\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate novelty scores for each item in solution\n        novelty_scores = abs((value1_lst[in_solution] / (current_value1 + 1e-6)) - (value2_lst[in_solution] / (current_value2 + 1e-6)))\n        marginal_contributions = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        removal_scores = marginal_contributions * (1 - novelty_scores)\n        worst_idx = in_solution[np.argmin(removal_scores)]\n        if current_weight - weight_lst[worst_idx] <= capacity:\n            new_solution[worst_idx] = 0\n            current_weight -= weight_lst[worst_idx]\n\n    # Phase 2: Adaptive addition of high-marginal items\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate potential additions with balanced objective bias\n        combined_marginals = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        novelty_scores = abs((value1_lst[excluded_items] / (current_value1 + 1e-6)) - (value2_lst[excluded_items] / (current_value2 + 1e-6)))\n        addition_scores = combined_marginals * (1 + novelty_scores)\n        best_add_idx = excluded_items[np.argmax(addition_scores)]\n        if current_weight + weight_lst[best_add_idx] <= capacity:\n            new_solution[best_add_idx] = 1\n\n    # Phase 3: Probabilistic flip mechanism\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high potential for improving underrepresented objective\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            improvement_potential = np.zeros(len(flip_candidates))\n            for i, idx in enumerate(flip_candidates):\n                if weight1 > weight2:\n                    improvement_potential[i] = value1_lst[idx] / (current_weight + 1e-6)\n                else:\n                    improvement_potential[i] = value2_lst[idx] / (current_weight + 1e-6)\n            flip_idx = flip_candidates[np.argmax(improvement_potential)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.5113855607808626,
            4.263887673616409
        ],
        "raw_score": [
            30.68564194763628,
            30.874891818054643
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine dominance and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    dominance_scores = np.sum(objectives / (np.max(objectives, axis=0) + 1e-6), axis=1)\n\n    # Calculate crowding distances\n    crowding_distances = np.zeros(len(archive))\n    for i in range(2):\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                continue\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    # Combine scores with adaptive weights\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    selection_scores = (0.6 * dominance_scores + 0.4 * crowding_distances) * (1 - (objectives[:, 0] / total_value1 + objectives[:, 1] / total_value2) / 2)\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's position\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Novelty-driven removal of underperforming items\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate novelty scores for each item in solution\n        novelty_scores = abs((value1_lst[in_solution] / (current_value1 + 1e-6)) - (value2_lst[in_solution] / (current_value2 + 1e-6)))\n        marginal_contributions = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        removal_scores = marginal_contributions * (1 - novelty_scores)\n        worst_idx = in_solution[np.argmin(removal_scores)]\n        if current_weight - weight_lst[worst_idx] <= capacity:\n            new_solution[worst_idx] = 0\n            current_weight -= weight_lst[worst_idx]\n\n    # Phase 2: Adaptive addition of high-marginal items\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        # Calculate potential additions with balanced objective bias\n        combined_marginals = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        novelty_scores = abs((value1_lst[excluded_items] / (current_value1 + 1e-6)) - (value2_lst[excluded_items] / (current_value2 + 1e-6)))\n        addition_scores = combined_marginals * (1 + novelty_scores)\n        best_add_idx = excluded_items[np.argmax(addition_scores)]\n        if current_weight + weight_lst[best_add_idx] <= capacity:\n            new_solution[best_add_idx] = 1\n\n    # Phase 3: Probabilistic flip mechanism\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high potential for improving underrepresented objective\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            improvement_potential = np.zeros(len(flip_candidates))\n            for i, idx in enumerate(flip_candidates):\n                if weight1 > weight2:\n                    improvement_potential[i] = value1_lst[idx] / (current_weight + 1e-6)\n                else:\n                    improvement_potential[i] = value2_lst[idx] / (current_weight + 1e-6)\n            flip_idx = flip_candidates[np.argmax(improvement_potential)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe heuristic selects a balanced solution from the archive, then applies a hybrid local search combining targeted swaps (prioritizing high-value items), probabilistic flips, feasibility checks, and greedy additions of valuable items. It dynamically adjusts weights based on current solution quality and ensures feasibility through intelligent item removals and additions. The approach balances exploration and exploitation while maintaining Pareto optimality potential.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 2, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate adaptive weights for objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Hybrid local search operator\n    n_items = len(weight_lst)\n    if n_items < 2:\n        return new_solution\n\n    # Step 1: Targeted swapping based on adaptive weights\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        swap_candidates = sorted(in_solution, key=lambda x: -(weight1 * value1_lst[x] + weight2 * value2_lst[x]))[:2]\n        if len(swap_candidates) == 2:\n            idx1, idx2 = swap_candidates\n            temp_weight = current_weight - weight_lst[idx1] + weight_lst[idx2]\n            if temp_weight <= capacity:\n                new_solution[idx1], new_solution[idx2] = new_solution[idx2], new_solution[idx1]\n                current_weight = temp_weight\n\n    # Step 2: Random flip with probability based on solution quality\n    flip_prob = 0.3 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.7 else 0.7\n    if np.random.random() < flip_prob and n_items > 0:\n        flip_idx = np.random.choice(n_items)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n                current_weight += weight_lst[flip_idx]\n\n    # Step 3: Ensure feasibility by removing the least valuable items if needed\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    # Step 4: Add the most valuable available items if there's remaining capacity\n    available_items = np.where(new_solution == 0)[0]\n    while len(available_items) > 0 and current_weight < capacity:\n        add_idx = available_items[np.argmax(weight1 * value1_lst[available_items] + weight2 * value2_lst[available_items])]\n        if current_weight + weight_lst[add_idx] <= capacity:\n            new_solution[add_idx] = 1\n            current_weight += weight_lst[add_idx]\n            available_items = np.where(new_solution == 0)[0]\n        else:\n            break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive using crowding distance to prioritize underrepresented regions of the Pareto front, then applies a hybrid local search that removes low-marginal-contribution items and adds high-weighted-marginal-contribution items, while ensuring feasibility through a probabilistic flip mechanism based on crowding distance. The selection process dynamically adjusts objective weights to balance exploration of both objectives, and the local search prioritizes items with higher potential for improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using crowding distance to prioritize underrepresented regions\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                continue\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: marginal contribution-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate marginal contributions for items in solution\n        marginal_contributions = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_weight + 1e-6)\n            ratio2 = value2_lst[i] / (current_weight + 1e-6)\n            marginal_contributions.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select item with lowest marginal contribution for potential removal\n        worst_idx = in_solution[np.argmin(marginal_contributions)]\n\n        # Calculate potential additions with weighted marginal contribution\n        combined_marginals = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / (weight_lst[potential_items] + 1e-6)\n        best_add_idx = potential_items[np.argmax(combined_marginals)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with crowding-aware probability\n    flip_prob = 0.2 + 0.6 * (crowding_distances[selected_idx] / (np.max(crowding_distances) + 1e-6))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential marginal improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_weight + 1e-6)\n                ratio2 = value2_lst[i] / (current_weight + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            **Keywords**:\n- **Adaptive dominance-aware selection**, **objective-biased novelty swaps**, **probabilistic feasibility-aware flips**, **Pareto-constrained exploration**.\n\n**Advice**:\n1. Select solutions via dynamic weights (e.g., weighted sum of normalized objectives) while prioritizing Pareto dominance.\n2. Replace low-marginal items with high-marginal ones from the archive, biased toward underrepresented objectives.\n3. Apply probabilistic flips, favoring items that improve underperforming objectives while respecting capacity.\n4. Enforce feasibility at every step via marginal contribution checks.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance, violating capacity constraints, or overfocusing on single objectives.\n\n**Explanation**:\nAdaptive dominance-aware selection balances exploration/exploitation, while objective-biased swaps ensure multi-objective progress. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 63,
        "algorithm": "The algorithm employs a dynamic Pareto-aware selection mechanism that prioritizes solutions with high crowding distances and underrepresented objective combinations, followed by a hybrid local search combining objective-biased swaps and probabilistic feasibility-aware operations. It dynamically adjusts objective weights based on dominance and marginal improvements, ensuring feasibility through capacity-constrained item additions/removals, and uses a novelty swap operator to drive multi-objective progress while maintaining diversity. The selection prioritizes solutions with lower dominance counts and higher crowding distances, while the local search focuses on improving underrepresented objectives through weighted marginal contributions and probabilistic flips.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and crowding distances\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(archive)\n    dominance_count = np.zeros(n_solutions)\n    crowding_distances = np.zeros(n_solutions)\n\n    # Compute dominance counts and crowding distances\n    for i in range(n_solutions):\n        for j in range(n_solutions):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dominance_count[i] += 1\n\n    # Normalize objectives for crowding distance calculation\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-6)\n\n    for m in range(2):  # For each objective\n        sorted_indices = np.argsort(normalized_obj[:, m])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            crowding_distances[sorted_indices[j]] += (normalized_obj[sorted_indices[j+1], m] - normalized_obj[sorted_indices[j-1], m])\n\n    # Combine dominance and crowding for selection\n    selection_scores = dominance_count + crowding_distances\n    selected_idx = np.argmin(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on solution dominance\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Novel objective-biased novelty swap\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Calculate marginal contributions for items in solution\n        marginal_contributions = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_weight + 1e-6)\n            ratio2 = value2_lst[i] / (current_weight + 1e-6)\n            marginal_contributions.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select item with lowest marginal contribution for potential removal\n        worst_idx = in_solution[np.argmin(marginal_contributions)]\n\n        # Calculate potential additions with weighted marginal contribution\n        combined_marginals = (weight1 * value1_lst[out_solution] + weight2 * value2_lst[out_solution]) / (weight_lst[out_solution] + 1e-6)\n        best_add_idx = out_solution[np.argmax(combined_marginals)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic feasibility-aware flip\n    flip_prob = 0.3 + 0.5 * (crowding_distances[selected_idx] / (np.max(crowding_distances) + 1e-6))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high potential for improving underrepresented objectives\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate objective biases\n            obj1_bias = (total_value1 - current_value1) / (total_value1 + 1e-6)\n            obj2_bias = (total_value2 - current_value2) / (total_value2 + 1e-6)\n\n            # Weighted selection based on objective biases\n            weights = np.zeros(len(flip_candidates))\n            for i, idx in enumerate(flip_candidates):\n                weights[i] = obj1_bias * value1_lst[idx] + obj2_bias * value2_lst[idx]\n\n            flip_idx = flip_candidates[np.argmax(weights)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Ensure feasibility by removing least valuable items if needed\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9430602622118498,
            1.0650815963745117
        ],
        "raw_score": [
            27.254307369453045,
            27.94107969160529
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and crowding distances\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(archive)\n    dominance_count = np.zeros(n_solutions)\n    crowding_distances = np.zeros(n_solutions)\n\n    # Compute dominance counts and crowding distances\n    for i in range(n_solutions):\n        for j in range(n_solutions):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dominance_count[i] += 1\n\n    # Normalize objectives for crowding distance calculation\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-6)\n\n    for m in range(2):  # For each objective\n        sorted_indices = np.argsort(normalized_obj[:, m])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            crowding_distances[sorted_indices[j]] += (normalized_obj[sorted_indices[j+1], m] - normalized_obj[sorted_indices[j-1], m])\n\n    # Combine dominance and crowding for selection\n    selection_scores = dominance_count + crowding_distances\n    selected_idx = np.argmin(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on solution dominance\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Novel objective-biased novelty swap\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Calculate marginal contributions for items in solution\n        marginal_contributions = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_weight + 1e-6)\n            ratio2 = value2_lst[i] / (current_weight + 1e-6)\n            marginal_contributions.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select item with lowest marginal contribution for potential removal\n        worst_idx = in_solution[np.argmin(marginal_contributions)]\n\n        # Calculate potential additions with weighted marginal contribution\n        combined_marginals = (weight1 * value1_lst[out_solution] + weight2 * value2_lst[out_solution]) / (weight_lst[out_solution] + 1e-6)\n        best_add_idx = out_solution[np.argmax(combined_marginals)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic feasibility-aware flip\n    flip_prob = 0.3 + 0.5 * (crowding_distances[selected_idx] / (np.max(crowding_distances) + 1e-6))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high potential for improving underrepresented objectives\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate objective biases\n            obj1_bias = (total_value1 - current_value1) / (total_value1 + 1e-6)\n            obj2_bias = (total_value2 - current_value2) / (total_value2 + 1e-6)\n\n            # Weighted selection based on objective biases\n            weights = np.zeros(len(flip_candidates))\n            for i, idx in enumerate(flip_candidates):\n                weights[i] = obj1_bias * value1_lst[idx] + obj2_bias * value2_lst[idx]\n\n            flip_idx = flip_candidates[np.argmax(weights)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Ensure feasibility by removing least valuable items if needed\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive using crowding distance to prioritize underrepresented regions of the Pareto front, then applies a hybrid local search that removes low-marginal-contribution items and adds high-weighted-marginal-contribution items, while ensuring feasibility through a probabilistic flip mechanism based on crowding distance. The selection process dynamically adjusts objective weights to balance exploration of both objectives, and the local search prioritizes items with higher potential for improvement.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using crowding distance to prioritize underrepresented regions\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                continue\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: marginal contribution-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate marginal contributions for items in solution\n        marginal_contributions = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_weight + 1e-6)\n            ratio2 = value2_lst[i] / (current_weight + 1e-6)\n            marginal_contributions.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select item with lowest marginal contribution for potential removal\n        worst_idx = in_solution[np.argmin(marginal_contributions)]\n\n        # Calculate potential additions with weighted marginal contribution\n        combined_marginals = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / (weight_lst[potential_items] + 1e-6)\n        best_add_idx = potential_items[np.argmax(combined_marginals)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with crowding-aware probability\n    flip_prob = 0.2 + 0.6 * (crowding_distances[selected_idx] / (np.max(crowding_distances) + 1e-6))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential marginal improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_weight + 1e-6)\n                ratio2 = value2_lst[i] / (current_weight + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 64,
        "algorithm": "The algorithm selects promising solutions from the archive using a hybrid metric combining crowding distance and value density, then applies a novel local search that probabilistically replaces low-efficiency items with high-potential candidates while maintaining feasibility through dynamic capacity checks. It prioritizes items based on efficiency scores calculated from weighted objective values and weights, with adaptive probabilities for replacements and flips to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and value density\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n    value_densities = np.zeros(len(archive))\n\n    for i in range(2):\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                continue\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    # Calculate value density (sum of normalized values per unit weight)\n    total_weight = np.sum(weight_lst)\n    for idx, (sol, _) in enumerate(archive):\n        sol_weight = np.sum(weight_lst * sol)\n        if sol_weight > 0:\n            value_densities[idx] = (np.sum(value1_lst * sol) + np.sum(value2_lst * sol)) / sol_weight\n        else:\n            value_densities[idx] = 0\n\n    # Combine metrics with adaptive weights\n    alpha = 0.6  # Weight for crowding distance\n    combined_scores = alpha * crowding_distances + (1 - alpha) * value_densities\n    selected_idx = np.argmin(combined_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / (total_value1 + 1e-6)) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / (total_value2 + 1e-6)) if total_value2 > 0 else 0.5\n\n    # Novel local search: probabilistic item replacement with efficiency scoring\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Calculate efficiency scores for items in solution\n        efficiency_scores = []\n        for i in in_solution:\n            efficiency = (weight1 * value1_lst[i] + weight2 * value2_lst[i]) / (weight_lst[i] + 1e-6)\n            efficiency_scores.append(efficiency)\n\n        # Calculate potential scores for items not in solution\n        potential_scores = []\n        for i in out_solution:\n            potential = (weight1 * value1_lst[i] + weight2 * value2_lst[i]) / (weight_lst[i] + 1e-6)\n            potential_scores.append(potential)\n\n        # Select candidate for removal (lowest efficiency)\n        worst_idx = in_solution[np.argmin(efficiency_scores)]\n        current_efficiency = efficiency_scores[np.argmin(efficiency_scores)]\n\n        # Select candidate for addition (highest potential)\n        best_add_idx = out_solution[np.argmax(potential_scores)]\n        new_efficiency = potential_scores[np.argmax(potential_scores)]\n\n        # Probabilistic replacement based on efficiency improvement\n        if new_efficiency > current_efficiency:\n            replacement_prob = min(1.0, (new_efficiency - current_efficiency) / (new_efficiency + 1e-6))\n            if np.random.random() < replacement_prob:\n                temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n                if temp_weight <= capacity:\n                    new_solution[worst_idx] = 0\n                    new_solution[best_add_idx] = 1\n                    current_weight = temp_weight\n\n    # Additional probabilistic flip with adaptive probability\n    flip_prob = 0.3 + 0.5 * (crowding_distances[selected_idx] / (np.max(crowding_distances) + 1e-6))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Select items with highest potential improvement\n            improvement_scores = []\n            for i in flip_candidates:\n                improvement = (weight1 * value1_lst[i] + weight2 * value2_lst[i]) / (weight_lst[i] + 1e-6)\n                improvement_scores.append(improvement)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9474684886669638,
            1.1541956067085266
        ],
        "raw_score": [
            27.28243927545612,
            27.925655257241498
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine crowding distance and value density\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n    value_densities = np.zeros(len(archive))\n\n    for i in range(2):\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                continue\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    # Calculate value density (sum of normalized values per unit weight)\n    total_weight = np.sum(weight_lst)\n    for idx, (sol, _) in enumerate(archive):\n        sol_weight = np.sum(weight_lst * sol)\n        if sol_weight > 0:\n            value_densities[idx] = (np.sum(value1_lst * sol) + np.sum(value2_lst * sol)) / sol_weight\n        else:\n            value_densities[idx] = 0\n\n    # Combine metrics with adaptive weights\n    alpha = 0.6  # Weight for crowding distance\n    combined_scores = alpha * crowding_distances + (1 - alpha) * value_densities\n    selected_idx = np.argmin(combined_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / (total_value1 + 1e-6)) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / (total_value2 + 1e-6)) if total_value2 > 0 else 0.5\n\n    # Novel local search: probabilistic item replacement with efficiency scoring\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Calculate efficiency scores for items in solution\n        efficiency_scores = []\n        for i in in_solution:\n            efficiency = (weight1 * value1_lst[i] + weight2 * value2_lst[i]) / (weight_lst[i] + 1e-6)\n            efficiency_scores.append(efficiency)\n\n        # Calculate potential scores for items not in solution\n        potential_scores = []\n        for i in out_solution:\n            potential = (weight1 * value1_lst[i] + weight2 * value2_lst[i]) / (weight_lst[i] + 1e-6)\n            potential_scores.append(potential)\n\n        # Select candidate for removal (lowest efficiency)\n        worst_idx = in_solution[np.argmin(efficiency_scores)]\n        current_efficiency = efficiency_scores[np.argmin(efficiency_scores)]\n\n        # Select candidate for addition (highest potential)\n        best_add_idx = out_solution[np.argmax(potential_scores)]\n        new_efficiency = potential_scores[np.argmax(potential_scores)]\n\n        # Probabilistic replacement based on efficiency improvement\n        if new_efficiency > current_efficiency:\n            replacement_prob = min(1.0, (new_efficiency - current_efficiency) / (new_efficiency + 1e-6))\n            if np.random.random() < replacement_prob:\n                temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n                if temp_weight <= capacity:\n                    new_solution[worst_idx] = 0\n                    new_solution[best_add_idx] = 1\n                    current_weight = temp_weight\n\n    # Additional probabilistic flip with adaptive probability\n    flip_prob = 0.3 + 0.5 * (crowding_distances[selected_idx] / (np.max(crowding_distances) + 1e-6))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Select items with highest potential improvement\n            improvement_scores = []\n            for i in flip_candidates:\n                improvement = (weight1 * value1_lst[i] + weight2 * value2_lst[i]) / (weight_lst[i] + 1e-6)\n                improvement_scores.append(improvement)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive using crowding distance to prioritize underrepresented regions of the Pareto front, then applies a hybrid local search that removes low-marginal-contribution items and adds high-weighted-marginal-contribution items, while ensuring feasibility through a probabilistic flip mechanism based on crowding distance. The selection process dynamically adjusts objective weights to balance exploration of both objectives, and the local search prioritizes items with higher potential for improvement.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using crowding distance to prioritize underrepresented regions\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                continue\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: marginal contribution-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate marginal contributions for items in solution\n        marginal_contributions = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_weight + 1e-6)\n            ratio2 = value2_lst[i] / (current_weight + 1e-6)\n            marginal_contributions.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select item with lowest marginal contribution for potential removal\n        worst_idx = in_solution[np.argmin(marginal_contributions)]\n\n        # Calculate potential additions with weighted marginal contribution\n        combined_marginals = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / (weight_lst[potential_items] + 1e-6)\n        best_add_idx = potential_items[np.argmax(combined_marginals)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with crowding-aware probability\n    flip_prob = 0.2 + 0.6 * (crowding_distances[selected_idx] / (np.max(crowding_distances) + 1e-6))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential marginal improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_weight + 1e-6)\n                ratio2 = value2_lst[i] / (current_weight + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 65,
        "algorithm": "This algorithm selects a solution from the archive using a combination of dominance and diversity metrics, then applies a temperature-based local search that prioritizes items with high marginal contributions (normalized by weight and value) while balancing exploration and exploitation through a dynamic temperature parameter. It swaps the worst item in the solution with the best potential item, with probabilistic acceptance based on weight feasibility and temperature, and may also perform random flips to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using a combination of dominance and diversity\n    objectives = np.array([obj for _, obj in archive])\n    dominance_counts = np.zeros(len(archive))\n    diversity_scores = np.zeros(len(archive))\n\n    # Calculate dominance counts\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]) and \\\n                   (objectives[i, 0] > objectives[j, 0] or objectives[i, 1] > objectives[j, 1]):\n                    dominance_counts[i] += 1\n\n    # Calculate diversity scores\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort(objectives[:, i])\n        for j in range(1, len(sorted_indices)-1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                continue\n            diversity_scores[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i] + 1e-6)\n\n    # Combine selection criteria\n    selection_scores = dominance_counts / (diversity_scores + 1e-6)\n    selected_idx = np.argmin(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic temperature parameter\n    temperature = 1.0 - (current_weight / capacity) if capacity > 0 else 0.5\n\n    # Novel local search: temperature-based marginal contribution\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate normalized marginal contributions\n        norm_value1 = value1_lst / (np.max(value1_lst) + 1e-6)\n        norm_value2 = value2_lst / (np.max(value2_lst) + 1e-6)\n        norm_weight = weight_lst / (np.max(weight_lst) + 1e-6)\n\n        # Calculate scores for items in solution\n        in_scores = (norm_value1[in_solution] + norm_value2[in_solution]) / (norm_weight[in_solution] + 1e-6)\n        worst_idx = in_solution[np.argmin(in_scores)]\n\n        # Calculate scores for potential items\n        out_scores = (norm_value1[potential_items] + norm_value2[potential_items]) / (norm_weight[potential_items] + 1e-6)\n        best_add_idx = potential_items[np.argmax(out_scores)]\n\n        # Temperature-based acceptance\n        delta_weight = weight_lst[best_add_idx] - weight_lst[worst_idx]\n        if current_weight + delta_weight <= capacity or np.random.random() < temperature:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight += delta_weight\n\n    # Temperature-based random flip\n    if np.random.random() < temperature and len(new_solution) > 0:\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            flip_scores = (norm_value1[flip_candidates] + norm_value2[flip_candidates]) / (norm_weight[flip_candidates] + 1e-6)\n            flip_idx = flip_candidates[np.argmin(flip_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8823513326151928,
            0.851681262254715
        ],
        "raw_score": [
            27.257964147767847,
            27.766000869422356
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using a combination of dominance and diversity\n    objectives = np.array([obj for _, obj in archive])\n    dominance_counts = np.zeros(len(archive))\n    diversity_scores = np.zeros(len(archive))\n\n    # Calculate dominance counts\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]) and \\\n                   (objectives[i, 0] > objectives[j, 0] or objectives[i, 1] > objectives[j, 1]):\n                    dominance_counts[i] += 1\n\n    # Calculate diversity scores\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort(objectives[:, i])\n        for j in range(1, len(sorted_indices)-1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                continue\n            diversity_scores[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i] + 1e-6)\n\n    # Combine selection criteria\n    selection_scores = dominance_counts / (diversity_scores + 1e-6)\n    selected_idx = np.argmin(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic temperature parameter\n    temperature = 1.0 - (current_weight / capacity) if capacity > 0 else 0.5\n\n    # Novel local search: temperature-based marginal contribution\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate normalized marginal contributions\n        norm_value1 = value1_lst / (np.max(value1_lst) + 1e-6)\n        norm_value2 = value2_lst / (np.max(value2_lst) + 1e-6)\n        norm_weight = weight_lst / (np.max(weight_lst) + 1e-6)\n\n        # Calculate scores for items in solution\n        in_scores = (norm_value1[in_solution] + norm_value2[in_solution]) / (norm_weight[in_solution] + 1e-6)\n        worst_idx = in_solution[np.argmin(in_scores)]\n\n        # Calculate scores for potential items\n        out_scores = (norm_value1[potential_items] + norm_value2[potential_items]) / (norm_weight[potential_items] + 1e-6)\n        best_add_idx = potential_items[np.argmax(out_scores)]\n\n        # Temperature-based acceptance\n        delta_weight = weight_lst[best_add_idx] - weight_lst[worst_idx]\n        if current_weight + delta_weight <= capacity or np.random.random() < temperature:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight += delta_weight\n\n    # Temperature-based random flip\n    if np.random.random() < temperature and len(new_solution) > 0:\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            flip_scores = (norm_value1[flip_candidates] + norm_value2[flip_candidates]) / (norm_weight[flip_candidates] + 1e-6)\n            flip_idx = flip_candidates[np.argmin(flip_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 3 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using crowding distance to prioritize underrepresented regions of the Pareto front, then applies a hybrid local search that removes low-marginal-contribution items and adds high-weighted-marginal-contribution items, while ensuring feasibility through a probabilistic flip mechanism based on crowding distance. The selection process dynamically adjusts objective weights to balance exploration of both objectives, and the local search prioritizes items with higher potential for improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using crowding distance to prioritize underrepresented regions\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                continue\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    selected_idx = np.argmin(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: marginal contribution-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate marginal contributions for items in solution\n        marginal_contributions = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_weight + 1e-6)\n            ratio2 = value2_lst[i] / (current_weight + 1e-6)\n            marginal_contributions.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select item with lowest marginal contribution for potential removal\n        worst_idx = in_solution[np.argmin(marginal_contributions)]\n\n        # Calculate potential additions with weighted marginal contribution\n        combined_marginals = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / (weight_lst[potential_items] + 1e-6)\n        best_add_idx = potential_items[np.argmax(combined_marginals)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with crowding-aware probability\n    flip_prob = 0.2 + 0.6 * (crowding_distances[selected_idx] / (np.max(crowding_distances) + 1e-6))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential marginal improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_weight + 1e-6)\n                ratio2 = value2_lst[i] / (current_weight + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using dynamic objective weighting, then applies a hybrid local search that removes the least novel item (based on value ratio balance) and adds the most valuable item (weighted by current objective priorities) while ensuring feasibility. It also includes probabilistic flipping of items with high potential improvement, prioritizing objectives that are currently underrepresented.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution using dynamic objective weighting to prioritize underrepresented objectives\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -(x[1][0] / total_value1 + x[1][1] / total_value2))\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: novelty-driven swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate novelty scores for items in solution\n        novelty_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            novelty_scores.append(abs(ratio1 - ratio2))\n\n        # Select least novel item for potential removal\n        least_novel_idx = in_solution[np.argmin(novelty_scores)]\n\n        # Calculate potential additions with weighted value metric\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        best_add_idx = potential_items[np.argmax(combined_values)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[least_novel_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[least_novel_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with objective-aware probability\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential improvement\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate potential improvement for each candidate\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            **Keywords**:\n- **Adaptive dominance-aware selection**, **objective-biased novelty swaps**, **probabilistic feasibility-aware flips**, **Pareto-constrained exploration**.\n\n**Advice**:\n1. Select solutions via dynamic weights (e.g., weighted sum of normalized objectives) while prioritizing Pareto dominance.\n2. Replace low-marginal items with high-marginal ones from the archive, biased toward underrepresented objectives.\n3. Apply probabilistic flips, favoring items that improve underperforming objectives while respecting capacity.\n4. Enforce feasibility at every step via marginal contribution checks.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance, violating capacity constraints, or overfocusing on single objectives.\n\n**Explanation**:\nAdaptive dominance-aware selection balances exploration/exploitation, while objective-biased swaps ensure multi-objective progress. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 66,
        "algorithm": "The algorithm selects a promising solution from the archive using adaptive dominance-aware selection (prioritizing high-potential, diverse solutions) and applies a hybrid local search that dynamically adjusts objective weights to improve underrepresented objectives. It performs objective-biased novelty swaps (removing low-contribution items and adding high-contribution items) and probabilistic flips (with feasibility checks) to generate feasible neighbors, ensuring balanced exploration of the solution space.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance-aware selection with crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                continue\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    # Combine crowding distance and normalized objective sum for selection\n    normalized_objectives = objectives.copy()\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    if total_value1 > 0:\n        normalized_objectives[:, 0] /= total_value1\n    if total_value2 > 0:\n        normalized_objectives[:, 1] /= total_value2\n    selection_scores = normalized_objectives.sum(axis=1) - 0.3 * crowding_distances  # Prioritize high potential and diversity\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = 1 - current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Hybrid local search: objective-biased novelty swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate marginal contributions for items in solution\n        marginal_contributions = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (weight_lst[i] + 1e-6)\n            ratio2 = value2_lst[i] / (weight_lst[i] + 1e-6)\n            marginal_contributions.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select item with lowest marginal contribution for potential removal\n        worst_idx = in_solution[np.argmin(marginal_contributions)]\n\n        # Calculate potential additions with weighted marginal contribution\n        combined_marginals = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / (weight_lst[potential_items] + 1e-6)\n        best_add_idx = potential_items[np.argmax(combined_marginals)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with feasibility-aware probability\n    flip_prob = 0.2 + 0.6 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential improvement for underperforming objectives\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (weight_lst[i] + 1e-6)\n                ratio2 = value2_lst[i] / (weight_lst[i] + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7661601735537622,
            0.5369604825973511
        ],
        "raw_score": [
            29.17113594416825,
            29.072171920640006
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance-aware selection with crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            if objectives[sorted_indices[-1], i] == objectives[sorted_indices[0], i]:\n                continue\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i]) / (objectives[sorted_indices[-1], i] - objectives[sorted_indices[0], i])\n\n    # Combine crowding distance and normalized objective sum for selection\n    normalized_objectives = objectives.copy()\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    if total_value1 > 0:\n        normalized_objectives[:, 0] /= total_value1\n    if total_value2 > 0:\n        normalized_objectives[:, 1] /= total_value2\n    selection_scores = normalized_objectives.sum(axis=1) - 0.3 * crowding_distances  # Prioritize high potential and diversity\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's underrepresentation\n    weight1 = 1 - current_value1 / total_value1 if total_value1 > 0 else 0.5\n    weight2 = 1 - current_value2 / total_value2 if total_value2 > 0 else 0.5\n\n    # Hybrid local search: objective-biased novelty swap\n    in_solution = np.where(new_solution == 1)[0]\n    potential_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(potential_items) > 0:\n        # Calculate marginal contributions for items in solution\n        marginal_contributions = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (weight_lst[i] + 1e-6)\n            ratio2 = value2_lst[i] / (weight_lst[i] + 1e-6)\n            marginal_contributions.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select item with lowest marginal contribution for potential removal\n        worst_idx = in_solution[np.argmin(marginal_contributions)]\n\n        # Calculate potential additions with weighted marginal contribution\n        combined_marginals = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / (weight_lst[potential_items] + 1e-6)\n        best_add_idx = potential_items[np.argmax(combined_marginals)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic flip with feasibility-aware probability\n    flip_prob = 0.2 + 0.6 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with highest potential improvement for underperforming objectives\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            improvement_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (weight_lst[i] + 1e-6)\n                ratio2 = value2_lst[i] / (weight_lst[i] + 1e-6)\n                improvement_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmax(improvement_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a balanced solution from the archive (prioritizing those with high combined objective product) and applies a hybrid local search combining weighted item addition, adaptive swapping, and probabilistic flipping, while dynamically adjusting weights based on solution quality and ensuring feasibility through capacity checks. It emphasizes objective-aware selection (using weighted value metrics) and diversity maintenance (through probabilistic flips), creating a balance between exploration and exploitation. The key design focuses on adaptive weights, combined value metrics, and solution quality-aware operations to improve multi-objective performance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced potential for both objectives\n    archive.sort(key=lambda x: -(x[1][0] * x[1][1]))  # Sort by product of objectives\n    selected_idx = min(len(archive) // 3, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate dynamic weights based on current solution quality\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Hybrid local search: weighted item addition\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate combined value metric with adaptive weights\n        combined_values = (weight1 * value1_lst[potential_items] + weight2 * value2_lst[potential_items]) / weight_lst[potential_items]\n        top_items = potential_items[np.argsort(combined_values)[-2:]]  # Select top 2 items\n\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping based on objective contributions\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate relative importance of items\n        importance = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        sorted_items = in_solution[np.argsort(importance)]\n\n        # Swap least important with most promising excluded items\n        if len(sorted_items) >= 2:\n            least_important = sorted_items[0]\n            most_promising = np.argmax(combined_values) if len(potential_items) > 0 else -1\n\n            if most_promising != -1 and most_promising in potential_items:\n                temp_weight = current_weight - weight_lst[least_important] + weight_lst[most_promising]\n                if temp_weight <= capacity:\n                    new_solution[least_important] = 0\n                    new_solution[most_promising] = 1\n\n    # Probabilistic flip based on solution quality and diversity\n    flip_prob = 0.4 if (current_value1 + current_value2) / (total_value1 + total_value2) > 0.6 else 0.8\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        flip_idx = np.random.choice(len(new_solution))\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n        else:\n            if current_weight + weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive based on its potential for improvement in both objectives, then applies a hybrid local search that prioritizes high-value-to-weight items, uses biased removal/addition, performs balanced swaps, and includes probabilistic flips\u2014with increased probabilities for swaps and flips to explore diverse regions while maintaining feasibility. It focuses on improving either objective 1 or 2 with a 40% bias, and uses value-to-weight ratios to guide item selection, ensuring the neighbor solution stays within capacity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection with higher value-to-weight focus\n    objective_bias = random.random()\n    if objective_bias < 0.4:\n        # Focus on value1 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement with higher value-to-weight ratio\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]  # Changed to max instead of min\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias and higher probability\n    if random.random() < 0.5:  # Increased from 0.4\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.4:\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with higher probability and diversity focus\n    if np.sum(new_solution) > 1 and random.random() < 0.6:  # Increased from 0.5\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with higher probability and different bias\n    if random.random() < 0.4:  # Increased from 0.3\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects the best solution from the archive based on combined normalized objective scores, then applies a three-phase local search: first removing low-marginal items, then adding high-marginal items, and finally performing a novelty-aware probabilistic flip to potentially improve the solution further while ensuring feasibility. The method dynamically adjusts weights based on underrepresented objectives and incorporates probabilistic exploration to balance exploitation and diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined normalized objective score\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -((x[1][0] / total_value1) + (x[1][1] / total_value2)))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic weights based on underrepresented objectives\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Remove low-marginal items\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        worst_idx = in_solution[np.argmin(marginal_values)]\n        if current_weight - weight_lst[worst_idx] <= capacity:\n            new_solution[worst_idx] = 0\n\n    # Phase 2: Add high-marginal items from archive\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        marginal_values = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        best_idx = excluded_items[np.argmax(marginal_values)]\n        if current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n\n    # Phase 3: Novelty-aware probabilistic flip\n    flip_prob = 0.4 + 0.4 * (1 - ((current_value1 / total_value1) + (current_value2 / total_value2)) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            novelty_scores = (abs((value1_lst[candidates] / (current_value1 + 1e-6)) - (value2_lst[candidates] / (current_value2 + 1e-6))))\n            flip_idx = candidates[np.argmax(novelty_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive Pareto-aware selection**, **objective-biased novelty swaps**, **probabilistic feasibility-aware flips**, **Pareto-constrained exploration**.\n\n**Advice**:\n1. Select solutions via dynamic weights (e.g., weighted sum of normalized objectives) while prioritizing Pareto dominance.\n2. Replace low-marginal items with high-marginal ones from the archive, biased toward underrepresented objectives.\n3. Apply probabilistic flips, favoring items that improve underperforming objectives while respecting capacity.\n4. Enforce feasibility at every step via marginal contribution checks.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance, violating capacity constraints, or overfocusing on single objectives.\n\n**Explanation**:\nAdaptive Pareto-aware selection balances exploration/exploitation, while objective-biased swaps ensure multi-objective progress. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 67,
        "algorithm": "The algorithm selects the Pareto-dominant solution from the archive, prioritizes swapping low-marginal items for high-marginal ones based on adaptive objective weights, and probabilistically flips items to improve underrepresented objectives while ensuring feasibility. It balances exploration and exploitation by dynamically adjusting selection probabilities and marginal contributions, favoring solutions with higher combined objective values while maintaining capacity constraints.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select Pareto-dominant solution\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate normalized objective weights\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Replace low-marginal items with high-marginal ones\n    in_solution = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(excluded_items) > 0:\n        # Calculate marginal values for included items\n        marginal_in = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        worst_idx = in_solution[np.argmin(marginal_in)]\n\n        # Calculate marginal values for excluded items\n        marginal_out = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        best_idx = excluded_items[np.argmax(marginal_out)]\n\n        # Swap if beneficial\n        if (current_weight - weight_lst[worst_idx] + weight_lst[best_idx]) <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_idx] = 1\n\n    # Phase 2: Probabilistic feasibility-aware flip\n    flip_prob = 0.5 * (weight1 + weight2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Flip item that contributes most to underrepresented objective\n            underrepresented = weight1 if weight1 > weight2 else weight2\n            flip_idx = candidates[np.argmax((underrepresented * value1_lst[candidates] + (1-underrepresented) * value2_lst[candidates]) / weight_lst[candidates])]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.3349642380087527,
            1.450662076473236
        ],
        "raw_score": [
            33.20708232163091,
            34.531149641933794
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select Pareto-dominant solution\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Calculate normalized objective weights\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Replace low-marginal items with high-marginal ones\n    in_solution = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(excluded_items) > 0:\n        # Calculate marginal values for included items\n        marginal_in = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        worst_idx = in_solution[np.argmin(marginal_in)]\n\n        # Calculate marginal values for excluded items\n        marginal_out = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        best_idx = excluded_items[np.argmax(marginal_out)]\n\n        # Swap if beneficial\n        if (current_weight - weight_lst[worst_idx] + weight_lst[best_idx]) <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_idx] = 1\n\n    # Phase 2: Probabilistic feasibility-aware flip\n    flip_prob = 0.5 * (weight1 + weight2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Flip item that contributes most to underrepresented objective\n            underrepresented = weight1 if weight1 > weight2 else weight2\n            flip_idx = candidates[np.argmax((underrepresented * value1_lst[candidates] + (1-underrepresented) * value2_lst[candidates]) / weight_lst[candidates])]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm employs a dynamic Pareto-aware selection mechanism that prioritizes solutions with high crowding distances and underrepresented objective combinations, followed by a hybrid local search combining objective-biased swaps and probabilistic feasibility-aware operations. It dynamically adjusts objective weights based on dominance and marginal improvements, ensuring feasibility through capacity-constrained item additions/removals, and uses a novelty swap operator to drive multi-objective progress while maintaining diversity. The selection prioritizes solutions with lower dominance counts and higher crowding distances, while the local search focuses on improving underrepresented objectives through weighted marginal contributions and probabilistic flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and crowding distances\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(archive)\n    dominance_count = np.zeros(n_solutions)\n    crowding_distances = np.zeros(n_solutions)\n\n    # Compute dominance counts and crowding distances\n    for i in range(n_solutions):\n        for j in range(n_solutions):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dominance_count[i] += 1\n\n    # Normalize objectives for crowding distance calculation\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-6)\n\n    for m in range(2):  # For each objective\n        sorted_indices = np.argsort(normalized_obj[:, m])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            crowding_distances[sorted_indices[j]] += (normalized_obj[sorted_indices[j+1], m] - normalized_obj[sorted_indices[j-1], m])\n\n    # Combine dominance and crowding for selection\n    selection_scores = dominance_count + crowding_distances\n    selected_idx = np.argmin(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on solution dominance\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Novel objective-biased novelty swap\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Calculate marginal contributions for items in solution\n        marginal_contributions = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_weight + 1e-6)\n            ratio2 = value2_lst[i] / (current_weight + 1e-6)\n            marginal_contributions.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select item with lowest marginal contribution for potential removal\n        worst_idx = in_solution[np.argmin(marginal_contributions)]\n\n        # Calculate potential additions with weighted marginal contribution\n        combined_marginals = (weight1 * value1_lst[out_solution] + weight2 * value2_lst[out_solution]) / (weight_lst[out_solution] + 1e-6)\n        best_add_idx = out_solution[np.argmax(combined_marginals)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic feasibility-aware flip\n    flip_prob = 0.3 + 0.5 * (crowding_distances[selected_idx] / (np.max(crowding_distances) + 1e-6))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high potential for improving underrepresented objectives\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate objective biases\n            obj1_bias = (total_value1 - current_value1) / (total_value1 + 1e-6)\n            obj2_bias = (total_value2 - current_value2) / (total_value2 + 1e-6)\n\n            # Weighted selection based on objective biases\n            weights = np.zeros(len(flip_candidates))\n            for i, idx in enumerate(flip_candidates):\n                weights[i] = obj1_bias * value1_lst[idx] + obj2_bias * value2_lst[idx]\n\n            flip_idx = flip_candidates[np.argmax(weights)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Ensure feasibility by removing least valuable items if needed\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm implements a multi-stage local search strategy that prioritizes value-driven item addition using dynamic objective weighting, removes dominated items to improve solution quality, and incorporates probabilistic exploration to maintain diversity while ensuring feasibility. It balances exploitation and exploration by adaptively adjusting flip probabilities based on current solution value ratios and contributions. The approach ensures solutions remain feasible by checking capacity constraints during item additions and removals.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined value\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's value ratios\n    ratio1 = current_value1 / (np.sum(value1_lst) + 1e-6)\n    ratio2 = current_value2 / (np.sum(value2_lst) + 1e-6)\n    weight1 = ratio1 * (1 - ratio1)\n    weight2 = ratio2 * (1 - ratio2)\n\n    # Value-driven item addition: prioritize items that maximize weighted value sum\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(-np.inf)\n                continue\n            weighted_value = weight1 * value1_lst[item] + weight2 * value2_lst[item]\n            value_scores.append(weighted_value)\n\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Dominance-aware item removal: remove items that are dominated in value space\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        dominated_items = []\n        for i in in_solution:\n            dominated = False\n            for j in in_solution:\n                if i != j and value1_lst[i] <= value1_lst[j] and value2_lst[i] <= value2_lst[j] and (value1_lst[i] < value1_lst[j] or value2_lst[i] < value2_lst[j]):\n                    dominated = True\n                    break\n            if dominated:\n                dominated_items.append(i)\n\n        if dominated_items:\n            remove_idx = np.random.choice(dominated_items)\n            new_solution[remove_idx] = 0\n\n    # Probabilistic exploration: flip items with low value contribution\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (np.sum(value1_lst) + np.sum(value2_lst) + 1e-6))\n    if np.random.random() < flip_prob and len(in_solution) > 0:\n        value_contributions = []\n        for i in in_solution:\n            contrib1 = value1_lst[i] / (current_value1 + 1e-6)\n            contrib2 = value2_lst[i] / (current_value2 + 1e-6)\n            value_contributions.append(weight1 * contrib1 + weight2 * contrib2)\n\n        flip_candidates = in_solution[np.argsort(value_contributions)[:2]]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive Pareto-aware selection**, **objective-biased novelty swaps**, **probabilistic feasibility-aware flips**, **Pareto-constrained exploration**.\n\n**Advice**:\n1. Select solutions via dynamic weights (e.g., weighted sum of normalized objectives) while prioritizing Pareto dominance.\n2. Replace low-marginal items with high-marginal ones from the archive, biased toward underrepresented objectives.\n3. Apply probabilistic flips, favoring items that improve underperforming objectives while respecting capacity.\n4. Enforce feasibility at every step via marginal contribution checks.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance, violating capacity constraints, or overfocusing on single objectives.\n\n**Explanation**:\nAdaptive Pareto-aware selection balances exploration/exploitation, while objective-biased swaps ensure multi-objective progress. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 68,
        "algorithm": "The algorithm combines adaptive Pareto-aware selection with a dynamic objective-balanced swap mechanism that prioritizes underrepresented objectives, using marginal contribution analysis and probabilistic feasibility checks, while maintaining diversity through crowding-distance-informed exploration and ensuring feasibility through multi-stage capacity validation. It dynamically adjusts objective weights based on solution dominance and selects items for removal or addition based on weighted marginal contributions, with higher priority given to objectives that are currently underrepresented. The algorithm also includes a probabilistic exploration phase that selectively removes items with high potential for improving both objectives, further refined by crowding-distance-based probabilities.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and crowding distances\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(archive)\n    dominance_count = np.zeros(n_solutions)\n    crowding_distances = np.zeros(n_solutions)\n\n    # Compute dominance counts\n    for i in range(n_solutions):\n        for j in range(n_solutions):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dominance_count[i] += 1\n\n    # Normalize objectives for crowding distance calculation\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-6)\n\n    for m in range(2):  # For each objective\n        sorted_indices = np.argsort(normalized_obj[:, m])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            crowding_distances[sorted_indices[j]] += (normalized_obj[sorted_indices[j+1], m] - normalized_obj[sorted_indices[j-1], m])\n\n    # Combine dominance and crowding for selection\n    selection_scores = dominance_count + crowding_distances\n    selected_idx = np.argmin(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on solution dominance\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Objective-balanced novelty swap\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Calculate marginal contributions for items in solution\n        marginal_contributions = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (weight_lst[i] + 1e-6)\n            ratio2 = value2_lst[i] / (weight_lst[i] + 1e-6)\n            marginal_contributions.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select item with lowest marginal contribution for potential removal\n        worst_idx = in_solution[np.argmin(marginal_contributions)]\n\n        # Calculate potential additions with weighted marginal contribution\n        combined_marginals = (weight1 * value1_lst[out_solution] + weight2 * value2_lst[out_solution]) / (weight_lst[out_solution] + 1e-6)\n        best_add_idx = out_solution[np.argmax(combined_marginals)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Crowding-distance-informed probabilistic exploration\n    explore_prob = 0.4 + 0.4 * (crowding_distances[selected_idx] / (np.max(crowding_distances) + 1e-6))\n    if np.random.random() < explore_prob and len(in_solution) > 0:\n        # Select items with high potential for improving both objectives\n        explore_candidates = np.where(new_solution == 1)[0]\n        if len(explore_candidates) > 0:\n            # Calculate balanced exploration weights\n            explore_weights = np.zeros(len(explore_candidates))\n            for i, idx in enumerate(explore_candidates):\n                explore_weights[i] = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-6)\n\n            explore_idx = explore_candidates[np.argmax(explore_weights)]\n            if current_weight - weight_lst[explore_idx] <= capacity:\n                new_solution[explore_idx] = 0\n\n    # Multi-stage feasibility enforcement\n    in_solution = np.where(new_solution == 1)[0]\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9133727536583189,
            1.0370060205459595
        ],
        "raw_score": [
            27.1928885092437,
            27.77156291715588
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and crowding distances\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(archive)\n    dominance_count = np.zeros(n_solutions)\n    crowding_distances = np.zeros(n_solutions)\n\n    # Compute dominance counts\n    for i in range(n_solutions):\n        for j in range(n_solutions):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dominance_count[i] += 1\n\n    # Normalize objectives for crowding distance calculation\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-6)\n\n    for m in range(2):  # For each objective\n        sorted_indices = np.argsort(normalized_obj[:, m])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            crowding_distances[sorted_indices[j]] += (normalized_obj[sorted_indices[j+1], m] - normalized_obj[sorted_indices[j-1], m])\n\n    # Combine dominance and crowding for selection\n    selection_scores = dominance_count + crowding_distances\n    selected_idx = np.argmin(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on solution dominance\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Objective-balanced novelty swap\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Calculate marginal contributions for items in solution\n        marginal_contributions = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (weight_lst[i] + 1e-6)\n            ratio2 = value2_lst[i] / (weight_lst[i] + 1e-6)\n            marginal_contributions.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select item with lowest marginal contribution for potential removal\n        worst_idx = in_solution[np.argmin(marginal_contributions)]\n\n        # Calculate potential additions with weighted marginal contribution\n        combined_marginals = (weight1 * value1_lst[out_solution] + weight2 * value2_lst[out_solution]) / (weight_lst[out_solution] + 1e-6)\n        best_add_idx = out_solution[np.argmax(combined_marginals)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Crowding-distance-informed probabilistic exploration\n    explore_prob = 0.4 + 0.4 * (crowding_distances[selected_idx] / (np.max(crowding_distances) + 1e-6))\n    if np.random.random() < explore_prob and len(in_solution) > 0:\n        # Select items with high potential for improving both objectives\n        explore_candidates = np.where(new_solution == 1)[0]\n        if len(explore_candidates) > 0:\n            # Calculate balanced exploration weights\n            explore_weights = np.zeros(len(explore_candidates))\n            for i, idx in enumerate(explore_candidates):\n                explore_weights[i] = (weight1 * value1_lst[idx] + weight2 * value2_lst[idx]) / (weight_lst[idx] + 1e-6)\n\n            explore_idx = explore_candidates[np.argmax(explore_weights)]\n            if current_weight - weight_lst[explore_idx] <= capacity:\n                new_solution[explore_idx] = 0\n\n    # Multi-stage feasibility enforcement\n    in_solution = np.where(new_solution == 1)[0]\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a high-quality base solution from the archive (sorted by combined objective scores) and applies a four-phase hybrid local search: (1) removing low-marginal-value items, (2) adding high-marginal-value items with novelty bias, (3) swapping items to improve objective balance, and (4) probabilistically flipping items based on feasibility and novelty. All operations ensure feasibility by checking weight constraints, with dynamic weights prioritizing underrepresented objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance-aware selection\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -((x[1][0] / total_value1) + (x[1][1] / total_value2)))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic weights based on underrepresented objectives\n    weight1 = 1 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = 1 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Phase 1: Remove low-marginal items with Pareto-constrained exploration\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n        worst_idx = in_solution[np.argmin(marginal_values)]\n        if current_weight - weight_lst[worst_idx] <= capacity:\n            new_solution[worst_idx] = 0\n\n    # Phase 2: Add high-marginal items from archive with novelty bias\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) > 0:\n        novelty_scores = abs((value1_lst[excluded_items] / (current_value1 + 1e-6)) - (value2_lst[excluded_items] / (current_value2 + 1e-6)))\n        marginal_values = (weight1 * value1_lst[excluded_items] + weight2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        combined_scores = marginal_values * novelty_scores\n        best_idx = excluded_items[np.argmax(combined_scores)]\n        if current_weight + weight_lst[best_idx] <= capacity:\n            new_solution[best_idx] = 1\n\n    # Phase 3: Objective-biased novelty swaps\n    if np.sum(new_solution) > 1 and np.random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        novelty_diff = abs((value1_lst[i] / (current_value1 + 1e-6)) - (value2_lst[i] / (current_value2 + 1e-6))) - \\\n                       abs((value1_lst[j] / (current_value1 + 1e-6)) - (value2_lst[j] / (current_value2 + 1e-6)))\n        if (novelty_diff > 0 and current_weight - weight_lst[i] + weight_lst[j] <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic feasibility-aware flips\n    flip_prob = 0.4 + 0.4 * (1 - ((current_value1 / total_value1) + (current_value2 / total_value2)) / 2)\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            novelty_scores = abs((value1_lst[candidates] / (current_value1 + 1e-6)) - (value2_lst[candidates] / (current_value2 + 1e-6)))\n            flip_idx = candidates[np.argmax(novelty_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm implements a multi-stage local search strategy that prioritizes value-driven item addition using dynamic objective weighting, removes dominated items to improve solution quality, and incorporates probabilistic exploration to maintain diversity while ensuring feasibility. It balances exploitation and exploration by adaptively adjusting flip probabilities based on current solution value ratios and contributions. The approach ensures solutions remain feasible by checking capacity constraints during item additions and removals.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined value\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's value ratios\n    ratio1 = current_value1 / (np.sum(value1_lst) + 1e-6)\n    ratio2 = current_value2 / (np.sum(value2_lst) + 1e-6)\n    weight1 = ratio1 * (1 - ratio1)\n    weight2 = ratio2 * (1 - ratio2)\n\n    # Value-driven item addition: prioritize items that maximize weighted value sum\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(-np.inf)\n                continue\n            weighted_value = weight1 * value1_lst[item] + weight2 * value2_lst[item]\n            value_scores.append(weighted_value)\n\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Dominance-aware item removal: remove items that are dominated in value space\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        dominated_items = []\n        for i in in_solution:\n            dominated = False\n            for j in in_solution:\n                if i != j and value1_lst[i] <= value1_lst[j] and value2_lst[i] <= value2_lst[j] and (value1_lst[i] < value1_lst[j] or value2_lst[i] < value2_lst[j]):\n                    dominated = True\n                    break\n            if dominated:\n                dominated_items.append(i)\n\n        if dominated_items:\n            remove_idx = np.random.choice(dominated_items)\n            new_solution[remove_idx] = 0\n\n    # Probabilistic exploration: flip items with low value contribution\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (np.sum(value1_lst) + np.sum(value2_lst) + 1e-6))\n    if np.random.random() < flip_prob and len(in_solution) > 0:\n        value_contributions = []\n        for i in in_solution:\n            contrib1 = value1_lst[i] / (current_value1 + 1e-6)\n            contrib2 = value2_lst[i] / (current_value2 + 1e-6)\n            value_contributions.append(weight1 * contrib1 + weight2 * contrib2)\n\n        flip_candidates = in_solution[np.argsort(value_contributions)[:2]]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive Pareto-aware selection**, **objective-biased novelty swaps**, **probabilistic feasibility-aware flips**, **Pareto-constrained exploration**.\n\n**Advice**:\n1. Select solutions via dynamic weights (e.g., weighted sum of normalized objectives) while prioritizing Pareto dominance.\n2. Replace low-marginal items with high-marginal ones from the archive, biased toward underrepresented objectives.\n3. Apply probabilistic flips, favoring items that improve underperforming objectives while respecting capacity.\n4. Enforce feasibility at every step via marginal contribution checks.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance, violating capacity constraints, or overfocusing on single objectives.\n\n**Explanation**:\nAdaptive Pareto-aware selection balances exploration/exploitation, while objective-biased swaps ensure multi-objective progress. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 69,
        "algorithm": "This algorithm combines adaptive Pareto-aware selection with a three-phase local search: it first replaces items with high novelty scores, then adds Pareto-dominating items, and finally probabilistically flips low-contribution items while maintaining feasibility. The method dynamically balances objective priorities based on solution imbalance and favors underrepresented objective ratios.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-aware selection with dynamic weighting\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -((x[1][0] / total_value1) * (x[1][1] / total_value2)))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's imbalance\n    imbalance1 = abs(current_value1 / (current_value2 + 1e-6) - 1)\n    imbalance2 = abs(current_value2 / (current_value1 + 1e-6) - 1)\n    weight1 = imbalance1 / (imbalance1 + imbalance2 + 1e-6)\n    weight2 = imbalance2 / (imbalance1 + imbalance2 + 1e-6)\n\n    # Phase 1: Novelty-driven item replacement\n    in_solution = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(excluded_items) > 0:\n        # Calculate novelty scores for excluded items\n        novelty_scores = []\n        for item in excluded_items:\n            if current_weight + weight_lst[item] > capacity:\n                novelty_scores.append(-np.inf)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            novelty = abs(ratio1 - ratio2)\n            novelty_scores.append(novelty)\n\n        if any(n > 0 for n in novelty_scores):\n            best_add = excluded_items[np.argmax(novelty_scores)]\n            if current_weight + weight_lst[best_add] <= capacity:\n                # Remove worst marginal item\n                marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n                worst_remove = in_solution[np.argmin(marginal_values)]\n                new_solution[worst_remove] = 0\n                new_solution[best_add] = 1\n\n    # Phase 2: Pareto-constrained item addition\n    if len(excluded_items) > 0:\n        pareto_scores = []\n        for item in excluded_items:\n            if current_weight + weight_lst[item] > capacity:\n                pareto_scores.append(-np.inf)\n                continue\n            # Check if adding this item would dominate any existing item\n            dominates = False\n            for i in in_solution:\n                if (value1_lst[item] >= value1_lst[i] and value2_lst[item] >= value2_lst[i] and\n                    (value1_lst[item] > value1_lst[i] or value2_lst[item] > value2_lst[i])):\n                    dominates = True\n                    break\n            if dominates:\n                pareto_scores.append(weight1 * value1_lst[item] + weight2 * value2_lst[item])\n            else:\n                pareto_scores.append(0)\n\n        if any(p > 0 for p in pareto_scores):\n            best_pareto = excluded_items[np.argmax(pareto_scores)]\n            if current_weight + weight_lst[best_pareto] <= capacity:\n                new_solution[best_pareto] = 1\n\n    # Phase 3: Probabilistic feasibility-aware flips\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(in_solution) > 0:\n        # Calculate objective imbalance scores\n        imbalance_scores = []\n        for item in in_solution:\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            imbalance_scores.append(abs(ratio1 - ratio2))\n\n        # Flip items with highest imbalance\n        flip_candidates = in_solution[np.argsort(imbalance_scores)[-2:]]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "metric_score": [
            -0.4530599229403437,
            2.2466063499450684
        ],
        "raw_score": [
            31.709041109084986,
            31.414869302976022
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-aware selection with dynamic weighting\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    archive.sort(key=lambda x: -((x[1][0] / total_value1) * (x[1][1] / total_value2)))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on current solution's imbalance\n    imbalance1 = abs(current_value1 / (current_value2 + 1e-6) - 1)\n    imbalance2 = abs(current_value2 / (current_value1 + 1e-6) - 1)\n    weight1 = imbalance1 / (imbalance1 + imbalance2 + 1e-6)\n    weight2 = imbalance2 / (imbalance1 + imbalance2 + 1e-6)\n\n    # Phase 1: Novelty-driven item replacement\n    in_solution = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(excluded_items) > 0:\n        # Calculate novelty scores for excluded items\n        novelty_scores = []\n        for item in excluded_items:\n            if current_weight + weight_lst[item] > capacity:\n                novelty_scores.append(-np.inf)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            novelty = abs(ratio1 - ratio2)\n            novelty_scores.append(novelty)\n\n        if any(n > 0 for n in novelty_scores):\n            best_add = excluded_items[np.argmax(novelty_scores)]\n            if current_weight + weight_lst[best_add] <= capacity:\n                # Remove worst marginal item\n                marginal_values = (weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution]) / weight_lst[in_solution]\n                worst_remove = in_solution[np.argmin(marginal_values)]\n                new_solution[worst_remove] = 0\n                new_solution[best_add] = 1\n\n    # Phase 2: Pareto-constrained item addition\n    if len(excluded_items) > 0:\n        pareto_scores = []\n        for item in excluded_items:\n            if current_weight + weight_lst[item] > capacity:\n                pareto_scores.append(-np.inf)\n                continue\n            # Check if adding this item would dominate any existing item\n            dominates = False\n            for i in in_solution:\n                if (value1_lst[item] >= value1_lst[i] and value2_lst[item] >= value2_lst[i] and\n                    (value1_lst[item] > value1_lst[i] or value2_lst[item] > value2_lst[i])):\n                    dominates = True\n                    break\n            if dominates:\n                pareto_scores.append(weight1 * value1_lst[item] + weight2 * value2_lst[item])\n            else:\n                pareto_scores.append(0)\n\n        if any(p > 0 for p in pareto_scores):\n            best_pareto = excluded_items[np.argmax(pareto_scores)]\n            if current_weight + weight_lst[best_pareto] <= capacity:\n                new_solution[best_pareto] = 1\n\n    # Phase 3: Probabilistic feasibility-aware flips\n    flip_prob = 0.3 + 0.5 * (1 - (current_value1 / total_value1 + current_value2 / total_value2) / 2)\n    if np.random.random() < flip_prob and len(in_solution) > 0:\n        # Calculate objective imbalance scores\n        imbalance_scores = []\n        for item in in_solution:\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            imbalance_scores.append(abs(ratio1 - ratio2))\n\n        # Flip items with highest imbalance\n        flip_candidates = in_solution[np.argsort(imbalance_scores)[-2:]]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm implements a multi-stage local search strategy that prioritizes value-driven item addition using dynamic objective weighting, removes dominated items to improve solution quality, and incorporates probabilistic exploration to maintain diversity while ensuring feasibility. It balances exploitation and exploration by adaptively adjusting flip probabilities based on current solution value ratios and contributions. The approach ensures solutions remain feasible by checking capacity constraints during item additions and removals.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined value\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's value ratios\n    ratio1 = current_value1 / (np.sum(value1_lst) + 1e-6)\n    ratio2 = current_value2 / (np.sum(value2_lst) + 1e-6)\n    weight1 = ratio1 * (1 - ratio1)\n    weight2 = ratio2 * (1 - ratio2)\n\n    # Value-driven item addition: prioritize items that maximize weighted value sum\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(-np.inf)\n                continue\n            weighted_value = weight1 * value1_lst[item] + weight2 * value2_lst[item]\n            value_scores.append(weighted_value)\n\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Dominance-aware item removal: remove items that are dominated in value space\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        dominated_items = []\n        for i in in_solution:\n            dominated = False\n            for j in in_solution:\n                if i != j and value1_lst[i] <= value1_lst[j] and value2_lst[i] <= value2_lst[j] and (value1_lst[i] < value1_lst[j] or value2_lst[i] < value2_lst[j]):\n                    dominated = True\n                    break\n            if dominated:\n                dominated_items.append(i)\n\n        if dominated_items:\n            remove_idx = np.random.choice(dominated_items)\n            new_solution[remove_idx] = 0\n\n    # Probabilistic exploration: flip items with low value contribution\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (np.sum(value1_lst) + np.sum(value2_lst) + 1e-6))\n    if np.random.random() < flip_prob and len(in_solution) > 0:\n        value_contributions = []\n        for i in in_solution:\n            contrib1 = value1_lst[i] / (current_value1 + 1e-6)\n            contrib2 = value2_lst[i] / (current_value2 + 1e-6)\n            value_contributions.append(weight1 * contrib1 + weight2 * contrib2)\n\n        flip_candidates = in_solution[np.argsort(value_contributions)[:2]]\n        if len(flip_candidates) > 0:\n            flip_idx = np.random.choice(flip_candidates)\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 70,
        "algorithm": "This algorithm implements a hybrid local search strategy that combines adaptive value-based selection with dynamic dominance filtering and probabilistic item swapping, prioritizing items based on a contribution-aware weighting scheme that balances exploration and exploitation while ensuring feasibility through capacity-constrained operations. It starts with the highest-value solution from the archive, then selectively adds promising items and removes dominated ones, with occasional probabilistic swaps to escape local optima, all while maintaining feasibility. The algorithm dynamically adjusts objective weighting based on the current solution's normalized values and uses probabilistic removal to diversify the search.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined normalized value\n    archive.sort(key=lambda x: -(x[1][0]/np.max(value1_lst) + x[1][1]/np.max(value2_lst)))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting based on current solution's normalized value ratios\n    norm_value1 = current_value1 / (np.max(value1_lst) + 1e-6)\n    norm_value2 = current_value2 / (np.max(value2_lst) + 1e-6)\n    weight1 = np.exp(norm_value1) / (np.exp(norm_value1) + np.exp(norm_value2) + 1e-6)\n    weight2 = 1 - weight1\n\n    # Value-driven item addition with contribution-aware selection\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(-np.inf)\n                continue\n            contrib_score = (weight1 * value1_lst[item] + weight2 * value2_lst[item]) / weight_lst[item]\n            value_scores.append(contrib_score)\n\n        top_items = potential_items[np.argsort(value_scores)[-2:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Dynamic dominance filtering with probabilistic removal\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        dominance_scores = []\n        for i in in_solution:\n            dominated_count = 0\n            for j in in_solution:\n                if i != j and value1_lst[i] <= value1_lst[j] and value2_lst[i] <= value2_lst[j] and (value1_lst[i] < value1_lst[j] or value2_lst[i] < value2_lst[j]):\n                    dominated_count += 1\n            dominance_scores.append(dominated_count)\n\n        if any(dominance_scores):\n            remove_prob = np.array(dominance_scores) / (np.sum(dominance_scores) + 1e-6)\n            remove_idx = np.random.choice(in_solution, p=remove_prob)\n            new_solution[remove_idx] = 0\n\n    # Probabilistic item swapping with capacity check\n    swap_prob = 0.1 + 0.4 * (1 - (current_value1 + current_value2) / (np.sum(value1_lst) + np.sum(value2_lst) + 1e-6))\n    if np.random.random() < swap_prob and len(in_solution) > 1:\n        item1, item2 = np.random.choice(in_solution, 2, replace=False)\n        if (current_weight - weight_lst[item1] + weight_lst[item2]) <= capacity:\n            new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8576533420299606,
            89.4975053369999
        ],
        "raw_score": [
            27.31824558778042,
            27.830372105293687
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined normalized value\n    archive.sort(key=lambda x: -(x[1][0]/np.max(value1_lst) + x[1][1]/np.max(value2_lst)))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective weighting based on current solution's normalized value ratios\n    norm_value1 = current_value1 / (np.max(value1_lst) + 1e-6)\n    norm_value2 = current_value2 / (np.max(value2_lst) + 1e-6)\n    weight1 = np.exp(norm_value1) / (np.exp(norm_value1) + np.exp(norm_value2) + 1e-6)\n    weight2 = 1 - weight1\n\n    # Value-driven item addition with contribution-aware selection\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(-np.inf)\n                continue\n            contrib_score = (weight1 * value1_lst[item] + weight2 * value2_lst[item]) / weight_lst[item]\n            value_scores.append(contrib_score)\n\n        top_items = potential_items[np.argsort(value_scores)[-2:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Dynamic dominance filtering with probabilistic removal\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        dominance_scores = []\n        for i in in_solution:\n            dominated_count = 0\n            for j in in_solution:\n                if i != j and value1_lst[i] <= value1_lst[j] and value2_lst[i] <= value2_lst[j] and (value1_lst[i] < value1_lst[j] or value2_lst[i] < value2_lst[j]):\n                    dominated_count += 1\n            dominance_scores.append(dominated_count)\n\n        if any(dominance_scores):\n            remove_prob = np.array(dominance_scores) / (np.sum(dominance_scores) + 1e-6)\n            remove_idx = np.random.choice(in_solution, p=remove_prob)\n            new_solution[remove_idx] = 0\n\n    # Probabilistic item swapping with capacity check\n    swap_prob = 0.1 + 0.4 * (1 - (current_value1 + current_value2) / (np.sum(value1_lst) + np.sum(value2_lst) + 1e-6))\n    if np.random.random() < swap_prob and len(in_solution) > 1:\n        item1, item2 = np.random.choice(in_solution, 2, replace=False)\n        if (current_weight - weight_lst[item1] + weight_lst[item2]) <= capacity:\n            new_solution[item1], new_solution[item2] = new_solution[item2], new_solution[item1]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search combining biased item removal/addition, balanced swaps, and probabilistic flips to generate high-quality neighbors while ensuring feasibility. The selection is guided by objective-biased probabilities, favoring either value1 or value2 improvement based on the current solution's potential, and the local search dynamically adjusts operations to explore diverse, high-potential regions of the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective improvement potential and select solution\n    max_value1 = np.sum(value1_lst)\n    max_value2 = np.sum(value2_lst)\n    potential_scores = []\n\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue\n\n        # Calculate normalized potential for each objective\n        potential1 = (max_value1 - obj[0]) / (max_value1 + 1e-8)\n        potential2 = (max_value2 - obj[1]) / (max_value2 + 1e-8)\n\n        # Combine with objective weights based on relative potential\n        combined_potential = (potential1 + potential2) * (1 + abs(potential1 - potential2))\n        potential_scores.append((sol, combined_potential))\n\n    if not potential_scores:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Select solution with highest potential\n    potential_scores.sort(key=lambda x: -x[1])\n    base_solution = potential_scores[0][0].copy()\n\n    # Generate neighbor with novel hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Phase 1: Objective-biased item selection\n    objective_bias = random.random()\n    if objective_bias < 0.5:\n        # Focus on value1 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value1/weight ratio\n            ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n    else:\n        # Focus on value2 improvement\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) > 0:\n            # Remove item with lowest value2/weight ratio\n            ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmin(ratios)]\n            if total_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Phase 2: Random addition with objective bias\n    if random.random() < 0.4:\n        candidates = np.where(new_solution == 0)[0]\n        if len(candidates) > 0:\n            if objective_bias < 0.5:\n                # Add item with highest value1/weight ratio\n                ratios = value1_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            else:\n                # Add item with highest value2/weight ratio\n                ratios = value2_lst[candidates] / (weight_lst[candidates] + 1e-8)\n            idx = candidates[np.argmax(ratios)]\n            if total_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    # Phase 3: Balanced swaps with diversity\n    if np.sum(new_solution) > 1 and random.random() < 0.5:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap maintains feasibility\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Phase 4: Probabilistic flip with objective bias\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with high potential for improvement, calculated as the sum of normalized objectives while considering Pareto dominance. It then applies a hybrid local search operator that combines value-driven item insertion, adaptive swapping based on trade-off scores, and probabilistic flips to maintain diversity, while strictly enforcing feasibility constraints. The method dynamically adjusts flip probabilities and prioritizes items with high marginal improvement, ensuring the generated neighbor solution is always valid and potentially Pareto-optimal.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance scores for each solution\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] > obj[0] and other_obj[1] >= obj[1]:\n                dominated += 1\n            elif other_obj[0] >= obj[0] and other_obj[1] > obj[1]:\n                dominated += 1\n        dominance_scores.append(-dominated)  # Negative for sorting\n\n    # Select solution with best balance of high potential and low dominance\n    archive_with_scores = list(zip(archive, dominance_scores))\n    archive_with_scores.sort(key=lambda x: (x[1], -(x[0][1][0] + x[0][1][1])))\n    base_solution = archive_with_scores[0][0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item insertion: prioritize items with high marginal improvement\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items to improve value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select worst items for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        for idx in worst_items:\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n                current_weight = current_weight - weight_lst[idx] + weight_lst[best_swap]\n\n    # Novelty-aware probabilistic flip\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with lowest value contribution for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Random swap for additional exploration\n    if np.random.random() < 0.3 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive Pareto-aware selection**, **objective-biased novelty swaps**, **probabilistic feasibility-aware flips**, **Pareto-constrained exploration**.\n\n**Advice**:\n1. Select solutions via dynamic weights (e.g., weighted sum of normalized objectives) while prioritizing Pareto dominance.\n2. Replace low-marginal items with high-marginal ones from the archive, biased toward underrepresented objectives.\n3. Apply probabilistic flips, favoring items that improve underperforming objectives while respecting capacity.\n4. Enforce feasibility at every step via marginal contribution checks.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance, violating capacity constraints, or overfocusing on single objectives.\n\n**Explanation**:\nAdaptive Pareto-aware selection balances exploration/exploitation, while objective-biased swaps ensure multi-objective progress. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 71,
        "algorithm": "The algorithm combines adaptive Pareto-aware selection with a hybrid local search that prioritizes marginal contribution analysis for removal, Pareto-constrained insertion for improvement, probabilistic flips to escape local optima, and random swaps for diversity, while dynamically balancing objective improvements and maintaining feasibility through continuous capacity checks. It selects solutions based on Pareto dominance and total value, then applies these phases to generate high-quality neighbors that explore the solution space more effectively than traditional methods. The algorithm emphasizes items with lower marginal contributions for removal and those that dominate existing items for insertion, while using probabilistic flips and swaps to maintain diversity and escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and objective scores\n    pareto_scores = []\n    for sol, obj in archive:\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] > obj[0] and other_obj[1] >= obj[1]:\n                dominated += 1\n            elif other_obj[0] >= obj[0] and other_obj[1] > obj[1]:\n                dominated += 1\n        pareto_scores.append((sol, obj, -dominated, obj[0] + obj[1]))\n\n    # Sort by Pareto dominance and total value\n    pareto_scores.sort(key=lambda x: (x[2], -x[3]))\n    base_solution = pareto_scores[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Phase 1: Marginal contribution analysis for removal\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate marginal contribution scores\n        marginal_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            marginal_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Remove items with lowest marginal contribution\n        worst_items = in_solution[np.argsort(marginal_scores)[:2]]\n        for idx in worst_items:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Phase 2: Pareto-constrained insertion\n    out_solution = np.where(new_solution == 0)[0]\n    if len(out_solution) > 0:\n        # Calculate insertion scores based on Pareto dominance\n        insertion_scores = []\n        for i in out_solution:\n            if current_weight + weight_lst[i] > capacity:\n                insertion_scores.append(-1)\n                continue\n            # Check if item would dominate any existing item\n            dominates = 0\n            for j in in_solution:\n                if value1_lst[i] >= value1_lst[j] and value2_lst[i] > value2_lst[j]:\n                    dominates += 1\n                elif value1_lst[i] > value1_lst[j] and value2_lst[i] >= value2_lst[j]:\n                    dominates += 1\n            insertion_scores.append(dominates)\n\n        # Insert items that dominate most\n        best_items = out_solution[np.argsort(insertion_scores)[-2:]]\n        for idx in best_items:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Probabilistic flips with objective bias\n    flip_prob = 0.3 + 0.2 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(in_solution) > 0:\n        # Select items with lowest value contribution for flipping\n        flip_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            flip_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        flip_idx = in_solution[np.argmin(flip_scores)]\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n\n    # Phase 4: Random swap for diversity\n    if np.random.random() < 0.4 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7966003955054756,
            18.51974919438362
        ],
        "raw_score": [
            27.525161868891058,
            27.977129000356904
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and objective scores\n    pareto_scores = []\n    for sol, obj in archive:\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] > obj[0] and other_obj[1] >= obj[1]:\n                dominated += 1\n            elif other_obj[0] >= obj[0] and other_obj[1] > obj[1]:\n                dominated += 1\n        pareto_scores.append((sol, obj, -dominated, obj[0] + obj[1]))\n\n    # Sort by Pareto dominance and total value\n    pareto_scores.sort(key=lambda x: (x[2], -x[3]))\n    base_solution = pareto_scores[0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Phase 1: Marginal contribution analysis for removal\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) > 0:\n        # Calculate marginal contribution scores\n        marginal_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            marginal_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Remove items with lowest marginal contribution\n        worst_items = in_solution[np.argsort(marginal_scores)[:2]]\n        for idx in worst_items:\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Phase 2: Pareto-constrained insertion\n    out_solution = np.where(new_solution == 0)[0]\n    if len(out_solution) > 0:\n        # Calculate insertion scores based on Pareto dominance\n        insertion_scores = []\n        for i in out_solution:\n            if current_weight + weight_lst[i] > capacity:\n                insertion_scores.append(-1)\n                continue\n            # Check if item would dominate any existing item\n            dominates = 0\n            for j in in_solution:\n                if value1_lst[i] >= value1_lst[j] and value2_lst[i] > value2_lst[j]:\n                    dominates += 1\n                elif value1_lst[i] > value1_lst[j] and value2_lst[i] >= value2_lst[j]:\n                    dominates += 1\n            insertion_scores.append(dominates)\n\n        # Insert items that dominate most\n        best_items = out_solution[np.argsort(insertion_scores)[-2:]]\n        for idx in best_items:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Phase 3: Probabilistic flips with objective bias\n    flip_prob = 0.3 + 0.2 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(in_solution) > 0:\n        # Select items with lowest value contribution for flipping\n        flip_scores = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n            flip_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        flip_idx = in_solution[np.argmin(flip_scores)]\n        if current_weight - weight_lst[flip_idx] <= capacity:\n            new_solution[flip_idx] = 0\n\n    # Phase 4: Random swap for diversity\n    if np.random.random() < 0.4 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm employs a dynamic Pareto-aware selection mechanism that prioritizes solutions with high crowding distances and underrepresented objective combinations, followed by a hybrid local search combining objective-biased swaps and probabilistic feasibility-aware operations. It dynamically adjusts objective weights based on dominance and marginal improvements, ensuring feasibility through capacity-constrained item additions/removals, and uses a novelty swap operator to drive multi-objective progress while maintaining diversity. The selection prioritizes solutions with lower dominance counts and higher crowding distances, while the local search focuses on improving underrepresented objectives through weighted marginal contributions and probabilistic flips.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and crowding distances\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(archive)\n    dominance_count = np.zeros(n_solutions)\n    crowding_distances = np.zeros(n_solutions)\n\n    # Compute dominance counts and crowding distances\n    for i in range(n_solutions):\n        for j in range(n_solutions):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dominance_count[i] += 1\n\n    # Normalize objectives for crowding distance calculation\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-6)\n\n    for m in range(2):  # For each objective\n        sorted_indices = np.argsort(normalized_obj[:, m])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            crowding_distances[sorted_indices[j]] += (normalized_obj[sorted_indices[j+1], m] - normalized_obj[sorted_indices[j-1], m])\n\n    # Combine dominance and crowding for selection\n    selection_scores = dominance_count + crowding_distances\n    selected_idx = np.argmin(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on solution dominance\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Novel objective-biased novelty swap\n    in_solution = np.where(new_solution == 1)[0]\n    out_solution = np.where(new_solution == 0)[0]\n\n    if len(in_solution) > 0 and len(out_solution) > 0:\n        # Calculate marginal contributions for items in solution\n        marginal_contributions = []\n        for i in in_solution:\n            ratio1 = value1_lst[i] / (current_weight + 1e-6)\n            ratio2 = value2_lst[i] / (current_weight + 1e-6)\n            marginal_contributions.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select item with lowest marginal contribution for potential removal\n        worst_idx = in_solution[np.argmin(marginal_contributions)]\n\n        # Calculate potential additions with weighted marginal contribution\n        combined_marginals = (weight1 * value1_lst[out_solution] + weight2 * value2_lst[out_solution]) / (weight_lst[out_solution] + 1e-6)\n        best_add_idx = out_solution[np.argmax(combined_marginals)]\n\n        # Perform swap if feasible\n        temp_weight = current_weight - weight_lst[worst_idx] + weight_lst[best_add_idx]\n        if temp_weight <= capacity:\n            new_solution[worst_idx] = 0\n            new_solution[best_add_idx] = 1\n            current_weight = temp_weight\n\n    # Probabilistic feasibility-aware flip\n    flip_prob = 0.3 + 0.5 * (crowding_distances[selected_idx] / (np.max(crowding_distances) + 1e-6))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high potential for improving underrepresented objectives\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            # Calculate objective biases\n            obj1_bias = (total_value1 - current_value1) / (total_value1 + 1e-6)\n            obj2_bias = (total_value2 - current_value2) / (total_value2 + 1e-6)\n\n            # Weighted selection based on objective biases\n            weights = np.zeros(len(flip_candidates))\n            for i, idx in enumerate(flip_candidates):\n                weights[i] = obj1_bias * value1_lst[idx] + obj2_bias * value2_lst[idx]\n\n            flip_idx = flip_candidates[np.argmax(weights)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Ensure feasibility by removing least valuable items if needed\n    while current_weight > capacity and len(in_solution) > 0:\n        remove_idx = in_solution[np.argmin(weight1 * value1_lst[in_solution] + weight2 * value2_lst[in_solution])]\n        new_solution[remove_idx] = 0\n        current_weight -= weight_lst[remove_idx]\n        in_solution = np.where(new_solution == 1)[0]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with high potential for improvement, calculated as the sum of normalized objectives while considering Pareto dominance. It then applies a hybrid local search operator that combines value-driven item insertion, adaptive swapping based on trade-off scores, and probabilistic flips to maintain diversity, while strictly enforcing feasibility constraints. The method dynamically adjusts flip probabilities and prioritizes items with high marginal improvement, ensuring the generated neighbor solution is always valid and potentially Pareto-optimal.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance scores for each solution\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] > obj[0] and other_obj[1] >= obj[1]:\n                dominated += 1\n            elif other_obj[0] >= obj[0] and other_obj[1] > obj[1]:\n                dominated += 1\n        dominance_scores.append(-dominated)  # Negative for sorting\n\n    # Select solution with best balance of high potential and low dominance\n    archive_with_scores = list(zip(archive, dominance_scores))\n    archive_with_scores.sort(key=lambda x: (x[1], -(x[0][1][0] + x[0][1][1])))\n    base_solution = archive_with_scores[0][0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item insertion: prioritize items with high marginal improvement\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items to improve value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select worst items for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        for idx in worst_items:\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n                current_weight = current_weight - weight_lst[idx] + weight_lst[best_swap]\n\n    # Novelty-aware probabilistic flip\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with lowest value contribution for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Random swap for additional exploration\n    if np.random.random() < 0.3 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive Pareto-aware selection**, **objective-biased novelty swaps**, **probabilistic feasibility-aware flips**, **Pareto-constrained exploration**.\n\n**Advice**:\n1. Select solutions via dynamic weights (e.g., weighted sum of normalized objectives) while prioritizing Pareto dominance.\n2. Replace low-marginal items with high-marginal ones from the archive, biased toward underrepresented objectives.\n3. Apply probabilistic flips, favoring items that improve underperforming objectives while respecting capacity.\n4. Enforce feasibility at every step via marginal contribution checks.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance, violating capacity constraints, or overfocusing on single objectives.\n\n**Explanation**:\nAdaptive Pareto-aware selection balances exploration/exploitation, while objective-biased swaps ensure multi-objective progress. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 72,
        "algorithm": "The algorithm combines adaptive Pareto-aware selection with dynamic objective weighting to prioritize solutions with high crowding distances and underrepresented objective combinations, followed by a hybrid local search that employs value-driven item insertion, adaptive swapping based on trade-off scores, and probabilistic flips biased toward improving underperforming objectives. It dynamically adjusts selection probabilities based on marginal contributions and dominance counts, while ensuring feasibility through capacity-constrained operations, and incorporates a novelty-aware probabilistic flip mechanism to maintain diversity and drive multi-objective progress. The algorithm prioritizes items with high marginal improvement in weighted value scores, performs adaptive swaps to optimize value trade-offs, and uses probabilistic flips to explore underrepresented regions of the solution space.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and crowding distances\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(archive)\n    dominance_count = np.zeros(n_solutions)\n    crowding_distances = np.zeros(n_solutions)\n\n    # Compute dominance counts and crowding distances\n    for i in range(n_solutions):\n        for j in range(n_solutions):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dominance_count[i] += 1\n\n    # Normalize objectives for crowding distance calculation\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-6)\n\n    for m in range(2):  # For each objective\n        sorted_indices = np.argsort(normalized_obj[:, m])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            crowding_distances[sorted_indices[j]] += (normalized_obj[sorted_indices[j+1], m] - normalized_obj[sorted_indices[j-1], m])\n\n    # Combine dominance and crowding for selection\n    selection_scores = dominance_count + crowding_distances\n    selected_idx = np.argmin(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on solution dominance\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Value-driven item insertion: prioritize items with high marginal improvement\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items to improve value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select worst items for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        for idx in worst_items:\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n                current_weight = current_weight - weight_lst[idx] + weight_lst[best_swap]\n\n    # Novelty-aware probabilistic flip\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with lowest value contribution for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Random swap for additional exploration\n    if np.random.random() < 0.3 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8167854907770334,
            1.5867044925689697
        ],
        "raw_score": [
            27.466892657111973,
            27.937643240631957
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and crowding distances\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(archive)\n    dominance_count = np.zeros(n_solutions)\n    crowding_distances = np.zeros(n_solutions)\n\n    # Compute dominance counts and crowding distances\n    for i in range(n_solutions):\n        for j in range(n_solutions):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dominance_count[i] += 1\n\n    # Normalize objectives for crowding distance calculation\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-6)\n\n    for m in range(2):  # For each objective\n        sorted_indices = np.argsort(normalized_obj[:, m])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(sorted_indices)-1):\n            crowding_distances[sorted_indices[j]] += (normalized_obj[sorted_indices[j+1], m] - normalized_obj[sorted_indices[j-1], m])\n\n    # Combine dominance and crowding for selection\n    selection_scores = dominance_count + crowding_distances\n    selected_idx = np.argmin(selection_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weights based on solution dominance\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (1 - current_value1 / total_value1) if total_value1 > 0 else 0.5\n    weight2 = (1 - current_value2 / total_value2) if total_value2 > 0 else 0.5\n\n    # Value-driven item insertion: prioritize items with high marginal improvement\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items to improve value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select worst items for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        for idx in worst_items:\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n                current_weight = current_weight - weight_lst[idx] + weight_lst[best_swap]\n\n    # Novelty-aware probabilistic flip\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with lowest value contribution for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Random swap for additional exploration\n    if np.random.random() < 0.3 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive by prioritizing those with high potential for improvement, calculated as the sum of normalized objectives while considering Pareto dominance. It then applies a hybrid local search operator that combines value-driven item insertion, adaptive swapping based on trade-off scores, and probabilistic flips to maintain diversity, while strictly enforcing feasibility constraints. The method dynamically adjusts flip probabilities and prioritizes items with high marginal improvement, ensuring the generated neighbor solution is always valid and potentially Pareto-optimal.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance scores for each solution\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] > obj[0] and other_obj[1] >= obj[1]:\n                dominated += 1\n            elif other_obj[0] >= obj[0] and other_obj[1] > obj[1]:\n                dominated += 1\n        dominance_scores.append(-dominated)  # Negative for sorting\n\n    # Select solution with best balance of high potential and low dominance\n    archive_with_scores = list(zip(archive, dominance_scores))\n    archive_with_scores.sort(key=lambda x: (x[1], -(x[0][1][0] + x[0][1][1])))\n    base_solution = archive_with_scores[0][0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item insertion: prioritize items with high marginal improvement\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items to improve value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select worst items for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        for idx in worst_items:\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n                current_weight = current_weight - weight_lst[idx] + weight_lst[best_swap]\n\n    # Novelty-aware probabilistic flip\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with lowest value contribution for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Random swap for additional exploration\n    if np.random.random() < 0.3 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 73,
        "algorithm": "The algorithm selects a promising solution from the archive based on dominance and value potential, then applies a hybrid local search combining value-based insertion, dominance-aware swapping, and probabilistic perturbation to explore the solution space while maintaining feasibility. It dynamically adjusts objective weights based on the current solution's position and prioritizes items that could dominate existing solutions, balancing exploration and exploitation. The method ensures feasibility by checking weight constraints at each step and uses probabilistic perturbations to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance and value potential scores\n    dominance_scores = []\n    value_potentials = []\n    for sol, obj in archive:\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] > obj[0] and other_obj[1] >= obj[1]:\n                dominated += 1\n            elif other_obj[0] >= obj[0] and other_obj[1] > obj[1]:\n                dominated += 1\n        dominance_scores.append(-dominated)\n\n        # Calculate value potential as normalized sum of objectives\n        total_value1 = np.sum(value1_lst)\n        total_value2 = np.sum(value2_lst)\n        potential = (obj[0]/total_value1 + obj[1]/total_value2) / 2\n        value_potentials.append(potential)\n\n    # Select solution with best balance of dominance and value potential\n    archive_with_scores = list(zip(archive, dominance_scores, value_potentials))\n    archive_with_scores.sort(key=lambda x: (x[1], -x[2]))\n    base_solution = archive_with_scores[0][0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-based insertion with dominance awareness\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate dominance-aware value scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n\n            # Check if adding this item would dominate any existing solution\n            dominance_bonus = 0\n            for sol, obj in archive:\n                if obj[0] < current_value1 + value1_lst[item] and obj[1] <= current_value2 + value2_lst[item]:\n                    dominance_bonus += 0.5\n\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2 + dominance_bonus)\n\n        # Select top 3 items with highest scores\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Dominance-aware swapping\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate dominance-aware trade-off scores\n        tradeoff_scores = []\n        for i in in_solution:\n            # Calculate how many solutions this item would dominate if removed\n            dominance_gain = 0\n            temp_weight = current_weight - weight_lst[i]\n            temp_value1 = current_value1 - value1_lst[i]\n            temp_value2 = current_value2 - value2_lst[i]\n\n            for sol, obj in archive:\n                if obj[0] > temp_value1 and obj[1] >= temp_value2:\n                    dominance_gain += 1\n\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6)) - dominance_gain\n            tradeoff_scores.append(tradeoff)\n\n        # Select worst items for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        for idx in worst_items:\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    # Check if swap would dominate any solution\n                    dominance_bonus = 0\n                    new_value1 = current_value1 - value1_lst[idx] + value1_lst[item]\n                    new_value2 = current_value2 - value2_lst[idx] + value2_lst[item]\n\n                    for sol, obj in archive:\n                        if obj[0] < new_value1 and obj[1] <= new_value2:\n                            dominance_bonus += 0.5\n\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2 + dominance_bonus\n\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n                current_weight = current_weight - weight_lst[idx] + weight_lst[best_swap]\n\n    # Probabilistic perturbation with dominance awareness\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with lowest value contribution and highest dominance gain\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            flip_scores = []\n            for i in flip_candidates:\n                # Calculate dominance gain if removed\n                dominance_gain = 0\n                temp_weight = current_weight - weight_lst[i]\n                temp_value1 = current_value1 - value1_lst[i]\n                temp_value2 = current_value2 - value2_lst[i]\n\n                for sol, obj in archive:\n                    if obj[0] > temp_value1 and obj[1] >= temp_value2:\n                        dominance_gain += 1\n\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                flip_scores.append(weight1 * ratio1 + weight2 * ratio2 - dominance_gain)\n\n            flip_idx = flip_candidates[np.argmin(flip_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Random swap for additional exploration\n    if np.random.random() < 0.3 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9227013166555078,
            2.2845222651958466
        ],
        "raw_score": [
            27.490698686550957,
            27.922276168455426
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance and value potential scores\n    dominance_scores = []\n    value_potentials = []\n    for sol, obj in archive:\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] > obj[0] and other_obj[1] >= obj[1]:\n                dominated += 1\n            elif other_obj[0] >= obj[0] and other_obj[1] > obj[1]:\n                dominated += 1\n        dominance_scores.append(-dominated)\n\n        # Calculate value potential as normalized sum of objectives\n        total_value1 = np.sum(value1_lst)\n        total_value2 = np.sum(value2_lst)\n        potential = (obj[0]/total_value1 + obj[1]/total_value2) / 2\n        value_potentials.append(potential)\n\n    # Select solution with best balance of dominance and value potential\n    archive_with_scores = list(zip(archive, dominance_scores, value_potentials))\n    archive_with_scores.sort(key=lambda x: (x[1], -x[2]))\n    base_solution = archive_with_scores[0][0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-based insertion with dominance awareness\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate dominance-aware value scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n\n            # Check if adding this item would dominate any existing solution\n            dominance_bonus = 0\n            for sol, obj in archive:\n                if obj[0] < current_value1 + value1_lst[item] and obj[1] <= current_value2 + value2_lst[item]:\n                    dominance_bonus += 0.5\n\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2 + dominance_bonus)\n\n        # Select top 3 items with highest scores\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Dominance-aware swapping\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate dominance-aware trade-off scores\n        tradeoff_scores = []\n        for i in in_solution:\n            # Calculate how many solutions this item would dominate if removed\n            dominance_gain = 0\n            temp_weight = current_weight - weight_lst[i]\n            temp_value1 = current_value1 - value1_lst[i]\n            temp_value2 = current_value2 - value2_lst[i]\n\n            for sol, obj in archive:\n                if obj[0] > temp_value1 and obj[1] >= temp_value2:\n                    dominance_gain += 1\n\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6)) - dominance_gain\n            tradeoff_scores.append(tradeoff)\n\n        # Select worst items for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        for idx in worst_items:\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    # Check if swap would dominate any solution\n                    dominance_bonus = 0\n                    new_value1 = current_value1 - value1_lst[idx] + value1_lst[item]\n                    new_value2 = current_value2 - value2_lst[idx] + value2_lst[item]\n\n                    for sol, obj in archive:\n                        if obj[0] < new_value1 and obj[1] <= new_value2:\n                            dominance_bonus += 0.5\n\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2 + dominance_bonus\n\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n                current_weight = current_weight - weight_lst[idx] + weight_lst[best_swap]\n\n    # Probabilistic perturbation with dominance awareness\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with lowest value contribution and highest dominance gain\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            flip_scores = []\n            for i in flip_candidates:\n                # Calculate dominance gain if removed\n                dominance_gain = 0\n                temp_weight = current_weight - weight_lst[i]\n                temp_value1 = current_value1 - value1_lst[i]\n                temp_value2 = current_value2 - value2_lst[i]\n\n                for sol, obj in archive:\n                    if obj[0] > temp_value1 and obj[1] >= temp_value2:\n                        dominance_gain += 1\n\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                flip_scores.append(weight1 * ratio1 + weight2 * ratio2 - dominance_gain)\n\n            flip_idx = flip_candidates[np.argmin(flip_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Random swap for additional exploration\n    if np.random.random() < 0.3 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive by prioritizing those with high potential for improvement, calculated as the sum of normalized objectives while considering Pareto dominance. It then applies a hybrid local search operator that combines value-driven item insertion, adaptive swapping based on trade-off scores, and probabilistic flips to maintain diversity, while strictly enforcing feasibility constraints. The method dynamically adjusts flip probabilities and prioritizes items with high marginal improvement, ensuring the generated neighbor solution is always valid and potentially Pareto-optimal.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance scores for each solution\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] > obj[0] and other_obj[1] >= obj[1]:\n                dominated += 1\n            elif other_obj[0] >= obj[0] and other_obj[1] > obj[1]:\n                dominated += 1\n        dominance_scores.append(-dominated)  # Negative for sorting\n\n    # Select solution with best balance of high potential and low dominance\n    archive_with_scores = list(zip(archive, dominance_scores))\n    archive_with_scores.sort(key=lambda x: (x[1], -(x[0][1][0] + x[0][1][1])))\n    base_solution = archive_with_scores[0][0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item insertion: prioritize items with high marginal improvement\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items to improve value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select worst items for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        for idx in worst_items:\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n                current_weight = current_weight - weight_lst[idx] + weight_lst[best_swap]\n\n    # Novelty-aware probabilistic flip\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with lowest value contribution for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Random swap for additional exploration\n    if np.random.random() < 0.3 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 74,
        "algorithm": "The algorithm selects a solution from the archive based on crowding distance to explore less crowded regions, then applies a hybrid local search combining value-driven insertion, adaptive swapping based on trade-off scores, and probabilistic flipping with dynamic probabilities, while ensuring feasibility through strict capacity checks. It prioritizes items with high marginal improvement in both objectives and dynamically adjusts exploration probabilities based on solution quality. The method balances exploitation (value-driven improvements) and exploration (randomized operations) to navigate the multi-objective solution space effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distance for each solution\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = []\n    for i in range(len(archive)):\n        left = objectives[i-1] if i > 0 else objectives[-1]\n        right = objectives[i+1] if i < len(archive)-1 else objectives[0]\n        dist = np.sum(np.abs(objectives[i] - left) + np.abs(objectives[i] - right))\n        crowding_distances.append(dist)\n\n    # Select solution with highest crowding distance (least explored)\n    archive_with_scores = list(zip(archive, crowding_distances))\n    archive_with_scores.sort(key=lambda x: -x[1])\n    base_solution = archive_with_scores[0][0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item insertion: prioritize items with high marginal improvement\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-5:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items to improve value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select worst items for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:3]]\n        for idx in worst_items:\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n                current_weight = current_weight - weight_lst[idx] + weight_lst[best_swap]\n\n    # Novelty-aware probabilistic flip with higher probability\n    flip_prob = 0.3 + 0.4 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with lowest value contribution for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Enhanced random swap for additional exploration\n    if np.random.random() < 0.4 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.763404400433018,
            2.605843663215637
        ],
        "raw_score": [
            28.963059003645213,
            30.50203374764756
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distance for each solution\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = []\n    for i in range(len(archive)):\n        left = objectives[i-1] if i > 0 else objectives[-1]\n        right = objectives[i+1] if i < len(archive)-1 else objectives[0]\n        dist = np.sum(np.abs(objectives[i] - left) + np.abs(objectives[i] - right))\n        crowding_distances.append(dist)\n\n    # Select solution with highest crowding distance (least explored)\n    archive_with_scores = list(zip(archive, crowding_distances))\n    archive_with_scores.sort(key=lambda x: -x[1])\n    base_solution = archive_with_scores[0][0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item insertion: prioritize items with high marginal improvement\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-5:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items to improve value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select worst items for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:3]]\n        for idx in worst_items:\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n                current_weight = current_weight - weight_lst[idx] + weight_lst[best_swap]\n\n    # Novelty-aware probabilistic flip with higher probability\n    flip_prob = 0.3 + 0.4 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with lowest value contribution for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Enhanced random swap for additional exploration\n    if np.random.random() < 0.4 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 3 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with high potential for improvement, calculated as the sum of normalized objectives while considering Pareto dominance. It then applies a hybrid local search operator that combines value-driven item insertion, adaptive swapping based on trade-off scores, and probabilistic flips to maintain diversity, while strictly enforcing feasibility constraints. The method dynamically adjusts flip probabilities and prioritizes items with high marginal improvement, ensuring the generated neighbor solution is always valid and potentially Pareto-optimal.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance scores for each solution\n    dominance_scores = []\n    for sol, obj in archive:\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] > obj[0] and other_obj[1] >= obj[1]:\n                dominated += 1\n            elif other_obj[0] >= obj[0] and other_obj[1] > obj[1]:\n                dominated += 1\n        dominance_scores.append(-dominated)  # Negative for sorting\n\n    # Select solution with best balance of high potential and low dominance\n    archive_with_scores = list(zip(archive, dominance_scores))\n    archive_with_scores.sort(key=lambda x: (x[1], -(x[0][1][0] + x[0][1][1])))\n    base_solution = archive_with_scores[0][0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item insertion: prioritize items with high marginal improvement\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items to improve value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select worst items for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        for idx in worst_items:\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n                current_weight = current_weight - weight_lst[idx] + weight_lst[best_swap]\n\n    # Novelty-aware probabilistic flip\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with lowest value contribution for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Random swap for additional exploration\n    if np.random.random() < 0.3 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm employs a hybrid selection strategy that prioritizes solutions with high value diversity, combining dynamic objective weighting with a multi-stage local search that includes value-driven item insertion, adaptive swapping, and probabilistic flipping to balance exploration and exploitation while ensuring feasibility. It dynamically adjusts flip probabilities based on the solution's Pareto dominance and focuses on improving value trade-offs through weighted value ratios and complementary item selections.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: prioritize solutions with high value diversity and potential for improvement\n    archive.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    selected_idx = min(len(archive) // 4, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item selection: prioritize items that create balanced value improvements\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-2:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items that create better value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select items with worst trade-offs for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:1]]\n        if len(worst_items) > 0:\n            idx = worst_items[0]\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n\n    # Dynamic exploration: probabilistic flip with value-aware probability\n    flip_prob = 0.1 + 0.4 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with high value potential for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            new_solution[flip_idx] = 0\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm intelligently selects a non-dominated solution from the archive by prioritizing those with high potential for improvement in either objective, then applies a hybrid local search operator that combines item swaps, random flips, and feasibility checks to generate diverse high-quality neighbors. It balances exploration (via random swaps and flips) with exploitation (by focusing on high-potential solutions) while ensuring all generated neighbors remain feasible. The selection prioritizes solutions with higher normalized objective sums, and the local search includes targeted item removals/additions, swaps between items, and probabilistic flips to maintain diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution based on potential for improvement\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            continue  # Skip infeasible solutions\n        normalized_obj = (obj[0] / (np.sum(value1_lst) + 1e-8), obj[1] / (np.sum(value2_lst) + 1e-8))\n        normalized_objectives.append((sol, normalized_obj))\n\n    if not normalized_objectives:\n        raise ValueError(\"No feasible solutions in archive\")\n\n    # Sort by sum of normalized objectives (prioritize solutions with higher potential)\n    normalized_objectives.sort(key=lambda x: -(x[1][0] + x[1][1]))\n    base_solution = normalized_objectives[0][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * new_solution)\n\n    # Randomly select an item to flip (basic local search)\n    candidates = np.where(new_solution == 1)[0]\n    if len(candidates) > 0:\n        idx = random.choice(candidates)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        else:\n            # If cannot remove, try adding a new item\n            candidates = np.where(new_solution == 0)[0]\n            for idx in candidates:\n                if total_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    break\n\n    # Apply a random swap between two items (exploration)\n    if np.sum(new_solution) > 1:\n        items = np.where(new_solution == 1)[0]\n        i, j = random.sample(list(items), 2)\n        # Check if swap is feasible\n        if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Apply a random flip with probability 0.3 (diversification)\n    if random.random() < 0.3:\n        idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[idx] == 1 and total_weight - weight_lst[idx] <= capacity:\n            new_solution[idx] = 0\n        elif new_solution[idx] == 0 and total_weight + weight_lst[idx] <= capacity:\n            new_solution[idx] = 1\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the BI-KP local search:\n\n**Keywords**:\n- **Adaptive Pareto-aware selection**, **objective-biased novelty swaps**, **probabilistic feasibility-aware flips**, **Pareto-constrained exploration**.\n\n**Advice**:\n1. Select solutions via dynamic weights (e.g., weighted sum of normalized objectives) while prioritizing Pareto dominance.\n2. Replace low-marginal items with high-marginal ones from the archive, biased toward underrepresented objectives.\n3. Apply probabilistic flips, favoring items that improve underperforming objectives while respecting capacity.\n4. Enforce feasibility at every step via marginal contribution checks.\n\n**Avoid**:\n- Static selection, blind randomness, fixed probabilities, and generic swaps.\n- Ignoring Pareto dominance, violating capacity constraints, or overfocusing on single objectives.\n\n**Explanation**:\nAdaptive Pareto-aware selection balances exploration/exploitation, while objective-biased swaps ensure multi-objective progress. Probabilistic flips and feasibility checks guarantee high-quality, feasible neighbors. Avoid rigid methods to prevent premature convergence.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 75,
        "algorithm": "The algorithm selects a promising solution from the archive based on Pareto dominance and normalized objective values, then applies a hybrid local search combining value-driven insertion, adaptive swapping, and probabilistic flips to generate a neighbor solution while ensuring feasibility. It prioritizes items with high marginal improvement based on dynamic objective weights, swaps items to optimize trade-offs, and probabilistically flips low-contribution items, with exploration enhanced by random swaps. The selection emphasizes solutions with high potential for improvement while the local search focuses on targeted modifications to enhance both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance scores and normalized objectives for each solution\n    dominance_scores = []\n    normalized_objectives = []\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n\n    for sol, obj in archive:\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] > obj[0] and other_obj[1] >= obj[1]:\n                dominated += 1\n            elif other_obj[0] >= obj[0] and other_obj[1] > obj[1]:\n                dominated += 1\n        dominance_scores.append(-dominated)  # Negative for sorting\n\n        norm_obj1 = obj[0] / (total_value1 + 1e-6)\n        norm_obj2 = obj[1] / (total_value2 + 1e-6)\n        normalized_objectives.append((norm_obj1, norm_obj2))\n\n    # Select solution with best balance of high potential and low dominance\n    archive_with_scores = list(zip(archive, dominance_scores, normalized_objectives))\n    archive_with_scores.sort(key=lambda x: (x[1], -(x[2][0] + x[2][1])))\n    base_solution = archive_with_scores[0][0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item insertion: prioritize items with high marginal improvement\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items to improve value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select worst items for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        for idx in worst_items:\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n                current_weight = current_weight - weight_lst[idx] + weight_lst[best_swap]\n\n    # Novelty-aware probabilistic flip\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with lowest value contribution for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Random swap for additional exploration\n    if np.random.random() < 0.3 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7814748609352387,
            1.004486322402954
        ],
        "raw_score": [
            27.18412767689565,
            27.967609385773507
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance scores and normalized objectives for each solution\n    dominance_scores = []\n    normalized_objectives = []\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n\n    for sol, obj in archive:\n        dominated = 0\n        for other_sol, other_obj in archive:\n            if other_obj[0] > obj[0] and other_obj[1] >= obj[1]:\n                dominated += 1\n            elif other_obj[0] >= obj[0] and other_obj[1] > obj[1]:\n                dominated += 1\n        dominance_scores.append(-dominated)  # Negative for sorting\n\n        norm_obj1 = obj[0] / (total_value1 + 1e-6)\n        norm_obj2 = obj[1] / (total_value2 + 1e-6)\n        normalized_objectives.append((norm_obj1, norm_obj2))\n\n    # Select solution with best balance of high potential and low dominance\n    archive_with_scores = list(zip(archive, dominance_scores, normalized_objectives))\n    archive_with_scores.sort(key=lambda x: (x[1], -(x[2][0] + x[2][1])))\n    base_solution = archive_with_scores[0][0][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Dynamic objective weighting based on current solution's position\n    weight1 = (current_value1 / (total_value1 + 1e-6)) * (1 - (current_value1 / (total_value1 + 1e-6)))\n    weight2 = (current_value2 / (total_value2 + 1e-6)) * (1 - (current_value2 / (total_value2 + 1e-6)))\n\n    # Value-driven item insertion: prioritize items with high marginal improvement\n    potential_items = np.where(new_solution == 0)[0]\n    if len(potential_items) > 0:\n        # Calculate value improvement scores\n        value_scores = []\n        for item in potential_items:\n            if current_weight + weight_lst[item] > capacity:\n                value_scores.append(0)\n                continue\n            ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n            ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n            value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n        # Select top items with highest value scores\n        top_items = potential_items[np.argsort(value_scores)[-3:]]\n        for item in top_items:\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Adaptive swapping: swap items to improve value trade-offs\n    in_solution = np.where(new_solution == 1)[0]\n    if len(in_solution) >= 2:\n        # Calculate trade-off scores for each item\n        tradeoff_scores = []\n        for i in in_solution:\n            tradeoff = abs((value1_lst[i] - current_value1) / (value2_lst[i] - current_value2 + 1e-6))\n            tradeoff_scores.append(tradeoff)\n\n        # Select worst items for potential removal\n        worst_items = in_solution[np.argsort(tradeoff_scores)[:2]]\n        for idx in worst_items:\n            # Find best item to swap with\n            best_swap = None\n            best_score = -1\n            for item in potential_items:\n                if current_weight - weight_lst[idx] + weight_lst[item] <= capacity:\n                    ratio1 = value1_lst[item] / (current_value1 + 1e-6)\n                    ratio2 = value2_lst[item] / (current_value2 + 1e-6)\n                    score = weight1 * ratio1 + weight2 * ratio2\n                    if score > best_score:\n                        best_score = score\n                        best_swap = item\n\n            if best_swap is not None:\n                new_solution[idx] = 0\n                new_solution[best_swap] = 1\n                current_weight = current_weight - weight_lst[idx] + weight_lst[best_swap]\n\n    # Novelty-aware probabilistic flip\n    flip_prob = 0.2 + 0.3 * (1 - (current_value1 + current_value2) / (total_value1 + total_value2))\n    if np.random.random() < flip_prob and len(new_solution) > 0:\n        # Select items with lowest value contribution for flipping\n        flip_candidates = np.where(new_solution == 1)[0]\n        if len(flip_candidates) > 0:\n            value_scores = []\n            for i in flip_candidates:\n                ratio1 = value1_lst[i] / (current_value1 + 1e-6)\n                ratio2 = value2_lst[i] / (current_value2 + 1e-6)\n                value_scores.append(weight1 * ratio1 + weight2 * ratio2)\n\n            flip_idx = flip_candidates[np.argmin(value_scores)]\n            if current_weight - weight_lst[flip_idx] <= capacity:\n                new_solution[flip_idx] = 0\n\n    # Random swap for additional exploration\n    if np.random.random() < 0.3 and len(in_solution) > 1:\n        i, j = random.sample(list(in_solution), 2)\n        if current_weight - weight_lst[i] + weight_lst[j] <= capacity:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "s1"
    }
]