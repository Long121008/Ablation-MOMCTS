[
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    def combined_score(obj):\n        return 0.5 * obj[0] + 0.5 * obj[1]  # Equal weights for both objectives\n    selected_solution = min(archive, key=lambda x: combined_score(x[1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify the worst node in terms of both objectives\n    node_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        node_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                         distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_node = np.argmax(node_scores)\n\n    # Step 2: Remove the worst node and reinsert it in a position that improves both objectives\n    removed_node = new_solution[worst_node]\n    new_solution = np.delete(new_solution, worst_node)\n\n    best_pos = 0\n    best_improvement = -float('inf')\n\n    for i in range(n-1):\n        # Try inserting the removed node between i and i+1\n        temp_solution = np.insert(new_solution, i, removed_node)\n        # Calculate the change in both objectives\n        prev = temp_solution[i-1]\n        curr = temp_solution[i]\n        next_ = temp_solution[(i+1)%(n-1)]\n\n        delta1 = (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]) - \\\n                 (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n        delta2 = (distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]) - \\\n                 (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n        improvement = -delta1 - delta2  # Negative because we want to minimize\n\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n\n    new_solution = np.insert(new_solution, best_pos, removed_node)\n\n    # Step 3: Apply a 3-opt move with a 60% probability to explore different configurations\n    if np.random.rand() < 0.6:\n        a, b, c = sorted(np.random.choice(n, 3, replace=False))\n        # Try different 3-opt configurations\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b][::-1], new_solution[b:c], new_solution[c:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c][::-1], new_solution[a:b], new_solution[c:]]),\n            np.concatenate([new_solution[:a], new_solution[a:b], new_solution[b:c][::-1], new_solution[c:]])\n        ]\n        # Evaluate all options and select the best one\n        best_option = new_solution\n        best_score = combined_score((sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)),\n                                    sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))))\n        for option in options:\n            score1 = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n))\n            score2 = sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            current_score = combined_score((score1, score2))\n            if current_score < best_score:\n                best_score = current_score\n                best_option = option\n        new_solution = best_option\n\n    return new_solution\n\n",
        "score": [
            5.885829592179676,
            5.710212425737046
        ]
    },
    {
        "algorithm": "The algorithm selects the best solution from the archive based on a weighted combined objective score (60% first objective, 40% second), then applies a hybrid local search combining probabilistic 3-opt moves (80% chance), biased edge insertion (60% chance), and adaptive 2-opt segment reversal (50% chance), ensuring feasibility at each step. The method prioritizes the first objective while balancing improvements in both spaces, with each operator targeting different aspects of tour optimization.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    def combined_score(obj):\n        return 0.6 * obj[0] + 0.4 * obj[1]\n\n    def is_feasible(tour):\n        return len(np.unique(tour)) == len(tour) and len(tour) == len(instance)\n\n    selected_solution = min(archive, key=lambda x: combined_score(x[1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Probabilistic 3-opt move with biased selection\n    if np.random.rand() < 0.8:\n        a, b, c = np.random.choice(n, size=3, replace=False)\n        a, b, c = sorted([a, b, c])\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b+1][::-1], new_solution[b+1:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c+1], new_solution[a:b], new_solution[c+1:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c+1][::-1], new_solution[a:b], new_solution[c+1:]])\n        ]\n        best_option = new_solution\n        best_score = combined_score((sum(distance_matrix_1[best_option[i], best_option[(i+1)%n]] for i in range(n)),\n                                    sum(distance_matrix_2[best_option[i], best_option[(i+1)%n]] for i in range(n))))\n        for option in options:\n            if is_feasible(option):\n                score1 = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n))\n                score2 = sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n                current_score = combined_score((score1, score2))\n                if current_score < best_score:\n                    best_score = current_score\n                    best_option = option\n        new_solution = best_option\n\n    # Step 2: Biased edge insertion for improvement\n    if np.random.rand() < 0.6:\n        worst_edge = np.argmax([distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)])\n        removed_node = new_solution[worst_edge]\n        temp_solution = np.delete(new_solution, worst_edge)\n        best_pos = 0\n        best_improvement = 0\n\n        for i in range(len(temp_solution)):\n            candidate = np.insert(temp_solution, i, removed_node)\n            if is_feasible(candidate):\n                delta1 = (distance_matrix_1[candidate[i-1], candidate[i]] + distance_matrix_1[candidate[i], candidate[(i+1)%n]] -\n                         (distance_matrix_1[temp_solution[i-1], temp_solution[i]] + distance_matrix_1[temp_solution[i], temp_solution[(i+1)%len(temp_solution)]]))\n                delta2 = (distance_matrix_2[candidate[i-1], candidate[i]] + distance_matrix_2[candidate[i], candidate[(i+1)%n]] -\n                         (distance_matrix_2[temp_solution[i-1], temp_solution[i]] + distance_matrix_2[temp_solution[i], temp_solution[(i+1)%len(temp_solution)]]))\n                improvement = -delta1 - delta2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_pos = i\n        new_solution = np.insert(temp_solution, best_pos, removed_node)\n\n    # Step 3: Adaptive 2-opt segment reversal\n    if np.random.rand() < 0.5:\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        candidate = np.concatenate([new_solution[:a], new_solution[a:b+1][::-1], new_solution[b+1:]])\n        if is_feasible(candidate):\n            delta1 = (sum(distance_matrix_1[candidate[i], candidate[(i+1)%n]] for i in range(n)) -\n                     sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)))\n            delta2 = (sum(distance_matrix_2[candidate[i], candidate[(i+1)%n]] for i in range(n)) -\n                     sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n)))\n            if delta1 + delta2 < 0:\n                new_solution = candidate\n\n    return new_solution\n\n",
        "score": [
            5.399567917958221,
            6.241680779401998
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a normalized objective score, then applies a hybrid local search combining worst-segment removal, adaptive 4-opt moves (70% probability), and biased edge swaps (50% probability), prioritizing segments and edges with higher combined distances in both objective spaces while maintaining feasibility through structured perturbations. The method balances exploration and exploitation by adaptively selecting local search operators and evaluating improvements across multiple objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = np.sum(normalized, axis=1)\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify and remove the worst segment (highest combined distance)\n    segment_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        segment_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                            distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_segment = np.argmax(segment_scores)\n    removed_node = new_solution[worst_segment]\n    new_solution = np.delete(new_solution, worst_segment)\n\n    # Step 2: Reinsert the removed node in the best position\n    best_pos = 0\n    best_improvement = -float('inf')\n    for i in range(n-1):\n        temp_solution = np.insert(new_solution, i, removed_node)\n        prev = temp_solution[i-1]\n        curr = temp_solution[i]\n        next_ = temp_solution[(i+1)%(n-1)]\n        delta1 = (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]) - \\\n                (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n        delta2 = (distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]) - \\\n                (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n        improvement = -delta1 - delta2\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n    new_solution = np.insert(new_solution, best_pos, removed_node)\n\n    # Step 3: Apply adaptive 4-opt move (70% probability)\n    if np.random.rand() < 0.7:\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b][::-1], new_solution[b:c], new_solution[c:d][::-1], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[c:d], new_solution[b:c], new_solution[a:b], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c][::-1], new_solution[a:b], new_solution[c:d], new_solution[d:]])\n        ]\n        best_option = new_solution\n        best_score = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                     sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n        for option in options:\n            score = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n)) + \\\n                    sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            if score < best_score:\n                best_score = score\n                best_option = option\n        new_solution = best_option\n\n    # Step 4: Perform biased edge swap (50% probability)\n    if np.random.rand() < 0.5:\n        edge_scores = np.zeros(n)\n        for i in range(n):\n            prev = new_solution[i-1]\n            curr = new_solution[i]\n            edge_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_2[prev, curr]\n        worst_edge = np.argmax(edge_scores)\n        best_swap = worst_edge\n        best_improvement = 0\n        for i in range(n):\n            if i != worst_edge and abs(i - worst_edge) > 1:\n                prev_worst = new_solution[(worst_edge-1)%n]\n                next_worst = new_solution[(worst_edge+1)%n]\n                prev_i = new_solution[(i-1)%n]\n                next_i = new_solution[(i+1)%n]\n                old_cost1 = distance_matrix_1[prev_worst, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[i]] + distance_matrix_1[new_solution[i], next_i]\n                new_cost1 = distance_matrix_1[prev_worst, new_solution[i]] + distance_matrix_1[new_solution[i], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_i]\n                old_cost2 = distance_matrix_2[prev_worst, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[i]] + distance_matrix_2[new_solution[i], next_i]\n                new_cost2 = distance_matrix_2[prev_worst, new_solution[i]] + distance_matrix_2[new_solution[i], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_i]\n                improvement = (old_cost1 + old_cost2) - (new_cost1 + new_cost2)\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_swap = i\n        if best_swap != worst_edge:\n            new_solution[worst_edge], new_solution[best_swap] = new_solution[best_swap], new_solution[worst_edge]\n\n    return new_solution\n\n",
        "score": [
            5.7301280137273505,
            5.9960207296721775
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a weighted combination of normalized objective values, then applies a hybrid local search combining adaptive segment reversal, weighted 3-opt moves, and biased node insertion, prioritizing high-distance segments while ensuring feasibility through constrained perturbations and objective-aware evaluation. It prioritizes the first objective (60%) over the second (40%) in both selection and neighborhood generation, with segment reversal targeting the worst segments and node insertion focusing on high-impact nodes. The approach balances exploration and exploitation through probabilistic application of operators and objective-aware evaluations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    combined_scores = np.sum(normalized * np.array([0.6, 0.4]), axis=1)  # Weighted combination\n    selected_idx = np.argmin(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify and reverse the worst segment with adaptive probability\n    segment_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        segment_scores[i] = (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]) * 0.7 + \\\n                           (distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]) * 0.3\n    worst_segment = np.argmax(segment_scores)\n    segment_length = np.random.randint(2, min(5, n//2))\n    segment_end = (worst_segment + segment_length) % n\n\n    if np.random.rand() < 0.6:\n        if worst_segment < segment_end:\n            new_solution[worst_segment:segment_end] = new_solution[worst_segment:segment_end][::-1]\n        else:\n            part1 = new_solution[worst_segment:]\n            part2 = new_solution[:segment_end]\n            reversed_segment = np.concatenate([part1[::-1], part2[::-1]])\n            new_solution = np.concatenate([reversed_segment, new_solution[segment_end:worst_segment]])\n\n    # Step 2: Apply weighted 3-opt move\n    if np.random.rand() < 0.75:\n        a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b][::-1], new_solution[b:c], new_solution[c:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c], new_solution[a:b][::-1], new_solution[c:]]),\n            np.concatenate([new_solution[:a], new_solution[a:b], new_solution[c:], new_solution[b:c][::-1]])\n        ]\n        best_option = new_solution\n        best_weighted_score = sum((distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] * 0.6 +\n                                  distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] * 0.4)\n                                 for i in range(n))\n        for option in options:\n            weighted_score = sum((distance_matrix_1[option[i], option[(i+1)%n]] * 0.6 +\n                                distance_matrix_2[option[i], option[(i+1)%n]] * 0.4)\n                               for i in range(n))\n            if weighted_score < best_weighted_score:\n                best_weighted_score = weighted_score\n                best_option = option\n        new_solution = best_option\n\n    # Step 3: Biased node insertion\n    if np.random.rand() < 0.6:\n        node_scores = np.zeros(n)\n        for i in range(n):\n            prev = new_solution[i-1]\n            curr = new_solution[i]\n            next_ = new_solution[(i+1)%n]\n            node_scores[i] = (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]) * 0.5 + \\\n                            (distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]) * 0.5\n        worst_node = np.argmax(node_scores)\n        removed_node = new_solution[worst_node]\n        new_solution = np.delete(new_solution, worst_node)\n\n        best_pos = 0\n        best_weighted_improvement = -float('inf')\n        for i in range(n-1):\n            temp_solution = np.insert(new_solution, i, removed_node)\n            prev = temp_solution[i-1]\n            curr = temp_solution[i]\n            next_ = temp_solution[(i+1)%(n-1)]\n            delta1 = (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]) - \\\n                    (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n            delta2 = (distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]) - \\\n                    (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n            weighted_improvement = -delta1 * 0.6 - delta2 * 0.4\n            if weighted_improvement > best_weighted_improvement:\n                best_weighted_improvement = weighted_improvement\n                best_pos = i\n        new_solution = np.insert(new_solution, best_pos, removed_node)\n\n    return new_solution\n\n",
        "score": [
            4.800699547797319,
            7.315086418984713
        ]
    },
    {
        "algorithm": "The algorithm selects the most balanced solution from the archive (by minimizing the sum of normalized objective scores) and applies a hybrid local search combining worst-segment removal/reinsertion, adaptive 3-opt moves (70% probability), objective-aware edge swaps (60% probability), and random segment reordering (30% probability). It prioritizes improving both objectives simultaneously by targeting high-cost segments and edges while ensuring feasibility through careful move validation. The method balances exploitation (targeted improvements) with exploration (random perturbations) using adaptive operator selection to generate high-quality neighbor solutions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = np.sum(normalized, axis=1)\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify and remove the worst segment\n    segment_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        segment_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                            distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_segment = np.argmax(segment_scores)\n    removed = new_solution[worst_segment]\n    new_solution = np.delete(new_solution, worst_segment)\n\n    # Step 2: Reinsert the removed segment in the best position\n    best_pos = 0\n    best_improvement = -float('inf')\n    for i in range(n-1):\n        temp_solution = np.insert(new_solution, i, removed)\n        prev = temp_solution[i-1]\n        curr = temp_solution[i]\n        next_ = temp_solution[(i+1)%(n-1)]\n        delta1 = (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]) - \\\n                (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n        delta2 = (distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]) - \\\n                (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n        improvement = -delta1 - delta2\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n    new_solution = np.insert(new_solution, best_pos, removed)\n\n    # Step 3: Apply adaptive 3-opt move (70% probability)\n    if np.random.rand() < 0.7:\n        a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b][::-1], new_solution[b:c], new_solution[c:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c], new_solution[a:b], new_solution[c:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c][::-1], new_solution[a:b], new_solution[c:]])\n        ]\n        best_option = new_solution\n        best_score = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                     sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n        for option in options:\n            score = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n)) + \\\n                   sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            if score < best_score:\n                best_score = score\n                best_option = option\n        new_solution = best_option\n\n    # Step 4: Perform objective-aware edge swap (60% probability)\n    if np.random.rand() < 0.6:\n        edge_scores = np.zeros(n)\n        for i in range(n):\n            prev = new_solution[i-1]\n            curr = new_solution[i]\n            edge_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_2[prev, curr]\n        worst_edge = np.argmax(edge_scores)\n        best_swap = worst_edge\n        best_improvement = 0\n        for i in range(n):\n            if i != worst_edge and abs(i - worst_edge) > 1:\n                prev_worst = new_solution[(worst_edge-1)%n]\n                next_worst = new_solution[(worst_edge+1)%n]\n                prev_i = new_solution[(i-1)%n]\n                next_i = new_solution[(i+1)%n]\n                old_cost1 = distance_matrix_1[prev_worst, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[i]] + distance_matrix_1[new_solution[i], next_i]\n                new_cost1 = distance_matrix_1[prev_worst, new_solution[i]] + distance_matrix_1[new_solution[i], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_i]\n                delta1 = new_cost1 - old_cost1\n                old_cost2 = distance_matrix_2[prev_worst, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[i]] + distance_matrix_2[new_solution[i], next_i]\n                new_cost2 = distance_matrix_2[prev_worst, new_solution[i]] + distance_matrix_2[new_solution[i], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_i]\n                delta2 = new_cost2 - old_cost2\n                improvement = -delta1 - delta2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_swap = i\n        if best_swap != worst_edge:\n            new_solution[worst_edge], new_solution[best_swap] = new_solution[best_swap], new_solution[worst_edge]\n\n    # Step 5: Random segment reordering (30% probability)\n    if np.random.rand() < 0.3:\n        seg_start = np.random.randint(0, n - 2)\n        seg_end = np.random.randint(seg_start + 2, n)\n        segment = new_solution[seg_start:seg_end]\n        np.random.shuffle(segment)\n        temp_solution = np.concatenate([new_solution[:seg_start], segment, new_solution[seg_end:]])\n        if len(np.unique(temp_solution)) == n:\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            6.220294876581997,
            5.356927599116917
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive using normalized objective scores, then applies a hybrid local search combining worst-segment removal, adaptive 4-opt moves (prioritizing segments with high combined distances), and biased edge insertion (focusing on long edges) to generate improved neighbors while maintaining feasibility. The method intelligently balances exploration and exploitation by probabilistically applying these operations to escape local optima while maintaining solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = np.sum(normalized, axis=1)\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify and remove the worst segment (highest combined distance)\n    segment_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        segment_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                            distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_segment = np.argmax(segment_scores)\n    removed_node = new_solution[worst_segment]\n    new_solution = np.delete(new_solution, worst_segment)\n\n    # Step 2: Reinsert the removed node in the best position\n    best_pos = 0\n    best_improvement = -float('inf')\n    for i in range(n-1):\n        temp_solution = np.insert(new_solution, i, removed_node)\n        prev = temp_solution[i-1]\n        curr = temp_solution[i]\n        next_ = temp_solution[(i+1)%(n-1)]\n        delta1 = (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]) - \\\n                (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n        delta2 = (distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]) - \\\n                (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n        improvement = -delta1 - delta2\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n    new_solution = np.insert(new_solution, best_pos, removed_node)\n\n    # Step 3: Apply adaptive 4-opt move (70% probability)\n    if np.random.rand() < 0.7:\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b][::-1], new_solution[b:c], new_solution[c:d][::-1], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[c:d], new_solution[b:c], new_solution[a:b], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c][::-1], new_solution[a:b], new_solution[c:d], new_solution[d:]])\n        ]\n        best_option = new_solution\n        best_score = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                     sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n        for option in options:\n            score = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n)) + \\\n                    sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            if score < best_score:\n                best_score = score\n                best_option = option\n        new_solution = best_option\n\n    # Step 4: Perform biased edge insertion (60% probability)\n    if np.random.rand() < 0.6:\n        worst_edge = np.argmax([distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)])\n        removed_node = new_solution[worst_edge]\n        temp_solution = np.delete(new_solution, worst_edge)\n        best_pos = 0\n        best_improvement = -float('inf')\n\n        for i in range(len(temp_solution)):\n            candidate = np.insert(temp_solution, i, removed_node)\n            delta1 = (distance_matrix_1[candidate[i-1], candidate[i]] + distance_matrix_1[candidate[i], candidate[(i+1)%len(candidate)]]) - \\\n                    (distance_matrix_1[temp_solution[i-1], temp_solution[i]] + distance_matrix_1[temp_solution[i], temp_solution[(i+1)%len(temp_solution)]])\n            delta2 = (distance_matrix_2[candidate[i-1], candidate[i]] + distance_matrix_2[candidate[i], candidate[(i+1)%len(candidate)]]) - \\\n                    (distance_matrix_2[temp_solution[i-1], temp_solution[i]] + distance_matrix_2[temp_solution[i], temp_solution[(i+1)%len(temp_solution)]])\n            improvement = -delta1 - delta2\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_pos = i\n        new_solution = np.insert(temp_solution, best_pos, removed_node)\n\n    return new_solution\n\n",
        "score": [
            5.894141691004092,
            5.716769718585903
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive using a normalized objective score, then applies a hybrid local search combining segment reversal of high-distance nodes, adaptive 3-opt moves (60% probability), and biased edge insertion (40% probability). It prioritizes improving both objectives by evaluating edge and segment costs in both spaces, ensuring feasibility through structured perturbations while maintaining valid TSP tours. The method balances exploration (random selection and operations) with exploitation (targeted improvements) to navigate the bi-objective space effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = np.sum(normalized, axis=1)\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify and reverse the worst segment (highest combined distance)\n    segment_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        segment_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                           distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_segment = np.argmax(segment_scores)\n    segment_length = np.random.randint(2, min(4, n//2))\n    start = worst_segment\n    end = (worst_segment + segment_length) % n\n    if start > end:\n        new_solution = np.concatenate([new_solution[end:start][::-1], new_solution[start:], new_solution[:end][::-1]])\n    else:\n        new_solution[start:end] = new_solution[start:end][::-1]\n\n    # Step 2: Apply adaptive 3-opt move (60% probability)\n    if np.random.rand() < 0.6:\n        a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b][::-1], new_solution[b:c], new_solution[c:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c], new_solution[a:b][::-1], new_solution[c:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c][::-1], new_solution[a:b], new_solution[c:]])\n        ]\n        best_option = new_solution\n        best_score = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                     sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n        for option in options:\n            score = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n)) + \\\n                    sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            if score < best_score:\n                best_score = score\n                best_option = option\n        new_solution = best_option\n\n    # Step 3: Perform biased edge insertion (40% probability)\n    if np.random.rand() < 0.4:\n        edge_scores = np.zeros(n)\n        for i in range(n):\n            prev = new_solution[i-1]\n            curr = new_solution[i]\n            edge_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_2[prev, curr]\n        worst_edge = np.argmax(edge_scores)\n        removed_node = new_solution[worst_edge]\n        new_solution = np.delete(new_solution, worst_edge)\n        best_pos = 0\n        best_improvement = -float('inf')\n        for i in range(n-1):\n            temp_solution = np.insert(new_solution, i, removed_node)\n            prev = temp_solution[i-1]\n            curr = temp_solution[i]\n            next_ = temp_solution[(i+1)%(n-1)]\n            delta1 = (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]) - \\\n                    (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n            delta2 = (distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]) - \\\n                    (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n            improvement = -delta1 - delta2\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_pos = i\n        new_solution = np.insert(new_solution, best_pos, removed_node)\n\n    return new_solution\n\n",
        "score": [
            5.535405859341016,
            6.310487335417495
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive using normalized objective scores, then applies a hybrid local search combining adaptive segment removal/reinsertion, probabilistic 3-opt moves (70% chance), and biased edge swaps (60% chance), prioritizing segments and edges with high combined distances in both objective spaces while ensuring feasibility through structured perturbations. The selection prioritizes solutions with lower normalized objective scores, while the local search focuses on improving the worst segments and edges in both objective spaces.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = np.sum(normalized, axis=1)\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify and remove the worst segment (highest combined distance)\n    segment_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        segment_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                            distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_segment = np.argmax(segment_scores)\n    removed_node = new_solution[worst_segment]\n    new_solution = np.delete(new_solution, worst_segment)\n\n    # Step 2: Reinsert the removed node in the best position\n    best_pos = 0\n    best_improvement = -float('inf')\n    for i in range(n-1):\n        temp_solution = np.insert(new_solution, i, removed_node)\n        prev = temp_solution[i-1]\n        curr = temp_solution[i]\n        next_ = temp_solution[(i+1)%(n-1)]\n        delta1 = (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]) - \\\n                (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n        delta2 = (distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]) - \\\n                (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n        improvement = -delta1 - delta2\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n    new_solution = np.insert(new_solution, best_pos, removed_node)\n\n    # Step 3: Apply probabilistic 3-opt move (70% probability)\n    if np.random.rand() < 0.7:\n        a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b+1][::-1], new_solution[b+1:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c+1], new_solution[a:b], new_solution[c+1:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c+1][::-1], new_solution[a:b], new_solution[c+1:]])\n        ]\n        best_option = new_solution\n        best_score = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                     sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n        for option in options:\n            score = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n)) + \\\n                    sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            if score < best_score:\n                best_score = score\n                best_option = option\n        new_solution = best_option\n\n    # Step 4: Perform biased edge swap (60% probability)\n    if np.random.rand() < 0.6:\n        edge_scores = np.zeros(n)\n        for i in range(n):\n            prev = new_solution[i-1]\n            curr = new_solution[i]\n            edge_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_2[prev, curr]\n        worst_edge = np.argmax(edge_scores)\n        best_swap = worst_edge\n        best_improvement = 0\n        for i in range(n):\n            if i != worst_edge and abs(i - worst_edge) > 1:\n                prev_worst = new_solution[(worst_edge-1)%n]\n                next_worst = new_solution[(worst_edge+1)%n]\n                prev_i = new_solution[(i-1)%n]\n                next_i = new_solution[(i+1)%n]\n                old_cost1 = distance_matrix_1[prev_worst, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[i]] + distance_matrix_1[new_solution[i], next_i]\n                new_cost1 = distance_matrix_1[prev_worst, new_solution[i]] + distance_matrix_1[new_solution[i], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_i]\n                old_cost2 = distance_matrix_2[prev_worst, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[i]] + distance_matrix_2[new_solution[i], next_i]\n                new_cost2 = distance_matrix_2[prev_worst, new_solution[i]] + distance_matrix_2[new_solution[i], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_i]\n                improvement = (old_cost1 + old_cost2) - (new_cost1 + new_cost2)\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_swap = i\n        if best_swap != worst_edge:\n            new_solution[worst_edge], new_solution[best_swap] = new_solution[best_swap], new_solution[worst_edge]\n\n    return new_solution\n\n",
        "score": [
            5.569424072867928,
            6.253996903426529
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by normalizing objectives and choosing the one with the lowest combined score, then applies a hybrid local search strategy: it first removes the worst segment (highest combined distance in both objectives) and reinserts it optimally, followed by adaptive 4-opt moves (70% probability) and biased edge swaps (50% probability) to further improve the solution while ensuring feasibility. The method prioritizes segments and edges with high combined distances for improvement, using probabilistic exploration of different neighborhood structures.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = np.sum(normalized, axis=1)\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify and remove the worst segment (highest total distance in both objectives)\n    segment_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        segment_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                            distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_segment = np.argmax(segment_scores)\n    removed = new_solution[worst_segment]\n    new_solution = np.delete(new_solution, worst_segment)\n\n    # Step 2: Reinsert the removed segment in the best position\n    best_pos = 0\n    best_improvement = 0\n    for i in range(n-1):\n        temp_solution = np.insert(new_solution, i, removed)\n        prev = temp_solution[i-1]\n        curr = temp_solution[i]\n        next_ = temp_solution[(i+1)%(n-1)]\n        delta1 = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] - \\\n                 (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n        delta2 = distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_] - \\\n                 (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n        improvement = -delta1 - delta2\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n    new_solution = np.insert(new_solution, best_pos, removed)\n\n    # Step 3: Apply adaptive 4-opt move (70% probability)\n    if np.random.rand() < 0.7:\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b][::-1], new_solution[b:c], new_solution[c:d][::-1], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[c:d], new_solution[b:c], new_solution[a:b], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c][::-1], new_solution[a:b], new_solution[c:d], new_solution[d:]])\n        ]\n        best_option = new_solution\n        best_score = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                     sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n        for option in options:\n            score = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n)) + \\\n                    sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            if score < best_score:\n                best_score = score\n                best_option = option\n        new_solution = best_option\n\n    # Step 4: Perform biased edge swap (50% probability)\n    if np.random.rand() < 0.5:\n        edge_scores = np.zeros(n)\n        for i in range(n):\n            prev = new_solution[i-1]\n            curr = new_solution[i]\n            edge_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_2[prev, curr]\n        worst_edge = np.argmax(edge_scores)\n        best_swap = worst_edge\n        best_improvement = 0\n        for i in range(n):\n            if i != worst_edge and abs(i - worst_edge) > 1:\n                prev_worst = new_solution[(worst_edge-1)%n]\n                next_worst = new_solution[(worst_edge+1)%n]\n                prev_i = new_solution[(i-1)%n]\n                next_i = new_solution[(i+1)%n]\n                old_cost1 = distance_matrix_1[prev_worst, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[i]] + distance_matrix_1[new_solution[i], next_i]\n                new_cost1 = distance_matrix_1[prev_worst, new_solution[i]] + distance_matrix_1[new_solution[i], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_i]\n                old_cost2 = distance_matrix_2[prev_worst, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[i]] + distance_matrix_2[new_solution[i], next_i]\n                new_cost2 = distance_matrix_2[prev_worst, new_solution[i]] + distance_matrix_2[new_solution[i], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_i]\n                improvement = (old_cost1 + old_cost2) - (new_cost1 + new_cost2)\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_swap = i\n        if best_swap != worst_edge:\n            new_solution[worst_edge], new_solution[best_swap] = new_solution[best_swap], new_solution[worst_edge]\n\n    return new_solution\n\n",
        "score": [
            6.5962745856836165,
            5.54039310583721
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (based on normalized objective scores) and applies a hybrid local search combining segment removal/reinsertion, adaptive 4-opt moves (70% probability), and biased edge swaps (50% probability), prioritizing segments and edges with higher combined distances in both objective spaces. It ensures feasibility by maintaining a valid TSP tour throughout all operations. The method balances exploration (via randomness in 4-opt and edge swaps) with exploitation (targeting high-cost segments/edges) to improve both objectives simultaneously.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = np.sum(normalized, axis=1)\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify and remove the worst segment (highest combined distance)\n    segment_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        segment_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                            distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_segment = np.argmax(segment_scores)\n    removed_node = new_solution[worst_segment]\n    new_solution = np.delete(new_solution, worst_segment)\n\n    # Step 2: Reinsert the removed node in the best position\n    best_pos = 0\n    best_improvement = -float('inf')\n    for i in range(n-1):\n        temp_solution = np.insert(new_solution, i, removed_node)\n        prev = temp_solution[i-1]\n        curr = temp_solution[i]\n        next_ = temp_solution[(i+1)%(n-1)]\n        delta1 = (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]) - \\\n                (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n        delta2 = (distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]) - \\\n                (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n        improvement = -delta1 - delta2\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n    new_solution = np.insert(new_solution, best_pos, removed_node)\n\n    # Step 3: Apply adaptive 4-opt move (70% probability)\n    if np.random.rand() < 0.7:\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b][::-1], new_solution[b:c], new_solution[c:d][::-1], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[c:d], new_solution[b:c], new_solution[a:b], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c][::-1], new_solution[a:b], new_solution[c:d], new_solution[d:]])\n        ]\n        best_option = new_solution\n        best_score = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                     sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n        for option in options:\n            score = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n)) + \\\n                    sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            if score < best_score:\n                best_score = score\n                best_option = option\n        new_solution = best_option\n\n    # Step 4: Perform biased edge swap (50% probability)\n    if np.random.rand() < 0.5:\n        edge_scores = np.zeros(n)\n        for i in range(n):\n            prev = new_solution[i-1]\n            curr = new_solution[i]\n            edge_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_2[prev, curr]\n        worst_edge = np.argmax(edge_scores)\n        best_swap = worst_edge\n        best_improvement = 0\n        for i in range(n):\n            if i != worst_edge and abs(i - worst_edge) > 1:\n                prev_worst = new_solution[(worst_edge-1)%n]\n                next_worst = new_solution[(worst_edge+1)%n]\n                prev_i = new_solution[(i-1)%n]\n                next_i = new_solution[(i+1)%n]\n                old_cost1 = distance_matrix_1[prev_worst, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[i]] + distance_matrix_1[new_solution[i], next_i]\n                new_cost1 = distance_matrix_1[prev_worst, new_solution[i]] + distance_matrix_1[new_solution[i], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_i]\n                old_cost2 = distance_matrix_2[prev_worst, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[i]] + distance_matrix_2[new_solution[i], next_i]\n                new_cost2 = distance_matrix_2[prev_worst, new_solution[i]] + distance_matrix_2[new_solution[i], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_i]\n                improvement = (old_cost1 + old_cost2) - (new_cost1 + new_cost2)\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_swap = i\n        if best_swap != worst_edge:\n            new_solution[worst_edge], new_solution[best_swap] = new_solution[best_swap], new_solution[worst_edge]\n\n    return new_solution\n\n",
        "score": [
            6.376746310326254,
            5.561677280256628
        ]
    }
]