[
    {
        "algorithm": "The algorithm selects a random solution from an archive, applies a hybrid 3-opt move to it, and then has a 50% chance to perform a novel edge-swap between two non-adjacent edges while ensuring the tour remains valid. The method prioritizes diversity by combining standard 3-opt with a custom edge-swap heuristic to explore the solution space more effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    selected_idx = np.random.choice(len(archive))\n    selected_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: Combine 3-opt with a novel edge-swap strategy\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Randomly select three distinct edges to modify\n    a, b, c = np.random.choice(n, size=3, replace=False)\n    a, b, c = sorted([a, b, c])\n\n    # Perform a 3-opt move (swap edges)\n    new_solution[a:b] = selected_solution[a:b][::-1]\n    new_solution[b:c] = selected_solution[b:c][::-1]\n\n    # Novel edge-swap: Swap two edges that cross in one space but are non-crossing in the other\n    if np.random.rand() < 0.5:  # 50% chance to apply the novel operator\n        i, j = np.random.choice(n, size=2, replace=False)\n        if i > j:\n            i, j = j, i\n        # Check if swapping these edges would create a valid tour\n        if not (i == 0 and j == n-1):  # Avoid swapping the first and last edges\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure the solution is valid (no duplicates)\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()  # Revert if invalid\n\n    return new_solution\n\n",
        "score": [
            -0.925254721365585,
            0.20645654201507568
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive with high potential for improvement (highest sum of normalized objective values) and applies a hybrid local search combining partial tour reversal and a constrained edge swap, ensuring feasibility by validating the tour structure and avoiding node duplicates. The edge swap is conditioned on improving both objectives, with a small randomness factor to escape local optima. The solution prioritizes exploration of promising regions while maintaining validity, moving beyond standard operators to balance exploitation and exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    normalized = objectives / max_obj\n    selected_idx = np.argmax(np.sum(normalized, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Partial tour reversal (explore a segment of the tour)\n    a, b = np.random.choice(n, size=2, replace=False)\n    a, b = sorted([a, b])\n    new_solution[a:b] = new_solution[a:b][::-1]\n\n    # Constrained edge swap: swap edges only if it improves both objectives\n    i, j = np.random.choice(n, size=2, replace=False)\n    if i > j:\n        i, j = j, i\n\n    # Check if swapping edges i and j improves both objectives\n    def calculate_cost(sol, dist_mat):\n        cost = 0\n        for k in range(n):\n            cost += dist_mat[sol[k], sol[(k+1)%n]]\n        return cost\n\n    current_cost1 = calculate_cost(new_solution, distance_matrix_1)\n    current_cost2 = calculate_cost(new_solution, distance_matrix_2)\n\n    temp_solution = new_solution.copy()\n    temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n\n    new_cost1 = calculate_cost(temp_solution, distance_matrix_1)\n    new_cost2 = calculate_cost(temp_solution, distance_matrix_2)\n\n    if (new_cost1 < current_cost1 and new_cost2 < current_cost2) or np.random.rand() < 0.2:  # Allow some randomness\n        new_solution = temp_solution\n\n    # Ensure the solution is valid (no duplicates)\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.9481146534985749,
            0.2827843427658081
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive with the highest variance in objectives (indicating diverse exploration potential) and applies a hybrid local search combining edge reversal and segment inversion, ensuring feasibility by validating node uniqueness and tour continuity. The method prioritizes solutions with high objective disparities and uses randomized segment reversals to explore the solution space while maintaining TSP feasibility. The key design ideas are: (1) objective diversity-based selection and (2) a hybrid local search operator that combines edge reversal and segment inversion.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high variance in objectives (diverse exploration potential)\n    variances = [abs(obj[0] - obj[1]) for _, obj in archive]\n    selected_idx = np.argmax(variances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Hybrid local search: combine edge reversal and segment inversion\n    a = np.random.randint(0, n)\n    b = np.random.randint(0, n)\n    while b == a:\n        b = np.random.randint(0, n)\n    start, end = min(a, b), max(a, b)\n\n    # Edge reversal between start and end\n    temp = new_solution.copy()\n    temp[start:end+1] = temp[start:end+1][::-1]\n\n    # Segment inversion (reverse a random segment)\n    c = np.random.randint(0, n)\n    d = np.random.randint(0, n)\n    while d == c:\n        d = np.random.randint(0, n)\n    seg_start, seg_end = min(c, d), max(c, d)\n    temp[seg_start:seg_end+1] = temp[seg_start:seg_end+1][::-1]\n\n    # Ensure the solution remains valid (no duplicates)\n    if len(np.unique(temp)) == n:\n        new_solution = temp\n\n    return new_solution\n\n",
        "score": [
            -0.5451367216570713,
            0.20511656999588013
        ]
    },
    {
        "algorithm": "The algorithm intelligently selects promising solutions from the archive by prioritizing those with balanced objective improvement potential, then applies a dynamic hybrid local search that adaptively switches between partial tour reversal and constrained node relocation based on objective dominance, ensuring feasibility through rigorous validation and incorporating small randomness to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Intelligent selection: prioritize solutions with balanced objective improvement potential\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    normalized = objectives / max_obj\n    dominance = np.prod(normalized, axis=1)  # Product of normalized objectives\n    selected_idx = np.argmax(dominance)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Dynamic hybrid local search\n    def calculate_cost(sol, dist_mat):\n        cost = 0\n        for k in range(n):\n            cost += dist_mat[sol[k], sol[(k+1)%n]]\n        return cost\n\n    current_cost1 = calculate_cost(new_solution, distance_matrix_1)\n    current_cost2 = calculate_cost(new_solution, distance_matrix_2)\n\n    # Determine operator based on objective dominance\n    if current_cost1 > current_cost2:\n        # Prioritize reversal for dominant objective\n        a, b = np.random.choice(n, size=2, replace=False)\n        a, b = sorted([a, b])\n        new_solution[a:b] = new_solution[a:b][::-1]\n    else:\n        # Prioritize node relocation for balanced improvement\n        k = np.random.randint(0, n)\n        l = np.random.randint(0, n)\n        while l == k or l == (k + 1) % n:\n            l = np.random.randint(0, n)\n        node = new_solution[k]\n        new_solution = np.delete(new_solution, k)\n        new_solution = np.insert(new_solution, l, node)\n\n    # Validate feasibility and objective improvement\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n    else:\n        new_cost1 = calculate_cost(new_solution, distance_matrix_1)\n        new_cost2 = calculate_cost(new_solution, distance_matrix_2)\n        if (new_cost1 >= current_cost1 and new_cost2 >= current_cost2) and np.random.rand() < 0.3:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.94438110626965,
            0.2759231925010681
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from an archive using a weighted combination of objective values and structural diversity, then applies a hybrid local search combining partial tour reversal with probabilistic node relocation to generate a neighbor solution while ensuring feasibility. The selection prioritizes solutions with balanced objectives and high diversity, while the local search adaptively adjusts segment sizes and relocation probabilities based on distance matrices to explore the solution space effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Selection strategy: combine objective diversity and structural diversity\n    objectives = np.array([obj for _, obj in archive])\n    norm_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n\n    # Calculate diversity score (distance to other solutions in objective space)\n    diversity_scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        other_objectives = np.delete(norm_objectives, i, axis=0)\n        diversity_scores[i] = np.mean(np.linalg.norm(norm_objectives[i] - other_objectives, axis=1))\n\n    # Combine objective and diversity scores\n    selection_weights = np.exp(-norm_objectives[:, 0] - norm_objectives[:, 1] + 0.5 * diversity_scores)\n    selection_weights /= selection_weights.sum()\n\n    selected_idx = np.random.choice(len(archive), p=selection_weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Novel hybrid local search\n    # Step 1: Partial tour reversal with adaptive segment size\n    segment_size = min(3, max(1, int(np.random.normal(n/4, n/8))))\n    start = np.random.randint(0, n - segment_size)\n    end = start + segment_size\n    new_solution[start:end+1] = new_solution[start:end+1][::-1]\n\n    # Step 2: Probabilistic node relocation based on distance matrices\n    for _ in range(2):\n        k = np.random.randint(0, n)\n        node = new_solution[k]\n\n        # Calculate relocation probabilities based on distance matrices\n        current_dist = (distance_matrix_1[new_solution[k-1], node] + distance_matrix_1[node, new_solution[(k+1)%n]] +\n                        distance_matrix_2[new_solution[k-1], node] + distance_matrix_2[node, new_solution[(k+1)%n]])\n\n        probs = np.zeros(n)\n        for l in range(n):\n            if l == k or l == (k-1)%n or l == (k+1)%n:\n                continue\n            new_dist = (distance_matrix_1[new_solution[(l-1)%n], node] + distance_matrix_1[node, new_solution[l]] +\n                        distance_matrix_2[new_solution[(l-1)%n], node] + distance_matrix_2[node, new_solution[l]])\n            probs[l] = np.exp(-(new_dist - current_dist) / (current_dist + 1e-8))\n\n        probs /= probs.sum()\n        l = np.random.choice(n, p=probs)\n\n        if l != k and l != (k-1)%n and l != (k+1)%n:\n            new_solution = np.delete(new_solution, k)\n            new_solution = np.insert(new_solution, l, node)\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.9756411093506061,
            0.6009257435798645
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the archive using Pareto-aware crowding distance, then applies a hybrid local search that alternates between distance-aware edge relocations and segment reversals based on the structural imbalance between the two objective spaces, ensuring feasibility by validating tour connectivity and node uniqueness. The operator selection prioritizes edge relocations for imbalanced solutions and segment reversals for balanced ones, with the imbalance ratio determining the approach.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if len(archive) == 0:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-aware selection: choose solutions with high objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    crowding_dist = np.zeros(len(archive))\n    for i in range(2):  # For each objective\n        sorted_idx = np.argsort(objectives[:, i])\n        crowding_dist[sorted_idx[0]] = np.inf\n        crowding_dist[sorted_idx[-1]] = np.inf\n        for j in range(1, len(archive)-1):\n            crowding_dist[sorted_idx[j]] += (objectives[sorted_idx[j+1], i] - objectives[sorted_idx[j-1], i])\n\n    # Select solutions with high crowding distance\n    top_indices = np.argsort(crowding_dist)[-max(1, len(archive) // 3):]\n    selected_idx = np.random.choice(top_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Calculate structural imbalance in both objective spaces\n    def calculate_imbalance(solution, distance_matrix):\n        total_length = 0\n        for i in range(n):\n            total_length += distance_matrix[solution[i], solution[(i+1)%n]]\n        return total_length\n\n    imbalance_1 = calculate_imbalance(new_solution, distance_matrix_1)\n    imbalance_2 = calculate_imbalance(new_solution, distance_matrix_2)\n    imbalance_ratio = abs(imbalance_1 - imbalance_2) / (imbalance_1 + imbalance_2 + 1e-8)\n\n    # Hybrid local search: alternate between operators based on imbalance\n    if imbalance_ratio > 0.3:  # If significant imbalance, prioritize distance-aware relocation\n        # Distance-aware edge relocation\n        if n > 3:\n            i = np.random.randint(0, n)\n            j = np.random.randint(0, n)\n            if i != j and (i != 0 or j != n-1):  # Avoid first/last edge\n                # Calculate potential improvement in both objectives\n                old_dist1 = distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]]\n                old_dist2 = distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]\n\n                # Swap edges\n                temp = new_solution[i]\n                new_solution[i] = new_solution[j]\n                new_solution[j] = temp\n\n                new_dist1 = distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]]\n                new_dist2 = distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]\n\n                # Revert if worse in both objectives\n                if new_dist1 > old_dist1 and new_dist2 > old_dist2:\n                    new_solution[j] = new_solution[i]\n                    new_solution[i] = temp\n    else:  # If balanced, prioritize segment reversal\n        if n > 3:\n            a, b = sorted(np.random.choice(n, 2, replace=False))\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Ensure feasibility\n    assert len(new_solution) == len(base_solution), \"Invalid neighbor: length mismatch\"\n    assert len(np.unique(new_solution)) == len(base_solution), \"Invalid neighbor: duplicate nodes\"\n\n    return new_solution\n\n",
        "score": [
            -0.9547265839760125,
            0.369709849357605
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution from the archive with high potential for improvement (highest sum of normalized objectives)\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    normalized = objectives / max_obj\n    selected_idx = np.argmax(np.sum(normalized, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Calculate node importance based on both objectives\n    def node_importance(node_idx):\n        contrib1 = distance_matrix_1[node_idx, base_solution[(node_idx-1)%n]] + distance_matrix_1[node_idx, base_solution[(node_idx+1)%n]]\n        contrib2 = distance_matrix_2[node_idx, base_solution[(node_idx-1)%n]] + distance_matrix_2[node_idx, base_solution[(node_idx+1)%n]]\n        return contrib1 + contrib2\n\n    importance = [node_importance(i) for i in range(n)]\n    sorted_nodes = np.argsort(importance)[::-1]\n\n    # Hybrid local search combining cross-dimensional node relocation and adaptive edge swap\n    for i in range(min(3, n//2)):\n        node = sorted_nodes[i]\n        best_pos = -1\n        min_cost = float('inf')\n\n        for pos in range(n):\n            if pos == node or pos == (node-1)%n or pos == (node+1)%n:\n                continue\n\n            temp_sol = new_solution.copy()\n            temp_sol = np.delete(temp_sol, node)\n            temp_sol = np.insert(temp_sol, pos, base_solution[node])\n\n            cost1 = sum(distance_matrix_1[temp_sol[k], temp_sol[(k+1)%n]] for k in range(n))\n            cost2 = sum(distance_matrix_2[temp_sol[k], temp_sol[(k+1)%n]] for k in range(n))\n            total_cost = cost1 + cost2\n\n            if total_cost < min_cost:\n                min_cost = total_cost\n                best_pos = pos\n\n        if best_pos != -1:\n            new_solution = np.delete(new_solution, best_pos)\n            new_solution = np.insert(new_solution, best_pos, base_solution[node])\n\n    # Adaptive edge swap with multi-objective validation\n    for _ in range(2):\n        i, j = np.random.choice(n, size=2, replace=False)\n        if i > j:\n            i, j = j, i\n\n        temp_solution = new_solution.copy()\n        temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n\n        cost1_new = sum(distance_matrix_1[temp_solution[k], temp_solution[(k+1)%n]] for k in range(n))\n        cost2_new = sum(distance_matrix_2[temp_solution[k], temp_solution[(k+1)%n]] for k in range(n))\n        cost1_old = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n        cost2_old = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n\n        if (cost1_new <= cost1_old and cost2_new <= cost2_old) or np.random.rand() < 0.15:\n            new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.9868076364651988,
            2.0267587304115295
        ]
    },
    {
        "algorithm": "The algorithm selects high-diversity solutions from the archive, prioritizes nodes with high importance in both objectives for relocation, and uses adaptive edge swaps to generate neighbors while ensuring feasibility. It balances exploration/exploitation through dynamic probabilities and thresholds, favoring moves that improve both objectives while maintaining tour validity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high objective diversity and low dominance rank\n    objectives = np.array([obj for _, obj in archive])\n    variance = np.var(objectives, axis=0)\n    diversity = np.sum(variance)\n    threshold = np.mean(variance) * 0.5\n    candidates = [i for i in range(len(archive)) if np.sum(variance) > threshold]\n\n    if not candidates:\n        selected_idx = np.random.choice(len(archive))\n    else:\n        selected_idx = np.argmax([np.sum(objectives[i]) for i in candidates])\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Calculate node importance for both objectives\n    def node_importance(node_idx):\n        contrib1 = (distance_matrix_1[node_idx, base_solution[(node_idx-1)%n]] +\n                     distance_matrix_1[node_idx, base_solution[(node_idx+1)%n]])\n        contrib2 = (distance_matrix_2[node_idx, base_solution[(node_idx-1)%n]] +\n                     distance_matrix_2[node_idx, base_solution[(node_idx+1)%n]])\n        return contrib1 + contrib2\n\n    importance = [node_importance(i) for i in range(n)]\n    sorted_nodes = np.argsort(importance)[::-1]\n\n    # Cross-dimensional node relocation with adaptive probability\n    for i in range(min(3, n//2)):\n        node = sorted_nodes[i]\n        prob = 0.5 + 0.5 * (importance[node] / max(importance))\n        if np.random.rand() > prob:\n            continue\n\n        best_pos = -1\n        min_cost = float('inf')\n\n        for pos in range(n):\n            if pos == node or pos == (node-1)%n or pos == (node+1)%n:\n                continue\n\n            temp_sol = new_solution.copy()\n            temp_sol = np.delete(temp_sol, node)\n            temp_sol = np.insert(temp_sol, pos, base_solution[node])\n\n            cost1 = sum(distance_matrix_1[temp_sol[k], temp_sol[(k+1)%n]] for k in range(n))\n            cost2 = sum(distance_matrix_2[temp_sol[k], temp_sol[(k+1)%n]] for k in range(n))\n            total_cost = cost1 + cost2\n\n            if total_cost < min_cost:\n                min_cost = total_cost\n                best_pos = pos\n\n        if best_pos != -1:\n            new_solution = np.delete(new_solution, best_pos)\n            new_solution = np.insert(new_solution, best_pos, base_solution[node])\n\n    # Adaptive edge swap with multi-objective validation\n    for _ in range(2):\n        i, j = np.random.choice(n, size=2, replace=False)\n        if i > j:\n            i, j = j, i\n\n        temp_solution = new_solution.copy()\n        temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n\n        cost1_new = sum(distance_matrix_1[temp_solution[k], temp_solution[(k+1)%n]] for k in range(n))\n        cost2_new = sum(distance_matrix_2[temp_solution[k], temp_solution[(k+1)%n]] for k in range(n))\n        cost1_old = sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n        cost2_old = sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n\n        threshold = 0.1 + 0.2 * (np.sum(objectives[selected_idx]) / np.sum(np.max(objectives, axis=0)))\n        if ((cost1_new <= cost1_old and cost2_new <= cost2_old) or\n            (np.random.rand() < threshold and (cost1_new <= cost1_old or cost2_new <= cost2_old))):\n            new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.9616758531127807,
            2.6132646203041077
        ]
    },
    {
        "algorithm": "The heuristic selects a solution from the archive prioritizing those with higher combined objective values (sum of costs), then applies a hybrid local search combining edge insertion and node relocation to explore diverse neighborhoods while ensuring feasibility. It randomly selects nodes to swap and relocate, validating the new solution to avoid duplicates, and returns the improved neighbor. The algorithm balances exploration (random selection) and exploitation (local search) while maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., highest crowding distance or Pareto dominance)\n    selected_idx = np.argmax([sum(obj) for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine edge insertion and node relocation\n    n = len(base_solution)\n    if n < 4:\n        return new_solution  # No improvement possible for small instances\n\n    # Step 1: Edge insertion (insert a node between two existing edges)\n    i = np.random.randint(0, n)\n    j = np.random.randint(0, n)\n    while j == i or j == (i + 1) % n:\n        j = np.random.randint(0, n)\n\n    # Ensure the insertion is valid (avoid revisiting nodes)\n    temp = new_solution.copy()\n    temp[i], temp[j] = temp[j], temp[i]\n\n    # Step 2: Node relocation (move a node to a new position)\n    k = np.random.randint(0, n)\n    while k == i or k == j:\n        k = np.random.randint(0, n)\n\n    temp[i], temp[k] = temp[k], temp[i]\n\n    # Ensure the solution remains valid (no duplicates)\n    if len(np.unique(temp)) == n:\n        new_solution = temp\n\n    return new_solution\n\n",
        "score": [
            -0.9020578250800095,
            0.21142607927322388
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Selection strategy: prioritize structurally balanced and nondominated solutions\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Calculate structural balance (low variance in segment lengths)\n    segment_vars = []\n    for sol in solutions:\n        segments = []\n        for i in range(len(sol)):\n            segments.append(distance_matrix_1[sol[i-1], sol[i]] + distance_matrix_2[sol[i-1], sol[i]])\n        segment_vars.append(np.var(segments))\n\n    # Identify nondominated solutions\n    is_dominated = np.zeros(len(archive), dtype=bool)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and not (objectives[j, 0] == objectives[i, 0] and objectives[j, 1] == objectives[i, 1]):\n                is_dominated[i] = True\n                break\n\n    # Combine structural balance and nondominated status\n    scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        if not is_dominated[i]:\n            scores[i] = 1 / (1 + segment_vars[i])\n\n    if np.sum(scores) == 0:\n        selected_idx = np.random.randint(0, len(archive))\n    else:\n        selected_idx = np.random.choice(len(archive), p=scores/scores.sum())\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive operator selection\n    if np.random.random() < 0.5:\n        # Segment-based reversal\n        segment_size = min(4, max(2, int(np.random.normal(n/5, n/10))))\n        start = np.random.randint(0, n - segment_size)\n        end = start + segment_size\n        new_solution[start:end+1] = new_solution[start:end+1][::-1]\n    else:\n        # Distance-aware node relocation\n        k = np.random.randint(0, n)\n        node = new_solution[k]\n\n        # Calculate relocation probabilities\n        current_dist = (distance_matrix_1[new_solution[k-1], node] + distance_matrix_1[node, new_solution[(k+1)%n]] +\n                        distance_matrix_2[new_solution[k-1], node] + distance_matrix_2[node, new_solution[(k+1)%n]])\n\n        probs = np.zeros(n)\n        for l in range(n):\n            if l == k or l == (k-1)%n or l == (k+1)%n:\n                continue\n            new_dist = (distance_matrix_1[new_solution[(l-1)%n], node] + distance_matrix_1[node, new_solution[l]] +\n                        distance_matrix_2[new_solution[(l-1)%n], node] + distance_matrix_2[node, new_solution[l]])\n            probs[l] = np.exp(-(new_dist - current_dist) / (current_dist + 1e-8))\n\n        probs /= probs.sum()\n        l = np.random.choice(n, p=probs)\n\n        if l != k and l != (k-1)%n and l != (k+1)%n:\n            new_solution = np.delete(new_solution, k)\n            new_solution = np.insert(new_solution, l, node)\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.9493323547445034,
            1.0181962251663208
        ]
    }
]