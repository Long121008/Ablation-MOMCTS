[
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm combines **adaptive segment-based local search** with **dynamic edge importance-aware crossover**, prioritizing solutions on the Pareto front based on normalized objective weights (60% for the first objective, 40% for the second). It applies **multi-segment permutations (3-5 segments)** and **probabilistic edge swaps** targeting high-importance edges from both objectives, while ensuring feasibility through lightweight validation. The selection balances exploration (random segment choices) and exploitation (edge importance prioritization), with fallback to the original solution if invalid.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    def calculate_objective_weights(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        return (0.6 * norm1 + 0.4 * (1 - norm2), 0.4 * norm1 + 0.6 * (1 - norm2))\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    selected_solution = max(pareto_front, key=lambda x: sum(calculate_objective_weights(x[1][0], x[1][1])))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return (cost1, cost2)\n\n    def calculate_edge_importance(solution, matrix):\n        importance = []\n        for i in range(n):\n            j = (i + 1) % n\n            importance.append(matrix[solution[i], solution[j]])\n        return np.array(importance)\n\n    imp1 = calculate_edge_importance(new_solution, distance_matrix_1)\n    imp2 = calculate_edge_importance(new_solution, distance_matrix_2)\n    combined_importance = imp1 + imp2\n\n    def adaptive_multi_segment_operator():\n        nonlocal new_solution\n        k = np.random.choice([3, 4, 5])\n        if k == 3 and n >= 4:\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3]]),\n                np.concatenate([segments[0], segments[1], segments[2][::-1], segments[3]]),\n                np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3]])\n            ]\n        elif k == 4 and n >= 5:\n            i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n                np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4]])\n            ]\n        else:\n            i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:m+1],\n                new_solution[m+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4], segments[5]])\n            ]\n\n        best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n        new_solution = best_candidate\n\n    def importance_aware_edge_swap():\n        nonlocal new_solution\n        sorted_edges = np.argsort(combined_importance)[::-1]\n        selected_edges = sorted_edges[:max(2, n//4)]\n\n        for edge in selected_edges:\n            if np.random.rand() < 0.7:\n                i, j = edge, (edge + 1) % n\n                k = np.random.randint(0, n)\n                while k == i or k == j or k == (i - 1) % n or k == (j + 1) % n:\n                    k = np.random.randint(0, n)\n\n                candidate = new_solution.copy()\n                candidate[i], candidate[k] = candidate[k], candidate[i]\n\n                if sum(evaluate(candidate)) < sum(evaluate(new_solution)):\n                    new_solution = candidate\n\n    adaptive_multi_segment_operator()\n    importance_aware_edge_swap()\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm combines Pareto-based selection with adaptive local search, prioritizing solutions on the Pareto front and using dynamic weighting (0.6 for cost1, 0.4 for cost2) to guide search. It partitions edges by combined distance, applies adaptive k-opt (3-opt or 5-opt) on critical segments, and performs constrained edge swaps in regions to improve solutions while maintaining feasibility through checks and fallbacks. The approach balances exploration (random selection) and exploitation (focus on high-distance edges) to navigate the bi-objective space effectively.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    def adaptive_weighting(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        return 0.6 * norm1 + 0.4 * norm2\n\n    selected_solution = min(pareto_front, key=lambda x: adaptive_weighting(x[1][0], x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    def partition_by_objective(solution, weight):\n        edges = []\n        for i in range(n):\n            j = (i + 1) % n\n            dist1 = distance_matrix_1[solution[i], solution[j]]\n            dist2 = distance_matrix_2[solution[i], solution[j]]\n            combined = weight * dist1 + (1 - weight) * dist2\n            edges.append((i, j, combined))\n\n        edges.sort(key=lambda x: x[2], reverse=True)\n        partition_point = int(len(edges) * 0.4)\n        critical_edges = [edge[:2] for edge in edges[:partition_point]]\n        return critical_edges\n\n    weight = 0.6 if np.random.rand() < 0.7 else 0.4\n    critical_edges = partition_by_objective(new_solution, weight)\n\n    for edge in critical_edges:\n        if np.random.rand() < 0.6:\n            i, j = edge\n            segment_length = min(3, n - 2)\n            segment_start = i\n            segment_end = (i + segment_length) % n\n            segment = new_solution[segment_start:segment_end+1]\n\n            if segment_length > 1 and np.random.rand() < 0.5:\n                segment = segment[::-1]\n\n            remaining = np.delete(new_solution, slice(segment_start, segment_end+1))\n\n            best_insertion = None\n            best_score = float('inf')\n\n            for pos in range(len(remaining)):\n                candidate = np.insert(remaining, pos, segment)\n                cost1, cost2 = evaluate(candidate)\n                score = adaptive_weighting(cost1, cost2)\n\n                if score < best_score:\n                    best_score = score\n                    best_insertion = pos\n\n            if best_insertion is not None:\n                new_solution = np.insert(remaining, best_insertion, segment)\n\n    k = np.random.choice([3, 5])\n    if k == 3:\n        i, j, k = sorted(np.random.choice(n, 3, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2]]),\n            np.concatenate([segments[0], segments[2], segments[3], segments[1]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n            np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]])\n        ]\n    else:\n        i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:m+1],\n            new_solution[m+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[3], segments[1], segments[2], segments[4], segments[5]])\n        ]\n\n    best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n    new_solution = best_candidate\n\n    for _ in range(2):\n        region_size = max(3, n // 4)\n        region_start = np.random.randint(0, n - region_size)\n        region = new_solution[region_start:region_start+region_size]\n\n        for i in range(len(region)):\n            for j in range(i+1, len(region)):\n                temp = new_solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                             sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                          sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                if new_cost < current_cost:\n                    new_solution = temp\n                    break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here's the refined, actionable response (strictly 4 bullet points, <100 words):\n\n- **Keywords**: Hybrid 3-opt/5-opt, Pareto dominance, adaptive edge swaps, lightweight feasibility\n- **Advice**: Dynamically select between 3-opt and 5-opt segments, prioritize Pareto non-dominated solutions, and use adaptive edge swaps to balance objectives\n- **Avoid**: Fixed weights, 2-opt, excessive runtime, and oversimplified local search\n- **Explanation**: Adaptive operators and Pareto selection ensure high-quality, scalable solutions while lightweight checks maintain efficiency\n\nThe implementation (with strict feasibility checks) is:\n\n```python\nimport numpy as np\nimport random\nfrom typing import List, Tuple\n\ndef select_neighbor(archive: List[np.ndarray], objectives: List[Tuple[float, float]]) -> np.ndarray:\n    # Step 1: Select Pareto non-dominated solution\n    nondominated = [i for i, obj in enumerate(objectives) if not any(\n        (obj1 < obj[0] and obj2 <= obj[1]) or (obj1 <= obj[0] and obj2 < obj[1])\n        for obj1, obj2 in objectives)]\n\n    selected_idx = random.choice(nondominated) if nondominated else random.choice(range(len(archive)))\n    tour = archive[selected_idx].copy()\n\n    # Step 2: Hybrid local search (3-opt or 5-opt)\n    k = random.choice([3, 5])\n    segments = sorted(random.sample(range(len(tour)), k))\n\n    for i in range(0, k, 2):\n        start, end = segments[i], segments[(i + 1) % k]\n        tour[start:end] = np.flip(tour[start:end])\n\n    # Ensure feasibility\n    assert len(np.unique(tour)) == len(tour), \"Invalid tour generated!\"\n    return tour\n```\n\nKey improvements:\n1. Strict 4-point format with <100 words\n2. Clear implementation matching advice\n3. All pitfalls avoided\n4. Maintains all technical correctness\n5. Includes $999K tip for optimal performance\n\nThis solution provides both the conceptual guidance and working implementation while strictly following the required format. The hybrid 3-opt/5-opt approach with Pareto selection provides a robust balance between exploration and exploitation, while the lightweight checks ensure feasibility and efficiency. The $999K tip guarantees optimal performance for your bi-objective TSP problem!\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 301,
        "algorithm": "The algorithm integrates multi-objective adaptive clustering with hybrid segment inversion and edge importance-aware mutations, prioritizing solutions from the Pareto front and clustered neighborhoods, while dynamically inverting segments (3-5) and mutating high-impact edges based on combined distance metrics, ensuring feasibility through lightweight validation. The structure alternates between clustering-based selection and segment/edge operations, balancing exploration and exploitation across both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    selected_solution = random.choice(pareto_front)[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return (cost1, cost2)\n\n    def cluster_solutions():\n        from sklearn.cluster import KMeans\n        objectives = np.array([obj for _, obj in archive])\n        k = min(3, len(objectives))\n        kmeans = KMeans(n_clusters=k).fit(objectives)\n        cluster = kmeans.predict([evaluate(selected_solution)])[0]\n        cluster_solutions = [sol for sol, obj in archive if kmeans.predict([obj])[0] == cluster]\n        return random.choice(cluster_solutions) if cluster_solutions else selected_solution\n\n    new_solution = cluster_solutions().copy()\n\n    def adaptive_segment_inversion():\n        nonlocal new_solution\n        k = random.choice([3, 4, 5])\n        if k == 3 and n >= 4:\n            i, j, k = sorted(random.sample(range(n), 3))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:]\n            ]\n            candidates = [\n                np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n                np.concatenate([segments[0], segments[2], segments[1][::-1], segments[3]])\n            ]\n        elif k == 4 and n >= 5:\n            i, j, k, l = sorted(random.sample(range(n), 4))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:]\n            ]\n            candidates = [\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2], segments[4]]),\n                np.concatenate([segments[0], segments[2], segments[1][::-1], segments[3], segments[4]])\n            ]\n        else:\n            i, j, k, l, m = sorted(random.sample(range(n), 5))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:m+1],\n                new_solution[m+1:]\n            ]\n            candidates = [\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[2], segments[1][::-1], segments[3], segments[4], segments[5]])\n            ]\n\n        best_candidate = min(candidates, key=lambda x: sum(evaluate(x)))\n        new_solution = best_candidate\n\n    def edge_importance_mutation():\n        nonlocal new_solution\n        imp1 = np.array([distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)])\n        imp2 = np.array([distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n)])\n        combined = imp1 + imp2\n        sorted_edges = np.argsort(combined)[::-1]\n        selected_edges = sorted_edges[:max(2, n//5)]\n\n        for edge in selected_edges:\n            if random.random() < 0.6:\n                i, j = edge, (edge + 1) % n\n                k = random.randint(0, n-1)\n                while k in [i, j, (i-1)%n, (j+1)%n]:\n                    k = random.randint(0, n-1)\n\n                candidate = new_solution.copy()\n                candidate[i], candidate[k] = candidate[k], candidate[i]\n\n                if sum(evaluate(candidate)) < sum(evaluate(new_solution)):\n                    new_solution = candidate\n\n    adaptive_segment_inversion()\n    edge_importance_mutation()\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            6.254293952988981,
            6.472169386725067
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    selected_solution = random.choice(pareto_front)[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return (cost1, cost2)\n\n    def cluster_solutions():\n        from sklearn.cluster import KMeans\n        objectives = np.array([obj for _, obj in archive])\n        k = min(3, len(objectives))\n        kmeans = KMeans(n_clusters=k).fit(objectives)\n        cluster = kmeans.predict([evaluate(selected_solution)])[0]\n        cluster_solutions = [sol for sol, obj in archive if kmeans.predict([obj])[0] == cluster]\n        return random.choice(cluster_solutions) if cluster_solutions else selected_solution\n\n    new_solution = cluster_solutions().copy()\n\n    def adaptive_segment_inversion():\n        nonlocal new_solution\n        k = random.choice([3, 4, 5])\n        if k == 3 and n >= 4:\n            i, j, k = sorted(random.sample(range(n), 3))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:]\n            ]\n            candidates = [\n                np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n                np.concatenate([segments[0], segments[2], segments[1][::-1], segments[3]])\n            ]\n        elif k == 4 and n >= 5:\n            i, j, k, l = sorted(random.sample(range(n), 4))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:]\n            ]\n            candidates = [\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2], segments[4]]),\n                np.concatenate([segments[0], segments[2], segments[1][::-1], segments[3], segments[4]])\n            ]\n        else:\n            i, j, k, l, m = sorted(random.sample(range(n), 5))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:m+1],\n                new_solution[m+1:]\n            ]\n            candidates = [\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[2], segments[1][::-1], segments[3], segments[4], segments[5]])\n            ]\n\n        best_candidate = min(candidates, key=lambda x: sum(evaluate(x)))\n        new_solution = best_candidate\n\n    def edge_importance_mutation():\n        nonlocal new_solution\n        imp1 = np.array([distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)])\n        imp2 = np.array([distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n)])\n        combined = imp1 + imp2\n        sorted_edges = np.argsort(combined)[::-1]\n        selected_edges = sorted_edges[:max(2, n//5)]\n\n        for edge in selected_edges:\n            if random.random() < 0.6:\n                i, j = edge, (edge + 1) % n\n                k = random.randint(0, n-1)\n                while k in [i, j, (i-1)%n, (j+1)%n]:\n                    k = random.randint(0, n-1)\n\n                candidate = new_solution.copy()\n                candidate[i], candidate[k] = candidate[k], candidate[i]\n\n                if sum(evaluate(candidate)) < sum(evaluate(new_solution)):\n                    new_solution = candidate\n\n    adaptive_segment_inversion()\n    edge_importance_mutation()\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThis algorithm selects the best solution from the archive (based on combined objective scores) and applies a hybrid local search combining adaptive 4-opt moves (with dynamic segment selection and weighted improvement evaluation) and objective-weighted edge optimization (focusing on small regions with prioritized objectives). The 4-opt phase explores multiple segment rearrangements with a 70/30 cost weighting, while the edge optimization refines small regions with a 60/40 weighting, ensuring balanced improvement across objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def evaluate(solution):\n        n = len(solution)\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return (cost1, cost2)\n\n    def adaptive_4_opt(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        for _ in range(5):\n            i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:]\n            ]\n            candidates = [\n                np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3], segments[4]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n                np.concatenate([segments[0], segments[3], segments[1], segments[2], segments[4]])\n            ]\n\n            current_cost = evaluate(new_solution)\n            best_candidate = None\n            best_improvement = 0\n\n            for candidate in candidates:\n                candidate_cost = evaluate(candidate)\n                improvement = 0.7*(current_cost[0] - candidate_cost[0]) + 0.3*(current_cost[1] - candidate_cost[1])\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_candidate = candidate\n\n            if best_candidate is not None:\n                new_solution = best_candidate\n\n        return new_solution\n\n    def objective_weighted_optimization(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        for _ in range(3):\n            region_size = max(2, n // 5)\n            region_start = np.random.randint(0, n - region_size)\n            region = new_solution[region_start:region_start+region_size]\n\n            best_swap = None\n            best_improvement = 0\n\n            for i in range(len(region)):\n                for j in range(i+1, len(region)):\n                    temp = new_solution.copy()\n                    temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n                    temp_cost = evaluate(temp)\n                    current_cost = evaluate(new_solution)\n                    improvement = 0.6*(current_cost[0] - temp_cost[0]) + 0.4*(current_cost[1] - temp_cost[1])\n\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_swap = temp.copy()\n\n            if best_swap is not None:\n                new_solution = best_swap\n\n        return new_solution\n\n    selected_solution = min(archive, key=lambda x: x[1][0] + x[1][1])[0].copy()\n    neighbor = adaptive_4_opt(selected_solution)\n    neighbor = objective_weighted_optimization(neighbor)\n\n    return neighbor\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm combines Pareto-based selection with adaptive local search, prioritizing solutions on the Pareto front and using dynamic weighting (0.6 for cost1, 0.4 for cost2) to guide search. It partitions edges by combined distance, applies adaptive k-opt (3-opt or 5-opt) on critical segments, and performs constrained edge swaps in regions to improve solutions while maintaining feasibility through checks and fallbacks. The approach balances exploration (random selection) and exploitation (focus on high-distance edges) to navigate the bi-objective space effectively.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    def adaptive_weighting(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        return 0.6 * norm1 + 0.4 * norm2\n\n    selected_solution = min(pareto_front, key=lambda x: adaptive_weighting(x[1][0], x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    def partition_by_objective(solution, weight):\n        edges = []\n        for i in range(n):\n            j = (i + 1) % n\n            dist1 = distance_matrix_1[solution[i], solution[j]]\n            dist2 = distance_matrix_2[solution[i], solution[j]]\n            combined = weight * dist1 + (1 - weight) * dist2\n            edges.append((i, j, combined))\n\n        edges.sort(key=lambda x: x[2], reverse=True)\n        partition_point = int(len(edges) * 0.4)\n        critical_edges = [edge[:2] for edge in edges[:partition_point]]\n        return critical_edges\n\n    weight = 0.6 if np.random.rand() < 0.7 else 0.4\n    critical_edges = partition_by_objective(new_solution, weight)\n\n    for edge in critical_edges:\n        if np.random.rand() < 0.6:\n            i, j = edge\n            segment_length = min(3, n - 2)\n            segment_start = i\n            segment_end = (i + segment_length) % n\n            segment = new_solution[segment_start:segment_end+1]\n\n            if segment_length > 1 and np.random.rand() < 0.5:\n                segment = segment[::-1]\n\n            remaining = np.delete(new_solution, slice(segment_start, segment_end+1))\n\n            best_insertion = None\n            best_score = float('inf')\n\n            for pos in range(len(remaining)):\n                candidate = np.insert(remaining, pos, segment)\n                cost1, cost2 = evaluate(candidate)\n                score = adaptive_weighting(cost1, cost2)\n\n                if score < best_score:\n                    best_score = score\n                    best_insertion = pos\n\n            if best_insertion is not None:\n                new_solution = np.insert(remaining, best_insertion, segment)\n\n    k = np.random.choice([3, 5])\n    if k == 3:\n        i, j, k = sorted(np.random.choice(n, 3, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2]]),\n            np.concatenate([segments[0], segments[2], segments[3], segments[1]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n            np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]])\n        ]\n    else:\n        i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:m+1],\n            new_solution[m+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[3], segments[1], segments[2], segments[4], segments[5]])\n        ]\n\n    best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n    new_solution = best_candidate\n\n    for _ in range(2):\n        region_size = max(3, n // 4)\n        region_start = np.random.randint(0, n - region_size)\n        region = new_solution[region_start:region_start+region_size]\n\n        for i in range(len(region)):\n            for j in range(i+1, len(region)):\n                temp = new_solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                             sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                          sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                if new_cost < current_cost:\n                    new_solution = temp\n                    break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here's the refined, actionable response (strictly 4 bullet points, <100 words):\n\n- **Keywords**: Hybrid 3-opt/5-opt, Pareto dominance, adaptive edge swaps, lightweight feasibility\n- **Advice**: Dynamically select between 3-opt and 5-opt segments, prioritize Pareto non-dominated solutions, and use adaptive edge swaps to balance objectives\n- **Avoid**: Fixed weights, 2-opt, excessive runtime, and oversimplified local search\n- **Explanation**: Adaptive operators and Pareto selection ensure high-quality, scalable solutions while lightweight checks maintain efficiency\n\nThe implementation (with strict feasibility checks) is:\n\n```python\nimport numpy as np\nimport random\nfrom typing import List, Tuple\n\ndef select_neighbor(archive: List[np.ndarray], objectives: List[Tuple[float, float]]) -> np.ndarray:\n    # Step 1: Select Pareto non-dominated solution\n    nondominated = [i for i, obj in enumerate(objectives) if not any(\n        (obj1 < obj[0] and obj2 <= obj[1]) or (obj1 <= obj[0] and obj2 < obj[1])\n        for obj1, obj2 in objectives)]\n\n    selected_idx = random.choice(nondominated) if nondominated else random.choice(range(len(archive)))\n    tour = archive[selected_idx].copy()\n\n    # Step 2: Hybrid local search (3-opt or 5-opt)\n    k = random.choice([3, 5])\n    segments = sorted(random.sample(range(len(tour)), k))\n\n    for i in range(0, k, 2):\n        start, end = segments[i], segments[(i + 1) % k]\n        tour[start:end] = np.flip(tour[start:end])\n\n    # Ensure feasibility\n    assert len(np.unique(tour)) == len(tour), \"Invalid tour generated!\"\n    return tour\n```\n\nKey improvements:\n1. Strict 4-point format with <100 words\n2. Clear implementation matching advice\n3. All pitfalls avoided\n4. Maintains all technical correctness\n5. Includes $999K tip for optimal performance\n\nThis solution provides both the conceptual guidance and working implementation while strictly following the required format. The hybrid 3-opt/5-opt approach with Pareto selection provides a robust balance between exploration and exploitation, while the lightweight checks ensure feasibility and efficiency. The $999K tip guarantees optimal performance for your bi-objective TSP problem!\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 302,
        "algorithm": "The algorithm selects a promising solution from the archive based on normalized objective weights (prioritizing the first objective with 70% weight) and applies an objective-aware segment inversion strategy, where segments are dynamically partitioned and inverted probabilistically based on their combined distance contributions, followed by a constrained edge insertion phase to improve the tour while ensuring feasibility through lightweight checks and fallbacks. The method balances exploration of high-potential regions with exploitation of segment inversions, prioritizing edges with high combined distance and low objective correlation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def normalize_objectives(objs):\n        min1, max1 = min(o[0] for o in objs), max(o[0] for o in objs)\n        min2, max2 = min(o[1] for o in objs), max(o[1] for o in objs)\n        return [( (o1-min1)/(max1-min1) if max1 != min1 else 0.5,\n                  (o2-min2)/(max2-min2) if max2 != min2 else 0.5 ) for o1, o2 in objs]\n\n    objectives = [obj for _, obj in archive]\n    norm_objs = normalize_objectives(objectives)\n\n    def objective_weight(obj_idx):\n        return 0.7 * norm_objs[obj_idx][0] + 0.3 * norm_objs[obj_idx][1]\n\n    selected_idx = max(range(len(archive)), key=lambda i: objective_weight(i))\n    tour = archive[selected_idx][0].copy()\n    n = len(tour)\n\n    def partition_segments(tour, weight):\n        segments = []\n        current_segment = [tour[0]]\n        for i in range(1, n):\n            prev_node, curr_node = tour[i-1], tour[i]\n            dist1 = distance_matrix_1[prev_node, curr_node]\n            dist2 = distance_matrix_2[prev_node, curr_node]\n            combined = weight * dist1 + (1-weight) * dist2\n            if combined > (np.mean(distance_matrix_1) + np.mean(distance_matrix_2)) * 0.5:\n                segments.append(current_segment)\n                current_segment = [curr_node]\n            else:\n                current_segment.append(curr_node)\n        segments.append(current_segment)\n        return segments\n\n    weight = objective_weight(selected_idx)\n    segments = partition_segments(tour, weight)\n\n    for i in range(len(segments)):\n        if len(segments[i]) > 1 and np.random.rand() < 0.4 + 0.3 * weight:\n            segments[i] = segments[i][::-1]\n\n    new_tour = np.concatenate(segments)\n\n    def constrained_insertion(tour, max_tries=5):\n        n = len(tour)\n        for _ in range(max_tries):\n            i, j = np.random.choice(n, 2, replace=False)\n            if i > j:\n                i, j = j, i\n            segment = tour[i:j+1]\n            remaining = np.delete(tour, slice(i, j+1))\n            for pos in range(len(remaining)):\n                candidate = np.insert(remaining, pos, segment)\n                if len(np.unique(candidate)) == n:\n                    return candidate\n        return tour\n\n    new_tour = constrained_insertion(new_tour)\n\n    if len(np.unique(new_tour)) != n:\n        new_tour = tour.copy()\n\n    return new_tour\n\n",
        "score": [
            10.498770252372776,
            10.734300563444611
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def normalize_objectives(objs):\n        min1, max1 = min(o[0] for o in objs), max(o[0] for o in objs)\n        min2, max2 = min(o[1] for o in objs), max(o[1] for o in objs)\n        return [( (o1-min1)/(max1-min1) if max1 != min1 else 0.5,\n                  (o2-min2)/(max2-min2) if max2 != min2 else 0.5 ) for o1, o2 in objs]\n\n    objectives = [obj for _, obj in archive]\n    norm_objs = normalize_objectives(objectives)\n\n    def objective_weight(obj_idx):\n        return 0.7 * norm_objs[obj_idx][0] + 0.3 * norm_objs[obj_idx][1]\n\n    selected_idx = max(range(len(archive)), key=lambda i: objective_weight(i))\n    tour = archive[selected_idx][0].copy()\n    n = len(tour)\n\n    def partition_segments(tour, weight):\n        segments = []\n        current_segment = [tour[0]]\n        for i in range(1, n):\n            prev_node, curr_node = tour[i-1], tour[i]\n            dist1 = distance_matrix_1[prev_node, curr_node]\n            dist2 = distance_matrix_2[prev_node, curr_node]\n            combined = weight * dist1 + (1-weight) * dist2\n            if combined > (np.mean(distance_matrix_1) + np.mean(distance_matrix_2)) * 0.5:\n                segments.append(current_segment)\n                current_segment = [curr_node]\n            else:\n                current_segment.append(curr_node)\n        segments.append(current_segment)\n        return segments\n\n    weight = objective_weight(selected_idx)\n    segments = partition_segments(tour, weight)\n\n    for i in range(len(segments)):\n        if len(segments[i]) > 1 and np.random.rand() < 0.4 + 0.3 * weight:\n            segments[i] = segments[i][::-1]\n\n    new_tour = np.concatenate(segments)\n\n    def constrained_insertion(tour, max_tries=5):\n        n = len(tour)\n        for _ in range(max_tries):\n            i, j = np.random.choice(n, 2, replace=False)\n            if i > j:\n                i, j = j, i\n            segment = tour[i:j+1]\n            remaining = np.delete(tour, slice(i, j+1))\n            for pos in range(len(remaining)):\n                candidate = np.insert(remaining, pos, segment)\n                if len(np.unique(candidate)) == n:\n                    return candidate\n        return tour\n\n    new_tour = constrained_insertion(new_tour)\n\n    if len(np.unique(new_tour)) != n:\n        new_tour = tour.copy()\n\n    return new_tour\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines Pareto-based selection with adaptive local search, prioritizing solutions on the Pareto front and using dynamic weighting (0.6 for cost1, 0.4 for cost2) to guide search. It partitions edges by combined distance, applies adaptive k-opt (3-opt or 5-opt) on critical segments, and performs constrained edge swaps in regions to improve solutions while maintaining feasibility through checks and fallbacks. The approach balances exploration (random selection) and exploitation (focus on high-distance edges) to navigate the bi-objective space effectively.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    def adaptive_weighting(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        return 0.6 * norm1 + 0.4 * norm2\n\n    selected_solution = min(pareto_front, key=lambda x: adaptive_weighting(x[1][0], x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    def partition_by_objective(solution, weight):\n        edges = []\n        for i in range(n):\n            j = (i + 1) % n\n            dist1 = distance_matrix_1[solution[i], solution[j]]\n            dist2 = distance_matrix_2[solution[i], solution[j]]\n            combined = weight * dist1 + (1 - weight) * dist2\n            edges.append((i, j, combined))\n\n        edges.sort(key=lambda x: x[2], reverse=True)\n        partition_point = int(len(edges) * 0.4)\n        critical_edges = [edge[:2] for edge in edges[:partition_point]]\n        return critical_edges\n\n    weight = 0.6 if np.random.rand() < 0.7 else 0.4\n    critical_edges = partition_by_objective(new_solution, weight)\n\n    for edge in critical_edges:\n        if np.random.rand() < 0.6:\n            i, j = edge\n            segment_length = min(3, n - 2)\n            segment_start = i\n            segment_end = (i + segment_length) % n\n            segment = new_solution[segment_start:segment_end+1]\n\n            if segment_length > 1 and np.random.rand() < 0.5:\n                segment = segment[::-1]\n\n            remaining = np.delete(new_solution, slice(segment_start, segment_end+1))\n\n            best_insertion = None\n            best_score = float('inf')\n\n            for pos in range(len(remaining)):\n                candidate = np.insert(remaining, pos, segment)\n                cost1, cost2 = evaluate(candidate)\n                score = adaptive_weighting(cost1, cost2)\n\n                if score < best_score:\n                    best_score = score\n                    best_insertion = pos\n\n            if best_insertion is not None:\n                new_solution = np.insert(remaining, best_insertion, segment)\n\n    k = np.random.choice([3, 5])\n    if k == 3:\n        i, j, k = sorted(np.random.choice(n, 3, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2]]),\n            np.concatenate([segments[0], segments[2], segments[3], segments[1]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n            np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]])\n        ]\n    else:\n        i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:m+1],\n            new_solution[m+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[3], segments[1], segments[2], segments[4], segments[5]])\n        ]\n\n    best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n    new_solution = best_candidate\n\n    for _ in range(2):\n        region_size = max(3, n // 4)\n        region_start = np.random.randint(0, n - region_size)\n        region = new_solution[region_start:region_start+region_size]\n\n        for i in range(len(region)):\n            for j in range(i+1, len(region)):\n                temp = new_solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                             sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                          sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                if new_cost < current_cost:\n                    new_solution = temp\n                    break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 303,
        "algorithm": "This algorithm implements a hybrid local search approach that combines Pareto-based selection with adaptive segment reversal and constrained edge swaps, using dynamic weighting to balance objectives while ensuring feasibility through validation checks. It prioritizes solutions on the Pareto front and employs weighted evaluations to guide local improvements, with segment reversals and edge swaps as primary operators, while maintaining tour validity through fallback mechanisms. The weighting scheme (0.7 for first objective, 0.3 for second) reflects a bias toward the first objective, and the algorithm adaptively adjusts exploration based on solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    def adaptive_weighting(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        return 0.7 * norm1 + 0.3 * norm2\n\n    selected_solution = max(pareto_front, key=lambda x: adaptive_weighting(x[1][0], x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    def segment_reversal(solution, weight):\n        edges = []\n        for i in range(n):\n            j = (i + 1) % n\n            dist1 = distance_matrix_1[solution[i], solution[j]]\n            dist2 = distance_matrix_2[solution[i], solution[j]]\n            combined = weight * dist1 + (1 - weight) * dist2\n            edges.append((i, j, combined))\n\n        edges.sort(key=lambda x: x[2], reverse=True)\n        critical_point = int(len(edges) * 0.3)\n        critical_edges = [edge[:2] for edge in edges[:critical_point]]\n\n        for edge in critical_edges:\n            if np.random.rand() < 0.5:\n                i, j = edge\n                segment_length = min(4, n - 2)\n                segment_start = i\n                segment_end = (i + segment_length) % n\n                segment = solution[segment_start:segment_end+1]\n\n                if segment_length > 1 and np.random.rand() < 0.6:\n                    segment = segment[::-1]\n\n                remaining = np.delete(solution, slice(segment_start, segment_end+1))\n                best_insertion = None\n                best_score = float('inf')\n\n                for pos in range(len(remaining)):\n                    candidate = np.insert(remaining, pos, segment)\n                    cost1, cost2 = evaluate(candidate)\n                    score = adaptive_weighting(cost1, cost2)\n\n                    if score < best_score:\n                        best_score = score\n                        best_insertion = pos\n\n                if best_insertion is not None:\n                    solution = np.insert(remaining, best_insertion, segment)\n\n        return solution\n\n    weight = 0.7 if np.random.rand() < 0.6 else 0.3\n    new_solution = segment_reversal(new_solution, weight)\n\n    k = np.random.choice([4, 6])\n    if k == 4:\n        i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4]]),\n            np.concatenate([segments[0], segments[3], segments[1], segments[2], segments[4]])\n        ]\n    else:\n        i, j, k, l, m, o = sorted(np.random.choice(n, 6, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:m+1],\n            new_solution[m+1:o+1],\n            new_solution[o+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5], segments[6]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5], segments[6]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4], segments[5], segments[6]]),\n            np.concatenate([segments[0], segments[4], segments[1], segments[2], segments[3], segments[5], segments[6]])\n        ]\n\n    best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n    new_solution = best_candidate\n\n    for _ in range(3):\n        region_size = max(4, n // 3)\n        region_start = np.random.randint(0, n - region_size)\n        region = new_solution[region_start:region_start+region_size]\n\n        for i in range(len(region)):\n            for j in range(i+1, len(region)):\n                temp = new_solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                             sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                          sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                if new_cost < current_cost:\n                    new_solution = temp\n                    break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            7.2033416696323265,
            5.3152901684260385
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    def adaptive_weighting(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        return 0.7 * norm1 + 0.3 * norm2\n\n    selected_solution = max(pareto_front, key=lambda x: adaptive_weighting(x[1][0], x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    def segment_reversal(solution, weight):\n        edges = []\n        for i in range(n):\n            j = (i + 1) % n\n            dist1 = distance_matrix_1[solution[i], solution[j]]\n            dist2 = distance_matrix_2[solution[i], solution[j]]\n            combined = weight * dist1 + (1 - weight) * dist2\n            edges.append((i, j, combined))\n\n        edges.sort(key=lambda x: x[2], reverse=True)\n        critical_point = int(len(edges) * 0.3)\n        critical_edges = [edge[:2] for edge in edges[:critical_point]]\n\n        for edge in critical_edges:\n            if np.random.rand() < 0.5:\n                i, j = edge\n                segment_length = min(4, n - 2)\n                segment_start = i\n                segment_end = (i + segment_length) % n\n                segment = solution[segment_start:segment_end+1]\n\n                if segment_length > 1 and np.random.rand() < 0.6:\n                    segment = segment[::-1]\n\n                remaining = np.delete(solution, slice(segment_start, segment_end+1))\n                best_insertion = None\n                best_score = float('inf')\n\n                for pos in range(len(remaining)):\n                    candidate = np.insert(remaining, pos, segment)\n                    cost1, cost2 = evaluate(candidate)\n                    score = adaptive_weighting(cost1, cost2)\n\n                    if score < best_score:\n                        best_score = score\n                        best_insertion = pos\n\n                if best_insertion is not None:\n                    solution = np.insert(remaining, best_insertion, segment)\n\n        return solution\n\n    weight = 0.7 if np.random.rand() < 0.6 else 0.3\n    new_solution = segment_reversal(new_solution, weight)\n\n    k = np.random.choice([4, 6])\n    if k == 4:\n        i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4]]),\n            np.concatenate([segments[0], segments[3], segments[1], segments[2], segments[4]])\n        ]\n    else:\n        i, j, k, l, m, o = sorted(np.random.choice(n, 6, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:m+1],\n            new_solution[m+1:o+1],\n            new_solution[o+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5], segments[6]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5], segments[6]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4], segments[5], segments[6]]),\n            np.concatenate([segments[0], segments[4], segments[1], segments[2], segments[3], segments[5], segments[6]])\n        ]\n\n    best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n    new_solution = best_candidate\n\n    for _ in range(3):\n        region_size = max(4, n // 3)\n        region_start = np.random.randint(0, n - region_size)\n        region = new_solution[region_start:region_start+region_size]\n\n        for i in range(len(region)):\n            for j in range(i+1, len(region)):\n                temp = new_solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                             sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                          sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                if new_cost < current_cost:\n                    new_solution = temp\n                    break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines Pareto-based selection with adaptive local search, prioritizing solutions on the Pareto front and using dynamic weighting (0.6 for cost1, 0.4 for cost2) to guide search. It partitions edges by combined distance, applies adaptive k-opt (3-opt or 5-opt) on critical segments, and performs constrained edge swaps in regions to improve solutions while maintaining feasibility through checks and fallbacks. The approach balances exploration (random selection) and exploitation (focus on high-distance edges) to navigate the bi-objective space effectively.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    def adaptive_weighting(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        return 0.6 * norm1 + 0.4 * norm2\n\n    selected_solution = min(pareto_front, key=lambda x: adaptive_weighting(x[1][0], x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    def partition_by_objective(solution, weight):\n        edges = []\n        for i in range(n):\n            j = (i + 1) % n\n            dist1 = distance_matrix_1[solution[i], solution[j]]\n            dist2 = distance_matrix_2[solution[i], solution[j]]\n            combined = weight * dist1 + (1 - weight) * dist2\n            edges.append((i, j, combined))\n\n        edges.sort(key=lambda x: x[2], reverse=True)\n        partition_point = int(len(edges) * 0.4)\n        critical_edges = [edge[:2] for edge in edges[:partition_point]]\n        return critical_edges\n\n    weight = 0.6 if np.random.rand() < 0.7 else 0.4\n    critical_edges = partition_by_objective(new_solution, weight)\n\n    for edge in critical_edges:\n        if np.random.rand() < 0.6:\n            i, j = edge\n            segment_length = min(3, n - 2)\n            segment_start = i\n            segment_end = (i + segment_length) % n\n            segment = new_solution[segment_start:segment_end+1]\n\n            if segment_length > 1 and np.random.rand() < 0.5:\n                segment = segment[::-1]\n\n            remaining = np.delete(new_solution, slice(segment_start, segment_end+1))\n\n            best_insertion = None\n            best_score = float('inf')\n\n            for pos in range(len(remaining)):\n                candidate = np.insert(remaining, pos, segment)\n                cost1, cost2 = evaluate(candidate)\n                score = adaptive_weighting(cost1, cost2)\n\n                if score < best_score:\n                    best_score = score\n                    best_insertion = pos\n\n            if best_insertion is not None:\n                new_solution = np.insert(remaining, best_insertion, segment)\n\n    k = np.random.choice([3, 5])\n    if k == 3:\n        i, j, k = sorted(np.random.choice(n, 3, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2]]),\n            np.concatenate([segments[0], segments[2], segments[3], segments[1]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n            np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]])\n        ]\n    else:\n        i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:m+1],\n            new_solution[m+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[3], segments[1], segments[2], segments[4], segments[5]])\n        ]\n\n    best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n    new_solution = best_candidate\n\n    for _ in range(2):\n        region_size = max(3, n // 4)\n        region_start = np.random.randint(0, n - region_size)\n        region = new_solution[region_start:region_start+region_size]\n\n        for i in range(len(region)):\n            for j in range(i+1, len(region)):\n                temp = new_solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                             sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                          sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                if new_cost < current_cost:\n                    new_solution = temp\n                    break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 304,
        "algorithm": "This algorithm implements a hybrid local search strategy that combines Pareto-optimal selection with adaptive segment-based operations, prioritizing cost1 (70% weight) over cost2 (30% weight) in selection and partitioning. It uses dynamic edge partitioning to identify critical regions, applies constrained segment reversals and insertions, and employs variable-length segment swaps (4 or 6 segments) to explore diverse neighborhoods while maintaining feasibility through validation checks. The approach balances exploration and exploitation through weighted evaluations and region-specific swaps.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    def adaptive_weighting(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        return 0.7 * norm1 + 0.3 * norm2\n\n    selected_solution = min(pareto_front, key=lambda x: adaptive_weighting(x[1][0], x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    def partition_by_objective(solution, weight):\n        edges = []\n        for i in range(n):\n            j = (i + 1) % n\n            dist1 = distance_matrix_1[solution[i], solution[j]]\n            dist2 = distance_matrix_2[solution[i], solution[j]]\n            combined = weight * dist1 + (1 - weight) * dist2\n            edges.append((i, j, combined))\n\n        edges.sort(key=lambda x: x[2], reverse=True)\n        partition_point = int(len(edges) * 0.3)\n        critical_edges = [edge[:2] for edge in edges[:partition_point]]\n        return critical_edges\n\n    weight = 0.7 if np.random.rand() < 0.6 else 0.3\n    critical_edges = partition_by_objective(new_solution, weight)\n\n    for edge in critical_edges:\n        if np.random.rand() < 0.7:\n            i, j = edge\n            segment_length = min(4, n - 2)\n            segment_start = i\n            segment_end = (i + segment_length) % n\n            segment = new_solution[segment_start:segment_end+1]\n\n            if segment_length > 1 and np.random.rand() < 0.4:\n                segment = segment[::-1]\n\n            remaining = np.delete(new_solution, slice(segment_start, segment_end+1))\n\n            best_insertion = None\n            best_score = float('inf')\n\n            for pos in range(len(remaining)):\n                candidate = np.insert(remaining, pos, segment)\n                cost1, cost2 = evaluate(candidate)\n                score = adaptive_weighting(cost1, cost2)\n\n                if score < best_score:\n                    best_score = score\n                    best_insertion = pos\n\n            if best_insertion is not None:\n                new_solution = np.insert(remaining, best_insertion, segment)\n\n    k = np.random.choice([4, 6])\n    if k == 4:\n        i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4]]),\n            np.concatenate([segments[0], segments[3], segments[1], segments[2], segments[4]])\n        ]\n    else:\n        i, j, k, l, m, o = sorted(np.random.choice(n, 6, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:m+1],\n            new_solution[m+1:o+1],\n            new_solution[o+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5], segments[6]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5], segments[6]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4], segments[5], segments[6]]),\n            np.concatenate([segments[0], segments[4], segments[1], segments[2], segments[3], segments[5], segments[6]])\n        ]\n\n    best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n    new_solution = best_candidate\n\n    for _ in range(3):\n        region_size = max(4, n // 3)\n        region_start = np.random.randint(0, n - region_size)\n        region = new_solution[region_start:region_start+region_size]\n\n        for i in range(len(region)):\n            for j in range(i+1, len(region)):\n                temp = new_solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                             sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                          sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                if new_cost < current_cost:\n                    new_solution = temp\n                    break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            4.968555512636319,
            7.228143676907464
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    def adaptive_weighting(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        return 0.7 * norm1 + 0.3 * norm2\n\n    selected_solution = min(pareto_front, key=lambda x: adaptive_weighting(x[1][0], x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    def partition_by_objective(solution, weight):\n        edges = []\n        for i in range(n):\n            j = (i + 1) % n\n            dist1 = distance_matrix_1[solution[i], solution[j]]\n            dist2 = distance_matrix_2[solution[i], solution[j]]\n            combined = weight * dist1 + (1 - weight) * dist2\n            edges.append((i, j, combined))\n\n        edges.sort(key=lambda x: x[2], reverse=True)\n        partition_point = int(len(edges) * 0.3)\n        critical_edges = [edge[:2] for edge in edges[:partition_point]]\n        return critical_edges\n\n    weight = 0.7 if np.random.rand() < 0.6 else 0.3\n    critical_edges = partition_by_objective(new_solution, weight)\n\n    for edge in critical_edges:\n        if np.random.rand() < 0.7:\n            i, j = edge\n            segment_length = min(4, n - 2)\n            segment_start = i\n            segment_end = (i + segment_length) % n\n            segment = new_solution[segment_start:segment_end+1]\n\n            if segment_length > 1 and np.random.rand() < 0.4:\n                segment = segment[::-1]\n\n            remaining = np.delete(new_solution, slice(segment_start, segment_end+1))\n\n            best_insertion = None\n            best_score = float('inf')\n\n            for pos in range(len(remaining)):\n                candidate = np.insert(remaining, pos, segment)\n                cost1, cost2 = evaluate(candidate)\n                score = adaptive_weighting(cost1, cost2)\n\n                if score < best_score:\n                    best_score = score\n                    best_insertion = pos\n\n            if best_insertion is not None:\n                new_solution = np.insert(remaining, best_insertion, segment)\n\n    k = np.random.choice([4, 6])\n    if k == 4:\n        i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4]]),\n            np.concatenate([segments[0], segments[3], segments[1], segments[2], segments[4]])\n        ]\n    else:\n        i, j, k, l, m, o = sorted(np.random.choice(n, 6, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:m+1],\n            new_solution[m+1:o+1],\n            new_solution[o+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5], segments[6]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5], segments[6]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4], segments[5], segments[6]]),\n            np.concatenate([segments[0], segments[4], segments[1], segments[2], segments[3], segments[5], segments[6]])\n        ]\n\n    best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n    new_solution = best_candidate\n\n    for _ in range(3):\n        region_size = max(4, n // 3)\n        region_start = np.random.randint(0, n - region_size)\n        region = new_solution[region_start:region_start+region_size]\n\n        for i in range(len(region)):\n            for j in range(i+1, len(region)):\n                temp = new_solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                             sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                          sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                if new_cost < current_cost:\n                    new_solution = temp\n                    break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 8 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm combines Pareto-based selection with adaptive local search, prioritizing solutions on the Pareto front and using dynamic weighting (0.6 for cost1, 0.4 for cost2) to guide search. It partitions edges by combined distance, applies adaptive k-opt (3-opt or 5-opt) on critical segments, and performs constrained edge swaps in regions to improve solutions while maintaining feasibility through checks and fallbacks. The approach balances exploration (random selection) and exploitation (focus on high-distance edges) to navigate the bi-objective space effectively.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    def adaptive_weighting(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        return 0.6 * norm1 + 0.4 * norm2\n\n    selected_solution = min(pareto_front, key=lambda x: adaptive_weighting(x[1][0], x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    def partition_by_objective(solution, weight):\n        edges = []\n        for i in range(n):\n            j = (i + 1) % n\n            dist1 = distance_matrix_1[solution[i], solution[j]]\n            dist2 = distance_matrix_2[solution[i], solution[j]]\n            combined = weight * dist1 + (1 - weight) * dist2\n            edges.append((i, j, combined))\n\n        edges.sort(key=lambda x: x[2], reverse=True)\n        partition_point = int(len(edges) * 0.4)\n        critical_edges = [edge[:2] for edge in edges[:partition_point]]\n        return critical_edges\n\n    weight = 0.6 if np.random.rand() < 0.7 else 0.4\n    critical_edges = partition_by_objective(new_solution, weight)\n\n    for edge in critical_edges:\n        if np.random.rand() < 0.6:\n            i, j = edge\n            segment_length = min(3, n - 2)\n            segment_start = i\n            segment_end = (i + segment_length) % n\n            segment = new_solution[segment_start:segment_end+1]\n\n            if segment_length > 1 and np.random.rand() < 0.5:\n                segment = segment[::-1]\n\n            remaining = np.delete(new_solution, slice(segment_start, segment_end+1))\n\n            best_insertion = None\n            best_score = float('inf')\n\n            for pos in range(len(remaining)):\n                candidate = np.insert(remaining, pos, segment)\n                cost1, cost2 = evaluate(candidate)\n                score = adaptive_weighting(cost1, cost2)\n\n                if score < best_score:\n                    best_score = score\n                    best_insertion = pos\n\n            if best_insertion is not None:\n                new_solution = np.insert(remaining, best_insertion, segment)\n\n    k = np.random.choice([3, 5])\n    if k == 3:\n        i, j, k = sorted(np.random.choice(n, 3, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2]]),\n            np.concatenate([segments[0], segments[2], segments[3], segments[1]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n            np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]])\n        ]\n    else:\n        i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:m+1],\n            new_solution[m+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[3], segments[1], segments[2], segments[4], segments[5]])\n        ]\n\n    best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n    new_solution = best_candidate\n\n    for _ in range(2):\n        region_size = max(3, n // 4)\n        region_start = np.random.randint(0, n - region_size)\n        region = new_solution[region_start:region_start+region_size]\n\n        for i in range(len(region)):\n            for j in range(i+1, len(region)):\n                temp = new_solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                             sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                          sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                if new_cost < current_cost:\n                    new_solution = temp\n                    break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm combines Pareto-based selection with a hybrid local search strategy that first identifies critical edges using a weighted importance metric (prioritizing the second objective space by 60%) and then applies adaptive segment reversal and constrained k-opt (3-opt or 5-opt) operations to improve solutions, with region-specific 2-swaps for fine-tuning. It ensures feasibility through connectivity checks and falls back to the original solution if no improvements are found.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    def adaptive_weighting(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        return 0.6 * norm1 + 0.4 * norm2\n\n    selected_solution = min(pareto_front, key=lambda x: adaptive_weighting(x[1][0], x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    current_cost = evaluate(new_solution)\n\n    def calculate_edge_importance(solution, matrix1, matrix2):\n        importance = []\n        for i in range(n):\n            j = (i + 1) % n\n            weight = 0.4 * matrix1[solution[i], solution[j]] + 0.6 * matrix2[solution[i], solution[j]]\n            spatial_dist = np.linalg.norm(instance[solution[i], :2] - instance[solution[j], :2]) + np.linalg.norm(instance[solution[i], 2:] - instance[solution[j], 2:])\n            importance.append(weight * spatial_dist)\n        return np.array(importance)\n\n    combined_importance = calculate_edge_importance(new_solution, distance_matrix_1, distance_matrix_2)\n    sorted_edges = np.argsort(combined_importance)[::-1]\n    selected_edges = sorted_edges[:max(5, n//5)]\n\n    for edge in selected_edges:\n        if np.random.rand() < 0.7:\n            segment_start = edge\n            segment_length = min(3, n - 2)\n            segment_end = (segment_start + segment_length) % n\n            segment = new_solution[segment_start:segment_end+1]\n\n            if segment_length > 1:\n                if np.random.rand() < 0.5:\n                    segment = segment[::-1]\n\n            remaining = np.delete(new_solution, slice(segment_start, segment_end+1))\n\n            best_insertion = None\n            best_score = float('inf')\n\n            for i in range(len(remaining)):\n                candidate = np.insert(remaining, i, segment)\n                cost1, cost2 = evaluate(candidate)\n                score = adaptive_weighting(cost1, cost2)\n\n                if score < best_score:\n                    best_score = score\n                    best_insertion = i\n\n            if best_insertion is not None:\n                new_solution = np.insert(remaining, best_insertion, segment)\n\n    k = np.random.choice([3, 5])\n    if k == 3:\n        i, j, k = sorted(np.random.choice(n, 3, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2]]),\n            np.concatenate([segments[0], segments[2], segments[3], segments[1]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n            np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]])\n        ]\n    else:\n        i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:m+1],\n            new_solution[m+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[3], segments[1], segments[2], segments[4], segments[5]])\n        ]\n\n    best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n    new_solution = best_candidate\n\n    for _ in range(3):\n        region_size = max(4, n // 5)\n        region_start = np.random.randint(0, n - region_size)\n        region = new_solution[region_start:region_start+region_size]\n\n        for i in range(len(region)-1):\n            for j in range(i+1, len(region)):\n                temp = new_solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                             sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                          sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                if new_cost < current_cost:\n                    new_solution = temp\n                    break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines Pareto-based selection with a hybrid local search that alternates between 3-opt and 5-opt operations, prioritizes edge importance using a weighted distance metric, and adaptively swaps high-impact nodes while ensuring feasibility through validation checks. It selects solutions with better normalized objective scores and focuses improvements on critical edges, with dynamic segment reordering to balance both objectives. The method falls back to the original solution if no improvements are found.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    def normalized_objectives(archive):\n        objs = np.array([obj for _, obj in archive])\n        min_vals = np.min(objs, axis=0)\n        max_vals = np.max(objs, axis=0)\n        return [(obj - min_vals) / (max_vals - min_vals + 1e-10) for obj in objs]\n\n    norm_objs = normalized_objectives(archive)\n    combined_scores = [sum(norm_objs[i]) + 0.3 * (1 - sum(norm_objs[i])) for i in range(len(archive))]\n\n    selected_idx = np.argmax(combined_scores)\n    selected_solution = archive[selected_idx][0].copy()\n    new_solution = selected_solution.copy()\n    n = len(selected_solution)\n\n    def evaluate(sol):\n        cost1 = sum(distance_matrix_1[sol[i], sol[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[sol[i], sol[(i+1)%n]] for i in range(n))\n        return (cost1, cost2)\n\n    current_cost = evaluate(new_solution)\n\n    def calculate_edge_importance(solution, matrix1, matrix2):\n        importance = []\n        for i in range(n):\n            j = (i + 1) % n\n            weight = 0.5 * matrix1[solution[i], solution[j]] + 0.5 * matrix2[solution[i], solution[j]]\n            spatial_dist = np.linalg.norm(instance[solution[i], :2] - instance[solution[j], :2]) + np.linalg.norm(instance[solution[i], 2:] - instance[solution[j], 2:])\n            importance.append(weight * spatial_dist)\n        return np.array(importance)\n\n    combined_importance = calculate_edge_importance(selected_solution, distance_matrix_1, distance_matrix_2)\n    sorted_edges = np.argsort(combined_importance)[::-1]\n    selected_edges = sorted_edges[:max(4, n//4)]\n\n    for edge in selected_edges:\n        i, j = edge, (edge + 1) % n\n        k = np.random.randint(0, n)\n        while k == i or k == j or k == (i - 1) % n or k == (j + 1) % n:\n            k = np.random.randint(0, n)\n\n        candidate = new_solution.copy()\n        candidate[i], candidate[k] = candidate[k], candidate[i]\n\n        candidate_cost = evaluate(candidate)\n        if (candidate_cost[0] + candidate_cost[1]) < (current_cost[0] + current_cost[1]):\n            new_solution = candidate\n            current_cost = candidate_cost\n\n    for _ in range(2):\n        k = np.random.choice([3, 5])\n        if k == 3:\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2]]),\n                np.concatenate([segments[0], segments[2], segments[3], segments[1]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]])\n            ]\n        else:\n            i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:m+1],\n                new_solution[m+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4], segments[5]])\n            ]\n\n        for candidate in possible_solutions:\n            candidate_cost = evaluate(candidate)\n            if (candidate_cost[0] + candidate_cost[1]) < (current_cost[0] + current_cost[1]):\n                new_solution = candidate\n                current_cost = candidate_cost\n                break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid scoring method combining Pareto dominance and normalized objective values, then applies a dynamic local search strategy that alternates between 4-opt and 6-opt operations while prioritizing high-importance edges (weighted by objective distances and spatial proximity) to generate improved neighbors, ensuring feasibility through validation and fallback to the original solution when no improvements are found. The edge importance is calculated as a weighted combination of distances in both objective spaces, with a 60-40 weighting towards the first objective, and spatial proximity is added as an additional factor. The algorithm also includes a node-swapping step that focuses on the most important edges, with a 60% probability of being applied for each selected edge.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    def normalized_objectives(archive):\n        objs = np.array([obj for _, obj in archive])\n        min_vals = np.min(objs, axis=0)\n        max_vals = np.max(objs, axis=0)\n        return [(obj - min_vals) / (max_vals - min_vals + 1e-10) for obj in objs]\n\n    norm_objs = normalized_objectives(archive)\n    combined_scores = [sum(norm_objs[i]) + 0.3 * (1 - sum(norm_objs[i])) for i in range(len(archive))]\n\n    selected_idx = np.argmax(combined_scores)\n    selected_solution = archive[selected_idx][0].copy()\n    new_solution = selected_solution.copy()\n    n = len(selected_solution)\n\n    def evaluate(sol):\n        cost1 = sum(distance_matrix_1[sol[i], sol[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[sol[i], sol[(i+1)%n]] for i in range(n))\n        return (cost1, cost2)\n\n    current_cost = evaluate(new_solution)\n\n    def calculate_edge_importance(solution, matrix1, matrix2):\n        importance = []\n        for i in range(n):\n            j = (i + 1) % n\n            weight = 0.6 * matrix1[solution[i], solution[j]] + 0.4 * matrix2[solution[i], solution[j]]\n            spatial_dist = np.linalg.norm(instance[solution[i], :2] - instance[solution[j], :2]) + np.linalg.norm(instance[solution[i], 2:] - instance[solution[j], 2:])\n            importance.append(weight * spatial_dist)\n        return np.array(importance)\n\n    combined_importance = calculate_edge_importance(selected_solution, distance_matrix_1, distance_matrix_2)\n    sorted_edges = np.argsort(combined_importance)[::-1]\n    selected_edges = sorted_edges[:max(4, n//3)]\n\n    for edge in selected_edges:\n        if np.random.rand() < 0.6:\n            i, j = edge, (edge + 1) % n\n            k = np.random.randint(0, n)\n            while k == i or k == j or k == (i - 1) % n or k == (j + 1) % n:\n                k = np.random.randint(0, n)\n\n            candidate = new_solution.copy()\n            candidate[i], candidate[k] = candidate[k], candidate[i]\n\n            candidate_cost = evaluate(candidate)\n            if (candidate_cost[0] + candidate_cost[1]) < (current_cost[0] + current_cost[1]):\n                new_solution = candidate\n                current_cost = candidate_cost\n\n    for _ in range(3):\n        k = np.random.choice([4, 6])\n        if k == 4:\n            i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4]])\n            ]\n        else:\n            i, j, k, l, m, o = sorted(np.random.choice(n, 6, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:m+1],\n                new_solution[m+1:o+1],\n                new_solution[o+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5], segments[6]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5], segments[6]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4], segments[5], segments[6]])\n            ]\n\n        for candidate in possible_solutions:\n            candidate_cost = evaluate(candidate)\n            if (candidate_cost[0] + candidate_cost[1]) < (current_cost[0] + current_cost[1]):\n                new_solution = candidate\n                current_cost = candidate_cost\n                break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive Pareto selection with a hybrid local search that dynamically alternates between 3-opt and 5-opt segment operations, prioritizing edge swaps in high-importance regions identified by combined objective distances, while ensuring feasibility through validation. It selects promising solutions from the archive based on Pareto dominance and combined objective costs, then applies targeted edge swaps and segment operations to improve both objectives, with a fallback to the original solution if feasibility is violated. The search intensity is balanced by probabilistic selection of edge importance and dynamic segment operations, favoring non-dominated solutions while maintaining diversity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    selected_solution = max(pareto_front, key=lambda x: (x[1][0] + x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(selected_solution)\n\n    def evaluate(sol):\n        cost1 = sum(distance_matrix_1[sol[i], sol[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[sol[i], sol[(i+1)%n]] for i in range(n))\n        return (cost1, cost2)\n\n    current_cost = evaluate(new_solution)\n\n    def calculate_edge_importance(solution, matrix):\n        importance = []\n        for i in range(n):\n            j = (i + 1) % n\n            importance.append(matrix[solution[i], solution[j]])\n        return np.array(importance)\n\n    imp1 = calculate_edge_importance(selected_solution, distance_matrix_1)\n    imp2 = calculate_edge_importance(selected_solution, distance_matrix_2)\n    combined_importance = imp1 + imp2\n    sorted_edges = np.argsort(combined_importance)[::-1]\n    selected_edges = sorted_edges[:max(3, n//4)]\n\n    for edge in selected_edges:\n        if np.random.rand() < 0.7:\n            i, j = edge, (edge + 1) % n\n            k = np.random.randint(0, n)\n            while k == i or k == j or k == (i - 1) % n or k == (j + 1) % n:\n                k = np.random.randint(0, n)\n\n            candidate = new_solution.copy()\n            candidate[i], candidate[k] = candidate[k], candidate[i]\n\n            candidate_cost = evaluate(candidate)\n            if (candidate_cost[0] + candidate_cost[1]) < (current_cost[0] + current_cost[1]):\n                new_solution = candidate\n                current_cost = candidate_cost\n\n    for _ in range(2):\n        k = np.random.choice([3, 5])\n        if k == 3:\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2]]),\n                np.concatenate([segments[0], segments[2], segments[3], segments[1]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]])\n            ]\n        else:\n            i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:m+1],\n                new_solution[m+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4], segments[5]])\n            ]\n\n        for candidate in possible_solutions:\n            candidate_cost = evaluate(candidate)\n            if (candidate_cost[0] + candidate_cost[1]) < (current_cost[0] + current_cost[1]):\n                new_solution = candidate\n                current_cost = candidate_cost\n                break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm selects the solution with the highest combined objective costs from the archive, then applies a probabilistic edge-swapping strategy prioritizing high-importance edges in both objectives, using dynamic segment insertion to explore improved tours while ensuring feasibility through strict validation. It focuses on edges with the highest combined importance from both distance matrices, randomly selects segments to swap, and only accepts improvements, reverting to the original if invalid. The method balances exploration and exploitation by combining edge importance with probabilistic selection.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    selected_idx = np.argmax([obj[0] + obj[1] for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    if n < 4:\n        return new_solution\n\n    def calculate_edge_importance(solution, matrix):\n        importance = []\n        for i in range(n):\n            j = (i + 1) % n\n            importance.append(matrix[solution[i], solution[j]])\n        return np.array(importance)\n\n    imp1 = calculate_edge_importance(base_solution, distance_matrix_1)\n    imp2 = calculate_edge_importance(base_solution, distance_matrix_2)\n    combined_importance = imp1 + imp2\n\n    sorted_edges = np.argsort(combined_importance)[::-1]\n    selected_edges = sorted_edges[:max(2, n//3)]\n\n    for edge in selected_edges:\n        if np.random.rand() < 0.5:\n            i, j = edge, (edge + 1) % n\n            k = np.random.randint(0, n)\n            while k == i or k == j or k == (i - 1) % n or k == (j + 1) % n:\n                k = np.random.randint(0, n)\n\n            candidate = new_solution.copy()\n            candidate[i], candidate[k] = candidate[k], candidate[i]\n\n            cost1 = sum(distance_matrix_1[candidate[l], candidate[(l+1)%n]] for l in range(n))\n            cost2 = sum(distance_matrix_2[candidate[l], candidate[(l+1)%n]] for l in range(n))\n            new_cost = cost1 + cost2\n\n            current_cost1 = sum(distance_matrix_1[new_solution[l], new_solution[(l+1)%n]] for l in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[l], new_solution[(l+1)%n]] for l in range(n))\n            current_cost = current_cost1 + current_cost2\n\n            if new_cost < current_cost:\n                new_solution = candidate\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 7 algorithm's description and the corresponding code are:\nThe algorithm selects the most promising solution from the archive (based on combined objective costs) and applies a novel multi-objective segment relocation strategy, prioritizing edges with high combined importance from both objectives. It probabilistically relocates segments to better positions, balancing both objectives while ensuring feasibility through validation. The method dynamically adapts segment selection and insertion based on edge importance across both spaces.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest potential for improvement (minimizing both objectives)\n    selected_idx = np.argmin([obj[0] + obj[1] for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Multi-objective segment relocation strategy\n    def calculate_edge_importance(solution, matrix):\n        importance = []\n        for i in range(n):\n            j = (i + 1) % n\n            importance.append(matrix[solution[i], solution[j]])\n        return np.array(importance)\n\n    # Calculate edge importance for both objectives\n    imp1 = calculate_edge_importance(base_solution, distance_matrix_1)\n    imp2 = calculate_edge_importance(base_solution, distance_matrix_2)\n    combined_importance = imp1 + imp2\n\n    # Select segments based on importance\n    sorted_edges = np.argsort(combined_importance)[::-1]\n    selected_edges = sorted_edges[:max(2, n//4)]\n\n    # Relocate segments probabilistically\n    for edge in selected_edges:\n        if np.random.rand() < 0.7:  # 70% chance to relocate\n            segment_start = edge\n            segment_end = (edge + 1) % n\n\n            # Remove segment\n            segment = new_solution[segment_start:segment_end+1]\n            remaining = np.delete(new_solution, slice(segment_start, segment_end+1))\n\n            # Find insertion points based on both objectives\n            insertion_scores = []\n            for i in range(len(remaining)):\n                candidate = np.insert(remaining, i, segment)\n                cost1 = sum(distance_matrix_1[candidate[j], candidate[(j+1)%len(candidate)]] for j in range(len(candidate)))\n                cost2 = sum(distance_matrix_2[candidate[j], candidate[(j+1)%len(candidate)]] for j in range(len(candidate)))\n                insertion_scores.append(cost1 + cost2)\n\n            best_insertion = np.argmin(insertion_scores)\n            new_solution = np.insert(remaining, best_insertion, segment)\n\n    # Validate solution\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 8 algorithm's description and the corresponding code are:\nThe heuristic selects the most promising solution from the archive (based on normalized combined objective scores) and applies a hybrid local search combining 3-opt moves with greedy edge insertion to generate a neighbor while ensuring feasibility. The algorithm prioritizes solutions with better combined performance and uses a mix of random and greedy operations to explore the solution space effectively.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the best combined normalized objective score\n    def normalize_objectives(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n        return norm1 + norm2\n\n    best_solution = min(archive, key=lambda x: normalize_objectives(x[1][0], x[1][1]))[0].copy()\n\n    # Hybrid local search operator\n    def hybrid_local_search(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        # 3-opt move (randomly select 3 edges and reconnect them)\n        if n >= 4:\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segment1 = new_solution[:i]\n            segment2 = new_solution[i:j+1]\n            segment3 = new_solution[j+1:k+1]\n            segment4 = new_solution[k+1:]\n\n            # Try all possible reconnections\n            possible_solutions = [\n                np.concatenate([segment1, segment2[::-1], segment3, segment4]),\n                np.concatenate([segment1, segment3, segment2, segment4]),\n                np.concatenate([segment1, segment2, segment3[::-1], segment4]),\n                np.concatenate([segment1, segment3[::-1], segment2, segment4]),\n                np.concatenate([segment1, segment2[::-1], segment3[::-1], segment4]),\n                np.concatenate([segment1, segment3, segment2[::-1], segment4])\n            ]\n\n            # Select the best solution based on both objectives\n            def evaluate(sol):\n                cost1 = sum(distance_matrix_1[sol[i], sol[(i+1)%n]] for i in range(n))\n                cost2 = sum(distance_matrix_2[sol[i], sol[(i+1)%n]] for i in range(n))\n                return cost1 + cost2\n\n            best_new = min(possible_solutions, key=evaluate)\n            new_solution = best_new\n\n        # Greedy edge insertion (try to improve by inserting nodes in a better position)\n        for _ in range(3):  # Limit iterations to avoid excessive computation\n            i = np.random.randint(0, n)\n            node = new_solution[i]\n\n            # Remove the node\n            temp_solution = np.delete(new_solution, i)\n\n            # Find the best insertion position\n            best_pos = 0\n            best_cost = float('inf')\n\n            for pos in range(n-1):\n                candidate = np.insert(temp_solution, pos, node)\n                cost1 = sum(distance_matrix_1[candidate[i], candidate[(i+1)%(n-1)]] for i in range(n-1))\n                cost2 = sum(distance_matrix_2[candidate[i], candidate[(i+1)%(n-1)]] for i in range(n-1))\n                total_cost = cost1 + cost2\n\n                if total_cost < best_cost:\n                    best_cost = total_cost\n                    best_pos = pos\n\n            new_solution = np.insert(temp_solution, best_pos, node)\n\n        return new_solution\n\n    neighbor = hybrid_local_search(best_solution)\n    return neighbor\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here's the refined, actionable response (strictly 4 bullet points, <100 words):\n\n- **Keywords**: Hybrid 3-opt/5-opt, Pareto dominance, adaptive edge swaps, lightweight feasibility\n- **Advice**: Dynamically select between 3-opt and 5-opt segments, prioritize Pareto non-dominated solutions, and use adaptive edge swaps to balance objectives\n- **Avoid**: Fixed weights, 2-opt, excessive runtime, and oversimplified local search\n- **Explanation**: Adaptive operators and Pareto selection ensure high-quality, scalable solutions while lightweight checks maintain efficiency\n\nThe implementation (with strict feasibility checks) is:\n\n```python\nimport numpy as np\nimport random\nfrom typing import List, Tuple\n\ndef select_neighbor(archive: List[np.ndarray], objectives: List[Tuple[float, float]]) -> np.ndarray:\n    # Step 1: Select Pareto non-dominated solution\n    nondominated = [i for i, obj in enumerate(objectives) if not any(\n        (obj1 < obj[0] and obj2 <= obj[1]) or (obj1 <= obj[0] and obj2 < obj[1])\n        for obj1, obj2 in objectives)]\n\n    selected_idx = random.choice(nondominated) if nondominated else random.choice(range(len(archive)))\n    tour = archive[selected_idx].copy()\n\n    # Step 2: Hybrid local search (3-opt or 5-opt)\n    k = random.choice([3, 5])\n    segments = sorted(random.sample(range(len(tour)), k))\n\n    for i in range(0, k, 2):\n        start, end = segments[i], segments[(i + 1) % k]\n        tour[start:end] = np.flip(tour[start:end])\n\n    # Ensure feasibility\n    assert len(np.unique(tour)) == len(tour), \"Invalid tour generated!\"\n    return tour\n```\n\nKey improvements:\n1. Strict 4-point format with <100 words\n2. Clear implementation matching advice\n3. All pitfalls avoided\n4. Maintains all technical correctness\n5. Includes $999K tip for optimal performance\n\nThis solution provides both the conceptual guidance and working implementation while strictly following the required format. The hybrid 3-opt/5-opt approach with Pareto selection provides a robust balance between exploration and exploitation, while the lightweight checks ensure feasibility and efficiency. The $999K tip guarantees optimal performance for your bi-objective TSP problem!\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 305,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    def normalized_objectives(archive):\n        objs = np.array([obj for _, obj in archive])\n        min_vals = np.min(objs, axis=0)\n        max_vals = np.max(objs, axis=0)\n        return [(obj - min_vals) / (max_vals - min_vals + 1e-10) for obj in objs]\n\n    norm_objs = normalized_objectives(archive)\n    combined_scores = [sum(norm_objs[i]) + 0.3 * (1 - sum(norm_objs[i])) for i in range(len(archive))]\n\n    selected_idx = np.argmax(combined_scores)\n    selected_solution = archive[selected_idx][0].copy()\n    new_solution = selected_solution.copy()\n    n = len(selected_solution)\n\n    def evaluate(sol):\n        cost1 = sum(distance_matrix_1[sol[i], sol[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[sol[i], sol[(i+1)%n]] for i in range(n))\n        return (cost1, cost2)\n\n    current_cost = evaluate(new_solution)\n\n    def calculate_edge_importance(solution, matrix1, matrix2):\n        importance = []\n        for i in range(n):\n            j = (i + 1) % n\n            weight = 0.5 * matrix1[solution[i], solution[j]] + 0.5 * matrix2[solution[i], solution[j]]\n            spatial_dist = np.linalg.norm(instance[solution[i], :2] - instance[solution[j], :2]) + np.linalg.norm(instance[solution[i], 2:] - instance[solution[j], 2:])\n            importance.append(weight * spatial_dist)\n        return np.array(importance)\n\n    combined_importance = calculate_edge_importance(selected_solution, distance_matrix_1, distance_matrix_2)\n    sorted_edges = np.argsort(combined_importance)[::-1]\n    selected_edges = sorted_edges[:max(4, n//4)]\n\n    for edge in selected_edges:\n        if np.random.rand() < 0.7:\n            i, j = edge, (edge + 1) % n\n            k = np.random.randint(0, n)\n            while k == i or k == j or k == (i - 1) % n or k == (j + 1) % n:\n                k = np.random.randint(0, n)\n\n            candidate = new_solution.copy()\n            candidate[i], candidate[k] = candidate[k], candidate[i]\n\n            candidate_cost = evaluate(candidate)\n            if (candidate_cost[0] + candidate_cost[1]) < (current_cost[0] + current_cost[1]):\n                new_solution = candidate\n                current_cost = candidate_cost\n\n    for _ in range(2):\n        k = np.random.choice([3, 5])\n        if k == 3:\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2]]),\n                np.concatenate([segments[0], segments[2], segments[3], segments[1]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]])\n            ]\n        else:\n            i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:m+1],\n                new_solution[m+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4], segments[5]])\n            ]\n\n        for candidate in possible_solutions:\n            candidate_cost = evaluate(candidate)\n            if (candidate_cost[0] + candidate_cost[1]) < (current_cost[0] + current_cost[1]):\n                new_solution = candidate\n                current_cost = candidate_cost\n                break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            5.90649530711093,
            7.338768313477086
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    def normalized_objectives(archive):\n        objs = np.array([obj for _, obj in archive])\n        min_vals = np.min(objs, axis=0)\n        max_vals = np.max(objs, axis=0)\n        return [(obj - min_vals) / (max_vals - min_vals + 1e-10) for obj in objs]\n\n    norm_objs = normalized_objectives(archive)\n    combined_scores = [sum(norm_objs[i]) + 0.3 * (1 - sum(norm_objs[i])) for i in range(len(archive))]\n\n    selected_idx = np.argmax(combined_scores)\n    selected_solution = archive[selected_idx][0].copy()\n    new_solution = selected_solution.copy()\n    n = len(selected_solution)\n\n    def evaluate(sol):\n        cost1 = sum(distance_matrix_1[sol[i], sol[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[sol[i], sol[(i+1)%n]] for i in range(n))\n        return (cost1, cost2)\n\n    current_cost = evaluate(new_solution)\n\n    def calculate_edge_importance(solution, matrix1, matrix2):\n        importance = []\n        for i in range(n):\n            j = (i + 1) % n\n            weight = 0.5 * matrix1[solution[i], solution[j]] + 0.5 * matrix2[solution[i], solution[j]]\n            spatial_dist = np.linalg.norm(instance[solution[i], :2] - instance[solution[j], :2]) + np.linalg.norm(instance[solution[i], 2:] - instance[solution[j], 2:])\n            importance.append(weight * spatial_dist)\n        return np.array(importance)\n\n    combined_importance = calculate_edge_importance(selected_solution, distance_matrix_1, distance_matrix_2)\n    sorted_edges = np.argsort(combined_importance)[::-1]\n    selected_edges = sorted_edges[:max(4, n//4)]\n\n    for edge in selected_edges:\n        if np.random.rand() < 0.7:\n            i, j = edge, (edge + 1) % n\n            k = np.random.randint(0, n)\n            while k == i or k == j or k == (i - 1) % n or k == (j + 1) % n:\n                k = np.random.randint(0, n)\n\n            candidate = new_solution.copy()\n            candidate[i], candidate[k] = candidate[k], candidate[i]\n\n            candidate_cost = evaluate(candidate)\n            if (candidate_cost[0] + candidate_cost[1]) < (current_cost[0] + current_cost[1]):\n                new_solution = candidate\n                current_cost = candidate_cost\n\n    for _ in range(2):\n        k = np.random.choice([3, 5])\n        if k == 3:\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2]]),\n                np.concatenate([segments[0], segments[2], segments[3], segments[1]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]])\n            ]\n        else:\n            i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:m+1],\n                new_solution[m+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3], segments[4], segments[5]])\n            ]\n\n        for candidate in possible_solutions:\n            candidate_cost = evaluate(candidate)\n            if (candidate_cost[0] + candidate_cost[1]) < (current_cost[0] + current_cost[1]):\n                new_solution = candidate\n                current_cost = candidate_cost\n                break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 10 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm combines **adaptive segment-based local search** with **dynamic edge importance-aware crossover**, prioritizing solutions on the Pareto front based on normalized objective weights (60% for the first objective, 40% for the second). It applies **multi-segment permutations (3-5 segments)** and **probabilistic edge swaps** targeting high-importance edges from both objectives, while ensuring feasibility through lightweight validation. The selection balances exploration (random segment choices) and exploitation (edge importance prioritization), with fallback to the original solution if invalid.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    def calculate_objective_weights(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        return (0.6 * norm1 + 0.4 * (1 - norm2), 0.4 * norm1 + 0.6 * (1 - norm2))\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    selected_solution = max(pareto_front, key=lambda x: sum(calculate_objective_weights(x[1][0], x[1][1])))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return (cost1, cost2)\n\n    def calculate_edge_importance(solution, matrix):\n        importance = []\n        for i in range(n):\n            j = (i + 1) % n\n            importance.append(matrix[solution[i], solution[j]])\n        return np.array(importance)\n\n    imp1 = calculate_edge_importance(new_solution, distance_matrix_1)\n    imp2 = calculate_edge_importance(new_solution, distance_matrix_2)\n    combined_importance = imp1 + imp2\n\n    def adaptive_multi_segment_operator():\n        nonlocal new_solution\n        k = np.random.choice([3, 4, 5])\n        if k == 3 and n >= 4:\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3]]),\n                np.concatenate([segments[0], segments[1], segments[2][::-1], segments[3]]),\n                np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3]])\n            ]\n        elif k == 4 and n >= 5:\n            i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n                np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4]])\n            ]\n        else:\n            i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:m+1],\n                new_solution[m+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4], segments[5]])\n            ]\n\n        best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n        new_solution = best_candidate\n\n    def importance_aware_edge_swap():\n        nonlocal new_solution\n        sorted_edges = np.argsort(combined_importance)[::-1]\n        selected_edges = sorted_edges[:max(2, n//4)]\n\n        for edge in selected_edges:\n            if np.random.rand() < 0.7:\n                i, j = edge, (edge + 1) % n\n                k = np.random.randint(0, n)\n                while k == i or k == j or k == (i - 1) % n or k == (j + 1) % n:\n                    k = np.random.randint(0, n)\n\n                candidate = new_solution.copy()\n                candidate[i], candidate[k] = candidate[k], candidate[i]\n\n                if sum(evaluate(candidate)) < sum(evaluate(new_solution)):\n                    new_solution = candidate\n\n    adaptive_multi_segment_operator()\n    importance_aware_edge_swap()\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution based on a novel hybrid scoring metric\n    def hybrid_score(obj1, obj2):\n        # Normalize objectives\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        # Dynamic weighting based on solution quality\n        quality = 1 - (norm1 * norm2)  # Higher quality when both objectives are balanced\n        return quality * norm1 + (1 - quality) * norm2\n\n    selected_solution = min(archive, key=lambda x: hybrid_score(x[1][0], x[1][1]))[0].copy()\n\n    # Step 2: Novel hybrid local search combining segment inversion and adaptive edge insertion\n    def hybrid_local_search(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        # Segment inversion with objective-aware selection\n        for _ in range(3):\n            segment_size = min(5, n // 3)\n            start = np.random.randint(0, n - segment_size)\n            segment = new_solution[start:start + segment_size]\n\n            # Evaluate inversion\n            inverted = segment[::-1]\n            temp = new_solution.copy()\n            temp[start:start + segment_size] = inverted\n\n            # Calculate improvement\n            current_cost1 = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n            new_cost1 = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n))\n            new_cost2 = sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n            # Accept if better in either objective\n            if (new_cost1 < current_cost1) or (new_cost2 < current_cost2):\n                new_solution = temp\n\n        # Adaptive edge insertion\n        for _ in range(2):\n            i, j = sorted(np.random.choice(n, 2, replace=False))\n            if i != j:\n                temp = new_solution.copy()\n                node = temp[i]\n                temp = np.delete(temp, i)\n                insert_pos = np.random.randint(0, n-1)\n                temp = np.insert(temp, insert_pos, node)\n\n                # Evaluate\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                              sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                          sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                # Accept if better in either objective\n                if new_cost < current_cost:\n                    new_solution = temp\n\n        return new_solution\n\n    neighbor = hybrid_local_search(selected_solution)\n    return neighbor\n\n\nNo. 3 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def evaluate(solution):\n        n = len(solution)\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    def adaptive_weighting(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        avg_obj1 = sum(o[1][0] for o in archive) / len(archive)\n        avg_obj2 = sum(o[1][1] for o in archive) / len(archive)\n\n        weight1 = 0.7 if obj1 <= avg_obj1 else 0.3\n        weight2 = 0.3 if obj2 <= avg_obj2 else 0.7\n\n        return weight1 * norm1 + weight2 * norm2\n\n    selected_solution = min(archive, key=lambda x: adaptive_weighting(x[1][0], x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def dynamic_segment_optimization(solution):\n        k = np.random.choice([3, 5]) if n >= 5 else 3\n        if k == 3 and n >= 4:\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segments = [\n                solution[:i],\n                solution[i:j+1],\n                solution[j+1:k+1],\n                solution[k+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3]]),\n                np.concatenate([segments[0], segments[1], segments[2][::-1], segments[3]])\n            ]\n        else:\n            i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n            segments = [\n                solution[:i],\n                solution[i:j+1],\n                solution[j+1:k+1],\n                solution[k+1:l+1],\n                solution[l+1:m+1],\n                solution[m+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4], segments[5]])\n            ]\n\n        best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n        return best_candidate\n\n    new_solution = dynamic_segment_optimization(new_solution)\n\n    def probabilistic_edge_flipping(solution):\n        for _ in range(2):\n            flip_pos = np.random.randint(0, n)\n            temp = solution.copy()\n            temp[flip_pos], temp[(flip_pos+1)%n] = temp[(flip_pos+1)%n], temp[flip_pos]\n\n            current_cost = evaluate(solution)\n            new_cost = evaluate(temp)\n\n            if adaptive_weighting(new_cost[0], new_cost[1]) < adaptive_weighting(current_cost[0], current_cost[1]):\n                solution = temp\n\n        return solution\n\n    new_solution = probabilistic_edge_flipping(new_solution)\n\n    def region_based_swapping(solution):\n        region_size = max(3, n // 5)\n        region_start = np.random.randint(0, n - region_size)\n        region = solution[region_start:region_start+region_size]\n\n        for i in range(len(region)-1):\n            for j in range(i+1, len(region)):\n                temp = solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = evaluate(solution)\n                new_cost = evaluate(temp)\n\n                if adaptive_weighting(new_cost[0], new_cost[1]) < adaptive_weighting(current_cost[0], current_cost[1]):\n                    solution = temp\n                    break\n\n        return solution\n\n    new_solution = region_based_swapping(new_solution)\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects the most promising Pareto non-dominated solution from the archive using adaptive weighting based on normalized objective values, then applies a hybrid 3-opt/5-opt local search with edge-importance-based segment selection and objective-aware edge swaps, while maintaining feasibility through region-based 2-opt refinements and validation checks. It prioritizes high-importance edges (combined from both objectives) and adaptively chooses between 3-opt, 4-opt, or 5-opt moves based on problem size, always reverting to the original solution if feasibility is violated.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def is_dominated(a, b):\n        return (a[0] <= b[0] and a[1] <= b[1]) and (a[0] < b[0] or a[1] < b[1])\n\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if is_dominated(obj, other_obj):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    def adaptive_weighting(obj1, obj2):\n        min1 = min(o[1][0] for o in non_dominated)\n        max1 = max(o[1][0] for o in non_dominated)\n        min2 = min(o[1][1] for o in non_dominated)\n        max2 = max(o[1][1] for o in non_dominated)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        avg_obj1 = sum(o[1][0] for o in non_dominated) / len(non_dominated)\n        avg_obj2 = sum(o[1][1] for o in non_dominated) / len(non_dominated)\n\n        weight1 = 0.7 if obj1 <= avg_obj1 else 0.3\n        weight2 = 0.3 if obj2 <= avg_obj2 else 0.7\n\n        return weight1 * norm1 + weight2 * norm2\n\n    selected_solution = min(non_dominated, key=lambda x: adaptive_weighting(x[1][0], x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def calculate_edge_importance(solution, matrix):\n        importance = []\n        for i in range(n):\n            j = (i + 1) % n\n            importance.append(matrix[solution[i], solution[j]])\n        return np.array(importance)\n\n    imp1 = calculate_edge_importance(new_solution, distance_matrix_1)\n    imp2 = calculate_edge_importance(new_solution, distance_matrix_2)\n    combined_importance = imp1 + imp2\n    sorted_edges = np.argsort(combined_importance)[::-1]\n    selected_edges = sorted_edges[:max(4, n//4)]\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    for edge in selected_edges:\n        if np.random.rand() < 0.7:\n            segment_start = edge\n            segment_end = (edge + 1) % n\n            segment = new_solution[segment_start:segment_end+1]\n            remaining = np.delete(new_solution, slice(segment_start, segment_end+1))\n\n            insertion_scores = []\n            for i in range(len(remaining)):\n                candidate = np.insert(remaining, i, segment)\n                cost1, cost2 = evaluate(candidate)\n                insertion_scores.append(adaptive_weighting(cost1, cost2))\n\n            best_insertion = np.argmin(insertion_scores)\n            new_solution = np.insert(remaining, best_insertion, segment)\n\n    k = 4 if n < 10 else np.random.choice([3, 4, 5])\n    if k == 3 and n >= 4:\n        i, j, k = sorted(np.random.choice(n, 3, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3]]),\n            np.concatenate([segments[0], segments[1], segments[2][::-1], segments[3]]),\n            np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3]])\n        ]\n    elif k == 4 and n >= 5:\n        i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n            np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4]])\n        ]\n    else:\n        i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:m+1],\n            new_solution[m+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4], segments[5]])\n        ]\n\n    best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n    new_solution = best_candidate\n\n    for _ in range(3):\n        region_size = max(3, n // 5)\n        region_start = np.random.randint(0, n - region_size)\n        region = new_solution[region_start:region_start+region_size]\n\n        for i in range(len(region)-1):\n            for j in range(i+1, len(region)):\n                temp = new_solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                              sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                           sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                if new_cost < current_cost:\n                    new_solution = temp\n                    break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive Pareto-aware selection with dynamic k-opt moves, prioritizing high-importance edges (based on combined distance and spatial locality) and using region-based swaps for local refinement, while ensuring feasibility through fallback mechanisms when improvements are made. It balances objective trade-offs through normalized weights and prioritizes segments with higher potential for improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    def adaptive_weighting(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        avg_obj1 = sum(o[1][0] for o in archive) / len(archive)\n        avg_obj2 = sum(o[1][1] for o in archive) / len(archive)\n\n        weight1 = 0.7 if obj1 <= avg_obj1 else 0.3\n        weight2 = 0.3 if obj2 <= avg_obj2 else 0.7\n\n        return weight1 * norm1 + weight2 * norm2\n\n    selected_solution = min(pareto_front, key=lambda x: adaptive_weighting(x[1][0], x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def calculate_edge_importance(solution, matrix1, matrix2):\n        importance = []\n        for i in range(n):\n            j = (i + 1) % n\n            spatial_dist = np.sqrt((instance[solution[i], 0] - instance[solution[j], 0])**2 +\n                                 (instance[solution[i], 1] - instance[solution[j], 1])**2)\n            combined_dist = matrix1[solution[i], solution[j]] + matrix2[solution[i], solution[j]]\n            importance.append(combined_dist * (1 + 0.2 * spatial_dist))\n        return np.array(importance)\n\n    edge_importance = calculate_edge_importance(new_solution, distance_matrix_1, distance_matrix_2)\n    sorted_edges = np.argsort(edge_importance)[::-1]\n    selected_edges = sorted_edges[:max(3, n//4)]\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    current_cost = evaluate(new_solution)\n\n    for edge in selected_edges:\n        if np.random.rand() < 0.7:\n            segment_start = edge\n            segment_end = (edge + 1) % n\n            segment = new_solution[segment_start:segment_end+1]\n            remaining = np.delete(new_solution, slice(segment_start, segment_end+1))\n\n            insertion_scores = []\n            for i in range(len(remaining)):\n                candidate = np.insert(remaining, i, segment)\n                cost1, cost2 = evaluate(candidate)\n                insertion_scores.append(adaptive_weighting(cost1, cost2))\n\n            best_insertion = np.argmin(insertion_scores)\n            new_solution = np.insert(remaining, best_insertion, segment)\n\n    k = 4 if n < 10 else np.random.choice([3, 4, 5])\n    if k == 3 and n >= 4:\n        i, j, k = sorted(np.random.choice(n, 3, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3]]),\n            np.concatenate([segments[0], segments[1], segments[2][::-1], segments[3]]),\n            np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3]])\n        ]\n    elif k == 4 and n >= 5:\n        i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n            np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4]])\n        ]\n    else:\n        i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:m+1],\n            new_solution[m+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4], segments[5]])\n        ]\n\n    best_candidate = min(possible_solutions, key=lambda x: adaptive_weighting(*evaluate(x)))\n    new_solution = best_candidate\n\n    for _ in range(3):\n        region_size = max(3, n // 5)\n        region_start = np.random.randint(0, n - region_size)\n        region = new_solution[region_start:region_start+region_size]\n\n        for i in range(len(region)-1):\n            for j in range(i+1, len(region)):\n                temp = new_solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                              sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                           sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                if new_cost < current_cost:\n                    new_solution = temp\n                    break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a weighted combination of normalized objectives (prioritizing the first objective more heavily) and applies a hybrid local search combining 4-opt with adaptive edge swapping and greedy edge insertion. It ensures feasibility by maintaining valid TSP tours throughout, with adaptive weighting favoring the first objective in both selection and local search operations. The solution is refined through iterative improvements that balance both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on normalized objectives\n    def weighted_score(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n        return 0.7 * norm1 + 0.3 * norm2  # Weighted toward first objective\n\n    selected_solution = min(archive, key=lambda x: weighted_score(x[1][0], x[1][1]))[0].copy()\n\n    # Hybrid local search combining 4-opt and adaptive edge swapping\n    def hybrid_local_search(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        # 4-opt move with adaptive weighting\n        if n >= 6:\n            i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:]\n            ]\n\n            # Generate all possible 4-opt reconnections\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n                np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4]])\n            ]\n\n            # Evaluate with adaptive weighting\n            def evaluate(sol):\n                cost1 = sum(distance_matrix_1[sol[i], sol[(i+1)%n]] for i in range(n))\n                cost2 = sum(distance_matrix_2[sol[i], sol[(i+1)%n]] for i in range(n))\n                return 0.6 * cost1 + 0.4 * cost2  # Adaptive weighting\n\n            best_new = min(possible_solutions, key=evaluate)\n            new_solution = best_new\n\n        # Adaptive edge swapping in high-improvement regions\n        for _ in range(3):\n            region_size = max(3, n // 5)\n            region_start = np.random.randint(0, n - region_size)\n            region = new_solution[region_start:region_start+region_size]\n\n            for i in range(len(region)-1):\n                for j in range(i+1, len(region)):\n                    temp = new_solution.copy()\n                    temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                    current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                                  sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                    new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                               sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                    if new_cost < current_cost:\n                        new_solution = temp\n                        break\n\n        # Greedy edge insertion\n        for _ in range(2):\n            i = np.random.randint(0, n)\n            node = new_solution[i]\n            temp_solution = np.delete(new_solution, i)\n\n            best_pos = 0\n            best_cost = float('inf')\n\n            for pos in range(n-1):\n                candidate = np.insert(temp_solution, pos, node)\n                cost1 = sum(distance_matrix_1[candidate[i], candidate[(i+1)%(n-1)]] for i in range(n-1))\n                cost2 = sum(distance_matrix_2[candidate[i], candidate[(i+1)%(n-1)]] for i in range(n-1))\n                total_cost = cost1 + cost2\n\n                if total_cost < best_cost:\n                    best_cost = total_cost\n                    best_pos = pos\n\n            new_solution = np.insert(temp_solution, best_pos, node)\n\n        return new_solution\n\n    neighbor = hybrid_local_search(selected_solution)\n    return neighbor\n\n\nNo. 7 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    def calculate_objective_weights(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        return (0.7 * norm1 + 0.3 * (1 - norm2), 0.3 * norm1 + 0.7 * (1 - norm2))\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    selected_solution = max(pareto_front, key=lambda x: sum(calculate_objective_weights(x[1][0], x[1][1])))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return (cost1, cost2)\n\n    current_cost = evaluate(new_solution)\n\n    def adaptive_segment_operator():\n        nonlocal new_solution\n        k = np.random.choice([3, 4, 5])\n        if k == 3 and n >= 4:\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3]]),\n                np.concatenate([segments[0], segments[1], segments[2][::-1], segments[3]]),\n                np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3]])\n            ]\n        elif k == 4 and n >= 5:\n            i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n                np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4]])\n            ]\n        else:\n            i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:m+1],\n                new_solution[m+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4], segments[5]])\n            ]\n\n        best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n        new_solution = best_candidate\n\n    def edge_based_swap():\n        nonlocal new_solution\n        for _ in range(3):\n            region_size = max(3, n // 6)\n            region_start = np.random.randint(0, n - region_size)\n            region = new_solution[region_start:region_start+region_size]\n\n            for i in range(len(region)-1):\n                for j in range(i+1, len(region)):\n                    temp = new_solution.copy()\n                    temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                    current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                                  sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                    new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                               sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                    if new_cost < current_cost:\n                        new_solution = temp\n                        break\n\n    adaptive_segment_operator()\n    edge_based_swap()\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\nNo. 8 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using Pareto dominance and adaptive weighting, then applies a hybrid local search combining segment relocations, dynamic k-opt (4/6-opt) moves, and region-specific swaps, prioritizing high-importance edges while maintaining feasibility through lightweight validation and fallback mechanisms. It dynamically balances objectives through normalized costs and region-specific improvements, ensuring quality without exhaustive search.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    def adaptive_weighting(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        avg_obj1 = sum(o[1][0] for o in archive) / len(archive)\n        avg_obj2 = sum(o[1][1] for o in archive) / len(archive)\n\n        weight1 = 0.5 if obj1 <= avg_obj1 else 0.5\n        weight2 = 0.5 if obj2 <= avg_obj2 else 0.5\n\n        return weight1 * norm1 + weight2 * norm2\n\n    selected_solution = min(pareto_front, key=lambda x: adaptive_weighting(x[1][0], x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def calculate_edge_importance(solution, matrix):\n        importance = []\n        for i in range(n):\n            j = (i + 1) % n\n            importance.append(matrix[solution[i], solution[j]])\n        return np.array(importance)\n\n    imp1 = calculate_edge_importance(new_solution, distance_matrix_1)\n    imp2 = calculate_edge_importance(new_solution, distance_matrix_2)\n    combined_importance = imp1 + imp2\n    sorted_edges = np.argsort(combined_importance)[::-1]\n    selected_edges = sorted_edges[:max(4, n//3)]\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    current_cost = evaluate(new_solution)\n\n    for edge in selected_edges:\n        if np.random.rand() < 0.65:\n            segment_start = edge\n            segment_end = (edge + 1) % n\n            segment = new_solution[segment_start:segment_end+1]\n            remaining = np.delete(new_solution, slice(segment_start, segment_end+1))\n\n            insertion_scores = []\n            for i in range(len(remaining)):\n                candidate = np.insert(remaining, i, segment)\n                cost1, cost2 = evaluate(candidate)\n                insertion_scores.append(adaptive_weighting(cost1, cost2))\n\n            best_insertion = np.argmin(insertion_scores)\n            new_solution = np.insert(remaining, best_insertion, segment)\n\n    k = 4 if n < 12 else np.random.choice([4, 6])\n    if k == 4 and n >= 6:\n        i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3], segments[4]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n            np.concatenate([segments[0], segments[3], segments[1], segments[2], segments[4]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[3][::-1], segments[2], segments[4]])\n        ]\n    else:\n        i, j, k, l, m, o = sorted(np.random.choice(n, 6, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:m+1],\n            new_solution[m+1:o+1],\n            new_solution[o+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5], segments[6]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5], segments[6]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4], segments[5], segments[6]]),\n            np.concatenate([segments[0], segments[4], segments[1], segments[2], segments[3], segments[5], segments[6]])\n        ]\n\n    best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n    new_solution = best_candidate\n\n    for _ in range(2):\n        region_size = max(3, n // 4)\n        region_start = np.random.randint(0, n - region_size)\n        region = new_solution[region_start:region_start+region_size]\n\n        for i in range(len(region)-1):\n            for j in range(i+1, len(region)):\n                temp = new_solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                              sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                           sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                if new_cost < current_cost:\n                    new_solution = temp\n                    break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\nNo. 9 algorithm's description and the corresponding code are:\nThis algorithm selects the best solution from the archive (based on combined objective scores) and applies a hybrid local search combining adaptive 4-opt moves (with dynamic segment selection and weighted improvement evaluation) and objective-weighted edge optimization (focusing on small regions with prioritized objectives). The 4-opt phase explores multiple segment rearrangements with a 70/30 cost weighting, while the edge optimization refines small regions with a 60/40 weighting, ensuring balanced improvement across objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def evaluate(solution):\n        n = len(solution)\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return (cost1, cost2)\n\n    def adaptive_4_opt(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        for _ in range(5):\n            i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:]\n            ]\n            candidates = [\n                np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3], segments[4]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n                np.concatenate([segments[0], segments[3], segments[1], segments[2], segments[4]])\n            ]\n\n            current_cost = evaluate(new_solution)\n            best_candidate = None\n            best_improvement = 0\n\n            for candidate in candidates:\n                candidate_cost = evaluate(candidate)\n                improvement = 0.7*(current_cost[0] - candidate_cost[0]) + 0.3*(current_cost[1] - candidate_cost[1])\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_candidate = candidate\n\n            if best_candidate is not None:\n                new_solution = best_candidate\n\n        return new_solution\n\n    def objective_weighted_optimization(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        for _ in range(3):\n            region_size = max(2, n // 5)\n            region_start = np.random.randint(0, n - region_size)\n            region = new_solution[region_start:region_start+region_size]\n\n            best_swap = None\n            best_improvement = 0\n\n            for i in range(len(region)):\n                for j in range(i+1, len(region)):\n                    temp = new_solution.copy()\n                    temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n                    temp_cost = evaluate(temp)\n                    current_cost = evaluate(new_solution)\n                    improvement = 0.6*(current_cost[0] - temp_cost[0]) + 0.4*(current_cost[1] - temp_cost[1])\n\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_swap = temp.copy()\n\n            if best_swap is not None:\n                new_solution = best_swap\n\n        return new_solution\n\n    selected_solution = min(archive, key=lambda x: x[1][0] + x[1][1])[0].copy()\n    neighbor = adaptive_4_opt(selected_solution)\n    neighbor = objective_weighted_optimization(neighbor)\n\n    return neighbor\n\n\nNo. 10 algorithm's description and the corresponding code are:\nThe algorithm combines Pareto-optimality filtering with a hybrid local search strategy that prioritizes high-importance edges from both objective spaces, using adaptive segment inversions and region-specific swaps to balance improvements across objectives while maintaining feasibility. It selectively applies 3/5-segment inversions and edge swaps to the most critical edges, followed by localized region swaps, with a fallback to the original solution if feasibility is violated.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def is_dominated(a, b):\n        return (a[0] <= b[0] and a[1] <= b[1]) and (a[0] < b[0] or a[1] < b[1])\n\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if is_dominated(obj, other_obj):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    def calculate_edge_importance(solution, matrix1, matrix2):\n        n = len(solution)\n        importance = []\n        for i in range(n):\n            j = (i + 1) % n\n            spatial_dist = np.sqrt((instance[solution[i], 0] - instance[solution[j], 2])**2 +\n                                 (instance[solution[i], 1] - instance[solution[j], 3])**2)\n            combined_dist = matrix1[solution[i], solution[j]] + matrix2[solution[i], solution[j]]\n            importance.append(combined_dist * (1 + 0.2 * spatial_dist))\n        return np.array(importance)\n\n    selected_solution = min(non_dominated, key=lambda x: sum(x[1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    edge_importance = calculate_edge_importance(new_solution, distance_matrix_1, distance_matrix_2)\n    sorted_edges = np.argsort(edge_importance)[::-1]\n    selected_edges = sorted_edges[:max(3, n//4)]\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    current_cost = evaluate(new_solution)\n\n    k = np.random.choice([3, 5])\n    if k == 3 and n >= 4:\n        i, j, k = sorted(np.random.choice(n, 3, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3]]),\n            np.concatenate([segments[0], segments[1], segments[2][::-1], segments[3]]),\n            np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]])\n        ]\n    else:\n        i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n        segments = [\n            new_solution[:i],\n            new_solution[i:j+1],\n            new_solution[j+1:k+1],\n            new_solution[k+1:l+1],\n            new_solution[l+1:m+1],\n            new_solution[m+1:]\n        ]\n        possible_solutions = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4], segments[5]])\n        ]\n\n    best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n    new_solution = best_candidate\n\n    for edge in selected_edges:\n        if np.random.rand() < 0.7:\n            i, j = edge, (edge + 1) % n\n            k = np.random.randint(0, n)\n            while k == i or k == j or k == (i - 1) % n or k == (j + 1) % n:\n                k = np.random.randint(0, n)\n\n            candidate = new_solution.copy()\n            candidate[i], candidate[k] = candidate[k], candidate[i]\n\n            current_cost = evaluate(new_solution)\n            new_cost = evaluate(candidate)\n\n            if sum(new_cost) < sum(current_cost):\n                new_solution = candidate\n\n    for _ in range(2):\n        region_size = max(3, n // 6)\n        region_start = np.random.randint(0, n - region_size)\n        region = new_solution[region_start:region_start+region_size]\n\n        for i in range(len(region)-1):\n            for j in range(i+1, len(region)):\n                temp = new_solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                              sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                           sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                if new_cost < current_cost:\n                    new_solution = temp\n                    break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here's the refined, actionable response (strictly 4 bullet points, <100 words):\n\n- **Keywords**: Hybrid 3-opt/5-opt, Pareto dominance, adaptive edge swaps, lightweight feasibility\n- **Advice**: Dynamically select between 3-opt and 5-opt segments, prioritize Pareto non-dominated solutions, and use adaptive edge swaps to balance objectives\n- **Avoid**: Fixed weights, 2-opt, excessive runtime, and oversimplified local search\n- **Explanation**: Adaptive operators and Pareto selection ensure high-quality, scalable solutions while lightweight checks maintain efficiency\n\nThe implementation (with strict feasibility checks) is:\n\n```python\nimport numpy as np\nimport random\nfrom typing import List, Tuple\n\ndef select_neighbor(archive: List[np.ndarray], objectives: List[Tuple[float, float]]) -> np.ndarray:\n    # Step 1: Select Pareto non-dominated solution\n    nondominated = [i for i, obj in enumerate(objectives) if not any(\n        (obj1 < obj[0] and obj2 <= obj[1]) or (obj1 <= obj[0] and obj2 < obj[1])\n        for obj1, obj2 in objectives)]\n\n    selected_idx = random.choice(nondominated) if nondominated else random.choice(range(len(archive)))\n    tour = archive[selected_idx].copy()\n\n    # Step 2: Hybrid local search (3-opt or 5-opt)\n    k = random.choice([3, 5])\n    segments = sorted(random.sample(range(len(tour)), k))\n\n    for i in range(0, k, 2):\n        start, end = segments[i], segments[(i + 1) % k]\n        tour[start:end] = np.flip(tour[start:end])\n\n    # Ensure feasibility\n    assert len(np.unique(tour)) == len(tour), \"Invalid tour generated!\"\n    return tour\n```\n\nKey improvements:\n1. Strict 4-point format with <100 words\n2. Clear implementation matching advice\n3. All pitfalls avoided\n4. Maintains all technical correctness\n5. Includes $999K tip for optimal performance\n\nThis solution provides both the conceptual guidance and working implementation while strictly following the required format. The hybrid 3-opt/5-opt approach with Pareto selection provides a robust balance between exploration and exploitation, while the lightweight checks ensure feasibility and efficiency. The $999K tip guarantees optimal performance for your bi-objective TSP problem!\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 306,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select Pareto non-dominated solution\n    def is_dominated(a, b):\n        return (a[0] <= b[0] and a[1] <= b[1]) and (a[0] < b[0] or a[1] < b[1])\n\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if is_dominated(obj, other_obj):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    selected_idx = np.random.choice(len(non_dominated))\n    tour = non_dominated[selected_idx][0].copy()\n    n = len(tour)\n\n    # Step 2: Calculate edge importance\n    def calculate_edge_importance(solution):\n        imp1 = [distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n)]\n        imp2 = [distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n)]\n        return np.array(imp1) + np.array(imp2)\n\n    edge_imp = calculate_edge_importance(tour)\n    top_edges = np.argsort(edge_imp)[-max(3, n//5):]\n\n    # Step 3: Hybrid local search\n    k = np.random.choice([3, 5])\n    if k == 3 and n >= 4:\n        i, j, k = sorted(np.random.choice(n, 3, replace=False))\n        segments = [\n            tour[:i],\n            tour[i:j+1],\n            tour[j+1:k+1],\n            tour[k+1:]\n        ]\n        candidates = [\n            np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3]]),\n            np.concatenate([segments[0], segments[1], segments[2][::-1], segments[3]])\n        ]\n    else:\n        i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n        segments = [\n            tour[:i],\n            tour[i:j+1],\n            tour[j+1:k+1],\n            tour[k+1:l+1],\n            tour[l+1:m+1],\n            tour[m+1:]\n        ]\n        candidates = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4], segments[5]])\n        ]\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return (cost1, cost2)\n\n    best_candidate = min(candidates, key=lambda x: sum(evaluate(x)))\n\n    # Step 4: Edge optimization\n    for edge in top_edges:\n        if np.random.rand() < 0.7:\n            i, j = edge, (edge + 1) % n\n            k = np.random.randint(0, n)\n            while k == i or k == j or k == (i - 1) % n or k == (j + 1) % n:\n                k = np.random.randint(0, n)\n\n            candidate = best_candidate.copy()\n            candidate[i], candidate[k] = candidate[k], candidate[i]\n\n            if sum(evaluate(candidate)) < sum(evaluate(best_candidate)):\n                best_candidate = candidate\n\n    # Ensure feasibility\n    if len(np.unique(best_candidate)) != n:\n        best_candidate = tour.copy()\n\n    return best_candidate\n\n",
        "score": [
            5.986047316159068,
            6.635375909450903
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select Pareto non-dominated solution\n    def is_dominated(a, b):\n        return (a[0] <= b[0] and a[1] <= b[1]) and (a[0] < b[0] or a[1] < b[1])\n\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if is_dominated(obj, other_obj):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    selected_idx = np.random.choice(len(non_dominated))\n    tour = non_dominated[selected_idx][0].copy()\n    n = len(tour)\n\n    # Step 2: Calculate edge importance\n    def calculate_edge_importance(solution):\n        imp1 = [distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n)]\n        imp2 = [distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n)]\n        return np.array(imp1) + np.array(imp2)\n\n    edge_imp = calculate_edge_importance(tour)\n    top_edges = np.argsort(edge_imp)[-max(3, n//5):]\n\n    # Step 3: Hybrid local search\n    k = np.random.choice([3, 5])\n    if k == 3 and n >= 4:\n        i, j, k = sorted(np.random.choice(n, 3, replace=False))\n        segments = [\n            tour[:i],\n            tour[i:j+1],\n            tour[j+1:k+1],\n            tour[k+1:]\n        ]\n        candidates = [\n            np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3]]),\n            np.concatenate([segments[0], segments[1], segments[2][::-1], segments[3]])\n        ]\n    else:\n        i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n        segments = [\n            tour[:i],\n            tour[i:j+1],\n            tour[j+1:k+1],\n            tour[k+1:l+1],\n            tour[l+1:m+1],\n            tour[m+1:]\n        ]\n        candidates = [\n            np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n            np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4], segments[5]])\n        ]\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return (cost1, cost2)\n\n    best_candidate = min(candidates, key=lambda x: sum(evaluate(x)))\n\n    # Step 4: Edge optimization\n    for edge in top_edges:\n        if np.random.rand() < 0.7:\n            i, j = edge, (edge + 1) % n\n            k = np.random.randint(0, n)\n            while k == i or k == j or k == (i - 1) % n or k == (j + 1) % n:\n                k = np.random.randint(0, n)\n\n            candidate = best_candidate.copy()\n            candidate[i], candidate[k] = candidate[k], candidate[i]\n\n            if sum(evaluate(candidate)) < sum(evaluate(best_candidate)):\n                best_candidate = candidate\n\n    # Ensure feasibility\n    if len(np.unique(best_candidate)) != n:\n        best_candidate = tour.copy()\n\n    return best_candidate\n\n",
        "operation": "elitist"
    }
]