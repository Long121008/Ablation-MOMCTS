[
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects the best solution from the archive (prioritizing combined objective scores) and applies a hybrid local search combining random node insertions and segment shifts, ensuring feasibility by validating tour uniqueness and completeness. It adaptively adjusts parameters to explore diverse neighborhoods while falling back to simpler operations if needed. The method prioritizes exploration by randomly perturbing segments and nodes, balancing exploration with feasibility checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the best combined objective score\n    archive.sort(key=lambda x: x[1][0] + x[1][1])\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: combine node insertions and segment shifts\n    # Step 1: Randomly select a node to insert elsewhere\n    node = np.random.choice(new_solution)\n    idx = np.where(new_solution == node)[0][0]\n    new_solution = np.delete(new_solution, idx)\n    insert_pos = np.random.randint(0, n)\n    new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Step 2: Randomly select a segment to shift\n    segment_size = np.random.randint(2, min(5, n))\n    start = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[start:start+segment_size]\n    new_solution = np.delete(new_solution, np.s_[start:start+segment_size])\n    insert_pos = np.random.randint(0, n - segment_size + 1)\n    new_solution = np.insert(new_solution, insert_pos, segment)\n\n    # Ensure the solution remains valid (no duplicates and all nodes visited)\n    if len(np.unique(new_solution)) != n:\n        # If invalid, revert to a simpler node insertion\n        new_solution = base_solution.copy()\n        node = np.random.choice(new_solution)\n        idx = np.where(new_solution == node)[0][0]\n        new_solution = np.delete(new_solution, idx)\n        insert_pos = np.random.randint(0, n)\n        new_solution = np.insert(new_solution, insert_pos, node)\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with weighted randomness favoring better objectives, then applies a hybrid local search combining node swapping (40% chance) and segment insertion (60% chance) for 15 iterations, ensuring feasibility by validating and repairing the tour if nodes are missing. The selection prioritizes solutions with lower objective values, while the local search explores diverse modifications to escape local optima.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    objectives = [obj for _, obj in archive]\n    min_obj1 = min(o[0] for o in objectives)\n    min_obj2 = min(o[1] for o in objectives)\n    weights = [(min_obj1 / o[0] + min_obj2 / o[1]) for o in objectives]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine node swapping and segment insertion\n    n = len(new_solution)\n    for _ in range(15):  # Increased iterations\n        # Randomly select two distinct edges to modify\n        a, b, c, d = sorted(random.sample(range(n), 4))\n\n        # Node swapping: swap two nodes\n        if random.random() < 0.4:\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n        # Segment insertion: move a segment between two random positions\n        else:\n            segment = new_solution[a:b]\n            new_solution = np.concatenate([new_solution[:c], segment, new_solution[b:c], new_solution[b:]])\n\n    # Ensure the solution remains a valid tour (visits each node exactly once)\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        # Recover feasibility by reinserting missing nodes\n        missing_nodes = np.setdiff1d(np.arange(n), unique_nodes)\n        for node in missing_nodes:\n            pos = random.randint(0, n-1)\n            new_solution = np.insert(new_solution, pos, node)\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the archive using Pareto dominance and diversity, then applies adaptive segment insertion with dynamic length and biased edge swaps prioritizing objective improvement, combining crowding-aware segment reversal and opportunistic edge swaps to generate high-quality neighbors while maintaining feasibility. The selection process favors top solutions, while the local search dynamically adjusts segment lengths and edge swaps based on objective improvements, with validation ensuring feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using Pareto dominance and diversity\n    objectives = np.array([obj for (sol, obj) in archive])\n    front = np.argsort(objectives[:, 0] + objectives[:, 1])[:min(3, len(archive))]  # Top solutions\n    selected_idx = np.random.choice(front)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive segment insertion with dynamic length\n    segment_length = max(3, int(np.random.random() * (n // 3)))\n    start = np.random.randint(0, n - segment_length + 1)\n    segment = new_solution[start:start+segment_length]\n\n    # Insert segment at a different position\n    insert_pos = np.random.randint(0, n - segment_length + 1)\n    if insert_pos != start:\n        new_solution = np.concatenate([\n            new_solution[:insert_pos],\n            segment,\n            np.delete(new_solution, np.arange(start, start+segment_length))\n        ])\n\n    # Biased edge swaps prioritizing objective improvement\n    for _ in range(2):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == 0 or b == n-1:\n            continue\n\n        # Calculate objective improvement\n        obj_before = (distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] +\n                      distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]) / 2\n        obj_after = (distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] +\n                    distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]) / 2\n\n        if obj_after < obj_before * 0.95 or np.random.random() < 0.2:\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using dominance-aware weighted random selection\n    objectives = np.array([obj for (sol, obj) in archive])\n    ranks = np.argsort(objectives[:, 0] + objectives[:, 1])\n    weights = 1.0 / (np.arange(len(ranks)) + 1)  # Higher weight for better solutions\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate dominance score for adaptive behavior\n    dominance_score = (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.max(objectives) + 1e-8)\n\n    # Dynamic segment inversion with size based on dominance\n    segment_size = max(2, min(n//2, int(np.random.normal(n//3, n//4))))\n    if np.random.random() < 0.7 * (1 - dominance_score):\n        start = np.random.randint(0, n - segment_size + 1)\n        new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Pareto-gap biased edge swaps\n    for _ in range(5):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == 0 or b == n-1:\n            continue\n\n        # Calculate Pareto gap for both objectives\n        gap_before = (distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] +\n                    distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]) / 2\n        gap_after = (distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] +\n                    distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]) / 2\n\n        if gap_after < gap_before * 0.9 or np.random.random() < 0.4 * dominance_score:\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Segment rotation for further exploration\n    if np.random.random() < 0.5 * (1 - dominance_score):\n        k = np.random.randint(1, n)\n        new_solution = np.roll(new_solution, k)\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using crowding-distance weighted randomness to prioritize less crowded regions of the Pareto front, then applies adaptive segment inversion and Pareto-gap biased edge swaps to generate high-quality neighbors while maintaining feasibility. It dynamically adjusts segment sizes and swap probabilities based on dominance rank, favoring more promising solutions.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using crowding-distance weighted randomness\n    objectives = np.array([obj for (sol, obj) in archive])\n    fronts = np.argsort(objectives[:, 0] + objectives[:, 1])\n    crowding_distances = np.zeros(len(archive))\n    for i in range(len(archive)):\n        left = max(0, i-1)\n        right = min(len(archive)-1, i+1)\n        crowding_distances[i] = np.sum(np.abs(objectives[i] - objectives[left]) + np.abs(objectives[i] - objectives[right]))\n\n    weights = crowding_distances / np.sum(crowding_distances)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Calculate dominance rank\n    ranks = np.argsort(objectives[:, 0] + objectives[:, 1])\n    dominance_rank = np.where(ranks == selected_idx)[0][0] / len(archive)\n\n    # Adaptive segment inversion\n    segment_size = max(2, min(n//2, int(np.random.normal(n//3, n//4) * (1 - dominance_rank))))\n    start = np.random.randint(0, n - segment_size + 1)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Pareto-gap biased edge swaps\n    for _ in range(3):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == 0 or b == n-1:\n            continue\n\n        # Calculate Pareto gap for both objectives\n        gap_before = (distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] +\n                    distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]) / 2\n        gap_after = (distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] +\n                    distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]) / 2\n\n        if gap_after < gap_before * 0.9 or np.random.random() < 0.3 * (1 - dominance_rank):\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm combines dominance-aware selection (prioritizing solutions with better combined objective scores and higher crowding distances) with a novel \"multi-objective segment fusion\" operator that merges or swaps segments of the tour to reduce gaps between objectives, while ensuring feasibility through adaptive reinsertion. The selection process balances exploration (via crowding distance) and exploitation (via dominance rank), while the segment fusion dynamically adjusts segment sizes and operations based on potential objective improvements.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: crowding distance and dominance rank\n    objectives = np.array([obj for (sol, obj) in archive])\n    ranks = np.argsort(objectives[:, 0] + objectives[:, 1])\n    gaps = np.abs(objectives[:, 0] - objectives[:, 1])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(len(archive)):\n        if i == 0 or i == len(archive)-1:\n            crowding_distances[i] = float('inf')\n        else:\n            crowding_distances[i] = gaps[i] + (objectives[i+1, 0] - objectives[i-1, 0]) + (objectives[i+1, 1] - objectives[i-1, 1])\n\n    weighted_scores = ranks + 0.3 * crowding_distances\n    selected_idx = np.random.choice(np.argsort(weighted_scores)[:min(3, len(archive))])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Multi-objective segment fusion\n    segment_size = max(2, int(n / (ranks[selected_idx] + 2)))\n    start1 = np.random.randint(0, n - segment_size + 1)\n    start2 = np.random.randint(0, n - segment_size + 1)\n\n    segment1 = new_solution[start1:start1+segment_size]\n    segment2 = new_solution[start2:start2+segment_size]\n\n    # Calculate potential gap reduction\n    def calculate_gap(seg):\n        total_gap = 0\n        for i in range(len(seg)-1):\n            total_gap += abs(distance_matrix_1[seg[i], seg[i+1]] - distance_matrix_2[seg[i], seg[i+1]])\n        return total_gap\n\n    gap1 = calculate_gap(segment1)\n    gap2 = calculate_gap(segment2)\n\n    if gap1 > gap2:\n        # Merge segments if it reduces the maximum gap\n        merged_segment = np.concatenate([segment1, segment2])\n        new_solution = np.concatenate([\n            new_solution[:start1],\n            merged_segment,\n            new_solution[start1+segment_size:]\n        ])\n    else:\n        # Swap segments if it improves balance\n        new_solution[start1:start1+segment_size] = segment2\n        new_solution[start2:start2+segment_size] = segment1\n\n    # Adaptive segment reinsertion for feasibility\n    if len(set(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        segment = np.array(list(missing))\n        insert_pos = np.random.randint(0, n)\n        new_solution = np.concatenate([\n            new_solution[:insert_pos],\n            segment,\n            new_solution[insert_pos:]\n        ])\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic for the bi-TSP, designed to maximize innovation and quality:\n\n- **Keywords**: Dominance-aware inversion, gap-biased swaps, crowding-distance selection, adaptive segment sizing.\n- **Advice**: Select a parent via crowding-distance-weighted randomness, invert a segment sized inversely to dominance rank, then perform edge swaps prioritizing Pareto-front gaps.\n- **Avoid**: Fixed segment lengths or static operators; instead, dynamically adjust segment size and bias swaps toward objective gaps.\n- **Explanation**: This hybrid approach balances exploration/exploitation by dynamically adapting to multi-objective dominance, ensuring feasible solutions while diversifying the search space. \ud83d\ude80\n\n**Step-by-step reasoning**:\n1. **Selection**: Use crowding distance to prioritize solutions in less-explored regions of the Pareto front.\n2. **Inversion**: Adapt segment size inversely to dominance rank to balance local and global search.\n3. **Swaps**: Bias edge swaps toward gaps in the Pareto front to focus improvement efforts.\n4. **Feasibility**: Dynamically adjust operators to ensure all generated solutions remain valid TSP tours.\n\n**Implementation steps**:\n1. **Parent Selection**: Compute crowding distances for all solutions and select a parent with weighted randomness.\n2. **Segment Inversion**: Invert a segment of size inversely proportional to the parent\u2019s dominance rank.\n3. **Gap-Biased Swaps**: Replace edges with those that minimize Pareto-front gaps in both objectives.\n4. **Feasibility Check**: Verify the neighbor solution is a valid tour before returning it.\n\nThis heuristic ensures high-quality, diverse solutions while avoiding common pitfalls like static operators or fixed segment lengths. \ud83d\ude80\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 301,
        "algorithm": "The algorithm selects high-potential solutions from the archive using crowding-distance weighted randomness, then applies dominance-aware segment inversion and gap-biased edge swaps to generate neighbors while dynamically adjusting segment sizes and swap probabilities based on Pareto-front gaps. It prioritizes solutions with higher crowding distances (better diversity) and dominance ranks (better quality) while balancing exploration and exploitation through probabilistic segment inversion and edge swaps that target objective gaps. The solution is validated to ensure feasibility before returning.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using crowding-distance weighted randomness\n    objectives = np.array([obj for (sol, obj) in archive])\n    fronts = np.argsort(objectives[:, 0] + objectives[:, 1])\n    crowding_distances = np.zeros(len(archive))\n    for i in range(len(archive)):\n        left = max(0, i-1)\n        right = min(len(archive)-1, i+1)\n        crowding_distances[i] = np.sum(np.abs(objectives[i] - objectives[left]) + np.abs(objectives[i] - objectives[right]))\n\n    weights = crowding_distances / np.sum(crowding_distances)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Calculate dominance rank\n    ranks = np.argsort(objectives[:, 0] + objectives[:, 1])\n    dominance_rank = np.where(ranks == selected_idx)[0][0] / len(archive)\n\n    # Dominance-aware segment inversion\n    segment_size = max(2, min(n//2, int(np.random.normal(n//3, n//4) * (1 - dominance_rank))))\n    start = np.random.randint(0, n - segment_size + 1)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Gap-biased edge swaps\n    for _ in range(3):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == 0 or b == n-1:\n            continue\n\n        # Calculate objective gaps\n        gap1_before = abs(distance_matrix_1[new_solution[a-1], new_solution[a]] - distance_matrix_2[new_solution[a-1], new_solution[a]])\n        gap1_after = abs(distance_matrix_1[new_solution[a-1], new_solution[b]] - distance_matrix_2[new_solution[a-1], new_solution[b]])\n        gap2_before = abs(distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] - distance_matrix_2[new_solution[b], new_solution[(b+1)%n]])\n        gap2_after = abs(distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] - distance_matrix_2[new_solution[a], new_solution[(b+1)%n]])\n\n        total_gap_before = gap1_before + gap2_before\n        total_gap_after = gap1_after + gap2_after\n\n        if total_gap_after < total_gap_before * 0.9 or np.random.random() < 0.3 * (1 - dominance_rank):\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9178258348004019,
            0.42770063877105713
        ],
        "raw_score": [
            6.779183967240791,
            7.042984036751384
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using crowding-distance weighted randomness\n    objectives = np.array([obj for (sol, obj) in archive])\n    fronts = np.argsort(objectives[:, 0] + objectives[:, 1])\n    crowding_distances = np.zeros(len(archive))\n    for i in range(len(archive)):\n        left = max(0, i-1)\n        right = min(len(archive)-1, i+1)\n        crowding_distances[i] = np.sum(np.abs(objectives[i] - objectives[left]) + np.abs(objectives[i] - objectives[right]))\n\n    weights = crowding_distances / np.sum(crowding_distances)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Calculate dominance rank\n    ranks = np.argsort(objectives[:, 0] + objectives[:, 1])\n    dominance_rank = np.where(ranks == selected_idx)[0][0] / len(archive)\n\n    # Dominance-aware segment inversion\n    segment_size = max(2, min(n//2, int(np.random.normal(n//3, n//4) * (1 - dominance_rank))))\n    start = np.random.randint(0, n - segment_size + 1)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Gap-biased edge swaps\n    for _ in range(3):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == 0 or b == n-1:\n            continue\n\n        # Calculate objective gaps\n        gap1_before = abs(distance_matrix_1[new_solution[a-1], new_solution[a]] - distance_matrix_2[new_solution[a-1], new_solution[a]])\n        gap1_after = abs(distance_matrix_1[new_solution[a-1], new_solution[b]] - distance_matrix_2[new_solution[a-1], new_solution[b]])\n        gap2_before = abs(distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] - distance_matrix_2[new_solution[b], new_solution[(b+1)%n]])\n        gap2_after = abs(distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] - distance_matrix_2[new_solution[a], new_solution[(b+1)%n]])\n\n        total_gap_before = gap1_before + gap2_before\n        total_gap_after = gap1_after + gap2_after\n\n        if total_gap_after < total_gap_before * 0.9 or np.random.random() < 0.3 * (1 - dominance_rank):\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm combines dominance-aware selection (prioritizing solutions with better combined objective scores and higher crowding distances) with a novel \"multi-objective segment fusion\" operator that merges or swaps segments of the tour to reduce gaps between objectives, while ensuring feasibility through adaptive reinsertion. The selection process balances exploration (via crowding distance) and exploitation (via dominance rank), while the segment fusion dynamically adjusts segment sizes and operations based on potential objective improvements.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: crowding distance and dominance rank\n    objectives = np.array([obj for (sol, obj) in archive])\n    ranks = np.argsort(objectives[:, 0] + objectives[:, 1])\n    gaps = np.abs(objectives[:, 0] - objectives[:, 1])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(len(archive)):\n        if i == 0 or i == len(archive)-1:\n            crowding_distances[i] = float('inf')\n        else:\n            crowding_distances[i] = gaps[i] + (objectives[i+1, 0] - objectives[i-1, 0]) + (objectives[i+1, 1] - objectives[i-1, 1])\n\n    weighted_scores = ranks + 0.3 * crowding_distances\n    selected_idx = np.random.choice(np.argsort(weighted_scores)[:min(3, len(archive))])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Multi-objective segment fusion\n    segment_size = max(2, int(n / (ranks[selected_idx] + 2)))\n    start1 = np.random.randint(0, n - segment_size + 1)\n    start2 = np.random.randint(0, n - segment_size + 1)\n\n    segment1 = new_solution[start1:start1+segment_size]\n    segment2 = new_solution[start2:start2+segment_size]\n\n    # Calculate potential gap reduction\n    def calculate_gap(seg):\n        total_gap = 0\n        for i in range(len(seg)-1):\n            total_gap += abs(distance_matrix_1[seg[i], seg[i+1]] - distance_matrix_2[seg[i], seg[i+1]])\n        return total_gap\n\n    gap1 = calculate_gap(segment1)\n    gap2 = calculate_gap(segment2)\n\n    if gap1 > gap2:\n        # Merge segments if it reduces the maximum gap\n        merged_segment = np.concatenate([segment1, segment2])\n        new_solution = np.concatenate([\n            new_solution[:start1],\n            merged_segment,\n            new_solution[start1+segment_size:]\n        ])\n    else:\n        # Swap segments if it improves balance\n        new_solution[start1:start1+segment_size] = segment2\n        new_solution[start2:start2+segment_size] = segment1\n\n    # Adaptive segment reinsertion for feasibility\n    if len(set(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        segment = np.array(list(missing))\n        insert_pos = np.random.randint(0, n)\n        new_solution = np.concatenate([\n            new_solution[:insert_pos],\n            segment,\n            new_solution[insert_pos:]\n        ])\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using crowding distance ranking, then applies a hybrid local search combining dynamic segment shuffling (adaptively sized) and biased edge swaps prioritizing high-crowding regions in both objective spaces, while occasionally introducing random perturbations for exploration. It ensures feasibility through explicit validation and balances exploitation (targeted improvements) with exploration (random variations).\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    front = np.argsort(objectives[:, 0] + objectives[:, 1])[:min(5, len(archive))]  # Top solutions\n    selected_idx = np.random.choice(front)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment shuffling with adaptive size\n    segment_size = max(2, int(np.random.random() * n // 3))\n    start = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[start:start+segment_size]\n    remaining = np.concatenate([new_solution[:start], new_solution[start+segment_size:]])\n\n    # Find best insertion position considering crowding\n    best_pos = 0\n    best_score = float('inf')\n\n    for pos in range(len(remaining)):\n        candidate = np.concatenate([remaining[:pos], segment, remaining[pos:]])\n        cost1 = sum(distance_matrix_1[candidate[j], candidate[(j+1)%len(candidate)]] for j in range(len(candidate)))\n        cost2 = sum(distance_matrix_2[candidate[j], candidate[(j+1)%len(candidate)]] for j in range(len(candidate)))\n        crowding = (cost1 + cost2) / (np.std(cost1) + np.std(cost2) + 1e-8)  # Crowding measure\n\n        if crowding < best_score:\n            best_score = crowding\n            best_pos = pos\n\n    new_solution = np.concatenate([remaining[:best_pos], segment, remaining[best_pos:]])\n\n    # Edge swaps biased toward high-crowding regions\n    for _ in range(3):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == 0 or b == n-1:\n            continue\n\n        # Calculate crowding impact\n        crowding_before = (distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] +\n                          distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]) / 2\n        crowding_after = (distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] +\n                         distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]) / 2\n\n        if crowding_after < crowding_before or np.random.random() < 0.3:\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Segment reversal for further exploration\n    if np.random.random() < 0.5:\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic for the bi-TSP, designed to maximize innovation and quality:\n\n- **Keywords**: Dominance-aware inversion, gap-biased swaps, crowding-distance selection, adaptive segment sizing.\n- **Advice**: Select a parent via crowding-distance-weighted randomness, invert a segment sized inversely to dominance rank, then perform edge swaps prioritizing Pareto-front gaps.\n- **Avoid**: Fixed segment lengths or static operators; instead, dynamically adjust segment size and bias swaps toward objective gaps.\n- **Explanation**: This hybrid approach balances exploration/exploitation by dynamically adapting to multi-objective dominance, ensuring feasible solutions while diversifying the search space. \ud83d\ude80\n\n**Step-by-step reasoning**:\n1. **Selection**: Use crowding distance to prioritize solutions in less-explored regions of the Pareto front.\n2. **Inversion**: Adapt segment size inversely to dominance rank to balance local and global search.\n3. **Swaps**: Bias edge swaps toward gaps in the Pareto front to focus improvement efforts.\n4. **Feasibility**: Dynamically adjust operators to ensure all generated solutions remain valid TSP tours.\n\n**Implementation steps**:\n1. **Parent Selection**: Compute crowding distances for all solutions and select a parent with weighted randomness.\n2. **Segment Inversion**: Invert a segment of size inversely proportional to the parent\u2019s dominance rank.\n3. **Gap-Biased Swaps**: Replace edges with those that minimize Pareto-front gaps in both objectives.\n4. **Feasibility Check**: Verify the neighbor solution is a valid tour before returning it.\n\nThis heuristic ensures high-quality, diverse solutions while avoiding common pitfalls like static operators or fixed segment lengths. \ud83d\ude80\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 302,
        "algorithm": "The algorithm selects a parent solution from the archive using crowding-distance-weighted randomness, then applies a novel hybrid local search strategy that dynamically inverts high-gap segments (based on objective differences) and uses a biased edge reversal operator prioritizing edges with significant objective gaps, ensuring feasibility through validation. The segment sizes are proportional to objective gaps, and the biased operator reverses edges only when it improves gap reduction, balancing exploitation and exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select parent using crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(len(archive)):\n        if i == 0 or i == len(archive)-1:\n            crowding_distances[i] = float('inf')\n        else:\n            crowding_distances[i] = (objectives[i+1, 0] - objectives[i-1, 0]) + (objectives[i+1, 1] - objectives[i-1, 1])\n\n    selected_idx = np.random.choice(np.argsort(crowding_distances)[-min(3, len(archive)):])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment sizes based on objective gaps\n    segment_sizes = []\n    for i in range(n-1):\n        gap = abs(distance_matrix_1[new_solution[i], new_solution[i+1]] - distance_matrix_2[new_solution[i], new_solution[i+1]])\n        segment_sizes.append(max(2, int(gap / (np.max(objectives) - np.min(objectives) + 1e-8) * n // 2)))\n\n    # Select and invert highest-gap segment\n    if segment_sizes:\n        max_gap_idx = np.argmax(segment_sizes)\n        segment_size = segment_sizes[max_gap_idx]\n        start = max(0, max_gap_idx - segment_size // 2)\n        end = min(n, start + segment_size)\n        new_solution[start:end] = new_solution[start:end][::-1]\n\n    # Biased edge reversal operator\n    for _ in range(2):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == b or b - a < 2:\n            continue\n\n        # Calculate gap before and after reversal\n        gap_before = abs(distance_matrix_1[new_solution[a], new_solution[a+1]] - distance_matrix_2[new_solution[a], new_solution[a+1]]) + \\\n                     abs(distance_matrix_1[new_solution[b-1], new_solution[b]] - distance_matrix_2[new_solution[b-1], new_solution[b]])\n        new_solution[a:b] = new_solution[a:b][::-1]\n        gap_after = abs(distance_matrix_1[new_solution[a], new_solution[a+1]] - distance_matrix_2[new_solution[a], new_solution[a+1]]) + \\\n                    abs(distance_matrix_1[new_solution[b-1], new_solution[b]] - distance_matrix_2[new_solution[b-1], new_solution[b]])\n\n        if gap_after > gap_before and np.random.random() < 0.7:\n            new_solution[a:b] = new_solution[a:b][::-1]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9648987099610042,
            0.44614797830581665
        ],
        "raw_score": [
            6.6748322495571655,
            6.452129281282218
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select parent using crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(len(archive)):\n        if i == 0 or i == len(archive)-1:\n            crowding_distances[i] = float('inf')\n        else:\n            crowding_distances[i] = (objectives[i+1, 0] - objectives[i-1, 0]) + (objectives[i+1, 1] - objectives[i-1, 1])\n\n    selected_idx = np.random.choice(np.argsort(crowding_distances)[-min(3, len(archive)):])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment sizes based on objective gaps\n    segment_sizes = []\n    for i in range(n-1):\n        gap = abs(distance_matrix_1[new_solution[i], new_solution[i+1]] - distance_matrix_2[new_solution[i], new_solution[i+1]])\n        segment_sizes.append(max(2, int(gap / (np.max(objectives) - np.min(objectives) + 1e-8) * n // 2)))\n\n    # Select and invert highest-gap segment\n    if segment_sizes:\n        max_gap_idx = np.argmax(segment_sizes)\n        segment_size = segment_sizes[max_gap_idx]\n        start = max(0, max_gap_idx - segment_size // 2)\n        end = min(n, start + segment_size)\n        new_solution[start:end] = new_solution[start:end][::-1]\n\n    # Biased edge reversal operator\n    for _ in range(2):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == b or b - a < 2:\n            continue\n\n        # Calculate gap before and after reversal\n        gap_before = abs(distance_matrix_1[new_solution[a], new_solution[a+1]] - distance_matrix_2[new_solution[a], new_solution[a+1]]) + \\\n                     abs(distance_matrix_1[new_solution[b-1], new_solution[b]] - distance_matrix_2[new_solution[b-1], new_solution[b]])\n        new_solution[a:b] = new_solution[a:b][::-1]\n        gap_after = abs(distance_matrix_1[new_solution[a], new_solution[a+1]] - distance_matrix_2[new_solution[a], new_solution[a+1]]) + \\\n                    abs(distance_matrix_1[new_solution[b-1], new_solution[b]] - distance_matrix_2[new_solution[b-1], new_solution[b]])\n\n        if gap_after > gap_before and np.random.random() < 0.7:\n            new_solution[a:b] = new_solution[a:b][::-1]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from an archive using an adaptive dominance score that combines Pareto efficiency with crowding distance, then applies a hybrid local search combining biased edge swapping (prioritizing edges that improve both objectives) with dynamic segment inversion and random segment rotation to maintain diversity while ensuring feasibility. The selection process favors solutions with higher dominance scores but incorporates crowding distance to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_solutions = len(archive)\n\n    # Adaptive dominance score calculation\n    dominance_scores = np.zeros(n_solutions)\n    for i in range(n_solutions):\n        for j in range(n_solutions):\n            if i != j:\n                if (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and \\\n                   (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                    dominance_scores[i] += 1\n                elif (objectives[i, 0] <= objectives[j, 0] and objectives[i, 1] <= objectives[j, 1]) and \\\n                     (objectives[i, 0] < objectives[j, 0] or objectives[i, 1] < objectives[j, 1]):\n                    dominance_scores[i] -= 1\n\n    # Normalize scores with crowding consideration\n    normalized_scores = np.zeros(n_solutions)\n    for i in range(n_solutions):\n        normalized_scores[i] = dominance_scores[i] + 0.3 * (np.sum((objectives[i] - objectives) ** 2) / n_solutions)\n\n    # Select solution with highest adaptive score\n    selected_idx = np.argmax(normalized_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search\n    # Phase 1: Biased edge swapping\n    swap_prob = 0.6 if dominance_scores[selected_idx] > 0 else 0.2\n    for i in range(n):\n        for j in range(i+2, n):\n            if np.random.random() < swap_prob:\n                # Calculate potential improvement\n                orig_cost = (distance_matrix_1[base_solution[i], base_solution[(i+1)%n]] +\n                            distance_matrix_1[base_solution[j], base_solution[(j+1)%n]] +\n                            distance_matrix_2[base_solution[i], base_solution[(i+1)%n]] +\n                            distance_matrix_2[base_solution[j], base_solution[(j+1)%n]])\n\n                new_cost = (distance_matrix_1[base_solution[i], base_solution[j]] +\n                            distance_matrix_1[base_solution[(i+1)%n], base_solution[(j+1)%n]] +\n                            distance_matrix_2[base_solution[i], base_solution[j]] +\n                            distance_matrix_2[base_solution[(i+1)%n], base_solution[(j+1)%n]])\n\n                if new_cost < orig_cost:\n                    # Perform swap\n                    new_solution[i+1:j+1] = base_solution[j:i:-1]\n\n    # Phase 2: Dynamic segment inversion\n    inv_prob = 0.4 if dominance_scores[selected_idx] > 0 else 0.1\n    if np.random.random() < inv_prob:\n        seg_size = max(2, min(n//2, int(np.random.normal(n//4, n//6))))\n        seg_start = np.random.randint(0, n - seg_size + 1)\n        new_solution[seg_start:seg_start+seg_size] = new_solution[seg_start:seg_start+seg_size][::-1]\n\n    # Phase 3: Random segment rotation\n    if np.random.random() < 0.3:\n        rot_size = max(2, min(n//3, int(np.random.normal(n//5, n//7))))\n        rot_start = np.random.randint(0, n - rot_size + 1)\n        rot_amount = np.random.randint(1, rot_size)\n        new_solution[rot_start:rot_start+rot_size] = np.roll(new_solution[rot_start:rot_start+rot_size], rot_amount)\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm combines dominance-aware selection with dynamic segment inversion and Pareto-front gap-biased edge swaps to generate high-quality neighbors. It prioritizes solutions with better combined objectives, dynamically adjusts segment sizes based on dominance rank, and performs edge swaps biased toward regions with high crowding distances or Pareto front gaps, while ensuring feasibility through multi-objective validation. The algorithm balances exploration and exploitation through adaptive segment manipulation and targeted edge operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using dominance-aware selection\n    objectives = np.array([obj for (sol, obj) in archive])\n    dominance = np.argsort(np.sum(objectives, axis=1))\n    selected_idx = np.random.choice(dominance[:min(5, len(archive))])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment inversion based on dominance\n    segment_size = max(2, int(np.random.random() * n * (1 - (selected_idx / len(archive)))))\n    start = np.random.randint(0, n - segment_size)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Pareto-front gap-biased edge swaps\n    for _ in range(3):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i == 0 or j == n-1:\n            continue\n\n        # Calculate crowding impact\n        crowding_before = (distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]] +\n                         distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]) / 2\n        crowding_after = (distance_matrix_1[new_solution[i-1], new_solution[j]] + distance_matrix_1[new_solution[i], new_solution[(j+1)%n]] +\n                         distance_matrix_2[new_solution[i-1], new_solution[j]] + distance_matrix_2[new_solution[i], new_solution[(j+1)%n]]) / 2\n\n        # Calculate Pareto gap\n        pareto_gap = (objectives[selected_idx, 0] - objectives[selected_idx, 1]) / (np.max(objectives, axis=0)[0] - np.min(objectives, axis=0)[1] + 1e-8)\n\n        if (crowding_after < crowding_before and np.random.random() < 0.5 + 0.5 * pareto_gap) or np.random.random() < 0.2 * (1 - pareto_gap):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Multi-objective validation\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic for the bi-TSP, designed to maximize innovation and quality:\n\n- **Keywords**: Dominance-aware inversion, gap-biased swaps, crowding-distance selection, adaptive segment sizing.\n- **Advice**: Select a parent via crowding-distance-weighted randomness, invert a segment sized inversely to dominance rank, then perform edge swaps prioritizing Pareto-front gaps.\n- **Avoid**: Fixed segment lengths or static operators; instead, dynamically adjust segment size and bias swaps toward objective gaps.\n- **Explanation**: This hybrid approach balances exploration/exploitation by dynamically adapting to multi-objective dominance, ensuring feasible solutions while diversifying the search space. \ud83d\ude80\n\n**Step-by-step reasoning**:\n1. **Selection**: Use crowding distance to prioritize solutions in less-explored regions of the Pareto front.\n2. **Inversion**: Adapt segment size inversely to dominance rank to balance local and global search.\n3. **Swaps**: Bias edge swaps toward gaps in the Pareto front to focus improvement efforts.\n4. **Feasibility**: Dynamically adjust operators to ensure all generated solutions remain valid TSP tours.\n\n**Implementation steps**:\n1. **Parent Selection**: Compute crowding distances for all solutions and select a parent with weighted randomness.\n2. **Segment Inversion**: Invert a segment of size inversely proportional to the parent\u2019s dominance rank.\n3. **Gap-Biased Swaps**: Replace edges with those that minimize Pareto-front gaps in both objectives.\n4. **Feasibility Check**: Verify the neighbor solution is a valid tour before returning it.\n\nThis heuristic ensures high-quality, diverse solutions while avoiding common pitfalls like static operators or fixed segment lengths. \ud83d\ude80\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 303,
        "algorithm": "This algorithm combines dominance-aware selection with adaptive segment manipulation and multi-objective edge swapping, where parent solutions are chosen based on a hybrid score of crowding distance and dominance rank, and then transformed using segment inversions and biased edge swaps to improve both objectives while maintaining feasibility. The method dynamically adjusts segment sizes and swap probabilities based on dominance ratios and objective gaps, with fallback mechanisms to ensure valid tours.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_solutions = len(archive)\n\n    # Calculate dominance ranks\n    dominance_ranks = np.zeros(n_solutions)\n    for i in range(n_solutions):\n        for j in range(n_solutions):\n            if i != j:\n                if (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and \\\n                   (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                    dominance_ranks[i] += 1\n\n    # Calculate crowding distances\n    crowding_distances = np.zeros(n_solutions)\n    sorted_indices = np.argsort(objectives[:, 0])\n    objectives_sorted = objectives[sorted_indices]\n    crowding_distances[sorted_indices[0]] = np.inf\n    crowding_distances[sorted_indices[-1]] = np.inf\n    for i in range(1, n_solutions-1):\n        crowding_distances[sorted_indices[i]] += (objectives_sorted[i+1, 0] - objectives_sorted[i-1, 0]) / (np.max(objectives[:, 0]) - np.min(objectives[:, 0]) + 1e-8)\n\n    sorted_indices = np.argsort(objectives[:, 1])\n    objectives_sorted = objectives[sorted_indices]\n    crowding_distances[sorted_indices[0]] += np.inf\n    crowding_distances[sorted_indices[-1]] += np.inf\n    for i in range(1, n_solutions-1):\n        crowding_distances[sorted_indices[i]] += (objectives_sorted[i+1, 1] - objectives_sorted[i-1, 1]) / (np.max(objectives[:, 1]) - np.min(objectives[:, 1]) + 1e-8)\n\n    # Hybrid selection score\n    hybrid_scores = crowding_distances / (dominance_ranks + 1)\n    selected_idx = np.argmax(hybrid_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment inversion\n    dominance_ratio = dominance_ranks[selected_idx] / (np.max(dominance_ranks) + 1)\n    segment_size = max(2, min(n//2, int(np.random.normal(n//3, n//6) * (1 - dominance_ratio))))\n    start = np.random.randint(0, n - segment_size + 1)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Multi-objective gap-biased edge swaps\n    objective_range = np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-8\n    objective_gaps = np.abs(objectives[selected_idx, 0] - objectives[selected_idx, 1]) / objective_range.mean()\n\n    for _ in range(3):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i == 0 or j == n-1:\n            continue\n\n        # Calculate cost before and after swap\n        cost_before = (distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]] +\n                      distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]) / 2\n        cost_after = (distance_matrix_1[new_solution[i-1], new_solution[j]] + distance_matrix_1[new_solution[i], new_solution[(j+1)%n]] +\n                      distance_matrix_2[new_solution[i-1], new_solution[j]] + distance_matrix_2[new_solution[i], new_solution[(j+1)%n]]) / 2\n\n        if cost_after < cost_before or np.random.random() < 0.3 * objective_gaps:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Dynamic validation\n    if len(set(new_solution)) != n:\n        # Fallback to segment rotation if inversion causes duplicates\n        rot_size = max(2, min(n//3, int(np.random.normal(n//5, n//7))))\n        rot_start = np.random.randint(0, n - rot_size + 1)\n        rot_amount = np.random.randint(1, rot_size)\n        new_solution[rot_start:rot_start+rot_size] = np.roll(new_solution[rot_start:rot_start+rot_size], rot_amount)\n\n    return new_solution\n\n",
        "metric_score": [
            -0.828849570867736,
            0.7842929363250732
        ],
        "raw_score": [
            6.920108901533484,
            7.679519084536361
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_solutions = len(archive)\n\n    # Calculate dominance ranks\n    dominance_ranks = np.zeros(n_solutions)\n    for i in range(n_solutions):\n        for j in range(n_solutions):\n            if i != j:\n                if (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and \\\n                   (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                    dominance_ranks[i] += 1\n\n    # Calculate crowding distances\n    crowding_distances = np.zeros(n_solutions)\n    sorted_indices = np.argsort(objectives[:, 0])\n    objectives_sorted = objectives[sorted_indices]\n    crowding_distances[sorted_indices[0]] = np.inf\n    crowding_distances[sorted_indices[-1]] = np.inf\n    for i in range(1, n_solutions-1):\n        crowding_distances[sorted_indices[i]] += (objectives_sorted[i+1, 0] - objectives_sorted[i-1, 0]) / (np.max(objectives[:, 0]) - np.min(objectives[:, 0]) + 1e-8)\n\n    sorted_indices = np.argsort(objectives[:, 1])\n    objectives_sorted = objectives[sorted_indices]\n    crowding_distances[sorted_indices[0]] += np.inf\n    crowding_distances[sorted_indices[-1]] += np.inf\n    for i in range(1, n_solutions-1):\n        crowding_distances[sorted_indices[i]] += (objectives_sorted[i+1, 1] - objectives_sorted[i-1, 1]) / (np.max(objectives[:, 1]) - np.min(objectives[:, 1]) + 1e-8)\n\n    # Hybrid selection score\n    hybrid_scores = crowding_distances / (dominance_ranks + 1)\n    selected_idx = np.argmax(hybrid_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment inversion\n    dominance_ratio = dominance_ranks[selected_idx] / (np.max(dominance_ranks) + 1)\n    segment_size = max(2, min(n//2, int(np.random.normal(n//3, n//6) * (1 - dominance_ratio))))\n    start = np.random.randint(0, n - segment_size + 1)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Multi-objective gap-biased edge swaps\n    objective_range = np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-8\n    objective_gaps = np.abs(objectives[selected_idx, 0] - objectives[selected_idx, 1]) / objective_range.mean()\n\n    for _ in range(3):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i == 0 or j == n-1:\n            continue\n\n        # Calculate cost before and after swap\n        cost_before = (distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]] +\n                      distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]) / 2\n        cost_after = (distance_matrix_1[new_solution[i-1], new_solution[j]] + distance_matrix_1[new_solution[i], new_solution[(j+1)%n]] +\n                      distance_matrix_2[new_solution[i-1], new_solution[j]] + distance_matrix_2[new_solution[i], new_solution[(j+1)%n]]) / 2\n\n        if cost_after < cost_before or np.random.random() < 0.3 * objective_gaps:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Dynamic validation\n    if len(set(new_solution)) != n:\n        # Fallback to segment rotation if inversion causes duplicates\n        rot_size = max(2, min(n//3, int(np.random.normal(n//5, n//7))))\n        rot_start = np.random.randint(0, n - rot_size + 1)\n        rot_amount = np.random.randint(1, rot_size)\n        new_solution[rot_start:rot_start+rot_size] = np.roll(new_solution[rot_start:rot_start+rot_size], rot_amount)\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive with weighted randomness favoring better objectives, then applies a hybrid local search combining node swapping (40% chance) and segment insertion (60% chance) for 15 iterations, ensuring feasibility by validating and repairing the tour if nodes are missing. The selection prioritizes solutions with lower objective values, while the local search explores diverse modifications to escape local optima.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    objectives = [obj for _, obj in archive]\n    min_obj1 = min(o[0] for o in objectives)\n    min_obj2 = min(o[1] for o in objectives)\n    weights = [(min_obj1 / o[0] + min_obj2 / o[1]) for o in objectives]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine node swapping and segment insertion\n    n = len(new_solution)\n    for _ in range(15):  # Increased iterations\n        # Randomly select two distinct edges to modify\n        a, b, c, d = sorted(random.sample(range(n), 4))\n\n        # Node swapping: swap two nodes\n        if random.random() < 0.4:\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n        # Segment insertion: move a segment between two random positions\n        else:\n            segment = new_solution[a:b]\n            new_solution = np.concatenate([new_solution[:c], segment, new_solution[b:c], new_solution[b:]])\n\n    # Ensure the solution remains a valid tour (visits each node exactly once)\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        # Recover feasibility by reinserting missing nodes\n        missing_nodes = np.setdiff1d(np.arange(n), unique_nodes)\n        for node in missing_nodes:\n            pos = random.randint(0, n-1)\n            new_solution = np.insert(new_solution, pos, node)\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm combines dominance-aware selection with dynamic segment inversion and Pareto-front gap-biased edge swaps to generate high-quality neighbors. It prioritizes solutions with better combined objectives, dynamically adjusts segment sizes based on dominance rank, and performs edge swaps biased toward regions with high crowding distances or Pareto front gaps, while ensuring feasibility through multi-objective validation. The algorithm balances exploration and exploitation through adaptive segment manipulation and targeted edge operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using dominance-aware selection\n    objectives = np.array([obj for (sol, obj) in archive])\n    dominance = np.argsort(np.sum(objectives, axis=1))\n    selected_idx = np.random.choice(dominance[:min(5, len(archive))])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment inversion based on dominance\n    segment_size = max(2, int(np.random.random() * n * (1 - (selected_idx / len(archive)))))\n    start = np.random.randint(0, n - segment_size)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Pareto-front gap-biased edge swaps\n    for _ in range(3):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i == 0 or j == n-1:\n            continue\n\n        # Calculate crowding impact\n        crowding_before = (distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]] +\n                         distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]) / 2\n        crowding_after = (distance_matrix_1[new_solution[i-1], new_solution[j]] + distance_matrix_1[new_solution[i], new_solution[(j+1)%n]] +\n                         distance_matrix_2[new_solution[i-1], new_solution[j]] + distance_matrix_2[new_solution[i], new_solution[(j+1)%n]]) / 2\n\n        # Calculate Pareto gap\n        pareto_gap = (objectives[selected_idx, 0] - objectives[selected_idx, 1]) / (np.max(objectives, axis=0)[0] - np.min(objectives, axis=0)[1] + 1e-8)\n\n        if (crowding_after < crowding_before and np.random.random() < 0.5 + 0.5 * pareto_gap) or np.random.random() < 0.2 * (1 - pareto_gap):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Multi-objective validation\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic for the bi-TSP, designed to maximize innovation and quality:\n\n- **Keywords**: Dominance-aware inversion, gap-biased swaps, crowding-distance selection, adaptive segment sizing.\n- **Advice**: Select a parent via crowding-distance-weighted randomness, invert a segment sized inversely to dominance rank, then perform edge swaps prioritizing Pareto-front gaps.\n- **Avoid**: Fixed segment lengths or static operators; instead, dynamically adjust segment size and bias swaps toward objective gaps.\n- **Explanation**: This hybrid approach balances exploration/exploitation by dynamically adapting to multi-objective dominance, ensuring feasible solutions while diversifying the search space. \ud83d\ude80\n\n**Step-by-step reasoning**:\n1. **Selection**: Use crowding distance to prioritize solutions in less-explored regions of the Pareto front.\n2. **Inversion**: Adapt segment size inversely to dominance rank to balance local and global search.\n3. **Swaps**: Bias edge swaps toward gaps in the Pareto front to focus improvement efforts.\n4. **Feasibility**: Dynamically adjust operators to ensure all generated solutions remain valid TSP tours.\n\n**Implementation steps**:\n1. **Parent Selection**: Compute crowding distances for all solutions and select a parent with weighted randomness.\n2. **Segment Inversion**: Invert a segment of size inversely proportional to the parent\u2019s dominance rank.\n3. **Gap-Biased Swaps**: Replace edges with those that minimize Pareto-front gaps in both objectives.\n4. **Feasibility Check**: Verify the neighbor solution is a valid tour before returning it.\n\nThis heuristic ensures high-quality, diverse solutions while avoiding common pitfalls like static operators or fixed segment lengths. \ud83d\ude80\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 304,
        "algorithm": "This algorithm combines dominance-aware selection with adaptive segment manipulation and multi-objective edge prioritization. It selects parent solutions based on crowding distance in the Pareto front, dynamically adjusts segment sizes according to dominance rank, and biases edge swaps toward regions with high Pareto-front gaps while ensuring feasibility through iterative validation and repair. The method prioritizes exploration of less-explored objective-space regions and adapts the search strategy based on dominance landscape, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distances for all solutions\n    objectives = np.array([obj for (sol, obj) in archive])\n    sorted_indices = np.argsort(objectives[:, 0])\n    crowding_distances = np.zeros(len(archive))\n    for i in range(1, len(archive)-1):\n        crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]) / (np.max(objectives[:, 0]) - np.min(objectives[:, 0]))\n    sorted_indices = np.argsort(objectives[:, 1])\n    for i in range(1, len(archive)-1):\n        crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], 1] - objectives[sorted_indices[i-1], 1]) / (np.max(objectives[:, 1]) - np.min(objectives[:, 1]))\n\n    # Select parent with crowding-distance-weighted randomness\n    weights = crowding_distances + 1e-8  # Avoid zero weights\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate dominance rank\n    dominance_rank = np.sum(objectives <= objectives[selected_idx], axis=1)\n    dominance_rank = np.argsort(dominance_rank).tolist().index(selected_idx)\n\n    # Adaptive segment inversion\n    segment_size = max(2, int(n / (dominance_rank + 1)))\n    start = random.randint(0, n - segment_size)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Calculate Pareto front gaps\n    max_obj = np.max(objectives, axis=0)\n    min_obj = np.min(objectives, axis=0)\n    gaps = (max_obj - min_obj) / (np.sum(max_obj - min_obj) + 1e-8)\n\n    # Gap-biased edge swaps\n    for _ in range(3):\n        i, j = sorted(random.sample(range(n), 2))\n\n        # Calculate edge contributions to both objectives\n        def edge_contribution(sol, idx):\n            prev = sol[idx-1]\n            curr = sol[idx]\n            next = sol[(idx+1)%n]\n            return (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next] +\n                    distance_matrix_2[prev, curr] + distance_matrix_2[curr, next]) / 2\n\n        contrib_before = edge_contribution(new_solution, i) + edge_contribution(new_solution, j)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        contrib_after = edge_contribution(new_solution, i) + edge_contribution(new_solution, j)\n\n        # Calculate gap impact\n        gap_impact = (contrib_after - contrib_before) * gaps\n\n        if random.random() < 0.5 + 0.5 * np.sum(gap_impact):\n            continue  # Keep the swap\n        else:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]  # Revert\n\n    # Feasibility check and repair\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing_nodes = np.setdiff1d(np.arange(n), unique_nodes)\n        for node in missing_nodes:\n            pos = random.randint(0, len(new_solution)-1)\n            new_solution = np.insert(new_solution, pos, node)\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9598579031877017,
            0.4059576988220215
        ],
        "raw_score": [
            7.789152291268676,
            8.197224439715047
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distances for all solutions\n    objectives = np.array([obj for (sol, obj) in archive])\n    sorted_indices = np.argsort(objectives[:, 0])\n    crowding_distances = np.zeros(len(archive))\n    for i in range(1, len(archive)-1):\n        crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], 0] - objectives[sorted_indices[i-1], 0]) / (np.max(objectives[:, 0]) - np.min(objectives[:, 0]))\n    sorted_indices = np.argsort(objectives[:, 1])\n    for i in range(1, len(archive)-1):\n        crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], 1] - objectives[sorted_indices[i-1], 1]) / (np.max(objectives[:, 1]) - np.min(objectives[:, 1]))\n\n    # Select parent with crowding-distance-weighted randomness\n    weights = crowding_distances + 1e-8  # Avoid zero weights\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate dominance rank\n    dominance_rank = np.sum(objectives <= objectives[selected_idx], axis=1)\n    dominance_rank = np.argsort(dominance_rank).tolist().index(selected_idx)\n\n    # Adaptive segment inversion\n    segment_size = max(2, int(n / (dominance_rank + 1)))\n    start = random.randint(0, n - segment_size)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Calculate Pareto front gaps\n    max_obj = np.max(objectives, axis=0)\n    min_obj = np.min(objectives, axis=0)\n    gaps = (max_obj - min_obj) / (np.sum(max_obj - min_obj) + 1e-8)\n\n    # Gap-biased edge swaps\n    for _ in range(3):\n        i, j = sorted(random.sample(range(n), 2))\n\n        # Calculate edge contributions to both objectives\n        def edge_contribution(sol, idx):\n            prev = sol[idx-1]\n            curr = sol[idx]\n            next = sol[(idx+1)%n]\n            return (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next] +\n                    distance_matrix_2[prev, curr] + distance_matrix_2[curr, next]) / 2\n\n        contrib_before = edge_contribution(new_solution, i) + edge_contribution(new_solution, j)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        contrib_after = edge_contribution(new_solution, i) + edge_contribution(new_solution, j)\n\n        # Calculate gap impact\n        gap_impact = (contrib_after - contrib_before) * gaps\n\n        if random.random() < 0.5 + 0.5 * np.sum(gap_impact):\n            continue  # Keep the swap\n        else:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]  # Revert\n\n    # Feasibility check and repair\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        missing_nodes = np.setdiff1d(np.arange(n), unique_nodes)\n        for node in missing_nodes:\n            pos = random.randint(0, len(new_solution)-1)\n            new_solution = np.insert(new_solution, pos, node)\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines dominance-aware selection with dynamic segment inversion and Pareto-front gap-biased edge swaps to generate high-quality neighbors. It prioritizes solutions with better combined objectives, dynamically adjusts segment sizes based on dominance rank, and performs edge swaps biased toward regions with high crowding distances or Pareto front gaps, while ensuring feasibility through multi-objective validation. The algorithm balances exploration and exploitation through adaptive segment manipulation and targeted edge operations.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using dominance-aware selection\n    objectives = np.array([obj for (sol, obj) in archive])\n    dominance = np.argsort(np.sum(objectives, axis=1))\n    selected_idx = np.random.choice(dominance[:min(5, len(archive))])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment inversion based on dominance\n    segment_size = max(2, int(np.random.random() * n * (1 - (selected_idx / len(archive)))))\n    start = np.random.randint(0, n - segment_size)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Pareto-front gap-biased edge swaps\n    for _ in range(3):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i == 0 or j == n-1:\n            continue\n\n        # Calculate crowding impact\n        crowding_before = (distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]] +\n                         distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]) / 2\n        crowding_after = (distance_matrix_1[new_solution[i-1], new_solution[j]] + distance_matrix_1[new_solution[i], new_solution[(j+1)%n]] +\n                         distance_matrix_2[new_solution[i-1], new_solution[j]] + distance_matrix_2[new_solution[i], new_solution[(j+1)%n]]) / 2\n\n        # Calculate Pareto gap\n        pareto_gap = (objectives[selected_idx, 0] - objectives[selected_idx, 1]) / (np.max(objectives, axis=0)[0] - np.min(objectives, axis=0)[1] + 1e-8)\n\n        if (crowding_after < crowding_before and np.random.random() < 0.5 + 0.5 * pareto_gap) or np.random.random() < 0.2 * (1 - pareto_gap):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Multi-objective validation\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 305,
        "algorithm": "This algorithm selects a promising solution from an archive using adaptive objective-aware selection, then applies a hybrid local search combining segment reversal with Pareto front-guided swaps, prioritizing edges that improve both objectives while maintaining feasibility through multi-stage validation. The method dynamically balances exploration and exploitation by weighting moves based on objective differences and distance improvements, ensuring valid TSP tours through set and coordinate validation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using adaptive objective-aware selection\n    objectives = np.array([obj for (sol, obj) in archive])\n    weights = np.exp(-np.sum(objectives, axis=1) / np.sum(objectives))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment reversal with objective-aware weighting\n    segment_size = max(2, int(np.random.random() * n * (1 - (objectives[selected_idx, 0] / np.max(objectives[:, 0] + 1e-8)))))\n    start = np.random.randint(0, n - segment_size)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Dynamic edge selection based on multi-objective dominance\n    obj_diff = objectives[selected_idx, 0] - objectives[selected_idx, 1]\n    for _ in range(3):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i == 0 or j == n-1:\n            continue\n\n        # Calculate combined distance improvement\n        dist_improvement = (distance_matrix_1[new_solution[i-1], new_solution[j]] + distance_matrix_1[new_solution[i], new_solution[(j+1)%n]] -\n                           distance_matrix_1[new_solution[i-1], new_solution[i]] - distance_matrix_1[new_solution[j], new_solution[(j+1)%n]]) / 2\n        dist_improvement += (distance_matrix_2[new_solution[i-1], new_solution[j]] + distance_matrix_2[new_solution[i], new_solution[(j+1)%n]] -\n                            distance_matrix_2[new_solution[i-1], new_solution[i]] - distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]) / 2\n\n        # Pareto front-guided swap probability\n        swap_prob = 0.5 + 0.5 * (obj_diff / (np.max(objectives[:, 0]) - np.min(objectives[:, 1]) + 1e-8))\n        if (dist_improvement < 0 and np.random.random() < swap_prob) or np.random.random() < 0.1 * (1 - swap_prob):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Multi-stage validation\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n    else:\n        # Additional validation against instance coordinates\n        for i in range(n):\n            if not np.array_equal(instance[new_solution[i]], instance[base_solution[i]]):\n                new_solution = base_solution.copy()\n                break\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7031469672718227,
            2.8778825402259827
        ],
        "raw_score": [
            9.12923533690892,
            9.314703130921313
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using adaptive objective-aware selection\n    objectives = np.array([obj for (sol, obj) in archive])\n    weights = np.exp(-np.sum(objectives, axis=1) / np.sum(objectives))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment reversal with objective-aware weighting\n    segment_size = max(2, int(np.random.random() * n * (1 - (objectives[selected_idx, 0] / np.max(objectives[:, 0] + 1e-8)))))\n    start = np.random.randint(0, n - segment_size)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Dynamic edge selection based on multi-objective dominance\n    obj_diff = objectives[selected_idx, 0] - objectives[selected_idx, 1]\n    for _ in range(3):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i == 0 or j == n-1:\n            continue\n\n        # Calculate combined distance improvement\n        dist_improvement = (distance_matrix_1[new_solution[i-1], new_solution[j]] + distance_matrix_1[new_solution[i], new_solution[(j+1)%n]] -\n                           distance_matrix_1[new_solution[i-1], new_solution[i]] - distance_matrix_1[new_solution[j], new_solution[(j+1)%n]]) / 2\n        dist_improvement += (distance_matrix_2[new_solution[i-1], new_solution[j]] + distance_matrix_2[new_solution[i], new_solution[(j+1)%n]] -\n                            distance_matrix_2[new_solution[i-1], new_solution[i]] - distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]) / 2\n\n        # Pareto front-guided swap probability\n        swap_prob = 0.5 + 0.5 * (obj_diff / (np.max(objectives[:, 0]) - np.min(objectives[:, 1]) + 1e-8))\n        if (dist_improvement < 0 and np.random.random() < swap_prob) or np.random.random() < 0.1 * (1 - swap_prob):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Multi-stage validation\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n    else:\n        # Additional validation against instance coordinates\n        for i in range(n):\n            if not np.array_equal(instance[new_solution[i]], instance[base_solution[i]]):\n                new_solution = base_solution.copy()\n                break\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines dominance-aware selection with dynamic segment inversion and Pareto-front gap-biased edge swaps to generate high-quality neighbors. It prioritizes solutions with better combined objectives, dynamically adjusts segment sizes based on dominance rank, and performs edge swaps biased toward regions with high crowding distances or Pareto front gaps, while ensuring feasibility through multi-objective validation. The algorithm balances exploration and exploitation through adaptive segment manipulation and targeted edge operations.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using dominance-aware selection\n    objectives = np.array([obj for (sol, obj) in archive])\n    dominance = np.argsort(np.sum(objectives, axis=1))\n    selected_idx = np.random.choice(dominance[:min(5, len(archive))])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment inversion based on dominance\n    segment_size = max(2, int(np.random.random() * n * (1 - (selected_idx / len(archive)))))\n    start = np.random.randint(0, n - segment_size)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Pareto-front gap-biased edge swaps\n    for _ in range(3):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i == 0 or j == n-1:\n            continue\n\n        # Calculate crowding impact\n        crowding_before = (distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]] +\n                         distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]) / 2\n        crowding_after = (distance_matrix_1[new_solution[i-1], new_solution[j]] + distance_matrix_1[new_solution[i], new_solution[(j+1)%n]] +\n                         distance_matrix_2[new_solution[i-1], new_solution[j]] + distance_matrix_2[new_solution[i], new_solution[(j+1)%n]]) / 2\n\n        # Calculate Pareto gap\n        pareto_gap = (objectives[selected_idx, 0] - objectives[selected_idx, 1]) / (np.max(objectives, axis=0)[0] - np.min(objectives, axis=0)[1] + 1e-8)\n\n        if (crowding_after < crowding_before and np.random.random() < 0.5 + 0.5 * pareto_gap) or np.random.random() < 0.2 * (1 - pareto_gap):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Multi-objective validation\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 306,
        "algorithm": "The algorithm selects promising solutions from the archive using dominance-based ranking, then applies adaptive segment relinking and Pareto-optimal edge flips to generate neighbors, prioritizing segments and edges that improve both objectives while ensuring feasibility through dominance validation. The segment size and operations are dynamically adjusted based on the solution's position in the archive, while edge flips are biased toward Pareto improvements.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    dominance = np.argsort(np.sum(objectives, axis=1))\n    selected_idx = np.random.choice(dominance[:min(3, len(archive))])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive dominance-weighted segment relinking\n    segment_size = max(2, int(np.random.random() * n * (1 - (selected_idx / len(archive))**2)))\n    start = np.random.randint(0, n - segment_size)\n    segment = new_solution[start:start+segment_size]\n    if np.random.random() < 0.7:\n        segment = np.concatenate([segment[:1], segment[1:][::-1]])\n    else:\n        segment = np.roll(segment, 1)\n    new_solution[start:start+segment_size] = segment\n\n    # Pareto-optimal edge flips\n    for _ in range(2):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i == 0 or j == n-1:\n            continue\n\n        # Calculate multi-objective impact\n        obj_before = (distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]],\n                      distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]])\n        obj_after = (distance_matrix_1[new_solution[i-1], new_solution[j]] + distance_matrix_1[new_solution[i], new_solution[(j+1)%n]],\n                     distance_matrix_2[new_solution[i-1], new_solution[j]] + distance_matrix_2[new_solution[i], new_solution[(j+1)%n]])\n\n        # Check Pareto dominance\n        if (obj_after[0] <= obj_before[0] and obj_after[1] < obj_before[1]) or (obj_after[0] < obj_before[0] and obj_after[1] <= obj_before[1]):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Dominance validation\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8452589819051036,
            0.38428372144699097
        ],
        "raw_score": [
            5.832194982415331,
            6.013774285246222
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    dominance = np.argsort(np.sum(objectives, axis=1))\n    selected_idx = np.random.choice(dominance[:min(3, len(archive))])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive dominance-weighted segment relinking\n    segment_size = max(2, int(np.random.random() * n * (1 - (selected_idx / len(archive))**2)))\n    start = np.random.randint(0, n - segment_size)\n    segment = new_solution[start:start+segment_size]\n    if np.random.random() < 0.7:\n        segment = np.concatenate([segment[:1], segment[1:][::-1]])\n    else:\n        segment = np.roll(segment, 1)\n    new_solution[start:start+segment_size] = segment\n\n    # Pareto-optimal edge flips\n    for _ in range(2):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i == 0 or j == n-1:\n            continue\n\n        # Calculate multi-objective impact\n        obj_before = (distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]],\n                      distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]])\n        obj_after = (distance_matrix_1[new_solution[i-1], new_solution[j]] + distance_matrix_1[new_solution[i], new_solution[(j+1)%n]],\n                     distance_matrix_2[new_solution[i-1], new_solution[j]] + distance_matrix_2[new_solution[i], new_solution[(j+1)%n]])\n\n        # Check Pareto dominance\n        if (obj_after[0] <= obj_before[0] and obj_after[1] < obj_before[1]) or (obj_after[0] < obj_before[0] and obj_after[1] <= obj_before[1]):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Dominance validation\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects the best solution from the archive (prioritizing combined objective scores) and applies a hybrid local search combining random node insertions and segment shifts, ensuring feasibility by validating tour uniqueness and completeness. It adaptively adjusts parameters to explore diverse neighborhoods while falling back to simpler operations if needed. The method prioritizes exploration by randomly perturbing segments and nodes, balancing exploration with feasibility checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the best combined objective score\n    archive.sort(key=lambda x: x[1][0] + x[1][1])\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: combine node insertions and segment shifts\n    # Step 1: Randomly select a node to insert elsewhere\n    node = np.random.choice(new_solution)\n    idx = np.where(new_solution == node)[0][0]\n    new_solution = np.delete(new_solution, idx)\n    insert_pos = np.random.randint(0, n)\n    new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Step 2: Randomly select a segment to shift\n    segment_size = np.random.randint(2, min(5, n))\n    start = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[start:start+segment_size]\n    new_solution = np.delete(new_solution, np.s_[start:start+segment_size])\n    insert_pos = np.random.randint(0, n - segment_size + 1)\n    new_solution = np.insert(new_solution, insert_pos, segment)\n\n    # Ensure the solution remains valid (no duplicates and all nodes visited)\n    if len(np.unique(new_solution)) != n:\n        # If invalid, revert to a simpler node insertion\n        new_solution = base_solution.copy()\n        node = np.random.choice(new_solution)\n        idx = np.where(new_solution == node)[0][0]\n        new_solution = np.delete(new_solution, idx)\n        insert_pos = np.random.randint(0, n)\n        new_solution = np.insert(new_solution, insert_pos, node)\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with weighted randomness favoring better objectives, then applies a hybrid local search combining node swapping (40% chance) and segment insertion (60% chance) for 15 iterations, ensuring feasibility by validating and repairing the tour if nodes are missing. The selection prioritizes solutions with lower objective values, while the local search explores diverse modifications to escape local optima.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    objectives = [obj for _, obj in archive]\n    min_obj1 = min(o[0] for o in objectives)\n    min_obj2 = min(o[1] for o in objectives)\n    weights = [(min_obj1 / o[0] + min_obj2 / o[1]) for o in objectives]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine node swapping and segment insertion\n    n = len(new_solution)\n    for _ in range(15):  # Increased iterations\n        # Randomly select two distinct edges to modify\n        a, b, c, d = sorted(random.sample(range(n), 4))\n\n        # Node swapping: swap two nodes\n        if random.random() < 0.4:\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n        # Segment insertion: move a segment between two random positions\n        else:\n            segment = new_solution[a:b]\n            new_solution = np.concatenate([new_solution[:c], segment, new_solution[b:c], new_solution[b:]])\n\n    # Ensure the solution remains a valid tour (visits each node exactly once)\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        # Recover feasibility by reinserting missing nodes\n        missing_nodes = np.setdiff1d(np.arange(n), unique_nodes)\n        for node in missing_nodes:\n            pos = random.randint(0, n-1)\n            new_solution = np.insert(new_solution, pos, node)\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the archive using Pareto dominance and diversity, then applies adaptive segment insertion with dynamic length and biased edge swaps prioritizing objective improvement, combining crowding-aware segment reversal and opportunistic edge swaps to generate high-quality neighbors while maintaining feasibility. The selection process favors top solutions, while the local search dynamically adjusts segment lengths and edge swaps based on objective improvements, with validation ensuring feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using Pareto dominance and diversity\n    objectives = np.array([obj for (sol, obj) in archive])\n    front = np.argsort(objectives[:, 0] + objectives[:, 1])[:min(3, len(archive))]  # Top solutions\n    selected_idx = np.random.choice(front)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive segment insertion with dynamic length\n    segment_length = max(3, int(np.random.random() * (n // 3)))\n    start = np.random.randint(0, n - segment_length + 1)\n    segment = new_solution[start:start+segment_length]\n\n    # Insert segment at a different position\n    insert_pos = np.random.randint(0, n - segment_length + 1)\n    if insert_pos != start:\n        new_solution = np.concatenate([\n            new_solution[:insert_pos],\n            segment,\n            np.delete(new_solution, np.arange(start, start+segment_length))\n        ])\n\n    # Biased edge swaps prioritizing objective improvement\n    for _ in range(2):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == 0 or b == n-1:\n            continue\n\n        # Calculate objective improvement\n        obj_before = (distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] +\n                      distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]) / 2\n        obj_after = (distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] +\n                    distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]) / 2\n\n        if obj_after < obj_before * 0.95 or np.random.random() < 0.2:\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using dominance-aware weighted random selection\n    objectives = np.array([obj for (sol, obj) in archive])\n    ranks = np.argsort(objectives[:, 0] + objectives[:, 1])\n    weights = 1.0 / (np.arange(len(ranks)) + 1)  # Higher weight for better solutions\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate dominance score for adaptive behavior\n    dominance_score = (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.max(objectives) + 1e-8)\n\n    # Dynamic segment inversion with size based on dominance\n    segment_size = max(2, min(n//2, int(np.random.normal(n//3, n//4))))\n    if np.random.random() < 0.7 * (1 - dominance_score):\n        start = np.random.randint(0, n - segment_size + 1)\n        new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Pareto-gap biased edge swaps\n    for _ in range(5):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == 0 or b == n-1:\n            continue\n\n        # Calculate Pareto gap for both objectives\n        gap_before = (distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] +\n                    distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]) / 2\n        gap_after = (distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] +\n                    distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]) / 2\n\n        if gap_after < gap_before * 0.9 or np.random.random() < 0.4 * dominance_score:\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Segment rotation for further exploration\n    if np.random.random() < 0.5 * (1 - dominance_score):\n        k = np.random.randint(1, n)\n        new_solution = np.roll(new_solution, k)\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using crowding-distance weighted randomness to prioritize less crowded regions of the Pareto front, then applies adaptive segment inversion and Pareto-gap biased edge swaps to generate high-quality neighbors while maintaining feasibility. It dynamically adjusts segment sizes and swap probabilities based on dominance rank, favoring more promising solutions.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using crowding-distance weighted randomness\n    objectives = np.array([obj for (sol, obj) in archive])\n    fronts = np.argsort(objectives[:, 0] + objectives[:, 1])\n    crowding_distances = np.zeros(len(archive))\n    for i in range(len(archive)):\n        left = max(0, i-1)\n        right = min(len(archive)-1, i+1)\n        crowding_distances[i] = np.sum(np.abs(objectives[i] - objectives[left]) + np.abs(objectives[i] - objectives[right]))\n\n    weights = crowding_distances / np.sum(crowding_distances)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Calculate dominance rank\n    ranks = np.argsort(objectives[:, 0] + objectives[:, 1])\n    dominance_rank = np.where(ranks == selected_idx)[0][0] / len(archive)\n\n    # Adaptive segment inversion\n    segment_size = max(2, min(n//2, int(np.random.normal(n//3, n//4) * (1 - dominance_rank))))\n    start = np.random.randint(0, n - segment_size + 1)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Pareto-gap biased edge swaps\n    for _ in range(3):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == 0 or b == n-1:\n            continue\n\n        # Calculate Pareto gap for both objectives\n        gap_before = (distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] +\n                    distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]) / 2\n        gap_after = (distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] +\n                    distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]) / 2\n\n        if gap_after < gap_before * 0.9 or np.random.random() < 0.3 * (1 - dominance_rank):\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm combines dominance-aware selection (prioritizing solutions with better combined objective scores and higher crowding distances) with a novel \"multi-objective segment fusion\" operator that merges or swaps segments of the tour to reduce gaps between objectives, while ensuring feasibility through adaptive reinsertion. The selection process balances exploration (via crowding distance) and exploitation (via dominance rank), while the segment fusion dynamically adjusts segment sizes and operations based on potential objective improvements.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: crowding distance and dominance rank\n    objectives = np.array([obj for (sol, obj) in archive])\n    ranks = np.argsort(objectives[:, 0] + objectives[:, 1])\n    gaps = np.abs(objectives[:, 0] - objectives[:, 1])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(len(archive)):\n        if i == 0 or i == len(archive)-1:\n            crowding_distances[i] = float('inf')\n        else:\n            crowding_distances[i] = gaps[i] + (objectives[i+1, 0] - objectives[i-1, 0]) + (objectives[i+1, 1] - objectives[i-1, 1])\n\n    weighted_scores = ranks + 0.3 * crowding_distances\n    selected_idx = np.random.choice(np.argsort(weighted_scores)[:min(3, len(archive))])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Multi-objective segment fusion\n    segment_size = max(2, int(n / (ranks[selected_idx] + 2)))\n    start1 = np.random.randint(0, n - segment_size + 1)\n    start2 = np.random.randint(0, n - segment_size + 1)\n\n    segment1 = new_solution[start1:start1+segment_size]\n    segment2 = new_solution[start2:start2+segment_size]\n\n    # Calculate potential gap reduction\n    def calculate_gap(seg):\n        total_gap = 0\n        for i in range(len(seg)-1):\n            total_gap += abs(distance_matrix_1[seg[i], seg[i+1]] - distance_matrix_2[seg[i], seg[i+1]])\n        return total_gap\n\n    gap1 = calculate_gap(segment1)\n    gap2 = calculate_gap(segment2)\n\n    if gap1 > gap2:\n        # Merge segments if it reduces the maximum gap\n        merged_segment = np.concatenate([segment1, segment2])\n        new_solution = np.concatenate([\n            new_solution[:start1],\n            merged_segment,\n            new_solution[start1+segment_size:]\n        ])\n    else:\n        # Swap segments if it improves balance\n        new_solution[start1:start1+segment_size] = segment2\n        new_solution[start2:start2+segment_size] = segment1\n\n    # Adaptive segment reinsertion for feasibility\n    if len(set(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        segment = np.array(list(missing))\n        insert_pos = np.random.randint(0, n)\n        new_solution = np.concatenate([\n            new_solution[:insert_pos],\n            segment,\n            new_solution[insert_pos:]\n        ])\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic for the bi-TSP, designed to maximize innovation and quality:\n\n- **Keywords**: Dominance-aware inversion, gap-biased swaps, crowding-distance selection, adaptive segment sizing.\n- **Advice**: Select a parent via crowding-distance-weighted randomness, invert a segment sized inversely to dominance rank, then perform edge swaps prioritizing Pareto-front gaps.\n- **Avoid**: Fixed segment lengths or static operators; instead, dynamically adjust segment size and bias swaps toward objective gaps.\n- **Explanation**: This hybrid approach balances exploration/exploitation by dynamically adapting to multi-objective dominance, ensuring feasible solutions while diversifying the search space. \ud83d\ude80\n\n**Step-by-step reasoning**:\n1. **Selection**: Use crowding distance to prioritize solutions in less-explored regions of the Pareto front.\n2. **Inversion**: Adapt segment size inversely to dominance rank to balance local and global search.\n3. **Swaps**: Bias edge swaps toward gaps in the Pareto front to focus improvement efforts.\n4. **Feasibility**: Dynamically adjust operators to ensure all generated solutions remain valid TSP tours.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 307,
        "algorithm": "The algorithm selects a solution from the archive using crowding-distance-weighted randomness to prioritize diverse, non-dominated regions, then applies adaptive segment inversion (sized inversely to dominance rank) and gap-biased edge swaps to minimize objective gaps while maintaining feasibility, ensuring high-quality neighbors through dominance-aware local search. The method balances exploration via segment inversion and exploitation via gap-biased swaps, with validation to preserve solution feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using crowding-distance weighted randomness\n    objectives = np.array([obj for (sol, obj) in archive])\n    fronts = np.argsort(objectives[:, 0] + objectives[:, 1])\n    crowding_distances = np.zeros(len(archive))\n    for i in range(len(archive)):\n        left = max(0, i-1)\n        right = min(len(archive)-1, i+1)\n        crowding_distances[i] = np.sum(np.abs(objectives[i] - objectives[left]) + np.abs(objectives[i] - objectives[right]))\n\n    weights = crowding_distances / np.sum(crowding_distances)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Calculate dominance rank\n    ranks = np.argsort(objectives[:, 0] + objectives[:, 1])\n    dominance_rank = np.where(ranks == selected_idx)[0][0] / len(archive)\n\n    # Adaptive segment inversion (size inversely proportional to dominance rank)\n    segment_size = max(2, min(n//2, int(n / (dominance_rank * 10 + 1))))\n    start = np.random.randint(0, n - segment_size + 1)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Gap-biased edge swaps (prioritize reducing objective gaps)\n    for _ in range(3):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == 0 or b == n-1:\n            continue\n\n        # Calculate gap before and after swap\n        gap_before = abs(distance_matrix_1[new_solution[a-1], new_solution[a]] - distance_matrix_2[new_solution[a-1], new_solution[a]]) + \\\n                     abs(distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] - distance_matrix_2[new_solution[b], new_solution[(b+1)%n]])\n        gap_after = abs(distance_matrix_1[new_solution[a-1], new_solution[b]] - distance_matrix_2[new_solution[a-1], new_solution[b]]) + \\\n                    abs(distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] - distance_matrix_2[new_solution[a], new_solution[(b+1)%n]])\n\n        if gap_after < gap_before * 0.95 or np.random.random() < 0.3 * (1 - dominance_rank):\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8719901172408048,
            0.41279447078704834
        ],
        "raw_score": [
            7.067986992289768,
            7.196190640938942
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using crowding-distance weighted randomness\n    objectives = np.array([obj for (sol, obj) in archive])\n    fronts = np.argsort(objectives[:, 0] + objectives[:, 1])\n    crowding_distances = np.zeros(len(archive))\n    for i in range(len(archive)):\n        left = max(0, i-1)\n        right = min(len(archive)-1, i+1)\n        crowding_distances[i] = np.sum(np.abs(objectives[i] - objectives[left]) + np.abs(objectives[i] - objectives[right]))\n\n    weights = crowding_distances / np.sum(crowding_distances)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Calculate dominance rank\n    ranks = np.argsort(objectives[:, 0] + objectives[:, 1])\n    dominance_rank = np.where(ranks == selected_idx)[0][0] / len(archive)\n\n    # Adaptive segment inversion (size inversely proportional to dominance rank)\n    segment_size = max(2, min(n//2, int(n / (dominance_rank * 10 + 1))))\n    start = np.random.randint(0, n - segment_size + 1)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Gap-biased edge swaps (prioritize reducing objective gaps)\n    for _ in range(3):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == 0 or b == n-1:\n            continue\n\n        # Calculate gap before and after swap\n        gap_before = abs(distance_matrix_1[new_solution[a-1], new_solution[a]] - distance_matrix_2[new_solution[a-1], new_solution[a]]) + \\\n                     abs(distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] - distance_matrix_2[new_solution[b], new_solution[(b+1)%n]])\n        gap_after = abs(distance_matrix_1[new_solution[a-1], new_solution[b]] - distance_matrix_2[new_solution[a-1], new_solution[b]]) + \\\n                    abs(distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] - distance_matrix_2[new_solution[a], new_solution[(b+1)%n]])\n\n        if gap_after < gap_before * 0.95 or np.random.random() < 0.3 * (1 - dominance_rank):\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "elitist"
    }
]