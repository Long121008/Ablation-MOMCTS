[
    {
        "algorithm": "The algorithm selects the best solution from the archive (prioritizing combined objective scores) and applies a hybrid local search combining random node insertions and segment shifts, ensuring feasibility by validating tour uniqueness and completeness. It adaptively adjusts parameters to explore diverse neighborhoods while falling back to simpler operations if needed. The method prioritizes exploration by randomly perturbing segments and nodes, balancing exploration with feasibility checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the best combined objective score\n    archive.sort(key=lambda x: x[1][0] + x[1][1])\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: combine node insertions and segment shifts\n    # Step 1: Randomly select a node to insert elsewhere\n    node = np.random.choice(new_solution)\n    idx = np.where(new_solution == node)[0][0]\n    new_solution = np.delete(new_solution, idx)\n    insert_pos = np.random.randint(0, n)\n    new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Step 2: Randomly select a segment to shift\n    segment_size = np.random.randint(2, min(5, n))\n    start = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[start:start+segment_size]\n    new_solution = np.delete(new_solution, np.s_[start:start+segment_size])\n    insert_pos = np.random.randint(0, n - segment_size + 1)\n    new_solution = np.insert(new_solution, insert_pos, segment)\n\n    # Ensure the solution remains valid (no duplicates and all nodes visited)\n    if len(np.unique(new_solution)) != n:\n        # If invalid, revert to a simpler node insertion\n        new_solution = base_solution.copy()\n        node = np.random.choice(new_solution)\n        idx = np.where(new_solution == node)[0][0]\n        new_solution = np.delete(new_solution, idx)\n        insert_pos = np.random.randint(0, n)\n        new_solution = np.insert(new_solution, insert_pos, node)\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9590416592200175,
            0.22849512100219727
        ],
        "raw_score": [
            6.281348843659081,
            7.059226482841522
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects promising solutions from an archive based on normalized objective scores and structural diversity, then applies a hybrid local search combining segment relocations and dynamic edge swaps, adaptively choosing operators based on solution quality and local topology to generate improved neighbors while ensuring feasibility. It prioritizes segment moves for higher-quality solutions and uses topology-aware edge swaps for others, with fallback to the original solution if invalidity occurs.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic solution selection: prioritize solutions with high normalized objectives and low structural redundancy\n    objectives = np.array([obj for (sol, obj) in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    structural_diversity = np.array([len(set(sol)) for (sol, _) in archive])  # Simple measure of structural diversity\n\n    # Combine normalized objectives and structural diversity for selection\n    scores = normalized.sum(axis=1) * (1 + 1 / (structural_diversity + 1e-8))\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search with adaptive operator selection\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Determine operator selection probabilities based on solution quality\n    sol_quality = (normalized[selected_idx][0] + normalized[selected_idx][1]) / 2\n    segment_prob = max(0.1, sol_quality * 0.8)  # Higher quality solutions favor segment moves\n    swap_prob = 1 - segment_prob\n\n    if np.random.random() < segment_prob:\n        # Adaptive segment relocation\n        segment_length = min(3, max(1, int(np.random.random() * n // 3)))\n        start_pos = np.random.randint(n)\n        end_pos = (start_pos + segment_length) % n\n\n        if start_pos < end_pos:\n            segment = new_solution[start_pos:end_pos]\n            remaining = np.concatenate([new_solution[:start_pos], new_solution[end_pos:]])\n        else:\n            segment = np.concatenate([new_solution[start_pos:], new_solution[:end_pos]])\n            remaining = new_solution[end_pos:start_pos]\n\n        # Find best insertion position considering both objectives\n        best_pos = 0\n        best_cost = float('inf')\n\n        for i in range(len(remaining)):\n            candidate = np.concatenate([remaining[:i], segment, remaining[i:]])\n            cost1 = sum(distance_matrix_1[candidate[j], candidate[(j+1)%len(candidate)]] for j in range(len(candidate)))\n            cost2 = sum(distance_matrix_2[candidate[j], candidate[(j+1)%len(candidate)]] for j in range(len(candidate)))\n            total_cost = cost1 + cost2\n\n            if total_cost < best_cost:\n                best_cost = total_cost\n                best_pos = i\n\n        new_solution = np.concatenate([remaining[:best_pos], segment, remaining[best_pos:]])\n    else:\n        # Dynamic edge swap with topology-aware selection\n        a, b, c = sorted(random.sample(range(n), 3))\n\n        # Determine swap type based on local topology\n        dist1 = distance_matrix_1[new_solution[a], new_solution[b]] + distance_matrix_1[new_solution[c], new_solution[(a-1)%n]]\n        dist2 = distance_matrix_2[new_solution[a], new_solution[b]] + distance_matrix_2[new_solution[c], new_solution[(a-1)%n]]\n\n        if dist1 + dist2 > distance_matrix_1[new_solution[a], new_solution[c]] + distance_matrix_1[new_solution[b], new_solution[(a-1)%n]] + \\\n           distance_matrix_2[new_solution[a], new_solution[c]] + distance_matrix_2[new_solution[b], new_solution[(a-1)%n]]:\n            # Perform the swap if it improves both objectives\n            new_solution[a], new_solution[c] = new_solution[c], new_solution[a]\n\n    # Ensure the solution is valid (no duplicates)\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9874616550993895,
            0.7441497445106506
        ],
        "raw_score": [
            10.517218484537604,
            10.642625561096308
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive with weighted randomness favoring better objectives, then applies a hybrid local search combining node swapping (40% chance) and segment insertion (60% chance) for 15 iterations, ensuring feasibility by validating and repairing the tour if nodes are missing. The selection prioritizes solutions with lower objective values, while the local search explores diverse modifications to escape local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    objectives = [obj for _, obj in archive]\n    min_obj1 = min(o[0] for o in objectives)\n    min_obj2 = min(o[1] for o in objectives)\n    weights = [(min_obj1 / o[0] + min_obj2 / o[1]) for o in objectives]\n    selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: combine node swapping and segment insertion\n    n = len(new_solution)\n    for _ in range(15):  # Increased iterations\n        # Randomly select two distinct edges to modify\n        a, b, c, d = sorted(random.sample(range(n), 4))\n\n        # Node swapping: swap two nodes\n        if random.random() < 0.4:\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n        # Segment insertion: move a segment between two random positions\n        else:\n            segment = new_solution[a:b]\n            new_solution = np.concatenate([new_solution[:c], segment, new_solution[b:c], new_solution[b:]])\n\n    # Ensure the solution remains a valid tour (visits each node exactly once)\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        # Recover feasibility by reinserting missing nodes\n        missing_nodes = np.setdiff1d(np.arange(n), unique_nodes)\n        for node in missing_nodes:\n            pos = random.randint(0, n-1)\n            new_solution = np.insert(new_solution, pos, node)\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9138960752940551,
            0.14283901453018188
        ],
        "raw_score": [
            10.419760007142234,
            10.631350875391004
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by prioritizing those with better balanced objectives (weighted 60% for the first and 40% for the second objective) and applies a hybrid local search combining edge swaps (70% probability) and segment reversals (50% probability) to generate a neighbor solution. If the generated solution is invalid, it reverts to a simpler edge swap to ensure feasibility. The approach balances exploration and exploitation by dynamically adjusting the search based on objective weights and prioritizing edge swaps for higher-quality solutions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with weighted objective score (prioritize better balance)\n    weights = np.array([0.6, 0.4])  # Weight for objectives\n    archive.sort(key=lambda x: np.dot(weights, x[1]))\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: edge swap + segment reversal\n    # Step 1: Edge swap with probability 0.7\n    if np.random.rand() < 0.7:\n        i, j = np.random.choice(n, size=2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 2: Segment reversal with probability 0.5\n    if np.random.rand() < 0.5:\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Validate solution\n    if len(np.unique(new_solution)) != n or len(new_solution) != n:\n        # If invalid, revert to single edge swap\n        new_solution = base_solution.copy()\n        i, j = np.random.choice(n, size=2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.962628363971866,
            0.3214622139930725
        ],
        "raw_score": [
            5.518734347771969,
            6.873537403646718
        ]
    },
    {
        "algorithm": "The algorithm combines crowding-distance-based selection with an adaptive hybrid local search that dynamically balances between large-segment shuffles (for exploration) and targeted edge swaps (for exploitation), guided by dominance levels to prioritize high-potential solutions while maintaining feasibility through validation. It adjusts segment sizes and swap probabilities based on dominance, ensuring a balance between exploration and exploitation in both objective spaces.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    front = np.argsort(objectives[:, 0] + objectives[:, 1])[:min(5, len(archive))]\n    selected_idx = np.random.choice(front)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Determine dominance level for adaptive behavior\n    dominance = (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.max(objectives, axis=0) + 1e-8)\n    dominance = np.mean(dominance)\n\n    # Dynamic segment size based on dominance\n    segment_size = max(2, int(np.random.random() * n * (1 - dominance)))\n\n    # Adaptive operator selection\n    if np.random.random() < 0.7 * (1 - dominance):\n        # Large-segment shuffle for exploration\n        start = np.random.randint(0, n - segment_size + 1)\n        segment = new_solution[start:start+segment_size]\n        remaining = np.concatenate([new_solution[:start], new_solution[start+segment_size:]])\n        best_pos = np.random.randint(0, len(remaining) + 1)\n        new_solution = np.concatenate([remaining[:best_pos], segment, remaining[best_pos:]])\n    else:\n        # Targeted edge swaps for exploitation\n        for _ in range(3):\n            a, b = sorted(np.random.choice(n, size=2, replace=False))\n            if a == 0 or b == n-1:\n                continue\n\n            # Calculate crowding impact\n            crowding_before = (distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] +\n                              distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]) / 2\n            crowding_after = (distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] +\n                            distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]) / 2\n\n            if crowding_after < crowding_before or np.random.random() < 0.3 * dominance:\n                new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Segment reversal for further exploration\n    if np.random.random() < 0.5 * (1 - dominance):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9687948536266036,
            0.3855568766593933
        ],
        "raw_score": [
            6.628736197152264,
            6.328462142450902
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection using crowding distance and Pareto dominance\n    objectives = np.array([obj for (sol, obj) in archive])\n    front_indices = np.argsort(objectives[:, 0] + objectives[:, 1])[:min(5, len(archive))]\n    crowding = np.zeros(len(front_indices))\n\n    for i, idx in enumerate(front_indices):\n        sol = archive[idx][0]\n        n = len(sol)\n        left = objectives[np.argsort(np.abs(objectives[:, 0] - objectives[idx, 0]))[1], 0] if len(objectives) > 1 else objectives[idx, 0]\n        right = objectives[np.argsort(np.abs(objectives[:, 0] - objectives[idx, 0]))[-1], 0] if len(objectives) > 1 else objectives[idx, 0]\n        crowding[i] = right - left\n\n    selected_idx = front_indices[np.argmax(crowding)]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid operator: dynamic segment shuffling with adaptive size and biased edge swaps\n    segment_size = max(2, min(n//3, int(np.random.normal(n//4, n//6))))\n    start = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[start:start+segment_size]\n    remaining = np.concatenate([new_solution[:start], new_solution[start+segment_size:]])\n\n    # Evaluate insertion positions considering both objectives\n    best_pos = 0\n    best_score = float('inf')\n\n    for pos in range(len(remaining)):\n        candidate = np.concatenate([remaining[:pos], segment, remaining[pos:]])\n        cost1 = sum(distance_matrix_1[candidate[j], candidate[(j+1)%len(candidate)]] for j in range(len(candidate)))\n        cost2 = sum(distance_matrix_2[candidate[j], candidate[(j+1)%len(candidate)]] for j in range(len(candidate)))\n        # Weighted crowding measure combining both objectives\n        crowding_score = (cost1 + cost2) / (np.std(cost1) + np.std(cost2) + 1e-8)\n\n        if crowding_score < best_score:\n            best_score = crowding_score\n            best_pos = pos\n\n    new_solution = np.concatenate([remaining[:best_pos], segment, remaining[best_pos:]])\n\n    # Biased edge swaps prioritizing high-crowding regions\n    for _ in range(5):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == 0 or b == n-1:\n            continue\n\n        # Calculate crowding impact for both objectives\n        crowding_before = (distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] +\n                          distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]) / 2\n        crowding_after = (distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] +\n                         distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]) / 2\n\n        if crowding_after < crowding_before * 0.9 or np.random.random() < 0.25:\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Segment reversal with adaptive probability based on tour diversity\n    if np.random.random() < 0.6:\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9941365231183279,
            1.137162983417511
        ],
        "raw_score": [
            5.0253070446397725,
            7.239715541016342
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the archive using Pareto dominance and diversity, then applies adaptive segment insertion with dynamic length and biased edge swaps prioritizing objective improvement, combining crowding-aware segment reversal and opportunistic edge swaps to generate high-quality neighbors while maintaining feasibility. The selection process favors top solutions, while the local search dynamically adjusts segment lengths and edge swaps based on objective improvements, with validation ensuring feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using Pareto dominance and diversity\n    objectives = np.array([obj for (sol, obj) in archive])\n    front = np.argsort(objectives[:, 0] + objectives[:, 1])[:min(3, len(archive))]  # Top solutions\n    selected_idx = np.random.choice(front)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive segment insertion with dynamic length\n    segment_length = max(3, int(np.random.random() * (n // 3)))\n    start = np.random.randint(0, n - segment_length + 1)\n    segment = new_solution[start:start+segment_length]\n\n    # Insert segment at a different position\n    insert_pos = np.random.randint(0, n - segment_length + 1)\n    if insert_pos != start:\n        new_solution = np.concatenate([\n            new_solution[:insert_pos],\n            segment,\n            np.delete(new_solution, np.arange(start, start+segment_length))\n        ])\n\n    # Biased edge swaps prioritizing objective improvement\n    for _ in range(2):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == 0 or b == n-1:\n            continue\n\n        # Calculate objective improvement\n        obj_before = (distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] +\n                      distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]) / 2\n        obj_after = (distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] +\n                    distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]) / 2\n\n        if obj_after < obj_before * 0.95 or np.random.random() < 0.2:\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6742482784628107,
            0.1022036075592041
        ],
        "raw_score": [
            6.976224185653362,
            7.299964776754653
        ]
    },
    {
        "algorithm": "The algorithm combines adaptive Pareto selection with a hybrid local search that prioritizes spatial coherence, multi-objective edge flips, and probabilistic segment rotations, dynamically adjusting segment sizes based on spatial variance and applying edge flips biased toward high-crowding regions while occasionally rotating segments to balance exploration and exploitation. It ensures feasibility by validating solutions and falls back to the original if invalid, while leveraging both objective-specific distance matrices and spatial distribution metrics to guide improvements.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    crowding = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = float('inf')\n        crowding[sorted_idx[-1]] = float('inf')\n        for i in range(1, len(archive)-1):\n            crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m] + 1e-8)\n\n    selected_idx = np.random.choice(np.argsort(-crowding)[:min(3, len(archive))])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Calculate spatial variance and dynamic segment size\n    coords1 = instance[base_solution, :2]\n    coords2 = instance[base_solution, 2:]\n    var1 = np.var(coords1, axis=0)\n    var2 = np.var(coords2, axis=0)\n    segment_size = max(2, min(n // 4, int((var1[0] + var1[1] + var2[0] + var2[1]) / 4 / np.mean(distance_matrix_1) * n)))\n\n    # Spatial coherence-based segment relocation\n    start = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[start:start+segment_size]\n    remaining = np.concatenate([new_solution[:start], new_solution[start+segment_size:]])\n\n    best_pos = 0\n    best_score = float('inf')\n\n    for pos in range(len(remaining)):\n        candidate = np.concatenate([remaining[:pos], segment, remaining[pos:]])\n        cost1 = sum(distance_matrix_1[candidate[j], candidate[(j+1)%len(candidate)]] for j in range(len(candidate)))\n        cost2 = sum(distance_matrix_2[candidate[j], candidate[(j+1)%len(candidate)]] for j in range(len(candidate)))\n\n        # Spatial coherence score\n        centroid1 = np.mean(instance[candidate, :2], axis=0)\n        centroid2 = np.mean(instance[candidate, 2:], axis=0)\n        spatial_score = (np.sum((instance[candidate, :2] - centroid1) ** 2) + np.sum((instance[candidate, 2:] - centroid2) ** 2)) / len(candidate)\n\n        score = (cost1 + cost2) / (segment_size * (spatial_score + 1e-8))\n\n        if score < best_score:\n            best_score = score\n            best_pos = pos\n\n    new_solution = np.concatenate([remaining[:best_pos], segment, remaining[best_pos:]])\n\n    # Multi-objective-aware edge flips\n    for _ in range(5):\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        if i == j or abs(i - j) < 2:\n            continue\n\n        # Calculate crowding impact\n        edges = [(new_solution[(i-1)%n], new_solution[i]), (new_solution[i], new_solution[(i+1)%n]),\n                 (new_solution[(j-1)%n], new_solution[j]), (new_solution[j], new_solution[(j+1)%n])]\n        crowding_before = sum((distance_matrix_1[u, v] + distance_matrix_2[u, v]) for u, v in edges) / 4\n\n        # Flip edges\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n        edges_flipped = [(new_solution[(i-1)%n], new_solution[i]), (new_solution[i], new_solution[(i+1)%n]),\n                        (new_solution[(j-1)%n], new_solution[j]), (new_solution[j], new_solution[(j+1)%n])]\n        crowding_after = sum((distance_matrix_1[u, v] + distance_matrix_2[u, v]) for u, v in edges_flipped) / 4\n\n        if crowding_after > crowding_before * 1.1 and np.random.random() > 0.3:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Probabilistic segment rotations\n    if np.random.random() < 0.4:\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        rotation = np.random.randint(1, min(4, b - a + 1))\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.972452912576687,
            1.5621699690818787
        ],
        "raw_score": [
            6.927862567234251,
            6.406807227532902
        ]
    },
    {
        "algorithm": "The algorithm selects a parent solution from the archive using crowding-distance-weighted randomness, then applies dominance-aware segment inversion (with segment size adapted to the solution's dominance level) followed by edge swaps prioritizing high-crowding regions in both objective spaces, ensuring feasibility through validation. The selection prioritizes solutions with high crowding distance, while the local search adapts its intensity based on dominance, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select parent solution using crowding-distance-weighted randomness\n    objectives = np.array([obj for (sol, obj) in archive])\n    front_indices = np.argsort(objectives[:, 0] + objectives[:, 1])[:min(5, len(archive))]\n    crowding = np.zeros(len(front_indices))\n\n    for i, idx in enumerate(front_indices):\n        sol = archive[idx][0]\n        n = len(sol)\n        left = objectives[np.argsort(np.abs(objectives[:, 0] - objectives[idx, 0]))[1], 0] if len(objectives) > 1 else objectives[idx, 0]\n        right = objectives[np.argsort(np.abs(objectives[:, 0] - objectives[idx, 0]))[-1], 0] if len(objectives) > 1 else objectives[idx, 0]\n        crowding[i] = right - left\n\n    selected_idx = front_indices[np.argmax(crowding)]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate dominance level for segment size adaptation\n    dominance = (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.max(objectives, axis=0) + 1e-8)\n    dominance = np.mean(dominance)\n\n    # Adaptive segment inversion\n    segment_size = max(2, int(np.random.random() * n * (1 - dominance)))\n    start = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[start:start+segment_size]\n\n    # Invert the segment with probability based on dominance\n    if np.random.random() < 0.7 * (1 - dominance):\n        segment = segment[::-1]\n\n    # Insert the segment at a different position\n    insert_pos = np.random.randint(0, n - segment_size + 1)\n    if insert_pos != start:\n        new_solution = np.concatenate([\n            new_solution[:insert_pos],\n            segment,\n            np.delete(new_solution, np.arange(start, start+segment_size))\n        ])\n\n    # Edge swaps prioritizing high-crowding regions\n    for _ in range(3):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == 0 or b == n-1:\n            continue\n\n        # Calculate crowding impact for both objectives\n        crowding_before = (distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] +\n                          distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]) / 2\n        crowding_after = (distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] +\n                        distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]) / 2\n\n        if crowding_after < crowding_before * 0.9 or np.random.random() < 0.3 * dominance:\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.636118110851297,
            0.15487730503082275
        ],
        "raw_score": [
            6.506512064015432,
            8.749241724349039
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution based on dominance and crowding distance\n    objectives = np.array([obj for (sol, obj) in archive])\n    pareto_front = np.lexsort((objectives[:, 1], objectives[:, 0]))\n    selected_idx = np.random.choice(pareto_front[:min(3, len(archive))])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(base_solution)\n    if n < 4:\n        return new_solution\n\n    # Dynamic segment inversion with dominance-aware size\n    dominance_rank = np.sum((objectives[:, 0] <= objectives[selected_idx, 0]) &\n                           (objectives[:, 1] <= objectives[selected_idx, 1]) &\n                           ((objectives[:, 0] < objectives[selected_idx, 0]) |\n                            (objectives[:, 1] < objectives[selected_idx, 1])))\n    segment_size = max(2, min(n//2, int(np.random.normal(n//4, n//6) * (1 + 0.2 * dominance_rank))))\n\n    start = np.random.randint(0, n - segment_size + 1)\n    new_solution[start:start+segment_size] = new_solution[start:start+segment_size][::-1]\n\n    # Crowding-aware edge swaps\n    for _ in range(3):\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        if a == 0 or b == n-1:\n            continue\n\n        # Calculate crowding impact\n        crowding_before = (distance_matrix_1[new_solution[a-1], new_solution[a]] +\n                          distance_matrix_1[new_solution[b], new_solution[(b+1)%n]] +\n                          distance_matrix_2[new_solution[a-1], new_solution[a]] +\n                          distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]) / 2\n        crowding_after = (distance_matrix_1[new_solution[a-1], new_solution[b]] +\n                         distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] +\n                         distance_matrix_2[new_solution[a-1], new_solution[b]] +\n                         distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]) / 2\n\n        if crowding_after < crowding_before * 0.95 or np.random.random() < 0.2:\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Validate solution\n    if len(set(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.943936697683537,
            0.27840763330459595
        ],
        "raw_score": [
            4.502489146487486,
            9.316550304096555
        ]
    }
]