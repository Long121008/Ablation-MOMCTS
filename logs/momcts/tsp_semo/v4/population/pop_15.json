[
    {
        "algorithm": "The heuristic selects the most promising solution from the archive (based on normalized combined objective scores) and applies a hybrid local search combining 3-opt moves with greedy edge insertion to generate a neighbor while ensuring feasibility. The algorithm prioritizes solutions with better combined performance and uses a mix of random and greedy operations to explore the solution space effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the best combined normalized objective score\n    def normalize_objectives(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n        return norm1 + norm2\n\n    best_solution = min(archive, key=lambda x: normalize_objectives(x[1][0], x[1][1]))[0].copy()\n\n    # Hybrid local search operator\n    def hybrid_local_search(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        # 3-opt move (randomly select 3 edges and reconnect them)\n        if n >= 4:\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segment1 = new_solution[:i]\n            segment2 = new_solution[i:j+1]\n            segment3 = new_solution[j+1:k+1]\n            segment4 = new_solution[k+1:]\n\n            # Try all possible reconnections\n            possible_solutions = [\n                np.concatenate([segment1, segment2[::-1], segment3, segment4]),\n                np.concatenate([segment1, segment3, segment2, segment4]),\n                np.concatenate([segment1, segment2, segment3[::-1], segment4]),\n                np.concatenate([segment1, segment3[::-1], segment2, segment4]),\n                np.concatenate([segment1, segment2[::-1], segment3[::-1], segment4]),\n                np.concatenate([segment1, segment3, segment2[::-1], segment4])\n            ]\n\n            # Select the best solution based on both objectives\n            def evaluate(sol):\n                cost1 = sum(distance_matrix_1[sol[i], sol[(i+1)%n]] for i in range(n))\n                cost2 = sum(distance_matrix_2[sol[i], sol[(i+1)%n]] for i in range(n))\n                return cost1 + cost2\n\n            best_new = min(possible_solutions, key=evaluate)\n            new_solution = best_new\n\n        # Greedy edge insertion (try to improve by inserting nodes in a better position)\n        for _ in range(3):  # Limit iterations to avoid excessive computation\n            i = np.random.randint(0, n)\n            node = new_solution[i]\n\n            # Remove the node\n            temp_solution = np.delete(new_solution, i)\n\n            # Find the best insertion position\n            best_pos = 0\n            best_cost = float('inf')\n\n            for pos in range(n-1):\n                candidate = np.insert(temp_solution, pos, node)\n                cost1 = sum(distance_matrix_1[candidate[i], candidate[(i+1)%(n-1)]] for i in range(n-1))\n                cost2 = sum(distance_matrix_2[candidate[i], candidate[(i+1)%(n-1)]] for i in range(n-1))\n                total_cost = cost1 + cost2\n\n                if total_cost < best_cost:\n                    best_cost = total_cost\n                    best_pos = pos\n\n            new_solution = np.insert(temp_solution, best_pos, node)\n\n        return new_solution\n\n    neighbor = hybrid_local_search(best_solution)\n    return neighbor\n\n",
        "score": [
            5.426902453633912,
            6.119995236995279
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive using a weighted combination of normalized objectives (prioritizing the second objective with a 0.6 weight), then applies a hybrid local search combining 5-opt moves with adaptive edge insertion, where the 5-opt operator evaluates all possible reconnections using adaptive weighting (0.7 for the first objective) and the edge insertion focuses on improving the second objective by inserting nodes in high-improvement regions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on normalized objectives (different weights)\n    def weighted_score(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n        return 0.4 * norm1 + 0.6 * norm2  # Different weighted toward second objective\n\n    selected_solution = min(archive, key=lambda x: weighted_score(x[1][0], x[1][1]))[0].copy()\n\n    # Hybrid 5-opt with adaptive edge insertion\n    def hybrid_local_search(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        # 5-opt move (randomly select 5 edges and reconnect)\n        if n >= 7:\n            i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:m+1],\n                new_solution[m+1:]\n            ]\n\n            # Generate all possible 5-opt reconnections\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[1], segments[4], segments[3], segments[2], segments[5]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4], segments[5]])\n            ]\n\n            # Evaluate with adaptive weighting (different weights)\n            def evaluate(sol):\n                cost1 = sum(distance_matrix_1[sol[i], sol[(i+1)%n]] for i in range(n))\n                cost2 = sum(distance_matrix_2[sol[i], sol[(i+1)%n]] for i in range(n))\n                return 0.7 * cost1 + 0.3 * cost2  # Different adaptive weighting\n\n            best_new = min(possible_solutions, key=evaluate)\n            new_solution = best_new\n\n        # Adaptive edge insertion (focus on second objective)\n        for _ in range(2):\n            # Select high-improvement region based on second objective\n            region_size = max(3, n // 4)\n            region_start = np.random.randint(0, n - region_size)\n            region = new_solution[region_start:region_start+region_size]\n\n            # Try inserting nodes within the region\n            for i in range(len(region)-1):\n                for j in range(i+1, len(region)):\n                    temp = new_solution.copy()\n                    node = temp[region_start+j]\n                    temp = np.delete(temp, region_start+j)\n                    insert_pos = np.random.randint(region_start, region_start+region_size)\n                    temp = np.insert(temp, insert_pos, node)\n\n                    # Check if improvement in second objective\n                    current_cost = sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                    new_cost = sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                    if new_cost < current_cost:\n                        new_solution = temp\n                        break\n\n        return new_solution\n\n    neighbor = hybrid_local_search(selected_solution)\n    return neighbor\n\n",
        "score": [
            7.754321393825167,
            4.665304336687817
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a weighted combination of normalized objectives (prioritizing the first objective more heavily) and applies a hybrid local search combining 4-opt with adaptive edge swapping and greedy edge insertion. It ensures feasibility by maintaining valid TSP tours throughout, with adaptive weighting favoring the first objective in both selection and local search operations. The solution is refined through iterative improvements that balance both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on normalized objectives\n    def weighted_score(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n        return 0.7 * norm1 + 0.3 * norm2  # Weighted toward first objective\n\n    selected_solution = min(archive, key=lambda x: weighted_score(x[1][0], x[1][1]))[0].copy()\n\n    # Hybrid local search combining 4-opt and adaptive edge swapping\n    def hybrid_local_search(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        # 4-opt move with adaptive weighting\n        if n >= 6:\n            i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:]\n            ]\n\n            # Generate all possible 4-opt reconnections\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n                np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4]])\n            ]\n\n            # Evaluate with adaptive weighting\n            def evaluate(sol):\n                cost1 = sum(distance_matrix_1[sol[i], sol[(i+1)%n]] for i in range(n))\n                cost2 = sum(distance_matrix_2[sol[i], sol[(i+1)%n]] for i in range(n))\n                return 0.6 * cost1 + 0.4 * cost2  # Adaptive weighting\n\n            best_new = min(possible_solutions, key=evaluate)\n            new_solution = best_new\n\n        # Adaptive edge swapping in high-improvement regions\n        for _ in range(3):\n            region_size = max(3, n // 5)\n            region_start = np.random.randint(0, n - region_size)\n            region = new_solution[region_start:region_start+region_size]\n\n            for i in range(len(region)-1):\n                for j in range(i+1, len(region)):\n                    temp = new_solution.copy()\n                    temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                    current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                                  sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                    new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                               sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                    if new_cost < current_cost:\n                        new_solution = temp\n                        break\n\n        # Greedy edge insertion\n        for _ in range(2):\n            i = np.random.randint(0, n)\n            node = new_solution[i]\n            temp_solution = np.delete(new_solution, i)\n\n            best_pos = 0\n            best_cost = float('inf')\n\n            for pos in range(n-1):\n                candidate = np.insert(temp_solution, pos, node)\n                cost1 = sum(distance_matrix_1[candidate[i], candidate[(i+1)%(n-1)]] for i in range(n-1))\n                cost2 = sum(distance_matrix_2[candidate[i], candidate[(i+1)%(n-1)]] for i in range(n-1))\n                total_cost = cost1 + cost2\n\n                if total_cost < best_cost:\n                    best_cost = total_cost\n                    best_pos = pos\n\n            new_solution = np.insert(temp_solution, best_pos, node)\n\n        return new_solution\n\n    neighbor = hybrid_local_search(selected_solution)\n    return neighbor\n\n",
        "score": [
            4.651765390545433,
            7.558972457057891
        ]
    },
    {
        "algorithm": "The algorithm dynamically selects a solution from the archive based on a balanced weighting of both objectives (60% first objective, 40% second), then applies a hybrid local search combining adaptive 3-opt moves with path relinking and greedy edge reversal, ensuring feasibility by only accepting improvements in either objective. The method prioritizes the first objective more heavily in selection and evaluation, while the local search explores constrained neighborhoods to maintain solution validity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic selection based on balanced objectives\n    def dynamic_score(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n        return 0.6 * norm1 + 0.4 * norm2  # Balanced weighting\n\n    selected_solution = min(archive, key=lambda x: dynamic_score(x[1][0], x[1][1]))[0].copy()\n\n    # Hybrid local search combining adaptive 3-opt and path relinking\n    def hybrid_local_search(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        # Adaptive 3-opt move\n        if n >= 5:\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:]\n            ]\n\n            # Generate all possible 3-opt reconnections\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3]]),\n                np.concatenate([segments[0], segments[3], segments[2], segments[1]])\n            ]\n\n            # Evaluate with balanced weighting\n            def evaluate(sol):\n                cost1 = sum(distance_matrix_1[sol[i], sol[(i+1)%n]] for i in range(n))\n                cost2 = sum(distance_matrix_2[sol[i], sol[(i+1)%n]] for i in range(n))\n                return 0.5 * cost1 + 0.5 * cost2\n\n            best_new = min(possible_solutions, key=evaluate)\n            new_solution = best_new\n\n        # Path relinking with objective-aware acceptance\n        for _ in range(2):\n            i = np.random.randint(0, n)\n            j = np.random.randint(0, n)\n            if i != j:\n                temp = new_solution.copy()\n                temp[i], temp[j] = temp[j], temp[i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                              sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                           sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                # Accept if better in either objective\n                if new_cost < current_cost:\n                    new_solution = temp\n\n        # Greedy edge reversal\n        for _ in range(2):\n            i = np.random.randint(0, n-1)\n            j = np.random.randint(i+1, n)\n            temp = new_solution.copy()\n            temp[i:j+1] = temp[i:j+1][::-1]\n\n            current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                          sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n            new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                       sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n            # Accept if better in either objective\n            if new_cost < current_cost:\n                new_solution = temp\n\n        return new_solution\n\n    neighbor = hybrid_local_search(selected_solution)\n    return neighbor\n\n",
        "score": [
            4.916729421433921,
            7.099183811604933
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using dynamic weighted scoring (prioritizing the first objective more heavily) and applies a hybrid local search combining 3-opt/5-opt moves with adaptive edge swapping. It evaluates improvements using Pareto-based criteria and falls back to the best candidate if no Pareto improvement is found, ensuring feasible TSP tours throughout all operations. The selection process favors solutions with better combined normalized performance, while the local search intelligently explores high-improvement regions in the solution space.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Dynamic weighted selection based on normalized objectives\n    def weighted_score(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n\n        # Dynamic weight based on archive diversity\n        avg_obj1 = sum(o[1][0] for o in archive) / len(archive)\n        avg_obj2 = sum(o[1][1] for o in archive) / len(archive)\n        weight1 = 0.7 if obj1 <= avg_obj1 else 0.5\n        weight2 = 0.3 if obj2 <= avg_obj2 else 0.5\n\n        return weight1 * norm1 + weight2 * norm2\n\n    selected_solution = min(archive, key=lambda x: weighted_score(x[1][0], x[1][1]))[0].copy()\n\n    # Hybrid local search combining 3-opt/5-opt with adaptive edge swapping\n    def hybrid_local_search(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        # 3-opt/5-opt move (randomly select 3 or 5 edges and reconnect)\n        if n >= 6:\n            k = np.random.choice([3, 5])\n            if k == 3 and n >= 4:\n                i, j, k = sorted(np.random.choice(n, 3, replace=False))\n                segments = [\n                    new_solution[:i],\n                    new_solution[i:j+1],\n                    new_solution[j+1:k+1],\n                    new_solution[k+1:]\n                ]\n\n                possible_solutions = [\n                    np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n                    np.concatenate([segments[0], segments[2], segments[1], segments[3]]),\n                    np.concatenate([segments[0], segments[1], segments[2][::-1], segments[3]]),\n                    np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]]),\n                    np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3]])\n                ]\n            else:  # 5-opt\n                i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n                segments = [\n                    new_solution[:i],\n                    new_solution[i:j+1],\n                    new_solution[j+1:k+1],\n                    new_solution[k+1:l+1],\n                    new_solution[l+1:m+1],\n                    new_solution[m+1:]\n                ]\n\n                possible_solutions = [\n                    np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n                    np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4], segments[5]]),\n                    np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n                    np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4], segments[5]])\n                ]\n\n            # Pareto-based evaluation\n            def evaluate(sol):\n                cost1 = sum(distance_matrix_1[sol[i], sol[(i+1)%n]] for i in range(n))\n                cost2 = sum(distance_matrix_2[sol[i], sol[(i+1)%n]] for i in range(n))\n                return (cost1, cost2)\n\n            current_cost = evaluate(new_solution)\n            improved = False\n\n            for candidate in possible_solutions:\n                candidate_cost = evaluate(candidate)\n                if (candidate_cost[0] <= current_cost[0] and candidate_cost[1] < current_cost[1]) or \\\n                   (candidate_cost[0] < current_cost[0] and candidate_cost[1] <= current_cost[1]):\n                    new_solution = candidate\n                    current_cost = candidate_cost\n                    improved = True\n\n            if not improved:\n                # Fallback to the best candidate if no Pareto improvement\n                best_candidate = min(possible_solutions, key=lambda x: (evaluate(x)[0] + evaluate(x)[1]))\n                new_solution = best_candidate\n\n        # Adaptive edge swapping in high-improvement regions\n        for _ in range(3):\n            region_size = max(3, n // 5)\n            region_start = np.random.randint(0, n - region_size)\n            region = new_solution[region_start:region_start+region_size]\n\n            for i in range(len(region)-1):\n                for j in range(i+1, len(region)):\n                    temp = new_solution.copy()\n                    temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                    current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                                  sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                    new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                               sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                    if new_cost < current_cost:\n                        new_solution = temp\n                        break\n\n        return new_solution\n\n    neighbor = hybrid_local_search(selected_solution)\n    return neighbor\n\n",
        "score": [
            6.135497457572057,
            5.532042096890348
        ]
    },
    {
        "algorithm": "The algorithm combines Pareto dominance-based selection with an adaptive segment recombination operator that dynamically selects between 3-opt and 5-opt segments, prioritizing solutions on the Pareto front while refining tours through region-specific edge swaps and hybrid evaluation metrics to balance objective trade-offs. It intelligently explores the solution space by dynamically choosing segment lengths and evaluating candidate solutions based on Pareto dominance or combined cost minimization.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    selected_solution = min(pareto_front, key=lambda x: x[1][0] + x[1][1])[0].copy()\n\n    def adaptive_segment_recombination(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        if n >= 6:\n            k = np.random.choice([3, 5])\n            if k == 3 and n >= 4:\n                i, j, k = sorted(np.random.choice(n, 3, replace=False))\n                segments = [\n                    new_solution[:i],\n                    new_solution[i:j+1],\n                    new_solution[j+1:k+1],\n                    new_solution[k+1:]\n                ]\n\n                possible_solutions = [\n                    np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n                    np.concatenate([segments[0], segments[2], segments[1], segments[3]]),\n                    np.concatenate([segments[0], segments[1], segments[2][::-1], segments[3]]),\n                    np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]]),\n                    np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3]])\n                ]\n            else:\n                i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n                segments = [\n                    new_solution[:i],\n                    new_solution[i:j+1],\n                    new_solution[j+1:k+1],\n                    new_solution[k+1:l+1],\n                    new_solution[l+1:m+1],\n                    new_solution[m+1:]\n                ]\n\n                possible_solutions = [\n                    np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n                    np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4], segments[5]]),\n                    np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n                    np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4], segments[5]])\n                ]\n\n            def evaluate(sol):\n                cost1 = sum(distance_matrix_1[sol[i], sol[(i+1)%n]] for i in range(n))\n                cost2 = sum(distance_matrix_2[sol[i], sol[(i+1)%n]] for i in range(n))\n                return (cost1, cost2)\n\n            current_cost = evaluate(new_solution)\n            improved = False\n\n            for candidate in possible_solutions:\n                candidate_cost = evaluate(candidate)\n                if (candidate_cost[0] <= current_cost[0] and candidate_cost[1] < current_cost[1]) or \\\n                   (candidate_cost[0] < current_cost[0] and candidate_cost[1] <= current_cost[1]):\n                    new_solution = candidate\n                    current_cost = candidate_cost\n                    improved = True\n\n            if not improved:\n                best_candidate = min(possible_solutions, key=lambda x: (evaluate(x)[0] + evaluate(x)[1]))\n                new_solution = best_candidate\n\n        region_size = max(3, n // 5)\n        for _ in range(3):\n            region_start = np.random.randint(0, n - region_size)\n            region = new_solution[region_start:region_start+region_size]\n\n            for i in range(len(region)-1):\n                for j in range(i+1, len(region)):\n                    temp = new_solution.copy()\n                    temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                    current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                                  sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                    new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                               sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                    if new_cost < current_cost:\n                        new_solution = temp\n                        break\n\n        return new_solution\n\n    neighbor = adaptive_segment_recombination(selected_solution)\n    return neighbor\n\n",
        "score": [
            5.8218903316082935,
            5.65755780979966
        ]
    },
    {
        "algorithm": "This heuristic algorithm first selects the most promising solution from the archive based on the combined objective score, then applies a hybrid local search combining adaptive k-opt moves (dynamically choosing between 3-opt and 5-opt) and region-based edge optimization, prioritizing high-improvement regions while ensuring feasibility through segment recombination. The algorithm balances exploration (random selection of segments and regions) with exploitation (greedy improvement), focusing on both objectives simultaneously.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def evaluate(solution):\n        n = len(solution)\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return (cost1, cost2)\n\n    def adaptive_k_opt(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n        k = 3 if n < 10 else 5 if n < 20 else np.random.choice([3, 5])\n\n        for _ in range(3):\n            if k == 3 and n >= 4:\n                i, j, k = sorted(np.random.choice(n, 3, replace=False))\n                segments = [\n                    new_solution[:i],\n                    new_solution[i:j+1],\n                    new_solution[j+1:k+1],\n                    new_solution[k+1:]\n                ]\n                candidates = [\n                    np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n                    np.concatenate([segments[0], segments[2], segments[1], segments[3]]),\n                    np.concatenate([segments[0], segments[1], segments[2][::-1], segments[3]])\n                ]\n            else:\n                i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n                segments = [\n                    new_solution[:i],\n                    new_solution[i:j+1],\n                    new_solution[j+1:k+1],\n                    new_solution[k+1:l+1],\n                    new_solution[l+1:m+1],\n                    new_solution[m+1:]\n                ]\n                candidates = [\n                    np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n                    np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2], segments[4], segments[5]]),\n                    np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]])\n                ]\n\n            current_cost = evaluate(new_solution)\n            best_candidate = None\n            best_improvement = 0\n\n            for candidate in candidates:\n                candidate_cost = evaluate(candidate)\n                improvement = (current_cost[0] - candidate_cost[0]) + (current_cost[1] - candidate_cost[1])\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_candidate = candidate\n\n            if best_candidate is not None:\n                new_solution = best_candidate\n\n        return new_solution\n\n    def region_optimization(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        for _ in range(5):\n            region_size = max(3, n // 4)\n            region_start = np.random.randint(0, n - region_size)\n            region = new_solution[region_start:region_start+region_size]\n\n            best_swap = None\n            best_improvement = 0\n\n            for i in range(len(region)):\n                for j in range(i+1, len(region)):\n                    temp = new_solution.copy()\n                    temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n                    temp_cost = evaluate(temp)\n                    current_cost = evaluate(new_solution)\n                    improvement = (current_cost[0] - temp_cost[0]) + (current_cost[1] - temp_cost[1])\n\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_swap = temp.copy()\n\n            if best_swap is not None:\n                new_solution = best_swap\n\n        return new_solution\n\n    selected_solution = min(archive, key=lambda x: x[1][0] + x[1][1])[0].copy()\n    neighbor = adaptive_k_opt(selected_solution)\n    neighbor = region_optimization(neighbor)\n\n    return neighbor\n\n",
        "score": [
            6.16582372719224,
            5.472235166135829
        ]
    },
    {
        "algorithm": "The algorithm combines Pareto dominance-based selection with hybrid 3-opt/5-opt moves, prioritizing solutions on the Pareto front while adaptively applying segment relocation and region-specific swaps to refine the tour. It dynamically balances exploration and exploitation by focusing on high-importance edges (combined from both objectives) and applying greedy improvements in local regions, ensuring feasibility through lightweight checks. The selection process normalizes objectives to balance trade-offs, while the local search alternates between segment relocations and k-opt moves (3-opt or 5-opt) based on solution size and quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    def normalize_objectives(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n        return norm1 + norm2\n\n    selected_solution = min(pareto_front, key=lambda x: normalize_objectives(x[1][0], x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    def calculate_edge_importance(solution, matrix):\n        importance = []\n        for i in range(n):\n            j = (i + 1) % n\n            importance.append(matrix[solution[i], solution[j]])\n        return np.array(importance)\n\n    imp1 = calculate_edge_importance(new_solution, distance_matrix_1)\n    imp2 = calculate_edge_importance(new_solution, distance_matrix_2)\n    combined_importance = imp1 + imp2\n    sorted_edges = np.argsort(combined_importance)[::-1]\n    selected_edges = sorted_edges[:max(2, n//4)]\n\n    def evaluate(solution):\n        cost1 = sum(distance_matrix_1[solution[i], solution[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[solution[i], solution[(i+1)%n]] for i in range(n))\n        return cost1, cost2\n\n    current_cost = evaluate(new_solution)\n\n    for edge in selected_edges:\n        if np.random.rand() < 0.7:\n            segment_start = edge\n            segment_end = (edge + 1) % n\n            segment = new_solution[segment_start:segment_end+1]\n            remaining = np.delete(new_solution, slice(segment_start, segment_end+1))\n\n            insertion_scores = []\n            for i in range(len(remaining)):\n                candidate = np.insert(remaining, i, segment)\n                cost1 = sum(distance_matrix_1[candidate[j], candidate[(j+1)%len(candidate)]] for j in range(len(candidate)))\n                cost2 = sum(distance_matrix_2[candidate[j], candidate[(j+1)%len(candidate)]] for j in range(len(candidate)))\n                insertion_scores.append(cost1 + cost2)\n\n            best_insertion = np.argmin(insertion_scores)\n            new_solution = np.insert(remaining, best_insertion, segment)\n\n    if n >= 4:\n        k = 3 if n < 6 else np.random.choice([3, 5])\n        if k == 3:\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3]]),\n                np.concatenate([segments[0], segments[1], segments[2][::-1], segments[3]]),\n                np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3]])\n            ]\n        else:\n            i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:m+1],\n                new_solution[m+1:]\n            ]\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n                np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4], segments[5]])\n            ]\n\n        best_candidate = min(possible_solutions, key=lambda x: sum(evaluate(x)))\n        new_solution = best_candidate\n\n    for _ in range(3):\n        region_size = max(3, n // 5)\n        region_start = np.random.randint(0, n - region_size)\n        region = new_solution[region_start:region_start+region_size]\n\n        for i in range(len(region)-1):\n            for j in range(i+1, len(region)):\n                temp = new_solution.copy()\n                temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                              sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                           sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                if new_cost < current_cost:\n                    new_solution = temp\n                    break\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            6.010837630895527,
            5.6323202542592705
        ]
    },
    {
        "algorithm": "The algorithm selects promising solutions from the archive using Pareto dominance and applies a hybrid local search combining dynamic 3-opt/5-opt moves with region-specific edge swapping, prioritizing solutions on the Pareto front while iteratively improving them by evaluating multiple candidate moves and ensuring feasibility through lightweight checks. It emphasizes non-dominated solutions and balances global (k-opt) and local (region-specific) improvements, with a fallback to the best candidate when no dominating move is found.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def pareto_dominance(a, b):\n        return (a[0] <= b[0] and a[1] < b[1]) or (a[0] < b[0] and a[1] <= b[1])\n\n    pareto_front = []\n    for solution, obj in archive:\n        dominated = False\n        for other_obj in [o[1] for o in archive]:\n            if pareto_dominance(other_obj, obj):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append((solution, obj))\n\n    if not pareto_front:\n        pareto_front = archive\n\n    selected_solution = min(pareto_front, key=lambda x: x[1][0] + x[1][1])[0].copy()\n\n    def hybrid_local_search(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        if n >= 6:\n            k = np.random.choice([3, 5])\n            if k == 3 and n >= 4:\n                i, j, k = sorted(np.random.choice(n, 3, replace=False))\n                segments = [\n                    new_solution[:i],\n                    new_solution[i:j+1],\n                    new_solution[j+1:k+1],\n                    new_solution[k+1:]\n                ]\n\n                possible_solutions = [\n                    np.concatenate([segments[0], segments[1][::-1], segments[2], segments[3]]),\n                    np.concatenate([segments[0], segments[2], segments[1], segments[3]]),\n                    np.concatenate([segments[0], segments[1], segments[2][::-1], segments[3]]),\n                    np.concatenate([segments[0], segments[2][::-1], segments[1], segments[3]]),\n                    np.concatenate([segments[0], segments[1][::-1], segments[2][::-1], segments[3]])\n                ]\n            else:\n                i, j, k, l, m = sorted(np.random.choice(n, 5, replace=False))\n                segments = [\n                    new_solution[:i],\n                    new_solution[i:j+1],\n                    new_solution[j+1:k+1],\n                    new_solution[k+1:l+1],\n                    new_solution[l+1:m+1],\n                    new_solution[m+1:]\n                ]\n\n                possible_solutions = [\n                    np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4], segments[5]]),\n                    np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4], segments[5]]),\n                    np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4], segments[5]]),\n                    np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4], segments[5]])\n                ]\n\n            def evaluate(sol):\n                cost1 = sum(distance_matrix_1[sol[i], sol[(i+1)%n]] for i in range(n))\n                cost2 = sum(distance_matrix_2[sol[i], sol[(i+1)%n]] for i in range(n))\n                return (cost1, cost2)\n\n            current_cost = evaluate(new_solution)\n            improved = False\n\n            for candidate in possible_solutions:\n                candidate_cost = evaluate(candidate)\n                if (candidate_cost[0] <= current_cost[0] and candidate_cost[1] < current_cost[1]) or \\\n                   (candidate_cost[0] < current_cost[0] and candidate_cost[1] <= current_cost[1]):\n                    new_solution = candidate\n                    current_cost = candidate_cost\n                    improved = True\n\n            if not improved:\n                best_candidate = min(possible_solutions, key=lambda x: (evaluate(x)[0] + evaluate(x)[1]))\n                new_solution = best_candidate\n\n        for _ in range(3):\n            region_size = max(3, n // 5)\n            region_start = np.random.randint(0, n - region_size)\n            region = new_solution[region_start:region_start+region_size]\n\n            for i in range(len(region)-1):\n                for j in range(i+1, len(region)):\n                    temp = new_solution.copy()\n                    temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                    current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                                  sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                    new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                               sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                    if new_cost < current_cost:\n                        new_solution = temp\n                        break\n\n        return new_solution\n\n    neighbor = hybrid_local_search(selected_solution)\n    return neighbor\n\n",
        "score": [
            5.712522256424664,
            5.889961155566451
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive based on a weighted combination of normalized objectives (prioritizing the first objective with a 0.7 weight), then applies a hybrid local search combining 4-opt moves with adaptive edge swapping. The 4-opt operator reconnects randomly selected segments in all possible ways and evaluates them using adaptive weighting (0.6 for the first objective), while the edge swapping focuses on high-improvement regions to refine the solution. The method ensures feasibility by maintaining valid TSP tours throughout all operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on normalized objectives\n    def weighted_score(obj1, obj2):\n        min1 = min(o[1][0] for o in archive)\n        max1 = max(o[1][0] for o in archive)\n        min2 = min(o[1][1] for o in archive)\n        max2 = max(o[1][1] for o in archive)\n\n        norm1 = (obj1 - min1) / (max1 - min1) if max1 != min1 else 0.5\n        norm2 = (obj2 - min2) / (max2 - min2) if max2 != min2 else 0.5\n        return 0.7 * norm1 + 0.3 * norm2  # Weighted toward first objective\n\n    selected_solution = min(archive, key=lambda x: weighted_score(x[1][0], x[1][1]))[0].copy()\n\n    # Hybrid 4-opt with adaptive edge swapping\n    def hybrid_local_search(solution):\n        n = len(solution)\n        new_solution = solution.copy()\n\n        # 4-opt move (randomly select 4 edges and reconnect)\n        if n >= 6:\n            i, j, k, l = sorted(np.random.choice(n, 4, replace=False))\n            segments = [\n                new_solution[:i],\n                new_solution[i:j+1],\n                new_solution[j+1:k+1],\n                new_solution[k+1:l+1],\n                new_solution[l+1:]\n            ]\n\n            # Generate all possible 4-opt reconnections\n            possible_solutions = [\n                np.concatenate([segments[0], segments[1], segments[3], segments[2], segments[4]]),\n                np.concatenate([segments[0], segments[1][::-1], segments[3], segments[2][::-1], segments[4]]),\n                np.concatenate([segments[0], segments[2], segments[1], segments[3], segments[4]]),\n                np.concatenate([segments[0], segments[3], segments[2], segments[1], segments[4]])\n            ]\n\n            # Evaluate with adaptive weighting\n            def evaluate(sol):\n                cost1 = sum(distance_matrix_1[sol[i], sol[(i+1)%n]] for i in range(n))\n                cost2 = sum(distance_matrix_2[sol[i], sol[(i+1)%n]] for i in range(n))\n                return 0.6 * cost1 + 0.4 * cost2  # Adaptive weighting\n\n            best_new = min(possible_solutions, key=evaluate)\n            new_solution = best_new\n\n        # Adaptive edge swapping\n        for _ in range(2):\n            # Select high-improvement region\n            region_size = max(3, n // 5)\n            region_start = np.random.randint(0, n - region_size)\n            region = new_solution[region_start:region_start+region_size]\n\n            # Try swapping edges within the region\n            for i in range(len(region)-1):\n                for j in range(i+1, len(region)):\n                    temp = new_solution.copy()\n                    temp[region_start+i], temp[region_start+j] = temp[region_start+j], temp[region_start+i]\n\n                    # Check if improvement\n                    current_cost = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                                  sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n                    new_cost = sum(distance_matrix_1[temp[i], temp[(i+1)%n]] for i in range(n)) + \\\n                               sum(distance_matrix_2[temp[i], temp[(i+1)%n]] for i in range(n))\n\n                    if new_cost < current_cost:\n                        new_solution = temp\n                        break\n\n        return new_solution\n\n    neighbor = hybrid_local_search(selected_solution)\n    return neighbor\n\n",
        "score": [
            4.676603931493985,
            7.643328294004073
        ]
    }
]