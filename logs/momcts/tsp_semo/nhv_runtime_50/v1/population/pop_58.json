[
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined objective improvement potential\n    objectives = np.array([obj[0] + obj[1] for _, obj in archive])\n    max_obj = np.max(objectives)\n    if max_obj == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_obj = objectives / max_obj\n        selected_idx = np.argmax(normalized_obj)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Calculate dominance status\n    is_dominated = False\n    current_obj = archive[selected_idx][1]\n    for _, other_obj in archive:\n        if other_obj[0] < current_obj[0] and other_obj[1] < current_obj[1]:\n            is_dominated = True\n            break\n\n    # Adaptive multi-segment rotation with objective-aware edge swaps\n    if is_dominated or np.random.random() < 0.3:\n        # Multi-segment rotation for dominated solutions or with probability\n        num_segments = max(2, min(4, int(np.sqrt(n))))\n        segment_length = max(3, n // num_segments)\n        segments = []\n        for i in range(num_segments):\n            start = i * segment_length\n            end = start + segment_length if i < num_segments - 1 else n\n            segments.append(new_solution[start:end])\n\n        # Rotate segments\n        rotation = np.random.randint(1, len(segments))\n        segments = segments[rotation:] + segments[:rotation]\n\n        # Reconstruct solution\n        new_solution = np.concatenate(segments)\n    else:\n        # Objective-aware edge swaps for non-dominated solutions\n        for _ in range(3):\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n            if i + 1 != j:\n                # Check if swap improves both objectives\n                old_dist1 = distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]]\n                new_dist1 = distance_matrix_1[new_solution[i-1], new_solution[j]] + distance_matrix_1[new_solution[i], new_solution[(j+1)%n]]\n                old_dist2 = distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]\n                new_dist2 = distance_matrix_2[new_solution[i-1], new_solution[j]] + distance_matrix_2[new_solution[i], new_solution[(j+1)%n]]\n\n                if (new_dist1 < old_dist1 and new_dist2 < old_dist2) or np.random.random() < 0.2:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.9895202361095508,
            0.44411444664001465
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive based on balanced dominance and diversity, then applies an adaptive multi-segment perturbation followed by objective-aware edge swaps to generate a neighbor solution while ensuring feasibility. It prioritizes segments of the tour for transformation based on the trade-off between objectives, and uses randomized edge swaps that favor improvements in both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with balanced dominance and diversity\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.max(objectives, axis=0, keepdims=True)\n    diversity = np.std(normalized_obj, axis=0)\n    selected_idx = np.argmax(np.sum(normalized_obj * diversity, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive multi-segment perturbation\n    num_segments = max(2, min(5, int(np.sqrt(n))))\n    segment_size = max(3, n // num_segments)\n    for i in range(num_segments):\n        start = i * segment_size\n        end = min(start + segment_size, n)\n        segment = new_solution[start:end]\n\n        # Adaptive transformation based on objective trade-off\n        obj1_trade = objectives[selected_idx][0] / (objectives[selected_idx][0] + objectives[selected_idx][1])\n        if np.random.rand() < obj1_trade:\n            segment = segment[::-1]\n        else:\n            shift = np.random.randint(1, len(segment))\n            segment = np.roll(segment, shift)\n\n        new_solution[start:end] = segment\n\n    # Objective-aware edge swaps\n    for _ in range(3):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i + 1 != j:\n            # Check if swap improves both objectives\n            old_dist1 = distance_matrix_1[new_solution[i], new_solution[i+1]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]]\n            new_dist1 = distance_matrix_1[new_solution[i], new_solution[j]] + distance_matrix_1[new_solution[i+1], new_solution[(j+1)%n]]\n            old_dist2 = distance_matrix_2[new_solution[i], new_solution[i+1]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]\n            new_dist2 = distance_matrix_2[new_solution[i], new_solution[j]] + distance_matrix_2[new_solution[i+1], new_solution[(j+1)%n]]\n\n            if (new_dist1 < old_dist1 and new_dist2 < old_dist2) or np.random.random() < 0.1:\n                new_solution[i+1], new_solution[j] = new_solution[j], new_solution[i+1]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -1.0297552063095865,
            0.579038143157959
        ]
    },
    {
        "algorithm": "The algorithm selects high-crowding-distance solutions from the archive, adaptively fuses 2-4 non-overlapping segments using objective-aware path relinking (prioritizing objectives based on their relative trade-off), and ensures feasibility by validating node visits, falling back to segment reversal if needed. The method balances exploration of diverse regions of the Pareto front with exploitation of promising segments, using distance matrices to guide fusion based on objective-specific path quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distance for each solution\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.max(objectives, axis=0, keepdims=True)\n    crowding_dist = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_idx = np.argsort(normalized_obj[:, i])\n        crowding_dist[sorted_idx[0]] = np.inf\n        crowding_dist[sorted_idx[-1]] = np.inf\n        for j in range(1, len(archive)-1):\n            crowding_dist[sorted_idx[j]] += normalized_obj[sorted_idx[j+1], i] - normalized_obj[sorted_idx[j-1], i]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment fusion (2-4 segments)\n    num_segments = np.random.randint(2, min(5, n//3))\n    segment_size = n // num_segments\n    segments = []\n    for i in range(num_segments):\n        start = i * segment_size\n        end = start + segment_size if i < num_segments - 1 else n\n        segments.append(new_solution[start:end])\n\n    # Objective-aware path relinking\n    for i in range(len(segments)):\n        for j in range(i+1, len(segments)):\n            # Check if segments can be fused without overlapping\n            if segments[i][-1] != segments[j][0] and segments[j][-1] != segments[i][0]:\n                # Relink based on objective trade-off\n                obj1_trade = current_obj[0] / (current_obj[0] + current_obj[1])\n                if np.random.rand() < obj1_trade:\n                    # Fuse with better path in first objective\n                    if distance_matrix_1[segments[i][-1], segments[j][0]] < distance_matrix_1[segments[j][-1], segments[i][0]]:\n                        segments[i] = np.concatenate([segments[i], segments[j]])\n                    else:\n                        segments[i] = np.concatenate([segments[j], segments[i]])\n                else:\n                    # Fuse with better path in second objective\n                    if distance_matrix_2[segments[i][-1], segments[j][0]] < distance_matrix_2[segments[j][-1], segments[i][0]]:\n                        segments[i] = np.concatenate([segments[i], segments[j]])\n                    else:\n                        segments[i] = np.concatenate([segments[j], segments[i]])\n\n    # Reconstruct solution\n    new_solution = np.concatenate(segments)\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if fusion fails\n        a = random.randint(0, n - 1)\n        b = random.randint(0, n - 1)\n        if a > b:\n            a, b = b, a\n        segment = new_solution[a:b+1]\n        new_solution[a:b+1] = segment[::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.9729124573246417,
            0.2580622434616089
        ]
    },
    {
        "algorithm": "The algorithm selects high-crowding-distance solutions from the archive, adaptively fuses 2-4 non-overlapping segments using objective-aware path relinking (prioritizing segments with better paths in the dominant objective), and ensures feasibility by validating node visits, falling back to segment reversal if fusion fails. It balances exploration of diverse Pareto regions with exploitation of promising segments guided by distance matrices.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distance for each solution\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.max(objectives, axis=0, keepdims=True)\n    crowding_dist = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_idx = np.argsort(normalized_obj[:, i])\n        crowding_dist[sorted_idx[0]] = np.inf\n        crowding_dist[sorted_idx[-1]] = np.inf\n        for j in range(1, len(archive)-1):\n            crowding_dist[sorted_idx[j]] += normalized_obj[sorted_idx[j+1], i] - normalized_obj[sorted_idx[j-1], i]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment fusion (2-4 segments)\n    num_segments = np.random.randint(2, min(5, n//3))\n    segment_size = n // num_segments\n    segments = []\n    for i in range(num_segments):\n        start = i * segment_size\n        end = start + segment_size if i < num_segments - 1 else n\n        segments.append(new_solution[start:end])\n\n    # Objective-aware path relinking\n    for i in range(len(segments)):\n        for j in range(i+1, len(segments)):\n            # Check if segments can be fused without overlapping\n            if segments[i][-1] != segments[j][0] and segments[j][-1] != segments[i][0]:\n                # Relink based on objective trade-off\n                obj1_trade = current_obj[0] / (current_obj[0] + current_obj[1])\n                if np.random.rand() < obj1_trade:\n                    # Fuse with better path in first objective\n                    if distance_matrix_1[segments[i][-1], segments[j][0]] < distance_matrix_1[segments[j][-1], segments[i][0]]:\n                        segments[i] = np.concatenate([segments[i], segments[j]])\n                    else:\n                        segments[i] = np.concatenate([segments[j], segments[i]])\n                else:\n                    # Fuse with better path in second objective\n                    if distance_matrix_2[segments[i][-1], segments[j][0]] < distance_matrix_2[segments[j][-1], segments[i][0]]:\n                        segments[i] = np.concatenate([segments[i], segments[j]])\n                    else:\n                        segments[i] = np.concatenate([segments[j], segments[i]])\n\n    # Reconstruct solution\n    new_solution = np.concatenate(segments)\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if fusion fails\n        a = random.randint(0, n - 1)\n        b = random.randint(0, n - 1)\n        if a > b:\n            a, b = b, a\n        segment = new_solution[a:b+1]\n        new_solution[a:b+1] = segment[::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.9317328076249916,
            0.2572314739227295
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive using normalized objective sums, divides it into 3-5 segments, merges them adaptively based on objective trade-offs (biasing toward the objective with higher relative value), and ensures feasibility by validating node visits or falling back to a random segment shuffle if needed. The key design ideas are objective-aware segment merging and adaptive trade-off handling, with a fallback mechanism to maintain feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate sum of normalized objectives for selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.max(objectives, axis=0, keepdims=True)\n    obj_sums = np.sum(normalized_obj, axis=1)\n    selected_idx = np.argmax(obj_sums)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment merging (3-5 segments)\n    num_segments = np.random.randint(3, min(6, n//2))\n    segment_size = n // num_segments\n    segments = []\n    for i in range(num_segments):\n        start = i * segment_size\n        end = start + segment_size if i < num_segments - 1 else n\n        segments.append(new_solution[start:end])\n\n    # Objective-aware segment merging with trade-off bias\n    for i in range(len(segments)):\n        for j in range(i+1, len(segments)):\n            obj1_trade = current_obj[0] / (current_obj[0] + current_obj[1] + 1e-8)\n            if np.random.rand() < obj1_trade:\n                # Merge with better path in first objective\n                cost1 = distance_matrix_1[segments[i][-1], segments[j][0]] + distance_matrix_1[segments[j][-1], segments[i][0]]\n                cost2 = distance_matrix_1[segments[i][0], segments[j][-1]] + distance_matrix_1[segments[j][0], segments[i][-1]]\n                if cost1 < cost2:\n                    segments[i] = np.concatenate([segments[i], segments[j]])\n                else:\n                    segments[i] = np.concatenate([segments[j], segments[i]])\n            else:\n                # Merge with better path in second objective\n                cost1 = distance_matrix_2[segments[i][-1], segments[j][0]] + distance_matrix_2[segments[j][-1], segments[i][0]]\n                cost2 = distance_matrix_2[segments[i][0], segments[j][-1]] + distance_matrix_2[segments[j][0], segments[i][-1]]\n                if cost1 < cost2:\n                    segments[i] = np.concatenate([segments[i], segments[j]])\n                else:\n                    segments[i] = np.concatenate([segments[j], segments[i]])\n\n    # Reconstruct solution\n    new_solution = np.concatenate(segments)\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to random segment shuffle\n        np.random.shuffle(segments)\n        new_solution = np.concatenate(segments)\n\n    return new_solution\n\n",
        "score": [
            -0.8995413523865355,
            0.10753679275512695
        ]
    },
    {
        "algorithm": "The algorithm selects a high-crowding-distance solution from the archive, adaptively fuses 2-4 non-overlapping segments using objective-aware path relinking (prioritizing either objective based on their relative trade-off), and ensures feasibility by validating node visits and falling back to a simple edge swap if needed. The key design ideas are the crowding-distance-based selection, adaptive segment fusion with objective-aware relinking, and strict feasibility validation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distance for each solution\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.max(objectives, axis=0, keepdims=True)\n    crowding_dist = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_idx = np.argsort(normalized_obj[:, i])\n        crowding_dist[sorted_idx[0]] = np.inf\n        crowding_dist[sorted_idx[-1]] = np.inf\n        for j in range(1, len(archive)-1):\n            crowding_dist[sorted_idx[j]] += normalized_obj[sorted_idx[j+1], i] - normalized_obj[sorted_idx[j-1], i]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment fusion (2-4 segments)\n    num_segments = np.random.randint(2, min(5, n//3))\n    segment_size = n // num_segments\n    segments = []\n    for i in range(num_segments):\n        start = i * segment_size\n        end = start + segment_size if i < num_segments - 1 else n\n        segments.append(new_solution[start:end])\n\n    # Objective-aware path relinking\n    for i in range(len(segments)):\n        for j in range(i+1, len(segments)):\n            # Check if segments can be fused without overlapping\n            if segments[i][-1] != segments[j][0] and segments[j][-1] != segments[i][0]:\n                # Relink based on objective trade-off\n                obj1_trade = current_obj[0] / (current_obj[0] + current_obj[1])\n                if np.random.rand() < obj1_trade:\n                    # Fuse with better path in first objective\n                    if distance_matrix_1[segments[i][-1], segments[j][0]] < distance_matrix_1[segments[j][-1], segments[i][0]]:\n                        segments[i] = np.concatenate([segments[i], segments[j]])\n                    else:\n                        segments[i] = np.concatenate([segments[j], segments[i]])\n                else:\n                    # Fuse with better path in second objective\n                    if distance_matrix_2[segments[i][-1], segments[j][0]] < distance_matrix_2[segments[j][-1], segments[i][0]]:\n                        segments[i] = np.concatenate([segments[i], segments[j]])\n                    else:\n                        segments[i] = np.concatenate([segments[j], segments[i]])\n\n    # Reconstruct solution\n    new_solution = np.concatenate(segments)\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple edge swap if fusion fails\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i + 1 != j:\n            new_solution[i+1], new_solution[j] = new_solution[j], new_solution[i+1]\n\n    return new_solution\n\n",
        "score": [
            -0.8756732743489246,
            0.2587517499923706
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid scoring metric that balances Pareto dominance and objective diversity, then applies adaptive segment merging and dynamic objective-aware node insertion to generate high-quality neighbors, prioritizing improvements in both objectives while ensuring tour feasibility through careful validation. The method dynamically balances improvements between objectives (weighted 60% for the first objective) and maintains solution validity by verifying node count and node set equality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection based on Pareto dominance and objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.max(objectives, axis=0, keepdims=True)\n    diversity = np.std(normalized_obj, axis=0)\n    dominance = np.sum(normalized_obj * diversity, axis=1)\n    balance = 1 / (1 + np.abs(normalized_obj[:, 0] - normalized_obj[:, 1]))\n    score = dominance * balance\n    selected_idx = np.argmax(score)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment merging\n    num_merges = np.random.randint(1, min(3, n // 4))\n    for _ in range(num_merges):\n        if len(new_solution) <= 4:\n            break\n\n        # Select two adjacent segments to merge\n        split_point = np.random.randint(1, len(new_solution)-1)\n        merged_segment = np.concatenate([new_solution[:split_point], new_solution[split_point:]])\n\n        # Evaluate merged segment\n        cost1 = sum(distance_matrix_1[merged_segment[i], merged_segment[(i+1)%len(merged_segment)]] for i in range(len(merged_segment)))\n        cost2 = sum(distance_matrix_2[merged_segment[i], merged_segment[(i+1)%len(merged_segment)]] for i in range(len(merged_segment)))\n\n        # Accept merge if it shows potential improvement\n        if cost1 < sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%len(new_solution)]] for i in range(len(new_solution))) or \\\n           cost2 < sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%len(new_solution)]] for i in range(len(new_solution))):\n            new_solution = merged_segment\n\n    # Dynamic objective-aware node insertion\n    for _ in range(min(3, n // 3)):\n        # Select a node to relocate\n        node_idx = np.random.randint(1, len(new_solution)-1)\n        node = new_solution[node_idx]\n\n        # Find best insertion point considering both objectives\n        best_pos = -1\n        best_improvement = (0, 0)\n\n        for pos in range(len(new_solution)):\n            if pos == node_idx or pos == (node_idx - 1) % len(new_solution):\n                continue\n\n            # Calculate potential improvement\n            old_cost1 = distance_matrix_1[new_solution[node_idx-1], new_solution[node_idx]] + \\\n                        distance_matrix_1[new_solution[node_idx], new_solution[(node_idx+1)%len(new_solution)]]\n            new_cost1 = distance_matrix_1[new_solution[node_idx-1], node] + \\\n                        distance_matrix_1[node, new_solution[(node_idx+1)%len(new_solution)]]\n\n            old_cost2 = distance_matrix_2[new_solution[node_idx-1], new_solution[node_idx]] + \\\n                        distance_matrix_2[new_solution[node_idx], new_solution[(node_idx+1)%len(new_solution)]]\n            new_cost2 = distance_matrix_2[new_solution[node_idx-1], node] + \\\n                        distance_matrix_2[node, new_solution[(node_idx+1)%len(new_solution)]]\n\n            improvement1 = old_cost1 - new_cost1\n            improvement2 = old_cost2 - new_cost2\n\n            # Consider both objectives with weighted balance\n            weighted_improvement = improvement1 * 0.6 + improvement2 * 0.4\n\n            if weighted_improvement > best_improvement[0] + best_improvement[1]:\n                best_pos = pos\n                best_improvement = (improvement1, improvement2)\n\n        if best_pos != -1:\n            # Perform the insertion\n            new_solution = np.concatenate([\n                new_solution[:node_idx],\n                new_solution[node_idx+1:],\n                np.array([node])\n            ])\n            new_solution = np.roll(new_solution, -best_pos)\n\n    # Ensure solution remains valid\n    if len(new_solution) != n or not np.array_equal(np.sort(new_solution), np.sort(base_solution)):\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -1.0039270925261317,
            1.121850311756134
        ]
    },
    {
        "algorithm": "The algorithm selects high-diversity solutions from the archive, applies adaptive multi-segment perturbations guided by objective trade-offs, and performs objective-aware edge swaps to generate high-quality neighbor solutions while maintaining feasibility through strict validation. It prioritizes segments based on the current objective trade-off (first objective vs. second objective) and uses segment reversal or rotation to improve solutions, followed by edge swaps that consider both objectives. The method ensures feasibility by validating uniqueness of nodes and falls back to segment reversal if needed.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate diversity scores\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.max(objectives, axis=0, keepdims=True)\n    diversity_scores = np.std(normalized_obj, axis=0)\n    selected_idx = np.argmax(np.sum(normalized_obj * diversity_scores, axis=1))\n\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive multi-segment perturbation\n    num_segments = np.random.randint(3, min(6, n//2))\n    segment_size = max(2, n // num_segments)\n    segments = []\n    for i in range(num_segments):\n        start = i * segment_size\n        end = start + segment_size if i < num_segments - 1 else n\n        segments.append(new_solution[start:end])\n\n    # Objective-aware segment transformations\n    obj1_trade = current_obj[0] / (current_obj[0] + current_obj[1])\n    for i in range(len(segments)):\n        if np.random.rand() < obj1_trade:\n            # Reverse segment if it improves first objective\n            if len(segments[i]) > 2 and distance_matrix_1[segments[i][-1], segments[i][0]] < distance_matrix_1[segments[i][0], segments[i][1]]:\n                segments[i] = segments[i][::-1]\n        else:\n            # Rotate segment if it improves second objective\n            if len(segments[i]) > 2 and distance_matrix_2[segments[i][-1], segments[i][0]] < distance_matrix_2[segments[i][0], segments[i][1]]:\n                shift = np.random.randint(1, len(segments[i]))\n                segments[i] = np.roll(segments[i], shift)\n\n    # Reconstruct solution\n    new_solution = np.concatenate(segments)\n\n    # Objective-aware edge swaps\n    for _ in range(5):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i + 1 != j:\n            # Check if swap improves both objectives\n            old_dist1 = distance_matrix_1[new_solution[i], new_solution[i+1]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]]\n            new_dist1 = distance_matrix_1[new_solution[i], new_solution[j]] + distance_matrix_1[new_solution[i+1], new_solution[(j+1)%n]]\n            old_dist2 = distance_matrix_2[new_solution[i], new_solution[i+1]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]\n            new_dist2 = distance_matrix_2[new_solution[i], new_solution[j]] + distance_matrix_2[new_solution[i+1], new_solution[(j+1)%n]]\n\n            if (new_dist1 < old_dist1 and new_dist2 < old_dist2) or np.random.random() < 0.15:\n                new_solution[i+1], new_solution[j] = new_solution[j], new_solution[i+1]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if needed\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        segment = new_solution[a:b+1]\n        new_solution[a:b+1] = segment[::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.9753793961780244,
            0.5770210027694702
        ]
    },
    {
        "algorithm": "The heuristic selects a solution from the archive with a bias toward lower combined objective values (prioritizing better solutions) and applies a hybrid local search that combines segment reversal and edge exchange to generate a neighbor solution, ensuring feasibility by maintaining a valid TSP tour structure. The selection is weighted by inverse objective values, and the local search introduces diversity through random segment reversals and edge swaps.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with a bias towards better objectives and diversity\n    selected_idx = random.choices(\n        range(len(archive)),\n        weights=[1 / (obj1 + obj2 + 1) for (_, (obj1, obj2)) in archive],\n        k=1\n    )[0]\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: combine edge exchange and segment reversal\n    n = len(base_solution)\n    new_solution = base_solution.copy()\n\n    # Randomly choose a segment to reverse\n    a = random.randint(0, n - 1)\n    b = random.randint(0, n - 1)\n    if a > b:\n        a, b = b, a\n    segment = new_solution[a:b+1]\n    new_solution[a:b+1] = segment[::-1]\n\n    # Randomly exchange two edges\n    i = random.randint(0, n - 1)\n    j = random.randint(0, n - 1)\n    if i != j and (i + 1) % n != j and (j + 1) % n != i:\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9272577568532457,
            0.41235780715942383
        ]
    },
    {
        "algorithm": "The algorithm selects a diverse solution from the archive using crowding distance, then applies a hybrid local search combining adaptive segment reversal and node insertion, prioritizing the objective with higher relative cost while maintaining feasibility through segment validation and fallback to random segment reversal. It operates on variable-length segments of the tour, with operations chosen probabilistically based on the current solution's objective trade-off, and ensures validity by checking for duplicate nodes and reverting to a simple segment reversal if needed.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest crowding distance for diversity\n    objectives = np.array([obj for _, obj in archive])\n    crowding = np.zeros(len(archive))\n    for m in range(2):  # For each objective\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding[sorted_idx[0]] = crowding[sorted_idx[-1]] = float('inf')\n        for i in range(1, len(archive)-1):\n            crowding[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m] + 1e-6)\n\n    selected_idx = np.argmax(crowding)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment-based hybrid perturbation\n    segment_size = np.random.randint(2, min(5, n//3))\n    num_segments = max(1, n // segment_size)\n    segments = []\n    for i in range(num_segments):\n        start = i * segment_size\n        end = start + segment_size if i < num_segments - 1 else n\n        segments.append(new_solution[start:end])\n\n    # Hybrid refinement: segment reversal with objective bias\n    for i in range(len(segments)):\n        if len(segments[i]) < 2:\n            continue\n\n        # Calculate segment cost in both objectives\n        seg_cost1 = sum(distance_matrix_1[segments[i][j], segments[i][(j+1)%len(segments[i])]] for j in range(len(segments[i])))\n        seg_cost2 = sum(distance_matrix_2[segments[i][j], segments[i][(j+1)%len(segments[i])]] for j in range(len(segments[i])))\n\n        # Decide operation based on objective trade-off\n        obj_trade = current_obj[0] / (current_obj[0] + current_obj[1] + 1e-6)\n        if np.random.rand() < obj_trade:\n            # Objective-aware segment reversal\n            if np.random.rand() < 0.7:  # Higher probability for reversal\n                segments[i] = segments[i][::-1]\n            else:\n                # Node insertion for fine-grained improvement\n                if len(segments[i]) > 2:\n                    a = np.random.randint(0, len(segments[i]))\n                    b = np.random.randint(0, len(segments[i]))\n                    if a != b:\n                        node = segments[i][a]\n                        segments[i] = np.concatenate([segments[i][:a], segments[i][a+1:b], [node], segments[i][b:]])\n        else:\n            # Alternative: segment rotation for better connectivity\n            rot = np.random.randint(1, len(segments[i]))\n            segments[i] = np.concatenate([segments[i][rot:], segments[i][:rot]])\n\n    # Reconstruct solution\n    new_solution = np.concatenate(segments)\n\n    # Ensure feasibility through segment validation\n    if len(np.unique(new_solution)) != n:\n        # Random segment reversal as fallback\n        a = np.random.randint(0, n - 1)\n        b = np.random.randint(a + 1, n)\n        segment = new_solution[a:b+1]\n        new_solution[a:b+1] = segment[::-1]\n\n    return new_solution\n\n",
        "score": [
            -1.0012971110471323,
            0.7504479885101318
        ]
    }
]