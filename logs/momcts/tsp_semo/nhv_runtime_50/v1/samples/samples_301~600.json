[
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from an archive based on crowding distance and objective diversity, then applies a hybrid local search combining adaptive segment inversion and objective-biased node swaps, dynamically adjusting segment sizes based on objective correlation while ensuring feasibility through strict validation of node visits. It prioritizes solutions with high crowding distance and diverse objectives, using correlation between the two objectives to adaptively determine segment sizes for local search, and employs both segment reversal and node swapping operations to explore the solution space while maintaining feasibility. The algorithm balances exploration and exploitation by dynamically adjusting search strategies based on objective relationships and evaluates potential improvements using both objective spaces.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high crowding distance and diverse objectives\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1]\n        elif i == len(archive)-1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = (abs(right[0] - left[0]) + abs(right[1] - left[1])) / 2\n        crowding_distances.append((sol, obj, dist))\n\n    selected = max(crowding_distances, key=lambda x: x[2])[0].copy()\n    new_solution = selected.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Calculate objective correlation\n    objectives = np.array([obj for _, obj in archive])\n    corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    corr = max(-0.5, min(0.5, corr))  # Limit correlation effect\n\n    # Adaptive segment sizes based on objective correlation\n    base_size = max(2, min(4, int(n * 0.15)))\n    seg_size1 = max(2, min(6, int(base_size * (1 + corr))))\n    seg_size2 = max(2, min(6, int(base_size * (1 - corr))))\n\n    # Select segments with different strategies\n    a = random.randint(0, n - seg_size1)\n    b = min(a + seg_size1, n)\n\n    if random.random() < 0.7:  # Higher chance of segment inversion\n        new_solution[a:b] = new_solution[a:b][::-1]\n    else:  # Node swap with objective bias\n        if random.random() < 0.6:\n            i, j = random.sample(range(a, b), 2)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Additional improvement with objective-aware 2-opt\n    for _ in range(2):\n        i, j = sorted(random.sample(range(n), 2))\n        if j - i > 1:\n            segment = new_solution[i:j]\n            reversed_segment = segment[::-1]\n\n            # Evaluate both configurations\n            def eval_segment(seg):\n                total1 = distance_matrix_1[new_solution[i-1], seg[0]] + distance_matrix_1[seg[-1], new_solution[j]]\n                total2 = distance_matrix_2[new_solution[i-1], seg[0]] + distance_matrix_2[seg[-1], new_solution[j]]\n                for k in range(len(seg)-1):\n                    total1 += distance_matrix_1[seg[k], seg[k+1]]\n                    total2 += distance_matrix_2[seg[k], seg[k+1]]\n                return (total1 + total2) / (total1 * total2) if (total1 * total2) != 0 else float('inf')\n\n            original_score = eval_segment(segment)\n            reversed_score = eval_segment(reversed_segment)\n\n            if reversed_score < original_score:\n                new_solution[i:j] = reversed_segment\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 301,
        "algorithm": "The algorithm combines crowding distance and dominance metrics to select promising solutions from an archive, then applies an adaptive local search that dynamically adjusts segment sizes and operations based on objective correlation and node centrality, using segment reversal, node shifting, and objective-aware swaps to explore the solution space while maintaining feasibility. The method prioritizes central nodes with more disruptive operations and peripheral nodes with conservative changes, with additional segment optimization based on a weighted objective function that accounts for correlation between objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection metric combining crowding distance and objective dominance\n    selection_scores = []\n    for i, (sol, obj) in enumerate(archive):\n        # Calculate crowding distance\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1]\n        elif i == len(archive)-1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n        dist = (abs(right[0] - left[0]) + abs(right[1] - left[1])) / 2\n\n        # Calculate dominance count (simplified)\n        dom_count = sum(1 for (_, o) in archive if (o[0] < obj[0] and o[1] < obj[1]))\n        score = dist * (1 + 0.5 * (1 / (1 + dom_count)))  # Combine metrics\n        selection_scores.append((sol, obj, score))\n\n    selected = max(selection_scores, key=lambda x: x[2])[0].copy()\n    new_solution = selected.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Calculate objective correlation and node centrality\n    objectives = np.array([obj for _, obj in archive])\n    corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    corr = max(-0.5, min(0.5, corr))\n\n    # Calculate node centrality (average distance to other nodes)\n    centrality = np.zeros(n)\n    for i in range(n):\n        centrality[i] = np.mean(distance_matrix_1[i]) + np.mean(distance_matrix_2[i])\n\n    # Adaptive segment selection based on correlation and centrality\n    base_size = max(2, min(5, int(n * 0.12)))\n    seg_size = max(2, min(7, int(base_size * (1 + 1.5 * corr))))\n\n    # Select segment with higher centrality nodes\n    segment_start = random.randint(0, n - seg_size)\n    segment_end = segment_start + seg_size\n    segment_nodes = new_solution[segment_start:segment_end]\n\n    # Calculate segment centrality\n    segment_centrality = np.mean(centrality[segment_nodes])\n\n    # Select operation based on segment centrality\n    if segment_centrality > np.mean(centrality):\n        # For central segments, use more disruptive operations\n        if random.random() < 0.6:\n            # Segment reversal with node shifting\n            new_solution[segment_start:segment_end] = new_solution[segment_start:segment_end][::-1]\n            if seg_size > 3 and random.random() < 0.4:\n                shift = random.randint(1, seg_size-1)\n                new_solution[segment_start:segment_end] = np.roll(new_solution[segment_start:segment_end], shift)\n        else:\n            # Node swap with objective bias\n            i, j = random.sample(range(segment_start, segment_end), 2)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n    else:\n        # For peripheral segments, use more conservative operations\n        if random.random() < 0.7:\n            # Segment inversion with limited scope\n            inv_size = max(2, min(4, int(seg_size * 0.7)))\n            inv_start = random.randint(segment_start, segment_end - inv_size)\n            new_solution[inv_start:inv_start+inv_size] = new_solution[inv_start:inv_start+inv_size][::-1]\n        else:\n            # Single node insertion\n            i = random.randint(segment_start, segment_end-1)\n            j = random.randint(0, n-1)\n            if j != i:\n                node = new_solution[i]\n                new_solution = np.delete(new_solution, i)\n                insert_pos = random.randint(0, n-2)\n                new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Additional improvement with objective-aware segment optimization\n    for _ in range(2):\n        i, j = sorted(random.sample(range(n), 2))\n        if j - i > 2:\n            segment = new_solution[i:j]\n            reversed_segment = segment[::-1]\n\n            # Evaluate both configurations with weighted objective function\n            def eval_segment(seg):\n                total1 = distance_matrix_1[new_solution[i-1], seg[0]] + distance_matrix_1[seg[-1], new_solution[j]]\n                total2 = distance_matrix_2[new_solution[i-1], seg[0]] + distance_matrix_2[seg[-1], new_solution[j]]\n                for k in range(len(seg)-1):\n                    total1 += distance_matrix_1[seg[k], seg[k+1]]\n                    total2 += distance_matrix_2[seg[k], seg[k+1]]\n                # Weighted objective function based on correlation\n                return (1 - 0.5 * corr) * total1 + (1 + 0.5 * corr) * total2\n\n            original_score = eval_segment(segment)\n            reversed_score = eval_segment(reversed_segment)\n\n            if reversed_score < original_score:\n                new_solution[i:j] = reversed_segment\n\n    return new_solution\n\n",
        "score": [
            -0.700467493372444,
            1.3675262928009033
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection metric combining crowding distance and objective dominance\n    selection_scores = []\n    for i, (sol, obj) in enumerate(archive):\n        # Calculate crowding distance\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1]\n        elif i == len(archive)-1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n        dist = (abs(right[0] - left[0]) + abs(right[1] - left[1])) / 2\n\n        # Calculate dominance count (simplified)\n        dom_count = sum(1 for (_, o) in archive if (o[0] < obj[0] and o[1] < obj[1]))\n        score = dist * (1 + 0.5 * (1 / (1 + dom_count)))  # Combine metrics\n        selection_scores.append((sol, obj, score))\n\n    selected = max(selection_scores, key=lambda x: x[2])[0].copy()\n    new_solution = selected.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Calculate objective correlation and node centrality\n    objectives = np.array([obj for _, obj in archive])\n    corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    corr = max(-0.5, min(0.5, corr))\n\n    # Calculate node centrality (average distance to other nodes)\n    centrality = np.zeros(n)\n    for i in range(n):\n        centrality[i] = np.mean(distance_matrix_1[i]) + np.mean(distance_matrix_2[i])\n\n    # Adaptive segment selection based on correlation and centrality\n    base_size = max(2, min(5, int(n * 0.12)))\n    seg_size = max(2, min(7, int(base_size * (1 + 1.5 * corr))))\n\n    # Select segment with higher centrality nodes\n    segment_start = random.randint(0, n - seg_size)\n    segment_end = segment_start + seg_size\n    segment_nodes = new_solution[segment_start:segment_end]\n\n    # Calculate segment centrality\n    segment_centrality = np.mean(centrality[segment_nodes])\n\n    # Select operation based on segment centrality\n    if segment_centrality > np.mean(centrality):\n        # For central segments, use more disruptive operations\n        if random.random() < 0.6:\n            # Segment reversal with node shifting\n            new_solution[segment_start:segment_end] = new_solution[segment_start:segment_end][::-1]\n            if seg_size > 3 and random.random() < 0.4:\n                shift = random.randint(1, seg_size-1)\n                new_solution[segment_start:segment_end] = np.roll(new_solution[segment_start:segment_end], shift)\n        else:\n            # Node swap with objective bias\n            i, j = random.sample(range(segment_start, segment_end), 2)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n    else:\n        # For peripheral segments, use more conservative operations\n        if random.random() < 0.7:\n            # Segment inversion with limited scope\n            inv_size = max(2, min(4, int(seg_size * 0.7)))\n            inv_start = random.randint(segment_start, segment_end - inv_size)\n            new_solution[inv_start:inv_start+inv_size] = new_solution[inv_start:inv_start+inv_size][::-1]\n        else:\n            # Single node insertion\n            i = random.randint(segment_start, segment_end-1)\n            j = random.randint(0, n-1)\n            if j != i:\n                node = new_solution[i]\n                new_solution = np.delete(new_solution, i)\n                insert_pos = random.randint(0, n-2)\n                new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Additional improvement with objective-aware segment optimization\n    for _ in range(2):\n        i, j = sorted(random.sample(range(n), 2))\n        if j - i > 2:\n            segment = new_solution[i:j]\n            reversed_segment = segment[::-1]\n\n            # Evaluate both configurations with weighted objective function\n            def eval_segment(seg):\n                total1 = distance_matrix_1[new_solution[i-1], seg[0]] + distance_matrix_1[seg[-1], new_solution[j]]\n                total2 = distance_matrix_2[new_solution[i-1], seg[0]] + distance_matrix_2[seg[-1], new_solution[j]]\n                for k in range(len(seg)-1):\n                    total1 += distance_matrix_1[seg[k], seg[k+1]]\n                    total2 += distance_matrix_2[seg[k], seg[k+1]]\n                # Weighted objective function based on correlation\n                return (1 - 0.5 * corr) * total1 + (1 + 0.5 * corr) * total2\n\n            original_score = eval_segment(segment)\n            reversed_score = eval_segment(reversed_segment)\n\n            if reversed_score < original_score:\n                new_solution[i:j] = reversed_segment\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from an archive based on crowding distance and objective diversity, then applies a hybrid local search combining adaptive segment inversion and objective-biased node swaps, dynamically adjusting segment sizes based on objective correlation while ensuring feasibility through strict validation of node visits. It prioritizes solutions with high crowding distance and diverse objectives, using correlation between the two objectives to adaptively determine segment sizes for local search, and employs both segment reversal and node swapping operations to explore the solution space while maintaining feasibility. The algorithm balances exploration and exploitation by dynamically adjusting search strategies based on objective relationships and evaluates potential improvements using both objective spaces.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high crowding distance and diverse objectives\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1]\n        elif i == len(archive)-1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = (abs(right[0] - left[0]) + abs(right[1] - left[1])) / 2\n        crowding_distances.append((sol, obj, dist))\n\n    selected = max(crowding_distances, key=lambda x: x[2])[0].copy()\n    new_solution = selected.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Calculate objective correlation\n    objectives = np.array([obj for _, obj in archive])\n    corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    corr = max(-0.5, min(0.5, corr))  # Limit correlation effect\n\n    # Adaptive segment sizes based on objective correlation\n    base_size = max(2, min(4, int(n * 0.15)))\n    seg_size1 = max(2, min(6, int(base_size * (1 + corr))))\n    seg_size2 = max(2, min(6, int(base_size * (1 - corr))))\n\n    # Select segments with different strategies\n    a = random.randint(0, n - seg_size1)\n    b = min(a + seg_size1, n)\n\n    if random.random() < 0.7:  # Higher chance of segment inversion\n        new_solution[a:b] = new_solution[a:b][::-1]\n    else:  # Node swap with objective bias\n        if random.random() < 0.6:\n            i, j = random.sample(range(a, b), 2)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Additional improvement with objective-aware 2-opt\n    for _ in range(2):\n        i, j = sorted(random.sample(range(n), 2))\n        if j - i > 1:\n            segment = new_solution[i:j]\n            reversed_segment = segment[::-1]\n\n            # Evaluate both configurations\n            def eval_segment(seg):\n                total1 = distance_matrix_1[new_solution[i-1], seg[0]] + distance_matrix_1[seg[-1], new_solution[j]]\n                total2 = distance_matrix_2[new_solution[i-1], seg[0]] + distance_matrix_2[seg[-1], new_solution[j]]\n                for k in range(len(seg)-1):\n                    total1 += distance_matrix_1[seg[k], seg[k+1]]\n                    total2 += distance_matrix_2[seg[k], seg[k+1]]\n                return (total1 + total2) / (total1 * total2) if (total1 * total2) != 0 else float('inf')\n\n            original_score = eval_segment(segment)\n            reversed_score = eval_segment(reversed_segment)\n\n            if reversed_score < original_score:\n                new_solution[i:j] = reversed_segment\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 302,
        "algorithm": "The algorithm selects a solution with high crowding distance from the archive, applies a hybrid local search combining adaptive segment rotation (with angle determined by objective correlation) and objective-balanced node insertions, while ensuring feasibility through strict validation. It prioritizes solutions with diverse objectives and dynamically adjusts segment parameters based on correlation between the two objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high crowding distance and diverse objectives\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1]\n        elif i == len(archive)-1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = (abs(right[0] - left[0]) + abs(right[1] - left[1])) / 2\n        crowding_distances.append((sol, obj, dist))\n\n    selected = max(crowding_distances, key=lambda x: x[2])[0].copy()\n    new_solution = selected.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Calculate objective correlation and diversity\n    objectives = np.array([obj for _, obj in archive])\n    corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    corr = max(-0.8, min(0.8, corr))  # More aggressive correlation effect\n\n    # Adaptive segment parameters\n    base_angle = 45  # Fixed base angle for rotation\n    rotation_angle = max(15, min(90, int(base_angle * (1 + corr))))\n    segment_length = max(3, min(8, int(n * 0.2)))\n\n    # Select segment and apply rotation\n    a = random.randint(0, n - segment_length)\n    b = min(a + segment_length, n)\n\n    # Rotate segment in both objective spaces\n    segment = new_solution[a:b]\n    rotated_segment = np.roll(segment, int(len(segment) * rotation_angle / 360), axis=0)\n    new_solution[a:b] = rotated_segment\n\n    # Objective-balanced node insertion\n    for _ in range(3):\n        i = random.randint(0, n-1)\n        j = random.randint(0, n-1)\n        if i != j:\n            node = new_solution[i]\n            new_solution = np.delete(new_solution, i)\n            insert_pos = min(j, len(new_solution))\n            new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Validate solution\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.6448151886693057,
            0.5583909749984741
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high crowding distance and diverse objectives\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1]\n        elif i == len(archive)-1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = (abs(right[0] - left[0]) + abs(right[1] - left[1])) / 2\n        crowding_distances.append((sol, obj, dist))\n\n    selected = max(crowding_distances, key=lambda x: x[2])[0].copy()\n    new_solution = selected.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Calculate objective correlation and diversity\n    objectives = np.array([obj for _, obj in archive])\n    corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    corr = max(-0.8, min(0.8, corr))  # More aggressive correlation effect\n\n    # Adaptive segment parameters\n    base_angle = 45  # Fixed base angle for rotation\n    rotation_angle = max(15, min(90, int(base_angle * (1 + corr))))\n    segment_length = max(3, min(8, int(n * 0.2)))\n\n    # Select segment and apply rotation\n    a = random.randint(0, n - segment_length)\n    b = min(a + segment_length, n)\n\n    # Rotate segment in both objective spaces\n    segment = new_solution[a:b]\n    rotated_segment = np.roll(segment, int(len(segment) * rotation_angle / 360), axis=0)\n    new_solution[a:b] = rotated_segment\n\n    # Objective-balanced node insertion\n    for _ in range(3):\n        i = random.randint(0, n-1)\n        j = random.randint(0, n-1)\n        if i != j:\n            node = new_solution[i]\n            new_solution = np.delete(new_solution, i)\n            insert_pos = min(j, len(new_solution))\n            new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Validate solution\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected.copy()\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from an archive based on crowding distance and objective diversity, then applies a hybrid local search combining adaptive segment inversion and objective-biased node swaps, dynamically adjusting segment sizes based on objective correlation while ensuring feasibility through strict validation of node visits. It prioritizes solutions with high crowding distance and diverse objectives, using correlation between the two objectives to adaptively determine segment sizes for local search, and employs both segment reversal and node swapping operations to explore the solution space while maintaining feasibility. The algorithm balances exploration and exploitation by dynamically adjusting search strategies based on objective relationships and evaluates potential improvements using both objective spaces.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high crowding distance and diverse objectives\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1]\n        elif i == len(archive)-1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = (abs(right[0] - left[0]) + abs(right[1] - left[1])) / 2\n        crowding_distances.append((sol, obj, dist))\n\n    selected = max(crowding_distances, key=lambda x: x[2])[0].copy()\n    new_solution = selected.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Calculate objective correlation\n    objectives = np.array([obj for _, obj in archive])\n    corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    corr = max(-0.5, min(0.5, corr))  # Limit correlation effect\n\n    # Adaptive segment sizes based on objective correlation\n    base_size = max(2, min(4, int(n * 0.15)))\n    seg_size1 = max(2, min(6, int(base_size * (1 + corr))))\n    seg_size2 = max(2, min(6, int(base_size * (1 - corr))))\n\n    # Select segments with different strategies\n    a = random.randint(0, n - seg_size1)\n    b = min(a + seg_size1, n)\n\n    if random.random() < 0.7:  # Higher chance of segment inversion\n        new_solution[a:b] = new_solution[a:b][::-1]\n    else:  # Node swap with objective bias\n        if random.random() < 0.6:\n            i, j = random.sample(range(a, b), 2)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Additional improvement with objective-aware 2-opt\n    for _ in range(2):\n        i, j = sorted(random.sample(range(n), 2))\n        if j - i > 1:\n            segment = new_solution[i:j]\n            reversed_segment = segment[::-1]\n\n            # Evaluate both configurations\n            def eval_segment(seg):\n                total1 = distance_matrix_1[new_solution[i-1], seg[0]] + distance_matrix_1[seg[-1], new_solution[j]]\n                total2 = distance_matrix_2[new_solution[i-1], seg[0]] + distance_matrix_2[seg[-1], new_solution[j]]\n                for k in range(len(seg)-1):\n                    total1 += distance_matrix_1[seg[k], seg[k+1]]\n                    total2 += distance_matrix_2[seg[k], seg[k+1]]\n                return (total1 + total2) / (total1 * total2) if (total1 * total2) != 0 else float('inf')\n\n            original_score = eval_segment(segment)\n            reversed_score = eval_segment(reversed_segment)\n\n            if reversed_score < original_score:\n                new_solution[i:j] = reversed_segment\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a high-potential solution from the archive by prioritizing those with balanced dominance and good objective trade-offs, then applies a hybrid local search combining adaptive segment fusion (with segment sizes dynamically adjusted based on objective ratios) and objective-aware node relocations to generate improved neighbors while ensuring feasibility through strict validation of node visits and edge connections. The selection process balances exploration and exploitation, while the local search operators simultaneously improve both objectives by evaluating multiple segment configurations and rotations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with balanced dominance and trade-off\n    dominated_counts = []\n    for sol, obj in archive:\n        count = 0\n        for _, other_obj in archive:\n            if other_obj[0] < obj[0] and other_obj[1] < obj[1]:\n                count += 1\n        dominated_counts.append((sol, obj, count))\n\n    # Prefer solutions with balanced dominance and good trade-off\n    selected = max(dominated_counts, key=lambda x: (x[2], -(x[1][0] + x[1][1]) / (x[1][0] * x[1][1])))[0].copy()\n\n    new_solution = selected.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Adaptive segment fusion with objective-aware node relocations\n    # Determine segment sizes based on objective trade-off\n    obj_ratio = archive[0][1][0] / archive[0][1][1] if archive[0][1][1] != 0 else 1.0\n    seg_size1 = max(2, min(5, int(n * 0.2 * (1 + obj_ratio))))\n    seg_size2 = max(2, min(5, int(n * 0.2 * (1 + 1/obj_ratio))))\n\n    # Select two segments of adaptive sizes\n    a = random.randint(0, n - seg_size1)\n    c = random.randint(0, n - seg_size2)\n    b = min(a + seg_size1, n)\n    d = min(c + seg_size2, n)\n\n    # Ensure segments don't overlap in a way that breaks the tour\n    if not (a <= c < b or c <= a < d):\n        # Merge segments and relocate nodes\n        segment1 = new_solution[a:b]\n        segment2 = new_solution[c:d]\n\n        # Objective-aware node relocations\n        def calculate_improvement(solution, distance_matrix):\n            total = 0\n            for i in range(len(solution)-1):\n                total += distance_matrix[solution[i], solution[i+1]]\n            total += distance_matrix[solution[-1], solution[0]]\n            return total\n\n        # Try different configurations\n        configurations = [\n            np.concatenate([new_solution[:a], segment2, segment1, new_solution[d:]]),\n            np.concatenate([new_solution[:a], segment2[::-1], segment1, new_solution[d:]]),\n            np.concatenate([new_solution[:a], segment1, segment2, new_solution[d:]]),\n            np.concatenate([new_solution[:a], segment1[::-1], segment2, new_solution[d:]])\n        ]\n\n        best_config = None\n        best_score = float('inf')\n\n        for config in configurations:\n            score1 = calculate_improvement(config, distance_matrix_1)\n            score2 = calculate_improvement(config, distance_matrix_2)\n            combined_score = (score1 + score2) / (score1 * score2) if (score1 * score2) != 0 else float('inf')\n\n            if combined_score < best_score:\n                best_score = combined_score\n                best_config = config\n\n        if best_config is not None:\n            new_solution = best_config.copy()\n\n    # Additional local improvement with random segment rotation\n    seg_start = random.randint(0, n-1)\n    seg_length = random.randint(2, min(5, n-1))\n    seg_end = min(seg_start + seg_length, n)\n    rotation = random.randint(1, seg_length-1)\n    new_solution[seg_start:seg_end] = np.roll(new_solution[seg_start:seg_end], rotation)\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThis algorithm selects a promising solution from the archive by prioritizing non-dominated solutions with better objective trade-offs, then applies a hybrid local search combining segment rotation and inversion to generate a neighbor solution while ensuring feasibility. The method intelligently balances exploration and exploitation by randomly selecting segments and rotating them to escape local optima.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a non-dominated solution if possible, otherwise select based on objective trade-off\n    non_dominated = []\n    for sol, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if other_obj[0] < obj[0] and other_obj[1] < obj[1]:\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((sol, obj))\n\n    if non_dominated:\n        # Select based on objective trade-off (better balance between objectives)\n        selected = min(non_dominated, key=lambda x: (x[1][0] + x[1][1]) / (x[1][0] * x[1][1]))[0].copy()\n    else:\n        selected = random.choice(archive)[0].copy()\n\n    new_solution = selected.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Novel hybrid local search: edge exchange with segment rotation\n    a, b = sorted(random.sample(range(n), 2))\n    c, d = sorted(random.sample(range(n), 2))\n\n    if a != c and b != d and not (a < c < b < d or c < a < d < b):\n        # Segment rotation instead of inversion\n        if random.random() < 0.5:\n            new_segment = np.concatenate([new_solution[a:b], new_solution[c:d]])\n        else:\n            new_segment = np.concatenate([new_solution[c:d], new_solution[a:b]])\n\n        if len(new_segment) == b - a + d - c:\n            new_solution[a:b] = new_segment[:b-a]\n            new_solution[c:d] = new_segment[b-a:]\n\n    # Segment rotation with random rotation amount\n    seg_start = random.randint(0, n-1)\n    seg_length = random.randint(2, min(5, n-1))\n    seg_end = min(seg_start + seg_length, n)\n    rotation = random.randint(1, seg_length-1)\n    new_solution[seg_start:seg_end] = np.roll(new_solution[seg_start:seg_end], rotation)\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe heuristic selects a promising solution (preferring non-dominated ones) from the archive, then applies a hybrid local search combining edge exchange (randomly swapping and inverting segments) and random segment inversion to generate a neighbor solution while ensuring feasibility. The method prioritizes non-dominated solutions for exploration and uses a mix of standard and novel operators to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a non-dominated solution if possible, otherwise select randomly\n    non_dominated = []\n    for sol, obj in archive:\n        is_dominated = False\n        for _, other_obj in archive:\n            if other_obj[0] < obj[0] and other_obj[1] < obj[1]:\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((sol, obj))\n\n    if non_dominated:\n        selected = random.choice(non_dominated)[0].copy()\n    else:\n        selected = random.choice(archive)[0].copy()\n\n    new_solution = selected.copy()\n\n    # Hybrid local search: combine edge exchange and random segment inversion\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Edge exchange (similar to 2-opt but more general)\n    a, b = sorted(random.sample(range(n), 2))\n    c, d = sorted(random.sample(range(n), 2))\n\n    # Ensure segments are valid and don't overlap in a way that breaks the tour\n    if a != c and b != d and not (a < c < b < d or c < a < d < b):\n        # Create new segments\n        new_segment = np.concatenate([new_solution[a:b], new_solution[c:d][::-1]])\n        if len(new_segment) == b - a + d - c:\n            new_solution[a:b] = new_segment[:b-a]\n            new_solution[c:d] = new_segment[b-a:]\n\n    # Random segment inversion (local improvement)\n    seg_start = random.randint(0, n-1)\n    seg_length = random.randint(2, min(5, n-1))\n    seg_end = min(seg_start + seg_length, n)\n    new_solution[seg_start:seg_end] = new_solution[seg_start:seg_end][::-1]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the optimized heuristic design addressing inefficiencies:\n\n- **Keywords**: *Adaptive multi-segment perturbation, Objective-aware edge swaps, Dominance-aware selection, Feasibility-preserving inversions*\n- **Advice**: Select solutions with balanced dominance and diversity, apply adaptive multi-segment perturbations (3-5 nodes) followed by objective-aware edge swaps, and dynamically adjust segment sizes based on objective trade-offs.\n- **Avoid**: Static segment sizes, blind randomness, or ignoring Pareto dominance; ensure feasibility by validating node visits and edge connections.\n- **Explanation**: Adaptive multi-segment perturbations and objective-aware edge swaps balance exploration and exploitation, while dominance-aware selection guides toward high-potential solutions, avoiding premature convergence. Feasibility is preserved through strict validation.\n\nThis balances exploration and exploitation while avoiding common pitfalls.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 303,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Selection: Prioritize solutions with balanced dominance and diversity, considering both crowding distance and objective trade-offs\n    dominated_counts = []\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        # Calculate dominance count\n        count = 0\n        for _, other_obj in archive:\n            if other_obj[0] < obj[0] and other_obj[1] < obj[1]:\n                count += 1\n        dominated_counts.append(count)\n\n        # Calculate crowding distance\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1]\n        elif i == len(archive)-1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n        dist = (abs(right[0] - left[0]) + abs(right[1] - left[1])) / 2\n        crowding_distances.append(dist)\n\n    # Combine metrics for selection (prioritize balanced dominance and high crowding distance)\n    selection_scores = []\n    for i, (sol, obj) in enumerate(archive):\n        # Normalize metrics\n        norm_dominated = dominated_counts[i] / max(1, max(dominated_counts))\n        norm_crowding = crowding_distances[i] / max(1, max(crowding_distances))\n        # Balance between dominance and diversity\n        score = 0.6 * (1 - norm_dominated) + 0.4 * norm_crowding\n        selection_scores.append((sol, score))\n\n    selected = max(selection_scores, key=lambda x: x[1])[0].copy()\n    new_solution = selected.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Calculate objective correlation and trade-off for adaptive segment sizes\n    objectives = np.array([obj for _, obj in archive])\n    corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    corr = max(-0.5, min(0.5, corr))  # Limit correlation effect\n    obj_ratio = objectives[0, 0] / objectives[0, 1] if objectives[0, 1] != 0 else 1.0\n\n    # Adaptive multi-segment perturbation (3-5 nodes) with objective-aware edge swaps\n    base_size = max(3, min(5, int(n * 0.15)))\n    seg_size1 = max(3, min(5, int(base_size * (1 + corr))))\n    seg_size2 = max(3, min(5, int(base_size * (1 + 1/obj_ratio))))\n\n    # Perform multiple segment operations\n    for _ in range(2):\n        # Select two segments of adaptive sizes\n        a = random.randint(0, n - seg_size1)\n        c = random.randint(0, n - seg_size2)\n        b = min(a + seg_size1, n)\n        d = min(c + seg_size2, n)\n\n        # Ensure segments don't overlap in a way that breaks the tour\n        if not (a <= c < b or c <= a < d):\n            # Create new segments with different configurations\n            segment1 = new_solution[a:b]\n            segment2 = new_solution[c:d]\n\n            # Try different configurations\n            configurations = [\n                np.concatenate([new_solution[:a], segment2, segment1, new_solution[d:]]),\n                np.concatenate([new_solution[:a], segment2[::-1], segment1, new_solution[d:]]),\n                np.concatenate([new_solution[:a], segment1, segment2, new_solution[d:]]),\n                np.concatenate([new_solution[:a], segment1[::-1], segment2, new_solution[d:]])\n            ]\n\n            # Evaluate configurations using both objectives\n            best_config = None\n            best_score = float('inf')\n\n            for config in configurations:\n                # Calculate total cost for each objective\n                total1 = 0\n                total2 = 0\n                for i in range(len(config)-1):\n                    total1 += distance_matrix_1[config[i], config[i+1]]\n                    total2 += distance_matrix_2[config[i], config[i+1]]\n                total1 += distance_matrix_1[config[-1], config[0]]\n                total2 += distance_matrix_2[config[-1], config[0]]\n\n                # Combine scores with objective trade-off consideration\n                combined_score = (total1 + total2) / (total1 * total2) if (total1 * total2) != 0 else float('inf')\n\n                if combined_score < best_score:\n                    best_score = combined_score\n                    best_config = config\n\n            if best_config is not None:\n                new_solution = best_config.copy()\n\n    # Additional improvement with segment rotation\n    seg_start = random.randint(0, n-1)\n    seg_length = random.randint(3, min(5, n-1))\n    seg_end = min(seg_start + seg_length, n)\n    rotation = random.randint(1, seg_length-1)\n    new_solution[seg_start:seg_end] = np.roll(new_solution[seg_start:seg_end], rotation)\n\n    return new_solution\n\n",
        "score": [
            -0.8576759471715074,
            1.5600979328155518
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Selection: Prioritize solutions with balanced dominance and diversity, considering both crowding distance and objective trade-offs\n    dominated_counts = []\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        # Calculate dominance count\n        count = 0\n        for _, other_obj in archive:\n            if other_obj[0] < obj[0] and other_obj[1] < obj[1]:\n                count += 1\n        dominated_counts.append(count)\n\n        # Calculate crowding distance\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1]\n        elif i == len(archive)-1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n        dist = (abs(right[0] - left[0]) + abs(right[1] - left[1])) / 2\n        crowding_distances.append(dist)\n\n    # Combine metrics for selection (prioritize balanced dominance and high crowding distance)\n    selection_scores = []\n    for i, (sol, obj) in enumerate(archive):\n        # Normalize metrics\n        norm_dominated = dominated_counts[i] / max(1, max(dominated_counts))\n        norm_crowding = crowding_distances[i] / max(1, max(crowding_distances))\n        # Balance between dominance and diversity\n        score = 0.6 * (1 - norm_dominated) + 0.4 * norm_crowding\n        selection_scores.append((sol, score))\n\n    selected = max(selection_scores, key=lambda x: x[1])[0].copy()\n    new_solution = selected.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Calculate objective correlation and trade-off for adaptive segment sizes\n    objectives = np.array([obj for _, obj in archive])\n    corr = np.corrcoef(objectives[:, 0], objectives[:, 1])[0, 1]\n    corr = max(-0.5, min(0.5, corr))  # Limit correlation effect\n    obj_ratio = objectives[0, 0] / objectives[0, 1] if objectives[0, 1] != 0 else 1.0\n\n    # Adaptive multi-segment perturbation (3-5 nodes) with objective-aware edge swaps\n    base_size = max(3, min(5, int(n * 0.15)))\n    seg_size1 = max(3, min(5, int(base_size * (1 + corr))))\n    seg_size2 = max(3, min(5, int(base_size * (1 + 1/obj_ratio))))\n\n    # Perform multiple segment operations\n    for _ in range(2):\n        # Select two segments of adaptive sizes\n        a = random.randint(0, n - seg_size1)\n        c = random.randint(0, n - seg_size2)\n        b = min(a + seg_size1, n)\n        d = min(c + seg_size2, n)\n\n        # Ensure segments don't overlap in a way that breaks the tour\n        if not (a <= c < b or c <= a < d):\n            # Create new segments with different configurations\n            segment1 = new_solution[a:b]\n            segment2 = new_solution[c:d]\n\n            # Try different configurations\n            configurations = [\n                np.concatenate([new_solution[:a], segment2, segment1, new_solution[d:]]),\n                np.concatenate([new_solution[:a], segment2[::-1], segment1, new_solution[d:]]),\n                np.concatenate([new_solution[:a], segment1, segment2, new_solution[d:]]),\n                np.concatenate([new_solution[:a], segment1[::-1], segment2, new_solution[d:]])\n            ]\n\n            # Evaluate configurations using both objectives\n            best_config = None\n            best_score = float('inf')\n\n            for config in configurations:\n                # Calculate total cost for each objective\n                total1 = 0\n                total2 = 0\n                for i in range(len(config)-1):\n                    total1 += distance_matrix_1[config[i], config[i+1]]\n                    total2 += distance_matrix_2[config[i], config[i+1]]\n                total1 += distance_matrix_1[config[-1], config[0]]\n                total2 += distance_matrix_2[config[-1], config[0]]\n\n                # Combine scores with objective trade-off consideration\n                combined_score = (total1 + total2) / (total1 * total2) if (total1 * total2) != 0 else float('inf')\n\n                if combined_score < best_score:\n                    best_score = combined_score\n                    best_config = config\n\n            if best_config is not None:\n                new_solution = best_config.copy()\n\n    # Additional improvement with segment rotation\n    seg_start = random.randint(0, n-1)\n    seg_length = random.randint(3, min(5, n-1))\n    seg_end = min(seg_start + seg_length, n)\n    rotation = random.randint(1, seg_length-1)\n    new_solution[seg_start:seg_end] = np.roll(new_solution[seg_start:seg_end], rotation)\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 5 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined objective improvement potential\n    objectives = np.array([obj[0] + obj[1] for _, obj in archive])\n    max_obj = np.max(objectives)\n    if max_obj == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_obj = objectives / max_obj\n        selected_idx = np.argmax(normalized_obj)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Calculate dominance status\n    is_dominated = False\n    current_obj = archive[selected_idx][1]\n    for _, other_obj in archive:\n        if other_obj[0] < current_obj[0] and other_obj[1] < current_obj[1]:\n            is_dominated = True\n            break\n\n    # Adaptive multi-segment rotation with objective-aware edge swaps\n    if is_dominated or np.random.random() < 0.3:\n        # Multi-segment rotation for dominated solutions or with probability\n        num_segments = max(2, min(4, int(np.sqrt(n))))\n        segment_length = max(3, n // num_segments)\n        segments = []\n        for i in range(num_segments):\n            start = i * segment_length\n            end = start + segment_length if i < num_segments - 1 else n\n            segments.append(new_solution[start:end])\n\n        # Rotate segments\n        rotation = np.random.randint(1, len(segments))\n        segments = segments[rotation:] + segments[:rotation]\n\n        # Reconstruct solution\n        new_solution = np.concatenate(segments)\n    else:\n        # Objective-aware edge swaps for non-dominated solutions\n        for _ in range(3):\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n            if i + 1 != j:\n                # Check if swap improves both objectives\n                old_dist1 = distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]]\n                new_dist1 = distance_matrix_1[new_solution[i-1], new_solution[j]] + distance_matrix_1[new_solution[i], new_solution[(j+1)%n]]\n                old_dist2 = distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]\n                new_dist2 = distance_matrix_2[new_solution[i-1], new_solution[j]] + distance_matrix_2[new_solution[i], new_solution[(j+1)%n]]\n\n                if (new_dist1 < old_dist1 and new_dist2 < old_dist2) or np.random.random() < 0.2:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive based on balanced dominance and diversity, then applies an adaptive multi-segment perturbation followed by objective-aware edge swaps to generate a neighbor solution while ensuring feasibility. It prioritizes segments of the tour for transformation based on the trade-off between objectives, and uses randomized edge swaps that favor improvements in both objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with balanced dominance and diversity\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.max(objectives, axis=0, keepdims=True)\n    diversity = np.std(normalized_obj, axis=0)\n    selected_idx = np.argmax(np.sum(normalized_obj * diversity, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive multi-segment perturbation\n    num_segments = max(2, min(5, int(np.sqrt(n))))\n    segment_size = max(3, n // num_segments)\n    for i in range(num_segments):\n        start = i * segment_size\n        end = min(start + segment_size, n)\n        segment = new_solution[start:end]\n\n        # Adaptive transformation based on objective trade-off\n        obj1_trade = objectives[selected_idx][0] / (objectives[selected_idx][0] + objectives[selected_idx][1])\n        if np.random.rand() < obj1_trade:\n            segment = segment[::-1]\n        else:\n            shift = np.random.randint(1, len(segment))\n            segment = np.roll(segment, shift)\n\n        new_solution[start:end] = segment\n\n    # Objective-aware edge swaps\n    for _ in range(3):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i + 1 != j:\n            # Check if swap improves both objectives\n            old_dist1 = distance_matrix_1[new_solution[i], new_solution[i+1]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]]\n            new_dist1 = distance_matrix_1[new_solution[i], new_solution[j]] + distance_matrix_1[new_solution[i+1], new_solution[(j+1)%n]]\n            old_dist2 = distance_matrix_2[new_solution[i], new_solution[i+1]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]\n            new_dist2 = distance_matrix_2[new_solution[i], new_solution[j]] + distance_matrix_2[new_solution[i+1], new_solution[(j+1)%n]]\n\n            if (new_dist1 < old_dist1 and new_dist2 < old_dist2) or np.random.random() < 0.1:\n                new_solution[i+1], new_solution[j] = new_solution[j], new_solution[i+1]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects high-crowding-distance solutions from the archive, adaptively fuses 2-4 non-overlapping segments using objective-aware path relinking (prioritizing objectives based on their relative trade-off), and ensures feasibility by validating node visits, falling back to segment reversal if needed. The method balances exploration of diverse regions of the Pareto front with exploitation of promising segments, using distance matrices to guide fusion based on objective-specific path quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distance for each solution\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.max(objectives, axis=0, keepdims=True)\n    crowding_dist = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_idx = np.argsort(normalized_obj[:, i])\n        crowding_dist[sorted_idx[0]] = np.inf\n        crowding_dist[sorted_idx[-1]] = np.inf\n        for j in range(1, len(archive)-1):\n            crowding_dist[sorted_idx[j]] += normalized_obj[sorted_idx[j+1], i] - normalized_obj[sorted_idx[j-1], i]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment fusion (2-4 segments)\n    num_segments = np.random.randint(2, min(5, n//3))\n    segment_size = n // num_segments\n    segments = []\n    for i in range(num_segments):\n        start = i * segment_size\n        end = start + segment_size if i < num_segments - 1 else n\n        segments.append(new_solution[start:end])\n\n    # Objective-aware path relinking\n    for i in range(len(segments)):\n        for j in range(i+1, len(segments)):\n            # Check if segments can be fused without overlapping\n            if segments[i][-1] != segments[j][0] and segments[j][-1] != segments[i][0]:\n                # Relink based on objective trade-off\n                obj1_trade = current_obj[0] / (current_obj[0] + current_obj[1])\n                if np.random.rand() < obj1_trade:\n                    # Fuse with better path in first objective\n                    if distance_matrix_1[segments[i][-1], segments[j][0]] < distance_matrix_1[segments[j][-1], segments[i][0]]:\n                        segments[i] = np.concatenate([segments[i], segments[j]])\n                    else:\n                        segments[i] = np.concatenate([segments[j], segments[i]])\n                else:\n                    # Fuse with better path in second objective\n                    if distance_matrix_2[segments[i][-1], segments[j][0]] < distance_matrix_2[segments[j][-1], segments[i][0]]:\n                        segments[i] = np.concatenate([segments[i], segments[j]])\n                    else:\n                        segments[i] = np.concatenate([segments[j], segments[i]])\n\n    # Reconstruct solution\n    new_solution = np.concatenate(segments)\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if fusion fails\n        a = random.randint(0, n - 1)\n        b = random.randint(0, n - 1)\n        if a > b:\n            a, b = b, a\n        segment = new_solution[a:b+1]\n        new_solution[a:b+1] = segment[::-1]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects high-crowding-distance solutions from the archive, adaptively fuses 2-4 non-overlapping segments using objective-aware path relinking (prioritizing segments with better paths in the dominant objective), and ensures feasibility by validating node visits, falling back to segment reversal if fusion fails. It balances exploration of diverse Pareto regions with exploitation of promising segments guided by distance matrices.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distance for each solution\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.max(objectives, axis=0, keepdims=True)\n    crowding_dist = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_idx = np.argsort(normalized_obj[:, i])\n        crowding_dist[sorted_idx[0]] = np.inf\n        crowding_dist[sorted_idx[-1]] = np.inf\n        for j in range(1, len(archive)-1):\n            crowding_dist[sorted_idx[j]] += normalized_obj[sorted_idx[j+1], i] - normalized_obj[sorted_idx[j-1], i]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment fusion (2-4 segments)\n    num_segments = np.random.randint(2, min(5, n//3))\n    segment_size = n // num_segments\n    segments = []\n    for i in range(num_segments):\n        start = i * segment_size\n        end = start + segment_size if i < num_segments - 1 else n\n        segments.append(new_solution[start:end])\n\n    # Objective-aware path relinking\n    for i in range(len(segments)):\n        for j in range(i+1, len(segments)):\n            # Check if segments can be fused without overlapping\n            if segments[i][-1] != segments[j][0] and segments[j][-1] != segments[i][0]:\n                # Relink based on objective trade-off\n                obj1_trade = current_obj[0] / (current_obj[0] + current_obj[1])\n                if np.random.rand() < obj1_trade:\n                    # Fuse with better path in first objective\n                    if distance_matrix_1[segments[i][-1], segments[j][0]] < distance_matrix_1[segments[j][-1], segments[i][0]]:\n                        segments[i] = np.concatenate([segments[i], segments[j]])\n                    else:\n                        segments[i] = np.concatenate([segments[j], segments[i]])\n                else:\n                    # Fuse with better path in second objective\n                    if distance_matrix_2[segments[i][-1], segments[j][0]] < distance_matrix_2[segments[j][-1], segments[i][0]]:\n                        segments[i] = np.concatenate([segments[i], segments[j]])\n                    else:\n                        segments[i] = np.concatenate([segments[j], segments[i]])\n\n    # Reconstruct solution\n    new_solution = np.concatenate(segments)\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if fusion fails\n        a = random.randint(0, n - 1)\n        b = random.randint(0, n - 1)\n        if a > b:\n            a, b = b, a\n        segment = new_solution[a:b+1]\n        new_solution[a:b+1] = segment[::-1]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using normalized objective sums, divides it into 3-5 segments, merges them adaptively based on objective trade-offs (biasing toward the objective with higher relative value), and ensures feasibility by validating node visits or falling back to a random segment shuffle if needed. The key design ideas are objective-aware segment merging and adaptive trade-off handling, with a fallback mechanism to maintain feasibility.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate sum of normalized objectives for selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.max(objectives, axis=0, keepdims=True)\n    obj_sums = np.sum(normalized_obj, axis=1)\n    selected_idx = np.argmax(obj_sums)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment merging (3-5 segments)\n    num_segments = np.random.randint(3, min(6, n//2))\n    segment_size = n // num_segments\n    segments = []\n    for i in range(num_segments):\n        start = i * segment_size\n        end = start + segment_size if i < num_segments - 1 else n\n        segments.append(new_solution[start:end])\n\n    # Objective-aware segment merging with trade-off bias\n    for i in range(len(segments)):\n        for j in range(i+1, len(segments)):\n            obj1_trade = current_obj[0] / (current_obj[0] + current_obj[1] + 1e-8)\n            if np.random.rand() < obj1_trade:\n                # Merge with better path in first objective\n                cost1 = distance_matrix_1[segments[i][-1], segments[j][0]] + distance_matrix_1[segments[j][-1], segments[i][0]]\n                cost2 = distance_matrix_1[segments[i][0], segments[j][-1]] + distance_matrix_1[segments[j][0], segments[i][-1]]\n                if cost1 < cost2:\n                    segments[i] = np.concatenate([segments[i], segments[j]])\n                else:\n                    segments[i] = np.concatenate([segments[j], segments[i]])\n            else:\n                # Merge with better path in second objective\n                cost1 = distance_matrix_2[segments[i][-1], segments[j][0]] + distance_matrix_2[segments[j][-1], segments[i][0]]\n                cost2 = distance_matrix_2[segments[i][0], segments[j][-1]] + distance_matrix_2[segments[j][0], segments[i][-1]]\n                if cost1 < cost2:\n                    segments[i] = np.concatenate([segments[i], segments[j]])\n                else:\n                    segments[i] = np.concatenate([segments[j], segments[i]])\n\n    # Reconstruct solution\n    new_solution = np.concatenate(segments)\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to random segment shuffle\n        np.random.shuffle(segments)\n        new_solution = np.concatenate(segments)\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design addressing inefficiencies:\n\n- **Keywords**: *Adaptive multi-segment perturbation, Objective-aware edge swaps, Dominance-aware selection, Feasibility-preserving inversions*\n- **Advice**: Select solutions with balanced dominance and diversity, apply adaptive multi-segment perturbations (3-5 nodes) followed by objective-aware edge swaps, and dynamically adjust segment sizes based on objective trade-offs.\n- **Avoid**: Static segment sizes, blind randomness, or ignoring Pareto dominance; ensure feasibility by validating node visits and edge connections.\n- **Explanation**: Adaptive multi-segment perturbations and objective-aware edge swaps balance exploration and exploitation, while dominance-aware selection guides toward high-potential solutions, avoiding premature convergence. Feasibility is preserved through strict validation.\n\nThis balances exploration and exploitation while avoiding common pitfalls.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 304,
        "algorithm": "The algorithm selects a high-crowding-distance solution from the archive, applies adaptive multi-segment perturbation (3-5 segments) with objective-aware segment fusion, and performs targeted edge swaps to improve both objectives while ensuring feasibility through validation and fallback mechanisms. It prioritizes solutions in crowded regions of the Pareto front and uses segment-based perturbations guided by objective trade-offs, followed by selective edge swaps that favor simultaneous improvements in both objectives. The approach balances exploration through segment fusion and exploitation through targeted swaps, with fallback mechanisms to maintain feasibility when perturbations fail.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distance for each solution\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.max(objectives, axis=0, keepdims=True)\n    crowding_dist = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_idx = np.argsort(normalized_obj[:, i])\n        crowding_dist[sorted_idx[0]] = np.inf\n        crowding_dist[sorted_idx[-1]] = np.inf\n        for j in range(1, len(archive)-1):\n            crowding_dist[sorted_idx[j]] += normalized_obj[sorted_idx[j+1], i] - normalized_obj[sorted_idx[j-1], i]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive multi-segment perturbation (3-5 segments)\n    num_segments = np.random.randint(3, min(6, n//2))\n    segment_size = n // num_segments\n    segments = []\n    for i in range(num_segments):\n        start = i * segment_size\n        end = start + segment_size if i < num_segments - 1 else n\n        segments.append(new_solution[start:end])\n\n    # Objective-aware segment fusion\n    for i in range(len(segments)):\n        for j in range(i+1, len(segments)):\n            obj1_trade = current_obj[0] / (current_obj[0] + current_obj[1] + 1e-8)\n            if np.random.rand() < obj1_trade:\n                # Merge with better path in first objective\n                cost1 = distance_matrix_1[segments[i][-1], segments[j][0]] + distance_matrix_1[segments[j][-1], segments[i][0]]\n                cost2 = distance_matrix_1[segments[i][0], segments[j][-1]] + distance_matrix_1[segments[j][0], segments[i][-1]]\n                if cost1 < cost2:\n                    segments[i] = np.concatenate([segments[i], segments[j]])\n                else:\n                    segments[i] = np.concatenate([segments[j], segments[i]])\n            else:\n                # Merge with better path in second objective\n                cost1 = distance_matrix_2[segments[i][-1], segments[j][0]] + distance_matrix_2[segments[j][-1], segments[i][0]]\n                cost2 = distance_matrix_2[segments[i][0], segments[j][-1]] + distance_matrix_2[segments[j][0], segments[i][-1]]\n                if cost1 < cost2:\n                    segments[i] = np.concatenate([segments[i], segments[j]])\n                else:\n                    segments[i] = np.concatenate([segments[j], segments[i]])\n\n    # Reconstruct solution\n    new_solution = np.concatenate(segments)\n\n    # Targeted edge swaps to improve both objectives\n    for _ in range(3):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i + 1 != j:\n            # Check if swap improves both objectives\n            old_dist1 = distance_matrix_1[new_solution[i], new_solution[i+1]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]]\n            new_dist1 = distance_matrix_1[new_solution[i], new_solution[j]] + distance_matrix_1[new_solution[i+1], new_solution[(j+1)%n]]\n            old_dist2 = distance_matrix_2[new_solution[i], new_solution[i+1]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]\n            new_dist2 = distance_matrix_2[new_solution[i], new_solution[j]] + distance_matrix_2[new_solution[i+1], new_solution[(j+1)%n]]\n\n            if (new_dist1 < old_dist1 and new_dist2 < old_dist2) or np.random.random() < 0.1:\n                new_solution[i+1], new_solution[j] = new_solution[j], new_solution[i+1]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if fusion fails\n        a = random.randint(0, n - 1)\n        b = random.randint(0, n - 1)\n        if a > b:\n            a, b = b, a\n        segment = new_solution[a:b+1]\n        new_solution[a:b+1] = segment[::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.9487633615962567,
            0.31975358724594116
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distance for each solution\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.max(objectives, axis=0, keepdims=True)\n    crowding_dist = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_idx = np.argsort(normalized_obj[:, i])\n        crowding_dist[sorted_idx[0]] = np.inf\n        crowding_dist[sorted_idx[-1]] = np.inf\n        for j in range(1, len(archive)-1):\n            crowding_dist[sorted_idx[j]] += normalized_obj[sorted_idx[j+1], i] - normalized_obj[sorted_idx[j-1], i]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive multi-segment perturbation (3-5 segments)\n    num_segments = np.random.randint(3, min(6, n//2))\n    segment_size = n // num_segments\n    segments = []\n    for i in range(num_segments):\n        start = i * segment_size\n        end = start + segment_size if i < num_segments - 1 else n\n        segments.append(new_solution[start:end])\n\n    # Objective-aware segment fusion\n    for i in range(len(segments)):\n        for j in range(i+1, len(segments)):\n            obj1_trade = current_obj[0] / (current_obj[0] + current_obj[1] + 1e-8)\n            if np.random.rand() < obj1_trade:\n                # Merge with better path in first objective\n                cost1 = distance_matrix_1[segments[i][-1], segments[j][0]] + distance_matrix_1[segments[j][-1], segments[i][0]]\n                cost2 = distance_matrix_1[segments[i][0], segments[j][-1]] + distance_matrix_1[segments[j][0], segments[i][-1]]\n                if cost1 < cost2:\n                    segments[i] = np.concatenate([segments[i], segments[j]])\n                else:\n                    segments[i] = np.concatenate([segments[j], segments[i]])\n            else:\n                # Merge with better path in second objective\n                cost1 = distance_matrix_2[segments[i][-1], segments[j][0]] + distance_matrix_2[segments[j][-1], segments[i][0]]\n                cost2 = distance_matrix_2[segments[i][0], segments[j][-1]] + distance_matrix_2[segments[j][0], segments[i][-1]]\n                if cost1 < cost2:\n                    segments[i] = np.concatenate([segments[i], segments[j]])\n                else:\n                    segments[i] = np.concatenate([segments[j], segments[i]])\n\n    # Reconstruct solution\n    new_solution = np.concatenate(segments)\n\n    # Targeted edge swaps to improve both objectives\n    for _ in range(3):\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        if i + 1 != j:\n            # Check if swap improves both objectives\n            old_dist1 = distance_matrix_1[new_solution[i], new_solution[i+1]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]]\n            new_dist1 = distance_matrix_1[new_solution[i], new_solution[j]] + distance_matrix_1[new_solution[i+1], new_solution[(j+1)%n]]\n            old_dist2 = distance_matrix_2[new_solution[i], new_solution[i+1]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]\n            new_dist2 = distance_matrix_2[new_solution[i], new_solution[j]] + distance_matrix_2[new_solution[i+1], new_solution[(j+1)%n]]\n\n            if (new_dist1 < old_dist1 and new_dist2 < old_dist2) or np.random.random() < 0.1:\n                new_solution[i+1], new_solution[j] = new_solution[j], new_solution[i+1]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if fusion fails\n        a = random.randint(0, n - 1)\n        b = random.randint(0, n - 1)\n        if a > b:\n            a, b = b, a\n        segment = new_solution[a:b+1]\n        new_solution[a:b+1] = segment[::-1]\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive using normalized objective sums, divides it into 3-5 segments, merges them adaptively based on objective trade-offs (biasing toward the objective with higher relative value), and ensures feasibility by validating node visits or falling back to a random segment shuffle if needed. The key design ideas are objective-aware segment merging and adaptive trade-off handling, with a fallback mechanism to maintain feasibility.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate sum of normalized objectives for selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.max(objectives, axis=0, keepdims=True)\n    obj_sums = np.sum(normalized_obj, axis=1)\n    selected_idx = np.argmax(obj_sums)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment merging (3-5 segments)\n    num_segments = np.random.randint(3, min(6, n//2))\n    segment_size = n // num_segments\n    segments = []\n    for i in range(num_segments):\n        start = i * segment_size\n        end = start + segment_size if i < num_segments - 1 else n\n        segments.append(new_solution[start:end])\n\n    # Objective-aware segment merging with trade-off bias\n    for i in range(len(segments)):\n        for j in range(i+1, len(segments)):\n            obj1_trade = current_obj[0] / (current_obj[0] + current_obj[1] + 1e-8)\n            if np.random.rand() < obj1_trade:\n                # Merge with better path in first objective\n                cost1 = distance_matrix_1[segments[i][-1], segments[j][0]] + distance_matrix_1[segments[j][-1], segments[i][0]]\n                cost2 = distance_matrix_1[segments[i][0], segments[j][-1]] + distance_matrix_1[segments[j][0], segments[i][-1]]\n                if cost1 < cost2:\n                    segments[i] = np.concatenate([segments[i], segments[j]])\n                else:\n                    segments[i] = np.concatenate([segments[j], segments[i]])\n            else:\n                # Merge with better path in second objective\n                cost1 = distance_matrix_2[segments[i][-1], segments[j][0]] + distance_matrix_2[segments[j][-1], segments[i][0]]\n                cost2 = distance_matrix_2[segments[i][0], segments[j][-1]] + distance_matrix_2[segments[j][0], segments[i][-1]]\n                if cost1 < cost2:\n                    segments[i] = np.concatenate([segments[i], segments[j]])\n                else:\n                    segments[i] = np.concatenate([segments[j], segments[i]])\n\n    # Reconstruct solution\n    new_solution = np.concatenate(segments)\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to random segment shuffle\n        np.random.shuffle(segments)\n        new_solution = np.concatenate(segments)\n\n    return new_solution\n\n\n        \n        The current objectives are: Negative Hypervolume = -0.8995413523865355, Runtime = 0.10753679275512695 (lower is better for both).\n        \n        Please create a new algorithm that is a modified version of the provided one, but with a strong focus on reducing runtime (e.g., optimize loops, use efficient data structures, remove redundant computations) while trying to maintain or improve Negative Hypervolume if possible.\n        \n        1. First, identify parts of the code that may cause high runtime and suggest optimizations.\n        2. Next, describe your new algorithm and main steps in one detailed sentence, incorporating runtime optimizations. The description must be inside boxed {}.\n        3. Finally, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.\nAdditionally, incorporate this long-term reflection for higher-level guidance:\nHere\u2019s the refined heuristic design addressing inefficiencies:\n\n- **Keywords**: *Adaptive multi-segment perturbation, Objective-aware edge swaps, Dominance-aware selection, Feasibility-preserving inversions*\n- **Advice**: Select solutions with balanced dominance and diversity, apply adaptive multi-segment perturbations (3-5 nodes) followed by objective-aware edge swaps, and dynamically adjust segment sizes based on objective trade-offs.\n- **Avoid**: Static segment sizes, blind randomness, or ignoring Pareto dominance; ensure feasibility by validating node visits and edge connections.\n- **Explanation**: Adaptive multi-segment perturbations and objective-aware edge swaps balance exploration and exploitation, while dominance-aware selection guides toward high-potential solutions, avoiding premature convergence. Feasibility is preserved through strict validation.\n\nThis balances exploration and exploitation while avoiding common pitfalls.",
        "sample_order": 305,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute normalized objectives for selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.maximum(np.max(objectives, axis=0, keepdims=True), 1e-8)\n    obj_sums = np.sum(normalized_obj, axis=1)\n    selected_idx = np.argmax(obj_sums)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment merging (3-5 segments)\n    num_segments = np.random.randint(3, min(6, n//2))\n    segment_size = n // num_segments\n    segments = []\n    for i in range(num_segments):\n        start = i * segment_size\n        end = start + segment_size if i < num_segments - 1 else n\n        segments.append(new_solution[start:end])\n\n    # Precompute segment costs to avoid redundant calculations\n    segment_costs = []\n    for i in range(len(segments)):\n        last_node = segments[i][-1]\n        first_node = segments[i][0]\n        segment_costs.append((distance_matrix_1[last_node], distance_matrix_2[last_node]))\n\n    # Objective-aware segment merging with trade-off bias\n    for i in range(len(segments)):\n        for j in range(i+1, len(segments)):\n            obj1_trade = current_obj[0] / (current_obj[0] + current_obj[1] + 1e-8)\n            if np.random.rand() < obj1_trade:\n                # Merge with better path in first objective\n                cost1 = segment_costs[i][0][segments[j][0]] + segment_costs[j][0][segments[i][0]]\n                cost2 = segment_costs[i][0][segments[j][-1]] + segment_costs[j][0][segments[i][-1]]\n                if cost1 < cost2:\n                    segments[i] = np.concatenate([segments[i], segments[j]])\n                else:\n                    segments[i] = np.concatenate([segments[j], segments[i]])\n            else:\n                # Merge with better path in second objective\n                cost1 = segment_costs[i][1][segments[j][0]] + segment_costs[j][1][segments[i][0]]\n                cost2 = segment_costs[i][1][segments[j][-1]] + segment_costs[j][1][segments[i][-1]]\n                if cost1 < cost2:\n                    segments[i] = np.concatenate([segments[i], segments[j]])\n                else:\n                    segments[i] = np.concatenate([segments[j], segments[i]])\n\n    # Reconstruct solution\n    new_solution = np.concatenate(segments)\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to random segment shuffle\n        np.random.shuffle(segments)\n        new_solution = np.concatenate(segments)\n\n    return new_solution\n\n",
        "score": [
            -0.9335562428082327,
            0.11554664373397827
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute normalized objectives for selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / np.maximum(np.max(objectives, axis=0, keepdims=True), 1e-8)\n    obj_sums = np.sum(normalized_obj, axis=1)\n    selected_idx = np.argmax(obj_sums)\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment merging (3-5 segments)\n    num_segments = np.random.randint(3, min(6, n//2))\n    segment_size = n // num_segments\n    segments = []\n    for i in range(num_segments):\n        start = i * segment_size\n        end = start + segment_size if i < num_segments - 1 else n\n        segments.append(new_solution[start:end])\n\n    # Precompute segment costs to avoid redundant calculations\n    segment_costs = []\n    for i in range(len(segments)):\n        last_node = segments[i][-1]\n        first_node = segments[i][0]\n        segment_costs.append((distance_matrix_1[last_node], distance_matrix_2[last_node]))\n\n    # Objective-aware segment merging with trade-off bias\n    for i in range(len(segments)):\n        for j in range(i+1, len(segments)):\n            obj1_trade = current_obj[0] / (current_obj[0] + current_obj[1] + 1e-8)\n            if np.random.rand() < obj1_trade:\n                # Merge with better path in first objective\n                cost1 = segment_costs[i][0][segments[j][0]] + segment_costs[j][0][segments[i][0]]\n                cost2 = segment_costs[i][0][segments[j][-1]] + segment_costs[j][0][segments[i][-1]]\n                if cost1 < cost2:\n                    segments[i] = np.concatenate([segments[i], segments[j]])\n                else:\n                    segments[i] = np.concatenate([segments[j], segments[i]])\n            else:\n                # Merge with better path in second objective\n                cost1 = segment_costs[i][1][segments[j][0]] + segment_costs[j][1][segments[i][0]]\n                cost2 = segment_costs[i][1][segments[j][-1]] + segment_costs[j][1][segments[i][-1]]\n                if cost1 < cost2:\n                    segments[i] = np.concatenate([segments[i], segments[j]])\n                else:\n                    segments[i] = np.concatenate([segments[j], segments[i]])\n\n    # Reconstruct solution\n    new_solution = np.concatenate(segments)\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to random segment shuffle\n        np.random.shuffle(segments)\n        new_solution = np.concatenate(segments)\n\n    return new_solution\n\n",
        "operation": "r1"
    }
]