[
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 1,
        "algorithm": "The algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n",
        "score": [
            -0.8740335775470593,
            0.49903690814971924
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 1,
        "algorithm": "The algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n",
        "score": [
            -0.8740335775470593,
            0.49903690814971924
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 1,
        "algorithm": "The algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n",
        "score": [
            -0.8740335775470593,
            0.49903690814971924
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n",
        "operation": "i1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 2,
        "algorithm": "The algorithm selects the best solution from the archive based on the sum of its two objectives, then applies a hybrid local search that reverses a randomly selected segment of the tour (edge-swap) to generate a neighbor solution, ensuring feasibility by falling back to a simple swap if the reversal causes duplicates. This approach prioritizes solutions with lower combined costs while using a constrained perturbation to explore the solution space efficiently.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on combined objective values\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n\n    # Hybrid local search: edge-swap with constrained perturbation\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Randomly select a segment to perturb\n    seg_start = np.random.randint(0, n - 2)\n    seg_length = np.random.randint(2, min(5, n - seg_start))\n    seg_end = seg_start + seg_length\n\n    # Reverse the segment (edge-swap)\n    new_solution[seg_start:seg_end] = new_solution[seg_start:seg_end][::-1]\n\n    # Ensure feasibility by checking for duplicates (though reversal should prevent this)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a simple swap if reversal causes issues\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.5449914955289381,
            0.4393578767776489
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on combined objective values\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n\n    # Hybrid local search: edge-swap with constrained perturbation\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Randomly select a segment to perturb\n    seg_start = np.random.randint(0, n - 2)\n    seg_length = np.random.randint(2, min(5, n - seg_start))\n    seg_end = seg_start + seg_length\n\n    # Reverse the segment (edge-swap)\n    new_solution[seg_start:seg_end] = new_solution[seg_start:seg_end][::-1]\n\n    # Ensure feasibility by checking for duplicates (though reversal should prevent this)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a simple swap if reversal causes issues\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 2,
        "algorithm": "The algorithm selects the best solution from the archive based on the sum of its two objectives, then applies a hybrid local search that reverses a randomly selected segment of the tour (edge-swap) to generate a neighbor solution, ensuring feasibility by falling back to a simple swap if the reversal causes duplicates. This approach prioritizes solutions with lower combined costs while using a constrained perturbation to explore the solution space efficiently.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on combined objective values\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n\n    # Hybrid local search: edge-swap with constrained perturbation\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Randomly select a segment to perturb\n    seg_start = np.random.randint(0, n - 2)\n    seg_length = np.random.randint(2, min(5, n - seg_start))\n    seg_end = seg_start + seg_length\n\n    # Reverse the segment (edge-swap)\n    new_solution[seg_start:seg_end] = new_solution[seg_start:seg_end][::-1]\n\n    # Ensure feasibility by checking for duplicates (though reversal should prevent this)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a simple swap if reversal causes issues\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.5449914955289381,
            0.4393578767776489
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on combined objective values\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n\n    # Hybrid local search: edge-swap with constrained perturbation\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Randomly select a segment to perturb\n    seg_start = np.random.randint(0, n - 2)\n    seg_length = np.random.randint(2, min(5, n - seg_start))\n    seg_end = seg_start + seg_length\n\n    # Reverse the segment (edge-swap)\n    new_solution[seg_start:seg_end] = new_solution[seg_start:seg_end][::-1]\n\n    # Ensure feasibility by checking for duplicates (though reversal should prevent this)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a simple swap if reversal causes issues\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "i1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 3,
        "algorithm": "The algorithm selects a solution from the archive with probability inversely proportional to its normalized objective values, then applies a hybrid local search combining edge swaps (reversing segments) and node relocations (moving single nodes) to generate a neighbor solution while ensuring feasibility. The selection prioritizes solutions with worse objectives (higher weights) to encourage exploration, while the local search balances exploration and exploitation through randomized segment reversals and node insertions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with probability inversely proportional to its objective values\n    objectives = np.array([obj for (sol, obj) in archive])\n    normalized_objectives = objectives / objectives.sum(axis=0, keepdims=True)\n    weights = 1 / (normalized_objectives.sum(axis=1) + 1e-6)  # Avoid division by zero\n    weights = weights / weights.sum()  # Normalize weights\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: combine edge swaps and node relocations\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Perform multiple edge swaps\n    for _ in range(2):\n        i, j = np.random.choice(n, 2, replace=False)\n        if i > j:\n            i, j = j, i\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Perform node relocation\n    for _ in range(1):\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        if i != j:\n            node = new_solution[i]\n            new_solution = np.delete(new_solution, i)\n            new_solution = np.insert(new_solution, j, node)\n\n    return new_solution\n\n",
        "score": [
            -0.7702270207510664,
            0.5045158863067627
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with probability inversely proportional to its objective values\n    objectives = np.array([obj for (sol, obj) in archive])\n    normalized_objectives = objectives / objectives.sum(axis=0, keepdims=True)\n    weights = 1 / (normalized_objectives.sum(axis=1) + 1e-6)  # Avoid division by zero\n    weights = weights / weights.sum()  # Normalize weights\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: combine edge swaps and node relocations\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Perform multiple edge swaps\n    for _ in range(2):\n        i, j = np.random.choice(n, 2, replace=False)\n        if i > j:\n            i, j = j, i\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Perform node relocation\n    for _ in range(1):\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        if i != j:\n            node = new_solution[i]\n            new_solution = np.delete(new_solution, i)\n            new_solution = np.insert(new_solution, j, node)\n\n    return new_solution\n\n",
        "operation": "i1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 4,
        "algorithm": "The algorithm selects a random solution from the archive and applies a hybrid local search combining edge swapping (reversing a random segment) and segment insertion (moving a random segment to another position), ensuring feasibility by reverting to edge swapping if duplicates arise. It prioritizes exploration by randomly sampling segments while maintaining tour validity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., non-dominated or with high variance in objectives)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution = archive[selected_idx][0].copy()\n    n = len(selected_solution)\n\n    # Hybrid local search: combine edge swapping with segment insertion\n    new_solution = selected_solution.copy()\n\n    # Edge swapping (similar to 2-opt but with a twist)\n    if n > 3:\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    # Segment insertion (novel mechanism)\n    if n > 4:\n        k, l = sorted(random.sample(range(n), 2))\n        segment = new_solution[k:l+1]\n        new_solution = np.concatenate([new_solution[:k], new_solution[l+1:], segment])\n\n    # Ensure feasibility (no duplicates and all nodes visited)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to edge swapping if segment insertion causes duplicates\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    return new_solution\n\n",
        "score": [
            -0.6955363394749712,
            0.4474228024482727
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., non-dominated or with high variance in objectives)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution = archive[selected_idx][0].copy()\n    n = len(selected_solution)\n\n    # Hybrid local search: combine edge swapping with segment insertion\n    new_solution = selected_solution.copy()\n\n    # Edge swapping (similar to 2-opt but with a twist)\n    if n > 3:\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    # Segment insertion (novel mechanism)\n    if n > 4:\n        k, l = sorted(random.sample(range(n), 2))\n        segment = new_solution[k:l+1]\n        new_solution = np.concatenate([new_solution[:k], new_solution[l+1:], segment])\n\n    # Ensure feasibility (no duplicates and all nodes visited)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to edge swapping if segment insertion causes duplicates\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    return new_solution\n\n",
        "operation": "i1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n1. First, describe the design idea and main steps of your algorithm in one sentence. The description must be inside within boxed {}. \n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 5,
        "algorithm": "The heuristic selects a random solution from the archive and applies a hybrid local search combining edge insertion and node swapping, prioritizing improvements that reduce the total tour length in both objective spaces while ensuring feasibility. The edge insertion randomly moves a node to a new position, and node swapping further refines the solution by swapping nodes if it improves the combined cost. The algorithm balances exploration (random selection) and exploitation (cost-based swapping) to generate high-quality neighbors.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not dominated by others)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and node swapping\n    n = len(new_solution)\n    if n < 4:\n        return new_solution  # Too small to apply operators\n\n    # Step 1: Edge insertion\n    i = np.random.randint(0, n)\n    j = np.random.randint(0, n)\n    while j == i or abs(j - i) == 1:\n        j = np.random.randint(0, n)\n\n    # Remove node at j and reinsert it after i\n    node = new_solution[j]\n    new_solution = np.concatenate([new_solution[:j], new_solution[j+1:]])\n    insert_pos = (i + 1) % len(new_solution)\n    new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Step 2: Node swapping (if beneficial)\n    if np.random.random() < 0.5:  # 50% chance to apply swapping\n        k = np.random.randint(0, len(new_solution))\n        l = np.random.randint(0, len(new_solution))\n        while k == l:\n            l = np.random.randint(0, len(new_solution))\n\n        # Calculate cost before and after swap\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n        temp_sol = new_solution.copy()\n        temp_sol[k], temp_sol[l] = temp_sol[l], temp_sol[k]\n        cost_after = calculate_cost(temp_sol, distance_matrix_1) + calculate_cost(temp_sol, distance_matrix_2)\n\n        if cost_after < cost_before:\n            new_solution = temp_sol\n\n    return new_solution\n\n",
        "score": [
            -0.7671850103342167,
            0.48066627979278564
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not dominated by others)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and node swapping\n    n = len(new_solution)\n    if n < 4:\n        return new_solution  # Too small to apply operators\n\n    # Step 1: Edge insertion\n    i = np.random.randint(0, n)\n    j = np.random.randint(0, n)\n    while j == i or abs(j - i) == 1:\n        j = np.random.randint(0, n)\n\n    # Remove node at j and reinsert it after i\n    node = new_solution[j]\n    new_solution = np.concatenate([new_solution[:j], new_solution[j+1:]])\n    insert_pos = (i + 1) % len(new_solution)\n    new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Step 2: Node swapping (if beneficial)\n    if np.random.random() < 0.5:  # 50% chance to apply swapping\n        k = np.random.randint(0, len(new_solution))\n        l = np.random.randint(0, len(new_solution))\n        while k == l:\n            l = np.random.randint(0, len(new_solution))\n\n        # Calculate cost before and after swap\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n        temp_sol = new_solution.copy()\n        temp_sol[k], temp_sol[l] = temp_sol[l], temp_sol[k]\n        cost_after = calculate_cost(temp_sol, distance_matrix_1) + calculate_cost(temp_sol, distance_matrix_2)\n\n        if cost_after < cost_before:\n            new_solution = temp_sol\n\n    return new_solution\n\n",
        "operation": "i1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive and applies a hybrid local search combining edge swapping (reversing a random segment) and segment insertion (moving a random segment to another position), ensuring feasibility by reverting to edge swapping if duplicates arise. It prioritizes exploration by randomly sampling segments while maintaining tour validity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., non-dominated or with high variance in objectives)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution = archive[selected_idx][0].copy()\n    n = len(selected_solution)\n\n    # Hybrid local search: combine edge swapping with segment insertion\n    new_solution = selected_solution.copy()\n\n    # Edge swapping (similar to 2-opt but with a twist)\n    if n > 3:\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    # Segment insertion (novel mechanism)\n    if n > 4:\n        k, l = sorted(random.sample(range(n), 2))\n        segment = new_solution[k:l+1]\n        new_solution = np.concatenate([new_solution[:k], new_solution[l+1:], segment])\n\n    # Ensure feasibility (no duplicates and all nodes visited)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to edge swapping if segment insertion causes duplicates\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            \n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 6,
        "algorithm": "The algorithm selects a non-dominated solution from the archive (prioritizing Pareto-optimal candidates) and applies a two-phase local search: first identifying high-quality segments (shortest in both objectives) and then reinserting them at random positions while ensuring feasibility through duplicate removal. If this fails, it defaults to a simple random swap. The method balances exploitation of good structures with controlled diversification while maintaining tour validity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with non-dominated objectives\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify high-quality segments\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            # Calculate segment quality based on both objectives\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            score = - (segment_length1 + segment_length2)  # Higher score for shorter segments\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reintegrate segment with dynamic boundary adjustment\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if all else fails\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9494995633810055,
            3.6105303168296814
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with non-dominated objectives\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify high-quality segments\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            # Calculate segment quality based on both objectives\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            score = - (segment_length1 + segment_length2)  # Higher score for shorter segments\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reintegrate segment with dynamic boundary adjustment\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if all else fails\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive and applies a hybrid local search combining edge swapping (reversing a random segment) and segment insertion (moving a random segment to another position), ensuring feasibility by reverting to edge swapping if duplicates arise. It prioritizes exploration by randomly sampling segments while maintaining tour validity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., non-dominated or with high variance in objectives)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution = archive[selected_idx][0].copy()\n    n = len(selected_solution)\n\n    # Hybrid local search: combine edge swapping with segment insertion\n    new_solution = selected_solution.copy()\n\n    # Edge swapping (similar to 2-opt but with a twist)\n    if n > 3:\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    # Segment insertion (novel mechanism)\n    if n > 4:\n        k, l = sorted(random.sample(range(n), 2))\n        segment = new_solution[k:l+1]\n        new_solution = np.concatenate([new_solution[:k], new_solution[l+1:], segment])\n\n    # Ensure feasibility (no duplicates and all nodes visited)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to edge swapping if segment insertion causes duplicates\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            \n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 6,
        "algorithm": "The algorithm selects a non-dominated solution from the archive (prioritizing Pareto-optimal candidates) and applies a two-phase local search: first identifying high-quality segments (shortest in both objectives) and then reinserting them at random positions while ensuring feasibility through duplicate removal. If this fails, it defaults to a simple random swap. The method balances exploitation of good structures with controlled diversification while maintaining tour validity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with non-dominated objectives\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify high-quality segments\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            # Calculate segment quality based on both objectives\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            score = - (segment_length1 + segment_length2)  # Higher score for shorter segments\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reintegrate segment with dynamic boundary adjustment\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if all else fails\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9494995633810055,
            3.6105303168296814
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with non-dominated objectives\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify high-quality segments\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            # Calculate segment quality based on both objectives\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            score = - (segment_length1 + segment_length2)  # Higher score for shorter segments\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reintegrate segment with dynamic boundary adjustment\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if all else fails\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 7,
        "algorithm": "The algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "score": [
            -0.9746621176519483,
            0.5717102885246277
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 7,
        "algorithm": "The algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "score": [
            -0.9746621176519483,
            0.5717102885246277
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 8,
        "algorithm": "The algorithm selects a promising solution from the archive using fitness-based probability (prioritizing solutions with lower combined objective costs) and applies a hybrid local search combining node shift and segment rotation to generate a neighbor while ensuring feasibility. The fitness scores are computed as the inverse of the sum of objectives, and the selection is probabilistic. The local search randomly shifts a node to a new position and rotates a segment of the tour to explore the solution space.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores (inverse of objective values)\n    objectives = np.array([obj for _, obj in archive])\n    fitness_scores = 1 / (objectives[:, 0] + objectives[:, 1] + 1e-6)  # Small epsilon to avoid division by zero\n    selection_probs = fitness_scores / np.sum(fitness_scores)\n\n    # Select a solution with probability proportional to fitness\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: node shift and segment rotation\n    # Shift a random node to a new position\n    node_to_shift = np.random.randint(0, n)\n    new_position = np.random.randint(0, n)\n    while new_position == node_to_shift:\n        new_position = np.random.randint(0, n)\n\n    shifted_node = new_solution[node_to_shift]\n    new_solution = np.concatenate([\n        new_solution[:node_to_shift],\n        new_solution[node_to_shift+1:new_position+1],\n        [shifted_node],\n        new_solution[new_position+1:]\n    ])\n\n    # Rotate a random segment\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    rotation_amount = np.random.randint(1, b - a + 1)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    return new_solution\n\n",
        "score": [
            -0.8194038682995677,
            0.2810159921646118
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores (inverse of objective values)\n    objectives = np.array([obj for _, obj in archive])\n    fitness_scores = 1 / (objectives[:, 0] + objectives[:, 1] + 1e-6)  # Small epsilon to avoid division by zero\n    selection_probs = fitness_scores / np.sum(fitness_scores)\n\n    # Select a solution with probability proportional to fitness\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: node shift and segment rotation\n    # Shift a random node to a new position\n    node_to_shift = np.random.randint(0, n)\n    new_position = np.random.randint(0, n)\n    while new_position == node_to_shift:\n        new_position = np.random.randint(0, n)\n\n    shifted_node = new_solution[node_to_shift]\n    new_solution = np.concatenate([\n        new_solution[:node_to_shift],\n        new_solution[node_to_shift+1:new_position+1],\n        [shifted_node],\n        new_solution[new_position+1:]\n    ])\n\n    # Rotate a random segment\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    rotation_amount = np.random.randint(1, b - a + 1)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 8,
        "algorithm": "The algorithm selects a promising solution from the archive using fitness-based probability (prioritizing solutions with lower combined objective costs) and applies a hybrid local search combining node shift and segment rotation to generate a neighbor while ensuring feasibility. The fitness scores are computed as the inverse of the sum of objectives, and the selection is probabilistic. The local search randomly shifts a node to a new position and rotates a segment of the tour to explore the solution space.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores (inverse of objective values)\n    objectives = np.array([obj for _, obj in archive])\n    fitness_scores = 1 / (objectives[:, 0] + objectives[:, 1] + 1e-6)  # Small epsilon to avoid division by zero\n    selection_probs = fitness_scores / np.sum(fitness_scores)\n\n    # Select a solution with probability proportional to fitness\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: node shift and segment rotation\n    # Shift a random node to a new position\n    node_to_shift = np.random.randint(0, n)\n    new_position = np.random.randint(0, n)\n    while new_position == node_to_shift:\n        new_position = np.random.randint(0, n)\n\n    shifted_node = new_solution[node_to_shift]\n    new_solution = np.concatenate([\n        new_solution[:node_to_shift],\n        new_solution[node_to_shift+1:new_position+1],\n        [shifted_node],\n        new_solution[new_position+1:]\n    ])\n\n    # Rotate a random segment\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    rotation_amount = np.random.randint(1, b - a + 1)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    return new_solution\n\n",
        "score": [
            -0.8194038682995677,
            0.2810159921646118
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores (inverse of objective values)\n    objectives = np.array([obj for _, obj in archive])\n    fitness_scores = 1 / (objectives[:, 0] + objectives[:, 1] + 1e-6)  # Small epsilon to avoid division by zero\n    selection_probs = fitness_scores / np.sum(fitness_scores)\n\n    # Select a solution with probability proportional to fitness\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: node shift and segment rotation\n    # Shift a random node to a new position\n    node_to_shift = np.random.randint(0, n)\n    new_position = np.random.randint(0, n)\n    while new_position == node_to_shift:\n        new_position = np.random.randint(0, n)\n\n    shifted_node = new_solution[node_to_shift]\n    new_solution = np.concatenate([\n        new_solution[:node_to_shift],\n        new_solution[node_to_shift+1:new_position+1],\n        [shifted_node],\n        new_solution[new_position+1:]\n    ])\n\n    # Rotate a random segment\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    rotation_amount = np.random.randint(1, b - a + 1)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects the best solution from the archive based on the sum of its two objectives, then applies a hybrid local search that reverses a randomly selected segment of the tour (edge-swap) to generate a neighbor solution, ensuring feasibility by falling back to a simple swap if the reversal causes duplicates. This approach prioritizes solutions with lower combined costs while using a constrained perturbation to explore the solution space efficiently.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on combined objective values\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n\n    # Hybrid local search: edge-swap with constrained perturbation\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Randomly select a segment to perturb\n    seg_start = np.random.randint(0, n - 2)\n    seg_length = np.random.randint(2, min(5, n - seg_start))\n    seg_end = seg_start + seg_length\n\n    # Reverse the segment (edge-swap)\n    new_solution[seg_start:seg_end] = new_solution[seg_start:seg_end][::-1]\n\n    # Ensure feasibility by checking for duplicates (though reversal should prevent this)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a simple swap if reversal causes issues\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a random solution from the archive and applies a hybrid local search combining edge swapping (reversing a random segment) and segment insertion (moving a random segment to another position), ensuring feasibility by reverting to edge swapping if duplicates arise. It prioritizes exploration by randomly sampling segments while maintaining tour validity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., non-dominated or with high variance in objectives)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution = archive[selected_idx][0].copy()\n    n = len(selected_solution)\n\n    # Hybrid local search: combine edge swapping with segment insertion\n    new_solution = selected_solution.copy()\n\n    # Edge swapping (similar to 2-opt but with a twist)\n    if n > 3:\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    # Segment insertion (novel mechanism)\n    if n > 4:\n        k, l = sorted(random.sample(range(n), 2))\n        segment = new_solution[k:l+1]\n        new_solution = np.concatenate([new_solution[:k], new_solution[l+1:], segment])\n\n    # Ensure feasibility (no duplicates and all nodes visited)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to edge swapping if segment insertion causes duplicates\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe heuristic selects a random solution from the archive and applies a hybrid local search combining edge insertion and node swapping, prioritizing improvements that reduce the total tour length in both objective spaces while ensuring feasibility. The edge insertion randomly moves a node to a new position, and node swapping further refines the solution by swapping nodes if it improves the combined cost. The algorithm balances exploration (random selection) and exploitation (cost-based swapping) to generate high-quality neighbors.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not dominated by others)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and node swapping\n    n = len(new_solution)\n    if n < 4:\n        return new_solution  # Too small to apply operators\n\n    # Step 1: Edge insertion\n    i = np.random.randint(0, n)\n    j = np.random.randint(0, n)\n    while j == i or abs(j - i) == 1:\n        j = np.random.randint(0, n)\n\n    # Remove node at j and reinsert it after i\n    node = new_solution[j]\n    new_solution = np.concatenate([new_solution[:j], new_solution[j+1:]])\n    insert_pos = (i + 1) % len(new_solution)\n    new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Step 2: Node swapping (if beneficial)\n    if np.random.random() < 0.5:  # 50% chance to apply swapping\n        k = np.random.randint(0, len(new_solution))\n        l = np.random.randint(0, len(new_solution))\n        while k == l:\n            l = np.random.randint(0, len(new_solution))\n\n        # Calculate cost before and after swap\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n        temp_sol = new_solution.copy()\n        temp_sol[k], temp_sol[l] = temp_sol[l], temp_sol[k]\n        cost_after = calculate_cost(temp_sol, distance_matrix_1) + calculate_cost(temp_sol, distance_matrix_2)\n\n        if cost_after < cost_before:\n            new_solution = temp_sol\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### Ineffective Self-Reflection\n- **Keywords**: Nondominated heuristics, dominated heuristics, exploration/exploitation, feasibility, hybrid approaches.\n- **Advice**: Focus on adaptive perturbation strategies (e.g., weighted selection + segment insertion) to balance exploration and exploitation while ensuring feasibility.\n- **Avoid**: Greedy cost-based swapping (dominated heuristics) or rigid local search operators (e.g., 2-opt) that limit diversity.\n- **Explanation**: Dominated heuristics risk premature convergence, while nondominated ones generalize better due to their adaptive, feasibility-aware design. A hybrid approach combining weighted selection with segment insertion is promising.\n\n### Heuristic Design (Example Implementation)\n```python\nimport numpy as np\nfrom random import choices, randint\n\ndef select_neighbor(archive):\n    # Step 1: Weighted selection of promising solutions\n    objectives = np.array([sol['objective'] for sol in archive])\n    # Normalize objectives and compute weights (e.g., crowding distance or Pareto dominance)\n    weights = np.random.rand(len(archive))  # Simplified; replace with actual metric\n    weights /= weights.sum()\n    selected_idx = choices(range(len(archive)), weights=weights, k=1)[0]\n    parent = archive[selected_idx]['tour'].copy()\n\n    # Step 2: Hybrid local search (e.g., segment insertion + edge reversal)\n    n = len(parent)\n    a, b = sorted(randint(0, n-1) for _ in range(2))  # Random segment\n    segment = parent[a:b+1]\n    remaining = np.concatenate([parent[:a], parent[b+1:]])\n    insert_pos = randint(0, len(remaining)-1)\n    new_tour = np.concatenate([remaining[:insert_pos], segment, remaining[insert_pos:]])\n\n    # Step 3: Edge reversal for local optimization\n    c, d = sorted(randint(0, n-1) for _ in range(2))\n    new_tour[c:d+1] = new_tour[c:d+1][::-1]\n\n    return {'tour': new_tour, 'objective': compute_objective(new_tour)}  # Replace with actual objective function\n```\n\n**Key Features**:\n1. **Weighted selection**: Prioritizes solutions with high potential (e.g., nondominated or high crowding distance).\n2. **Hybrid local search**: Combines segment insertion and edge reversal for diverse perturbations.\n3. **Feasibility guarantee**: Ensures no nodes are skipped or revisited.\n4. **Adaptive**: Can be extended with problem-specific metrics (e.g., objective normalization).\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 9,
        "algorithm": "The algorithm selects a solution from the archive using weighted random selection (prioritizing lower-cost solutions) and applies a hybrid local search combining segment reversal, edge insertion, and conditional node swapping (only if beneficial for both objectives). It ensures feasibility by validating the solution and falling back to segment reversal if duplicates occur. The method balances exploration (via random operations) and exploitation (via cost-aware swaps) while maintaining valid TSP tours.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values\n    objectives = np.array([sum(obj) for _, obj in archive])\n    weights = 1 / (objectives + 1e-6)  # Inverse of combined cost\n    weights /= weights.sum()\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + edge insertion + node swapping\n    if n > 3:\n        # Segment reversal\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n        # Edge insertion\n        if n > 4:\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n            while c == d or (c == a and d == b):\n                c, d = sorted(np.random.choice(n, 2, replace=False))\n            new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n        # Node swapping (if beneficial)\n        if np.random.random() < 0.3:  # Lower probability to balance exploration\n            k, l = np.random.choice(n, 2, replace=False)\n            temp_solution = new_solution.copy()\n            temp_solution[k], temp_solution[l] = temp_solution[l], temp_solution[k]\n\n            # Calculate cost before and after swap\n            def calculate_cost(sol, dist_mat):\n                total = 0\n                for idx in range(len(sol)):\n                    total += dist_mat[sol[idx-1], sol[idx]]\n                return total\n\n            cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n            cost_after = calculate_cost(temp_solution, distance_matrix_1) + calculate_cost(temp_solution, distance_matrix_2)\n\n            if cost_after < cost_before:\n                new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if duplicates exist\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.8917089614433672,
            0.5027415752410889
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values\n    objectives = np.array([sum(obj) for _, obj in archive])\n    weights = 1 / (objectives + 1e-6)  # Inverse of combined cost\n    weights /= weights.sum()\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + edge insertion + node swapping\n    if n > 3:\n        # Segment reversal\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n        # Edge insertion\n        if n > 4:\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n            while c == d or (c == a and d == b):\n                c, d = sorted(np.random.choice(n, 2, replace=False))\n            new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n        # Node swapping (if beneficial)\n        if np.random.random() < 0.3:  # Lower probability to balance exploration\n            k, l = np.random.choice(n, 2, replace=False)\n            temp_solution = new_solution.copy()\n            temp_solution[k], temp_solution[l] = temp_solution[l], temp_solution[k]\n\n            # Calculate cost before and after swap\n            def calculate_cost(sol, dist_mat):\n                total = 0\n                for idx in range(len(sol)):\n                    total += dist_mat[sol[idx-1], sol[idx]]\n                return total\n\n            cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n            cost_after = calculate_cost(temp_solution, distance_matrix_1) + calculate_cost(temp_solution, distance_matrix_2)\n\n            if cost_after < cost_before:\n                new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if duplicates exist\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive with probability inversely proportional to its normalized objective values, then applies a hybrid local search combining edge swaps (reversing segments) and node relocations (moving single nodes) to generate a neighbor solution while ensuring feasibility. The selection prioritizes solutions with worse objectives (higher weights) to encourage exploration, while the local search balances exploration and exploitation through randomized segment reversals and node insertions.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with probability inversely proportional to its objective values\n    objectives = np.array([obj for (sol, obj) in archive])\n    normalized_objectives = objectives / objectives.sum(axis=0, keepdims=True)\n    weights = 1 / (normalized_objectives.sum(axis=1) + 1e-6)  # Avoid division by zero\n    weights = weights / weights.sum()  # Normalize weights\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: combine edge swaps and node relocations\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Perform multiple edge swaps\n    for _ in range(2):\n        i, j = np.random.choice(n, 2, replace=False)\n        if i > j:\n            i, j = j, i\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Perform node relocation\n    for _ in range(1):\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        if i != j:\n            node = new_solution[i]\n            new_solution = np.delete(new_solution, i)\n            new_solution = np.insert(new_solution, j, node)\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 10,
        "algorithm": "The algorithm randomly selects a solution from the archive (prioritizing randomness over complexity) and applies a single edge swap (reversing a segment between two randomly chosen nodes) to generate a neighbor, ensuring feasibility by maintaining a valid TSP tour. It avoids redundant computations by directly copying and modifying the solution, while the distance matrices are unused, suggesting they may be intended for future extensions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Simplified selection: pick a random solution if archive has multiple entries, else use the first\n    if len(archive) > 1:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        selected_idx = 0\n    base_solution = archive[selected_idx][0].copy()\n\n    # Single edge swap for efficiency\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n    i, j = np.random.choice(n, 2, replace=False)\n    if i > j:\n        i, j = j, i\n    new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.8504151591944094,
            0.4467051029205322
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Simplified selection: pick a random solution if archive has multiple entries, else use the first\n    if len(archive) > 1:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        selected_idx = 0\n    base_solution = archive[selected_idx][0].copy()\n\n    # Single edge swap for efficiency\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n    i, j = np.random.choice(n, 2, replace=False)\n    if i > j:\n        i, j = j, i\n    new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe heuristic selects a random solution from the archive and applies a hybrid local search combining edge insertion and node swapping, prioritizing improvements that reduce the total tour length in both objective spaces while ensuring feasibility. The edge insertion randomly moves a node to a new position, and node swapping further refines the solution by swapping nodes if it improves the combined cost. The algorithm balances exploration (random selection) and exploitation (cost-based swapping) to generate high-quality neighbors.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not dominated by others)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and node swapping\n    n = len(new_solution)\n    if n < 4:\n        return new_solution  # Too small to apply operators\n\n    # Step 1: Edge insertion\n    i = np.random.randint(0, n)\n    j = np.random.randint(0, n)\n    while j == i or abs(j - i) == 1:\n        j = np.random.randint(0, n)\n\n    # Remove node at j and reinsert it after i\n    node = new_solution[j]\n    new_solution = np.concatenate([new_solution[:j], new_solution[j+1:]])\n    insert_pos = (i + 1) % len(new_solution)\n    new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Step 2: Node swapping (if beneficial)\n    if np.random.random() < 0.5:  # 50% chance to apply swapping\n        k = np.random.randint(0, len(new_solution))\n        l = np.random.randint(0, len(new_solution))\n        while k == l:\n            l = np.random.randint(0, len(new_solution))\n\n        # Calculate cost before and after swap\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n        temp_sol = new_solution.copy()\n        temp_sol[k], temp_sol[l] = temp_sol[l], temp_sol[k]\n        cost_after = calculate_cost(temp_sol, distance_matrix_1) + calculate_cost(temp_sol, distance_matrix_2)\n\n        if cost_after < cost_before:\n            new_solution = temp_sol\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Ineffective Self-Reflection\n- **Keywords**: Nondominated heuristics, dominated heuristics, exploration/exploitation, feasibility, hybrid approaches.\n- **Advice**: Focus on adaptive perturbation strategies (e.g., weighted selection + segment insertion) to balance exploration and exploitation while ensuring feasibility.\n- **Avoid**: Greedy cost-based swapping (dominated heuristics) or rigid local search operators (e.g., 2-opt) that limit diversity.\n- **Explanation**: Dominated heuristics risk premature convergence, while nondominated ones generalize better due to their adaptive, feasibility-aware design. A hybrid approach combining weighted selection with segment insertion is promising.\n\n### Heuristic Design (Example Implementation)\n```python\nimport numpy as np\nfrom random import choices, randint\n\ndef select_neighbor(archive):\n    # Step 1: Weighted selection of promising solutions\n    objectives = np.array([sol['objective'] for sol in archive])\n    # Normalize objectives and compute weights (e.g., crowding distance or Pareto dominance)\n    weights = np.random.rand(len(archive))  # Simplified; replace with actual metric\n    weights /= weights.sum()\n    selected_idx = choices(range(len(archive)), weights=weights, k=1)[0]\n    parent = archive[selected_idx]['tour'].copy()\n\n    # Step 2: Hybrid local search (e.g., segment insertion + edge reversal)\n    n = len(parent)\n    a, b = sorted(randint(0, n-1) for _ in range(2))  # Random segment\n    segment = parent[a:b+1]\n    remaining = np.concatenate([parent[:a], parent[b+1:]])\n    insert_pos = randint(0, len(remaining)-1)\n    new_tour = np.concatenate([remaining[:insert_pos], segment, remaining[insert_pos:]])\n\n    # Step 3: Edge reversal for local optimization\n    c, d = sorted(randint(0, n-1) for _ in range(2))\n    new_tour[c:d+1] = new_tour[c:d+1][::-1]\n\n    return {'tour': new_tour, 'objective': compute_objective(new_tour)}  # Replace with actual objective function\n```\n\n**Key Features**:\n1. **Weighted selection**: Prioritizes solutions with high potential (e.g., nondominated or high crowding distance).\n2. **Hybrid local search**: Combines segment insertion and edge reversal for diverse perturbations.\n3. **Feasibility guarantee**: Ensures no nodes are skipped or revisited.\n4. **Adaptive**: Can be extended with problem-specific metrics (e.g., objective normalization).\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 11,
        "algorithm": "The algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion\n    segment_size = max(2, min(n // 3, int(np.random.normal(loc=n//4, scale=n//6))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with dynamic range\n    reversal_range = max(2, min(n // 2, int(np.random.exponential(scale=n//3))))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.825258031508011,
            0.574952244758606
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion\n    segment_size = max(2, min(n // 3, int(np.random.normal(loc=n//4, scale=n//6))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with dynamic range\n    reversal_range = max(2, min(n // 2, int(np.random.exponential(scale=n//3))))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 12,
        "algorithm": "This heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "score": [
            -0.9310379678551315,
            0.2135852575302124
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 12,
        "algorithm": "This heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "score": [
            -0.9310379678551315,
            0.2135852575302124
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 13,
        "algorithm": "The algorithm selects a promising solution from the archive using weighted random selection based on objective values (prioritizing better solutions), then applies a hybrid local search combining adaptive segment reversal and edge insertion. The segment size is dynamically determined based on solution quality and instance size, while edge insertion prioritizes high-distance edges in both objectives, ensuring feasibility by maintaining valid TSP tours throughout. The method balances exploration and exploitation through probabilistic operations and distance-based prioritization.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment size based on solution quality and instance size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics with adaptive selection\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on edge distance\n            if n > 3 and np.random.random() < 0.7:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    # Select node with highest potential improvement\n                    candidate_scores = []\n                    for e in candidates:\n                        u = new_solution[c]\n                        v = new_solution[e]\n                        w = new_solution[d]\n                        improvement = (distance_matrix_1[u][v] + distance_matrix_1[v][w] - distance_matrix_1[u][w]) + \\\n                                    (distance_matrix_2[u][v] + distance_matrix_2[v][w] - distance_matrix_2[u][w])\n                        candidate_scores.append(improvement)\n\n                    best_candidate = candidates[np.argmax(candidate_scores)]\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[best_candidate:best_candidate+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "score": [
            -0.7954168051312039,
            0.36960649490356445
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment size based on solution quality and instance size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics with adaptive selection\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on edge distance\n            if n > 3 and np.random.random() < 0.7:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    # Select node with highest potential improvement\n                    candidate_scores = []\n                    for e in candidates:\n                        u = new_solution[c]\n                        v = new_solution[e]\n                        w = new_solution[d]\n                        improvement = (distance_matrix_1[u][v] + distance_matrix_1[v][w] - distance_matrix_1[u][w]) + \\\n                                    (distance_matrix_2[u][v] + distance_matrix_2[v][w] - distance_matrix_2[u][w])\n                        candidate_scores.append(improvement)\n\n                    best_candidate = candidates[np.argmax(candidate_scores)]\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[best_candidate:best_candidate+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Ineffective Self-Reflection\n- **Keywords**: Nondominated heuristics, dominated heuristics, exploration/exploitation, feasibility, hybrid approaches.\n- **Advice**: Focus on adaptive perturbation strategies (e.g., weighted selection + segment insertion) to balance exploration and exploitation while ensuring feasibility.\n- **Avoid**: Greedy cost-based swapping (dominated heuristics) or rigid local search operators (e.g., 2-opt) that limit diversity.\n- **Explanation**: Dominated heuristics risk premature convergence, while nondominated ones generalize better due to their adaptive, feasibility-aware design. A hybrid approach combining weighted selection with segment insertion is promising.\n\n### Heuristic Design (Example Implementation)\n```python\nimport numpy as np\nfrom random import choices, randint\n\ndef select_neighbor(archive):\n    # Step 1: Weighted selection of promising solutions\n    objectives = np.array([sol['objective'] for sol in archive])\n    # Normalize objectives and compute weights (e.g., crowding distance or Pareto dominance)\n    weights = np.random.rand(len(archive))  # Simplified; replace with actual metric\n    weights /= weights.sum()\n    selected_idx = choices(range(len(archive)), weights=weights, k=1)[0]\n    parent = archive[selected_idx]['tour'].copy()\n\n    # Step 2: Hybrid local search (e.g., segment insertion + edge reversal)\n    n = len(parent)\n    a, b = sorted(randint(0, n-1) for _ in range(2))  # Random segment\n    segment = parent[a:b+1]\n    remaining = np.concatenate([parent[:a], parent[b+1:]])\n    insert_pos = randint(0, len(remaining)-1)\n    new_tour = np.concatenate([remaining[:insert_pos], segment, remaining[insert_pos:]])\n\n    # Step 3: Edge reversal for local optimization\n    c, d = sorted(randint(0, n-1) for _ in range(2))\n    new_tour[c:d+1] = new_tour[c:d+1][::-1]\n\n    return {'tour': new_tour, 'objective': compute_objective(new_tour)}  # Replace with actual objective function\n```\n\n**Key Features**:\n1. **Weighted selection**: Prioritizes solutions with high potential (e.g., nondominated or high crowding distance).\n2. **Hybrid local search**: Combines segment insertion and edge reversal for diverse perturbations.\n3. **Feasibility guarantee**: Ensures no nodes are skipped or revisited.\n4. **Adaptive**: Can be extended with problem-specific metrics (e.g., objective normalization).\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 14,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection of promising solutions using a combination of objective values and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Step 3: Hybrid local search combining segment reversal and adaptive edge insertion\n    # First perform segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Then perform adaptive edge insertion based on high combined distance\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on its distance\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_distances = [distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]] for i in candidates]\n                candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n                e = np.random.choice(candidates, p=candidate_weights)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 4: Additional local improvement with edge reversal\n    if n > 3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Reverse the segment between the two selected edges\n            if c1 < d1 and c2 > d2:  # Ensure proper segment selection\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.9596813386903245,
            0.29400932788848877
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection of promising solutions using a combination of objective values and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Step 3: Hybrid local search combining segment reversal and adaptive edge insertion\n    # First perform segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Then perform adaptive edge insertion based on high combined distance\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on its distance\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_distances = [distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]] for i in candidates]\n                candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n                e = np.random.choice(candidates, p=candidate_weights)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 4: Additional local improvement with edge reversal\n    if n > 3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Reverse the segment between the two selected edges\n            if c1 < d1 and c2 > d2:  # Ensure proper segment selection\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using fitness-based probability (prioritizing solutions with lower combined objective costs) and applies a hybrid local search combining node shift and segment rotation to generate a neighbor while ensuring feasibility. The fitness scores are computed as the inverse of the sum of objectives, and the selection is probabilistic. The local search randomly shifts a node to a new position and rotates a segment of the tour to explore the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores (inverse of objective values)\n    objectives = np.array([obj for _, obj in archive])\n    fitness_scores = 1 / (objectives[:, 0] + objectives[:, 1] + 1e-6)  # Small epsilon to avoid division by zero\n    selection_probs = fitness_scores / np.sum(fitness_scores)\n\n    # Select a solution with probability proportional to fitness\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: node shift and segment rotation\n    # Shift a random node to a new position\n    node_to_shift = np.random.randint(0, n)\n    new_position = np.random.randint(0, n)\n    while new_position == node_to_shift:\n        new_position = np.random.randint(0, n)\n\n    shifted_node = new_solution[node_to_shift]\n    new_solution = np.concatenate([\n        new_solution[:node_to_shift],\n        new_solution[node_to_shift+1:new_position+1],\n        [shifted_node],\n        new_solution[new_position+1:]\n    ])\n\n    # Rotate a random segment\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    rotation_amount = np.random.randint(1, b - a + 1)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using weighted random selection (prioritizing lower-cost solutions) and applies a hybrid local search combining segment reversal, edge insertion, and conditional node swapping (only if beneficial for both objectives). It ensures feasibility by validating the solution and falling back to segment reversal if duplicates occur. The method balances exploration (via random operations) and exploitation (via cost-aware swaps) while maintaining valid TSP tours.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values\n    objectives = np.array([sum(obj) for _, obj in archive])\n    weights = 1 / (objectives + 1e-6)  # Inverse of combined cost\n    weights /= weights.sum()\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + edge insertion + node swapping\n    if n > 3:\n        # Segment reversal\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n        # Edge insertion\n        if n > 4:\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n            while c == d or (c == a and d == b):\n                c, d = sorted(np.random.choice(n, 2, replace=False))\n            new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n        # Node swapping (if beneficial)\n        if np.random.random() < 0.3:  # Lower probability to balance exploration\n            k, l = np.random.choice(n, 2, replace=False)\n            temp_solution = new_solution.copy()\n            temp_solution[k], temp_solution[l] = temp_solution[l], temp_solution[k]\n\n            # Calculate cost before and after swap\n            def calculate_cost(sol, dist_mat):\n                total = 0\n                for idx in range(len(sol)):\n                    total += dist_mat[sol[idx-1], sol[idx]]\n                return total\n\n            cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n            cost_after = calculate_cost(temp_solution, distance_matrix_1) + calculate_cost(temp_solution, distance_matrix_2)\n\n            if cost_after < cost_before:\n                new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if duplicates exist\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### Keywords\n- Adaptive local search, hybrid perturbation, cost-aware selection, feasibility preservation, exploration-exploitation balance.\n\n### Advice\n- Combine **segment insertion** with **edge reversal** or **rotation** to diversify perturbations while preserving feasibility.\n- Use **weighted selection** based on Pareto dominance or crowding distance to prioritize promising solutions.\n- Introduce **conditional operators** (e.g., reverse segments only if they improve one objective) to avoid over-optimization.\n- Ensure **feasibility** by validating tours after perturbations (e.g., check for duplicates or missing nodes).\n\n### Avoid\n- Greedy, single-operator strategies (e.g., always using 2-opt or edge swaps).\n- Static perturbation sizes or probabilities (e.g., fixed segment lengths).\n- Ignoring objective trade-offs (e.g., always optimizing one objective at the expense of the other).\n\n### Explanation\nHybrid local search balances exploration (random segment operations) and exploitation (cost-aware edge prioritization). Adaptive selection and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while weighted selection focuses computational effort on high-potential regions. This approach generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 15,
        "algorithm": "The algorithm selects a promising solution from the archive using Pareto-dominance-based weighted selection, then applies a hybrid local search combining adaptive segment rotation and cost-aware edge insertion to generate a neighbor solution while ensuring feasibility through checks and fallback mechanisms. It prioritizes non-dominated solutions with lower combined costs and focuses on improving high-cost edges in both objective spaces. The method balances exploration (via exponential segment size) and exploitation (via cost-aware edge selection) while maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance-based weighted selection\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(archive)\n    weights = np.zeros(n_solutions)\n\n    for i in range(n_solutions):\n        dominated = False\n        for j in range(n_solutions):\n            if i != j and (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                dominated = True\n                break\n        if not dominated:\n            weights[i] = 1.0 / (1.0 + np.sum(objectives[i]))\n\n    if np.sum(weights) == 0:\n        weights = np.ones(n_solutions) / n_solutions\n    else:\n        weights /= np.sum(weights)\n\n    selected_idx = np.random.choice(n_solutions, p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: adaptive segment rotation and cost-aware edge insertion\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=3))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation_amount = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a node that improves both objectives\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                best_candidate = None\n                min_cost = float('inf')\n\n                for e in candidates:\n                    temp_solution = np.concatenate([\n                        new_solution[:c+1],\n                        new_solution[e:e+1],\n                        new_solution[c+1:]\n                    ])\n\n                    def calculate_cost(sol, dist_mat):\n                        total = 0\n                        for idx in range(len(sol)):\n                            total += dist_mat[sol[idx-1], sol[idx]]\n                        return total\n\n                    cost1 = calculate_cost(temp_solution, distance_matrix_1)\n                    cost2 = calculate_cost(temp_solution, distance_matrix_2)\n                    total_cost = cost1 + cost2\n\n                    if total_cost < min_cost:\n                        min_cost = total_cost\n                        best_candidate = e\n\n                if best_candidate is not None:\n                    new_solution = np.concatenate([\n                        new_solution[:c+1],\n                        new_solution[best_candidate:best_candidate+1],\n                        new_solution[c+1:]\n                    ])\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.8997583200364865,
            2.6796183586120605
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance-based weighted selection\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(archive)\n    weights = np.zeros(n_solutions)\n\n    for i in range(n_solutions):\n        dominated = False\n        for j in range(n_solutions):\n            if i != j and (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                dominated = True\n                break\n        if not dominated:\n            weights[i] = 1.0 / (1.0 + np.sum(objectives[i]))\n\n    if np.sum(weights) == 0:\n        weights = np.ones(n_solutions) / n_solutions\n    else:\n        weights /= np.sum(weights)\n\n    selected_idx = np.random.choice(n_solutions, p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: adaptive segment rotation and cost-aware edge insertion\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=3))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation_amount = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a node that improves both objectives\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                best_candidate = None\n                min_cost = float('inf')\n\n                for e in candidates:\n                    temp_solution = np.concatenate([\n                        new_solution[:c+1],\n                        new_solution[e:e+1],\n                        new_solution[c+1:]\n                    ])\n\n                    def calculate_cost(sol, dist_mat):\n                        total = 0\n                        for idx in range(len(sol)):\n                            total += dist_mat[sol[idx-1], sol[idx]]\n                        return total\n\n                    cost1 = calculate_cost(temp_solution, distance_matrix_1)\n                    cost2 = calculate_cost(temp_solution, distance_matrix_2)\n                    total_cost = cost1 + cost2\n\n                    if total_cost < min_cost:\n                        min_cost = total_cost\n                        best_candidate = e\n\n                if best_candidate is not None:\n                    new_solution = np.concatenate([\n                        new_solution[:c+1],\n                        new_solution[best_candidate:best_candidate+1],\n                        new_solution[c+1:]\n                    ])\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a non-dominated solution from the archive (prioritizing Pareto-optimal candidates) and applies a two-phase local search: first identifying high-quality segments (shortest in both objectives) and then reinserting them at random positions while ensuring feasibility through duplicate removal. If this fails, it defaults to a simple random swap. The method balances exploitation of good structures with controlled diversification while maintaining tour validity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with non-dominated objectives\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify high-quality segments\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            # Calculate segment quality based on both objectives\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            score = - (segment_length1 + segment_length2)  # Higher score for shorter segments\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reintegrate segment with dynamic boundary adjustment\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if all else fails\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 16,
        "algorithm": "The algorithm first selects a promising solution from the archive by identifying Pareto-optimal candidates (or random if none exist), then applies a segment-based local search that evaluates only the top 5% of potential segments using precomputed cumulative sums to avoid redundant distance calculations, with a fallback to a random swap when duplicates are detected. The method prioritizes non-dominated solutions and focuses computational effort on high-potential segments while ensuring feasibility through efficient duplicate removal.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Optimized non-dominated selection using sorting\n    objectives = np.array([obj for _, obj in archive])\n    sorted_indices = np.lexsort((objectives[:, 1], objectives[:, 0]))\n    non_dominated = []\n    last_obj = None\n\n    for idx in sorted_indices:\n        current_obj = objectives[idx]\n        if last_obj is None or not (current_obj[0] >= last_obj[0] and current_obj[1] >= last_obj[1]):\n            non_dominated.append(idx)\n            last_obj = current_obj\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Precompute segment costs for top 5% of potential segments\n    segment_scores = []\n    max_segments = max(1, n // 20)  # Only evaluate top 5% of segments\n\n    # Use cumulative sums for faster segment cost calculation\n    cumsum1 = np.cumsum(distance_matrix_1[new_solution[:-1], new_solution[1:]])\n    cumsum2 = np.cumsum(distance_matrix_2[new_solution[:-1], new_solution[1:]])\n\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):\n            # Calculate segment cost using cumulative sums\n            segment_cost1 = cumsum1[j-1] - (cumsum1[i-1] if i > 0 else 0)\n            segment_cost2 = cumsum2[j-1] - (cumsum2[i-1] if i > 0 else 0)\n            score = -(segment_cost1 + segment_cost2)\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Simple reinsertion without duplicate check\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:]\n        ])\n\n    # Efficient duplicate removal\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) < n:\n        # Fallback to simple swap if needed\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9183696622019364,
            0.5027822852134705
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Optimized non-dominated selection using sorting\n    objectives = np.array([obj for _, obj in archive])\n    sorted_indices = np.lexsort((objectives[:, 1], objectives[:, 0]))\n    non_dominated = []\n    last_obj = None\n\n    for idx in sorted_indices:\n        current_obj = objectives[idx]\n        if last_obj is None or not (current_obj[0] >= last_obj[0] and current_obj[1] >= last_obj[1]):\n            non_dominated.append(idx)\n            last_obj = current_obj\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Precompute segment costs for top 5% of potential segments\n    segment_scores = []\n    max_segments = max(1, n // 20)  # Only evaluate top 5% of segments\n\n    # Use cumulative sums for faster segment cost calculation\n    cumsum1 = np.cumsum(distance_matrix_1[new_solution[:-1], new_solution[1:]])\n    cumsum2 = np.cumsum(distance_matrix_2[new_solution[:-1], new_solution[1:]])\n\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):\n            # Calculate segment cost using cumulative sums\n            segment_cost1 = cumsum1[j-1] - (cumsum1[i-1] if i > 0 else 0)\n            segment_cost2 = cumsum2[j-1] - (cumsum2[i-1] if i > 0 else 0)\n            score = -(segment_cost1 + segment_cost2)\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Simple reinsertion without duplicate check\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:]\n        ])\n\n    # Efficient duplicate removal\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) < n:\n        # Fallback to simple swap if needed\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using fitness-based probability (prioritizing solutions with lower combined objective costs) and applies a hybrid local search combining node shift and segment rotation to generate a neighbor while ensuring feasibility. The fitness scores are computed as the inverse of the sum of objectives, and the selection is probabilistic. The local search randomly shifts a node to a new position and rotates a segment of the tour to explore the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores (inverse of objective values)\n    objectives = np.array([obj for _, obj in archive])\n    fitness_scores = 1 / (objectives[:, 0] + objectives[:, 1] + 1e-6)  # Small epsilon to avoid division by zero\n    selection_probs = fitness_scores / np.sum(fitness_scores)\n\n    # Select a solution with probability proportional to fitness\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: node shift and segment rotation\n    # Shift a random node to a new position\n    node_to_shift = np.random.randint(0, n)\n    new_position = np.random.randint(0, n)\n    while new_position == node_to_shift:\n        new_position = np.random.randint(0, n)\n\n    shifted_node = new_solution[node_to_shift]\n    new_solution = np.concatenate([\n        new_solution[:node_to_shift],\n        new_solution[node_to_shift+1:new_position+1],\n        [shifted_node],\n        new_solution[new_position+1:]\n    ])\n\n    # Rotate a random segment\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    rotation_amount = np.random.randint(1, b - a + 1)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive and applies a hybrid local search combining edge swapping (reversing a random segment) and segment insertion (moving a random segment to another position), ensuring feasibility by reverting to edge swapping if duplicates arise. It prioritizes exploration by randomly sampling segments while maintaining tour validity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., non-dominated or with high variance in objectives)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution = archive[selected_idx][0].copy()\n    n = len(selected_solution)\n\n    # Hybrid local search: combine edge swapping with segment insertion\n    new_solution = selected_solution.copy()\n\n    # Edge swapping (similar to 2-opt but with a twist)\n    if n > 3:\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    # Segment insertion (novel mechanism)\n    if n > 4:\n        k, l = sorted(random.sample(range(n), 2))\n        segment = new_solution[k:l+1]\n        new_solution = np.concatenate([new_solution[:k], new_solution[l+1:], segment])\n\n    # Ensure feasibility (no duplicates and all nodes visited)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to edge swapping if segment insertion causes duplicates\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords\n- Adaptive local search, hybrid perturbation, cost-aware selection, feasibility preservation, exploration-exploitation balance.\n\n### Advice\n- Combine **segment insertion** with **edge reversal** or **rotation** to diversify perturbations while preserving feasibility.\n- Use **weighted selection** based on Pareto dominance or crowding distance to prioritize promising solutions.\n- Introduce **conditional operators** (e.g., reverse segments only if they improve one objective) to avoid over-optimization.\n- Ensure **feasibility** by validating tours after perturbations (e.g., check for duplicates or missing nodes).\n\n### Avoid\n- Greedy, single-operator strategies (e.g., always using 2-opt or edge swaps).\n- Static perturbation sizes or probabilities (e.g., fixed segment lengths).\n- Ignoring objective trade-offs (e.g., always optimizing one objective at the expense of the other).\n\n### Explanation\nHybrid local search balances exploration (random segment operations) and exploitation (cost-aware edge prioritization). Adaptive selection and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while weighted selection focuses computational effort on high-potential regions. This approach generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 17,
        "algorithm": "The algorithm selects a promising solution from the archive using Pareto dominance and crowding distance, then applies a hybrid local search combining segment crossover (randomly swapping two segments of the tour) and conditional edge reversal (reversing a segment if it improves at least one objective). It ensures feasibility by validating the tour and falling back to a random swap if duplicates occur, balancing exploration and exploitation dynamically.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and crowding distance to select a promising solution\n    objectives = np.array([obj for _, obj in archive])\n    is_dominated = np.zeros(len(archive), dtype=bool)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                is_dominated[i] = True\n                break\n\n    non_dominated_indices = np.where(~is_dominated)[0]\n    if len(non_dominated_indices) > 0:\n        selected_idx = np.random.choice(non_dominated_indices)\n    else:\n        # Fallback to random selection if no non-dominated solutions\n        selected_idx = np.random.randint(0, len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: segment crossover and conditional edge reversal\n    # Segment crossover\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    c, d = sorted(np.random.choice(n, 2, replace=False))\n    segment1 = new_solution[a:b+1]\n    segment2 = new_solution[c:d+1]\n    new_solution = np.concatenate([new_solution[:a], segment2, new_solution[b+1:c], segment1, new_solution[d+1:]])\n\n    # Conditional edge reversal\n    if n > 3:\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        reversed_segment = np.flip(new_solution[i:j+1])\n        temp_solution = np.concatenate([new_solution[:i], reversed_segment, new_solution[j+1:]])\n\n        # Check if reversal improves at least one objective\n        def calculate_cost(sol, dist_matrix):\n            cost = 0\n            for k in range(len(sol) - 1):\n                cost += dist_matrix[sol[k], sol[k+1]]\n            cost += dist_matrix[sol[-1], sol[0]]\n            return cost\n\n        original_cost1 = calculate_cost(new_solution, distance_matrix_1)\n        original_cost2 = calculate_cost(new_solution, distance_matrix_2)\n        new_cost1 = calculate_cost(temp_solution, distance_matrix_1)\n        new_cost2 = calculate_cost(temp_solution, distance_matrix_2)\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to random swap if duplicates occur\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8219294269133868,
            0.32037270069122314
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and crowding distance to select a promising solution\n    objectives = np.array([obj for _, obj in archive])\n    is_dominated = np.zeros(len(archive), dtype=bool)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                is_dominated[i] = True\n                break\n\n    non_dominated_indices = np.where(~is_dominated)[0]\n    if len(non_dominated_indices) > 0:\n        selected_idx = np.random.choice(non_dominated_indices)\n    else:\n        # Fallback to random selection if no non-dominated solutions\n        selected_idx = np.random.randint(0, len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: segment crossover and conditional edge reversal\n    # Segment crossover\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    c, d = sorted(np.random.choice(n, 2, replace=False))\n    segment1 = new_solution[a:b+1]\n    segment2 = new_solution[c:d+1]\n    new_solution = np.concatenate([new_solution[:a], segment2, new_solution[b+1:c], segment1, new_solution[d+1:]])\n\n    # Conditional edge reversal\n    if n > 3:\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        reversed_segment = np.flip(new_solution[i:j+1])\n        temp_solution = np.concatenate([new_solution[:i], reversed_segment, new_solution[j+1:]])\n\n        # Check if reversal improves at least one objective\n        def calculate_cost(sol, dist_matrix):\n            cost = 0\n            for k in range(len(sol) - 1):\n                cost += dist_matrix[sol[k], sol[k+1]]\n            cost += dist_matrix[sol[-1], sol[0]]\n            return cost\n\n        original_cost1 = calculate_cost(new_solution, distance_matrix_1)\n        original_cost2 = calculate_cost(new_solution, distance_matrix_2)\n        new_cost1 = calculate_cost(temp_solution, distance_matrix_1)\n        new_cost2 = calculate_cost(temp_solution, distance_matrix_2)\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to random swap if duplicates occur\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a random solution from the archive and applies a hybrid local search combining edge swapping (reversing a random segment) and segment insertion (moving a random segment to another position), ensuring feasibility by reverting to edge swapping if duplicates arise. It prioritizes exploration by randomly sampling segments while maintaining tour validity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., non-dominated or with high variance in objectives)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution = archive[selected_idx][0].copy()\n    n = len(selected_solution)\n\n    # Hybrid local search: combine edge swapping with segment insertion\n    new_solution = selected_solution.copy()\n\n    # Edge swapping (similar to 2-opt but with a twist)\n    if n > 3:\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    # Segment insertion (novel mechanism)\n    if n > 4:\n        k, l = sorted(random.sample(range(n), 2))\n        segment = new_solution[k:l+1]\n        new_solution = np.concatenate([new_solution[:k], new_solution[l+1:], segment])\n\n    # Ensure feasibility (no duplicates and all nodes visited)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to edge swapping if segment insertion causes duplicates\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 18,
        "algorithm": "The algorithm selects a promising solution from the archive using a weighted combination of its objectives, then applies a hybrid local search combining adaptive segment reversal and distance-aware node swapping, ensuring feasibility by validating the tour and falling back to simple swaps if needed. The selection prioritizes diversity through random weights, while the local search focuses on improving both objectives by evaluating changes in distance matrices.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest weighted sum of objectives (prioritizing diversity)\n    weights = np.random.uniform(0.3, 0.7, size=len(archive))\n    objectives = np.array([obj for _, obj in archive])\n    scores = objectives[:, 0] * weights + objectives[:, 1] * (1 - weights)\n    selected_idx = np.argmax(scores)\n    selected_solution = archive[selected_idx][0].copy()\n    n = len(selected_solution)\n\n    new_solution = selected_solution.copy()\n\n    # Novel segment reversal with adaptive length\n    if n > 4:\n        segment_length = min(random.randint(2, n//2), n-2)\n        start = random.randint(0, n - segment_length)\n        end = start + segment_length\n        new_solution[start:end] = np.flip(new_solution[start:end])\n\n    # Node swapping with distance-based preference\n    if n > 3:\n        i, j = random.sample(range(n), 2)\n        node_i, node_j = new_solution[i], new_solution[j]\n        dist1_diff = (distance_matrix_1[node_i, new_solution[(i-1)%n]] + distance_matrix_1[node_i, new_solution[(i+1)%n]] +\n                      distance_matrix_1[node_j, new_solution[(j-1)%n]] + distance_matrix_1[node_j, new_solution[(j+1)%n]]) - \\\n                     (distance_matrix_1[new_solution[i], new_solution[(i-1)%n]] + distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] +\n                      distance_matrix_1[new_solution[j], new_solution[(j-1)%n]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]])\n        dist2_diff = (distance_matrix_2[node_i, new_solution[(i-1)%n]] + distance_matrix_2[node_i, new_solution[(i+1)%n]] +\n                      distance_matrix_2[node_j, new_solution[(j-1)%n]] + distance_matrix_2[node_j, new_solution[(j+1)%n]]) - \\\n                     (distance_matrix_2[new_solution[i], new_solution[(i-1)%n]] + distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] +\n                      distance_matrix_2[new_solution[j], new_solution[(j-1)%n]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]])\n        if dist1_diff + dist2_diff < 0:  # Only swap if improves both objectives\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if tour becomes invalid\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.887538505648509,
            0.5161455273628235
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest weighted sum of objectives (prioritizing diversity)\n    weights = np.random.uniform(0.3, 0.7, size=len(archive))\n    objectives = np.array([obj for _, obj in archive])\n    scores = objectives[:, 0] * weights + objectives[:, 1] * (1 - weights)\n    selected_idx = np.argmax(scores)\n    selected_solution = archive[selected_idx][0].copy()\n    n = len(selected_solution)\n\n    new_solution = selected_solution.copy()\n\n    # Novel segment reversal with adaptive length\n    if n > 4:\n        segment_length = min(random.randint(2, n//2), n-2)\n        start = random.randint(0, n - segment_length)\n        end = start + segment_length\n        new_solution[start:end] = np.flip(new_solution[start:end])\n\n    # Node swapping with distance-based preference\n    if n > 3:\n        i, j = random.sample(range(n), 2)\n        node_i, node_j = new_solution[i], new_solution[j]\n        dist1_diff = (distance_matrix_1[node_i, new_solution[(i-1)%n]] + distance_matrix_1[node_i, new_solution[(i+1)%n]] +\n                      distance_matrix_1[node_j, new_solution[(j-1)%n]] + distance_matrix_1[node_j, new_solution[(j+1)%n]]) - \\\n                     (distance_matrix_1[new_solution[i], new_solution[(i-1)%n]] + distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] +\n                      distance_matrix_1[new_solution[j], new_solution[(j-1)%n]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]])\n        dist2_diff = (distance_matrix_2[node_i, new_solution[(i-1)%n]] + distance_matrix_2[node_i, new_solution[(i+1)%n]] +\n                      distance_matrix_2[node_j, new_solution[(j-1)%n]] + distance_matrix_2[node_j, new_solution[(j+1)%n]]) - \\\n                     (distance_matrix_2[new_solution[i], new_solution[(i-1)%n]] + distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] +\n                      distance_matrix_2[new_solution[j], new_solution[(j-1)%n]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]])\n        if dist1_diff + dist2_diff < 0:  # Only swap if improves both objectives\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if tour becomes invalid\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a random solution from the archive and applies a hybrid local search combining edge swapping (reversing a random segment) and segment insertion (moving a random segment to another position), ensuring feasibility by reverting to edge swapping if duplicates arise. It prioritizes exploration by randomly sampling segments while maintaining tour validity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., non-dominated or with high variance in objectives)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution = archive[selected_idx][0].copy()\n    n = len(selected_solution)\n\n    # Hybrid local search: combine edge swapping with segment insertion\n    new_solution = selected_solution.copy()\n\n    # Edge swapping (similar to 2-opt but with a twist)\n    if n > 3:\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    # Segment insertion (novel mechanism)\n    if n > 4:\n        k, l = sorted(random.sample(range(n), 2))\n        segment = new_solution[k:l+1]\n        new_solution = np.concatenate([new_solution[:k], new_solution[l+1:], segment])\n\n    # Ensure feasibility (no duplicates and all nodes visited)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to edge swapping if segment insertion causes duplicates\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 19,
        "algorithm": "The algorithm selects a solution from the archive with high objective variance, then applies a hybrid local search combining segment relocation and edge reversal to generate a neighbor solution while ensuring feasibility through a uniqueness check. It prioritizes solutions with diverse objectives and uses random segment operations to explore the search space creatively, falling back to edge reversal if needed. The key design ideas are the variance-based selection, hybrid local search, and novel feasibility checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (high variance in objectives)\n    objectives = [obj for _, obj in archive]\n    variances = [np.var(obj) for obj in objectives]\n    selected_idx = np.argmax(variances)\n    selected_solution = archive[selected_idx][0].copy()\n    n = len(selected_solution)\n\n    # Hybrid local search: segment relocation with edge reversal\n    new_solution = selected_solution.copy()\n\n    # Segment relocation (novel mechanism)\n    if n > 3:\n        a, b = sorted(random.sample(range(n), 2))\n        segment = new_solution[a:b+1]\n        new_solution = np.concatenate([new_solution[:a], new_solution[b+1:], segment])\n\n    # Edge reversal (modified 2-opt)\n    if n > 4:\n        c, d = sorted(random.sample(range(n), 2))\n        new_solution[c:d+1] = np.flip(new_solution[c:d+1])\n\n    # Feasibility check (no duplicates and all nodes visited)\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n or not np.array_equal(np.sort(unique_nodes), np.sort(selected_solution)):\n        # Fallback to edge reversal if segment relocation causes issues\n        e, f = sorted(random.sample(range(n), 2))\n        new_solution[e:f+1] = np.flip(new_solution[e:f+1])\n\n    return new_solution\n\n",
        "score": [
            -0.8379150781365681,
            0.9839516878128052
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (high variance in objectives)\n    objectives = [obj for _, obj in archive]\n    variances = [np.var(obj) for obj in objectives]\n    selected_idx = np.argmax(variances)\n    selected_solution = archive[selected_idx][0].copy()\n    n = len(selected_solution)\n\n    # Hybrid local search: segment relocation with edge reversal\n    new_solution = selected_solution.copy()\n\n    # Segment relocation (novel mechanism)\n    if n > 3:\n        a, b = sorted(random.sample(range(n), 2))\n        segment = new_solution[a:b+1]\n        new_solution = np.concatenate([new_solution[:a], new_solution[b+1:], segment])\n\n    # Edge reversal (modified 2-opt)\n    if n > 4:\n        c, d = sorted(random.sample(range(n), 2))\n        new_solution[c:d+1] = np.flip(new_solution[c:d+1])\n\n    # Feasibility check (no duplicates and all nodes visited)\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n or not np.array_equal(np.sort(unique_nodes), np.sort(selected_solution)):\n        # Fallback to edge reversal if segment relocation causes issues\n        e, f = sorted(random.sample(range(n), 2))\n        new_solution[e:f+1] = np.flip(new_solution[e:f+1])\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection of promising solutions using a combination of objective values and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Step 3: Hybrid local search combining segment reversal and adaptive edge insertion\n    # First perform segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Then perform adaptive edge insertion based on high combined distance\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on its distance\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_distances = [distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]] for i in candidates]\n                candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n                e = np.random.choice(candidates, p=candidate_weights)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 4: Additional local improvement with edge reversal\n    if n > 3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Reverse the segment between the two selected edges\n            if c1 < d1 and c2 > d2:  # Ensure proper segment selection\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### Keywords\n- **Adaptive local search**, **hybrid perturbation**, **cost-aware selection**, **feasibility preservation**, **exploration-exploitation balance**.\n\n### Advice\n- Combine **segment insertion** with **edge reversal** or **rotation** to diversify perturbations while preserving feasibility.\n- Use **weighted selection** based on Pareto dominance or crowding distance to prioritize promising solutions.\n- Introduce **conditional operators** (e.g., reverse segments only if they improve one objective) to avoid over-optimization.\n- Ensure **feasibility** by validating tours after perturbations (e.g., check for duplicates or missing nodes).\n\n### Avoid\n- Greedy, single-operator strategies (e.g., always using 2-opt or edge swaps).\n- Static perturbation sizes or probabilities (e.g., fixed segment lengths).\n- Ignoring objective trade-offs (e.g., always optimizing one objective at the expense of the other).\n\n### Explanation\nHybrid local search balances exploration (random segment operations) and exploitation (cost-aware edge prioritization). Adaptive selection and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while weighted selection focuses computational effort on high-potential regions. This approach generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 20,
        "algorithm": "The algorithm combines cost-sensitive selection with an adaptive hybrid local search that prioritizes high-distance edges in both objectives through dynamic segment rotation and probabilistic edge relocation, while maintaining feasibility through conditional perturbations and segment reversal. It intelligently selects solutions based on Pareto dominance and objective improvement potential, using multi-objective distance prioritization to guide the search. The method balances exploration and exploitation by dynamically adjusting segment sizes and applying conditional operations to refine the tour.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Cost-sensitive selection with Pareto dominance awareness\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    dominance = np.sum(normalized_obj < 0.5, axis=1)  # Count of objectives where solution is better than median\n    weights = dominance / np.sum(dominance)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with cost-aware sizing\n    segment_size = max(2, min(n // 3, int(np.exp(np.random.normal(scale=1.5)))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Rotation direction based on objective improvement potential\n    rotation_dir = 1 if np.random.rand() < 0.7 else -1\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], np.random.randint(1, segment_size) * rotation_dir)\n\n    # Probabilistic edge relocation with multi-objective distance prioritization\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_scores = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_scores.append(combined_distances[u][v])\n\n        edge_scores = np.array(edge_scores)\n        edge_probs = edge_scores / np.sum(edge_scores)\n        selected_edge = np.random.choice(n, p=edge_probs)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            # Candidate selection based on both objectives\n            candidate_scores = []\n            for i in candidates:\n                node = new_solution[i]\n                score = (distance_matrix_1[new_solution[c]][node] + distance_matrix_2[new_solution[c]][node]) * \\\n                        (distance_matrix_1[node][new_solution[d]] + distance_matrix_2[node][new_solution[d]])\n                candidate_scores.append(score)\n\n            candidate_probs = np.array(candidate_scores) / np.sum(candidate_scores)\n            e = np.random.choice(candidates, p=candidate_probs)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal for local improvement\n    if n > 4 and np.random.rand() < 0.3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Ensure proper segment selection and improvement potential\n            if c1 < d1 and c2 > d2 and (d1 + 1) % n != c2:\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.8564302310325977,
            0.32124507427215576
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Cost-sensitive selection with Pareto dominance awareness\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    dominance = np.sum(normalized_obj < 0.5, axis=1)  # Count of objectives where solution is better than median\n    weights = dominance / np.sum(dominance)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with cost-aware sizing\n    segment_size = max(2, min(n // 3, int(np.exp(np.random.normal(scale=1.5)))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Rotation direction based on objective improvement potential\n    rotation_dir = 1 if np.random.rand() < 0.7 else -1\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], np.random.randint(1, segment_size) * rotation_dir)\n\n    # Probabilistic edge relocation with multi-objective distance prioritization\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_scores = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_scores.append(combined_distances[u][v])\n\n        edge_scores = np.array(edge_scores)\n        edge_probs = edge_scores / np.sum(edge_scores)\n        selected_edge = np.random.choice(n, p=edge_probs)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            # Candidate selection based on both objectives\n            candidate_scores = []\n            for i in candidates:\n                node = new_solution[i]\n                score = (distance_matrix_1[new_solution[c]][node] + distance_matrix_2[new_solution[c]][node]) * \\\n                        (distance_matrix_1[node][new_solution[d]] + distance_matrix_2[node][new_solution[d]])\n                candidate_scores.append(score)\n\n            candidate_probs = np.array(candidate_scores) / np.sum(candidate_scores)\n            e = np.random.choice(candidates, p=candidate_probs)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal for local improvement\n    if n > 4 and np.random.rand() < 0.3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Ensure proper segment selection and improvement potential\n            if c1 < d1 and c2 > d2 and (d1 + 1) % n != c2:\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a non-dominated solution from the archive (prioritizing Pareto-optimal candidates) and applies a two-phase local search: first identifying high-quality segments (shortest in both objectives) and then reinserting them at random positions while ensuring feasibility through duplicate removal. If this fails, it defaults to a simple random swap. The method balances exploitation of good structures with controlled diversification while maintaining tour validity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with non-dominated objectives\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify high-quality segments\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            # Calculate segment quality based on both objectives\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            score = - (segment_length1 + segment_length2)  # Higher score for shorter segments\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reintegrate segment with dynamic boundary adjustment\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if all else fails\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 21,
        "algorithm": "The algorithm first efficiently identifies non-dominated solutions by comparing objectives, then selects a promising solution and applies a segment-based local search using precomputed cumulative sums to identify and relocate high-cost segments while ensuring feasibility, with a fallback to random swaps if needed. The method prioritizes reducing total tour length in both objectives through intelligent segment relocation and maintains feasibility through duplicate removal.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Fast non-dominated selection\n    objectives = np.array([obj for _, obj in archive])\n    is_dominated = np.zeros(len(objectives), dtype=bool)\n    for i in range(len(objectives)):\n        if is_dominated[i]:\n            continue\n        for j in range(i+1, len(objectives)):\n            if (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1] and\n                (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1])):\n                is_dominated[i] = True\n                break\n    non_dominated = np.where(~is_dominated)[0]\n\n    if len(non_dominated) > 0:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Precompute cumulative sums for both objectives\n    cumsum1 = np.zeros(n+1)\n    cumsum2 = np.zeros(n+1)\n    for i in range(1, n+1):\n        cumsum1[i] = cumsum1[i-1] + distance_matrix_1[new_solution[i-1], new_solution[i%n]]\n        cumsum2[i] = cumsum2[i-1] + distance_matrix_2[new_solution[i-1], new_solution[i%n]]\n\n    # Find best segment using cumulative sums\n    best_score = -np.inf\n    best_i, best_j = 0, 1\n    max_segment = min(10, n//2)\n    for i in range(n):\n        for j in range(i+2, min(i+max_segment, n)):\n            segment_length1 = cumsum1[j+1] - cumsum1[i] + distance_matrix_1[new_solution[j], new_solution[i]]\n            segment_length2 = cumsum2[j+1] - cumsum2[i] + distance_matrix_2[new_solution[j], new_solution[i]]\n            score = - (segment_length1 + segment_length2)\n            if score > best_score:\n                best_score = score\n                best_i, best_j = i, j\n\n    if best_i < best_j:\n        best_segment = new_solution[best_i:best_j+1]\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Fast duplicate removal\n        _, unique_indices = np.unique(new_solution, return_index=True)\n        if len(unique_indices) != n:\n            missing = np.setdiff1d(np.arange(n), new_solution)\n            new_solution = np.concatenate([new_solution[np.sort(unique_indices)], missing])\n\n    # Simplified fallback\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.7738781696978164,
            1.3090673685073853
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Fast non-dominated selection\n    objectives = np.array([obj for _, obj in archive])\n    is_dominated = np.zeros(len(objectives), dtype=bool)\n    for i in range(len(objectives)):\n        if is_dominated[i]:\n            continue\n        for j in range(i+1, len(objectives)):\n            if (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1] and\n                (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1])):\n                is_dominated[i] = True\n                break\n    non_dominated = np.where(~is_dominated)[0]\n\n    if len(non_dominated) > 0:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Precompute cumulative sums for both objectives\n    cumsum1 = np.zeros(n+1)\n    cumsum2 = np.zeros(n+1)\n    for i in range(1, n+1):\n        cumsum1[i] = cumsum1[i-1] + distance_matrix_1[new_solution[i-1], new_solution[i%n]]\n        cumsum2[i] = cumsum2[i-1] + distance_matrix_2[new_solution[i-1], new_solution[i%n]]\n\n    # Find best segment using cumulative sums\n    best_score = -np.inf\n    best_i, best_j = 0, 1\n    max_segment = min(10, n//2)\n    for i in range(n):\n        for j in range(i+2, min(i+max_segment, n)):\n            segment_length1 = cumsum1[j+1] - cumsum1[i] + distance_matrix_1[new_solution[j], new_solution[i]]\n            segment_length2 = cumsum2[j+1] - cumsum2[i] + distance_matrix_2[new_solution[j], new_solution[i]]\n            score = - (segment_length1 + segment_length2)\n            if score > best_score:\n                best_score = score\n                best_i, best_j = i, j\n\n    if best_i < best_j:\n        best_segment = new_solution[best_i:best_j+1]\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Fast duplicate removal\n        _, unique_indices = np.unique(new_solution, return_index=True)\n        if len(unique_indices) != n:\n            missing = np.setdiff1d(np.arange(n), new_solution)\n            new_solution = np.concatenate([new_solution[np.sort(unique_indices)], missing])\n\n    # Simplified fallback\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm combines cost-sensitive selection with an adaptive hybrid local search that prioritizes high-distance edges in both objectives through dynamic segment rotation and probabilistic edge relocation, while maintaining feasibility through conditional perturbations and segment reversal. It intelligently selects solutions based on Pareto dominance and objective improvement potential, using multi-objective distance prioritization to guide the search. The method balances exploration and exploitation by dynamically adjusting segment sizes and applying conditional operations to refine the tour.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Cost-sensitive selection with Pareto dominance awareness\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    dominance = np.sum(normalized_obj < 0.5, axis=1)  # Count of objectives where solution is better than median\n    weights = dominance / np.sum(dominance)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with cost-aware sizing\n    segment_size = max(2, min(n // 3, int(np.exp(np.random.normal(scale=1.5)))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Rotation direction based on objective improvement potential\n    rotation_dir = 1 if np.random.rand() < 0.7 else -1\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], np.random.randint(1, segment_size) * rotation_dir)\n\n    # Probabilistic edge relocation with multi-objective distance prioritization\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_scores = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_scores.append(combined_distances[u][v])\n\n        edge_scores = np.array(edge_scores)\n        edge_probs = edge_scores / np.sum(edge_scores)\n        selected_edge = np.random.choice(n, p=edge_probs)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            # Candidate selection based on both objectives\n            candidate_scores = []\n            for i in candidates:\n                node = new_solution[i]\n                score = (distance_matrix_1[new_solution[c]][node] + distance_matrix_2[new_solution[c]][node]) * \\\n                        (distance_matrix_1[node][new_solution[d]] + distance_matrix_2[node][new_solution[d]])\n                candidate_scores.append(score)\n\n            candidate_probs = np.array(candidate_scores) / np.sum(candidate_scores)\n            e = np.random.choice(candidates, p=candidate_probs)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal for local improvement\n    if n > 4 and np.random.rand() < 0.3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Ensure proper segment selection and improvement potential\n            if c1 < d1 and c2 > d2 and (d1 + 1) % n != c2:\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects the best solution from the archive based on the sum of its two objectives, then applies a hybrid local search that reverses a randomly selected segment of the tour (edge-swap) to generate a neighbor solution, ensuring feasibility by falling back to a simple swap if the reversal causes duplicates. This approach prioritizes solutions with lower combined costs while using a constrained perturbation to explore the solution space efficiently.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on combined objective values\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n\n    # Hybrid local search: edge-swap with constrained perturbation\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Randomly select a segment to perturb\n    seg_start = np.random.randint(0, n - 2)\n    seg_length = np.random.randint(2, min(5, n - seg_start))\n    seg_end = seg_start + seg_length\n\n    # Reverse the segment (edge-swap)\n    new_solution[seg_start:seg_end] = new_solution[seg_start:seg_end][::-1]\n\n    # Ensure feasibility by checking for duplicates (though reversal should prevent this)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a simple swap if reversal causes issues\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords\n- **Adaptive local search**, **hybrid perturbation**, **cost-aware selection**, **feasibility preservation**, **exploration-exploitation balance**.\n\n### Advice\n- Combine **segment insertion** with **edge reversal** or **rotation** to diversify perturbations while preserving feasibility.\n- Use **weighted selection** based on Pareto dominance or crowding distance to prioritize promising solutions.\n- Introduce **conditional operators** (e.g., reverse segments only if they improve one objective) to avoid over-optimization.\n- Ensure **feasibility** by validating tours after perturbations (e.g., check for duplicates or missing nodes).\n\n### Avoid\n- Greedy, single-operator strategies (e.g., always using 2-opt or edge swaps).\n- Static perturbation sizes or probabilities (e.g., fixed segment lengths).\n- Ignoring objective trade-offs (e.g., always optimizing one objective at the expense of the other).\n\n### Explanation\nHybrid local search balances exploration (random segment operations) and exploitation (cost-aware edge prioritization). Adaptive selection and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while weighted selection focuses computational effort on high-potential regions. This approach generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 22,
        "algorithm": "The algorithm dynamically selects a promising solution from the archive based on a weighted combination of Pareto dominance and improvement potential, then generates a neighbor by probabilistically inserting a segment from another solution while ensuring feasibility through conditional edge swaps and segment reversals, with segment size and insertion points adjusted based on combined objective improvement. The method prioritizes solutions with higher dominance and lower normalized objective values, while the local search focuses on adaptive segment operations to balance exploration and exploitation across both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on Pareto dominance and objective improvement\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    dominance = np.sum(normalized_obj < 0.5, axis=1)\n    improvement_potential = np.exp(-np.sum(normalized_obj, axis=1))\n    weights = (dominance * improvement_potential) / np.sum(dominance * improvement_potential)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment insertion from another solution\n    donor_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n    donor_solution = archive[donor_idx][0]\n\n    # Select a segment from donor solution\n    segment_size = max(2, min(n // 4, int(np.exp(np.random.normal(scale=1.0)))))\n    a = np.random.randint(0, n - segment_size + 1)\n    donor_segment = donor_solution[a:a+segment_size]\n\n    # Find insertion point in new solution\n    insertion_scores = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        # Score based on both objectives\n        score = (distance_matrix_1[u][donor_segment[0]] + distance_matrix_2[u][donor_segment[0]]) + \\\n                (distance_matrix_1[donor_segment[-1]][v] + distance_matrix_2[donor_segment[-1]][v])\n        insertion_scores.append(score)\n\n    insertion_scores = np.array(insertion_scores)\n    insertion_probs = insertion_scores / np.sum(insertion_scores)\n    insertion_point = np.random.choice(n, p=insertion_probs)\n\n    # Insert segment and handle duplicates\n    new_solution = np.concatenate([new_solution[:insertion_point+1], donor_segment, new_solution[insertion_point+1:]])\n    if len(new_solution) > n:\n        # Remove duplicates while preserving order\n        _, unique_indices = np.unique(new_solution, return_index=True)\n        new_solution = new_solution[np.sort(unique_indices)]\n        # If still too long, truncate and append missing nodes\n        if len(new_solution) > n:\n            new_solution = new_solution[:n]\n        missing_nodes = np.setdiff1d(np.arange(n), new_solution)\n        new_solution = np.concatenate([new_solution, missing_nodes])\n\n    # Conditional segment reversal for local improvement\n    if n > 4 and np.random.rand() < 0.4:\n        # Select a segment to reverse based on combined distance\n        segment_start = np.random.randint(0, n - 2)\n        segment_length = np.random.randint(2, min(5, n - segment_start))\n        segment_end = segment_start + segment_length\n\n        # Calculate improvement potential\n        u = new_solution[segment_start]\n        v = new_solution[segment_end]\n        original_cost = distance_matrix_1[u][v] + distance_matrix_2[u][v]\n        new_cost = distance_matrix_1[u][new_solution[segment_end-1]] + distance_matrix_2[u][new_solution[segment_end-1]] + \\\n                    distance_matrix_1[new_solution[segment_start+1]][v] + distance_matrix_2[new_solution[segment_start+1]][v]\n\n        if new_cost < original_cost:\n            new_solution[segment_start:segment_end] = new_solution[segment_start:segment_end][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.8366239941157638,
            0.7625570297241211
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on Pareto dominance and objective improvement\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    dominance = np.sum(normalized_obj < 0.5, axis=1)\n    improvement_potential = np.exp(-np.sum(normalized_obj, axis=1))\n    weights = (dominance * improvement_potential) / np.sum(dominance * improvement_potential)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment insertion from another solution\n    donor_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n    donor_solution = archive[donor_idx][0]\n\n    # Select a segment from donor solution\n    segment_size = max(2, min(n // 4, int(np.exp(np.random.normal(scale=1.0)))))\n    a = np.random.randint(0, n - segment_size + 1)\n    donor_segment = donor_solution[a:a+segment_size]\n\n    # Find insertion point in new solution\n    insertion_scores = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        # Score based on both objectives\n        score = (distance_matrix_1[u][donor_segment[0]] + distance_matrix_2[u][donor_segment[0]]) + \\\n                (distance_matrix_1[donor_segment[-1]][v] + distance_matrix_2[donor_segment[-1]][v])\n        insertion_scores.append(score)\n\n    insertion_scores = np.array(insertion_scores)\n    insertion_probs = insertion_scores / np.sum(insertion_scores)\n    insertion_point = np.random.choice(n, p=insertion_probs)\n\n    # Insert segment and handle duplicates\n    new_solution = np.concatenate([new_solution[:insertion_point+1], donor_segment, new_solution[insertion_point+1:]])\n    if len(new_solution) > n:\n        # Remove duplicates while preserving order\n        _, unique_indices = np.unique(new_solution, return_index=True)\n        new_solution = new_solution[np.sort(unique_indices)]\n        # If still too long, truncate and append missing nodes\n        if len(new_solution) > n:\n            new_solution = new_solution[:n]\n        missing_nodes = np.setdiff1d(np.arange(n), new_solution)\n        new_solution = np.concatenate([new_solution, missing_nodes])\n\n    # Conditional segment reversal for local improvement\n    if n > 4 and np.random.rand() < 0.4:\n        # Select a segment to reverse based on combined distance\n        segment_start = np.random.randint(0, n - 2)\n        segment_length = np.random.randint(2, min(5, n - segment_start))\n        segment_end = segment_start + segment_length\n\n        # Calculate improvement potential\n        u = new_solution[segment_start]\n        v = new_solution[segment_end]\n        original_cost = distance_matrix_1[u][v] + distance_matrix_2[u][v]\n        new_cost = distance_matrix_1[u][new_solution[segment_end-1]] + distance_matrix_2[u][new_solution[segment_end-1]] + \\\n                    distance_matrix_1[new_solution[segment_start+1]][v] + distance_matrix_2[new_solution[segment_start+1]][v]\n\n        if new_cost < original_cost:\n            new_solution[segment_start:segment_end] = new_solution[segment_start:segment_end][::-1]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects the best solution from the archive based on the sum of its two objectives, then applies a hybrid local search that reverses a randomly selected segment of the tour (edge-swap) to generate a neighbor solution, ensuring feasibility by falling back to a simple swap if the reversal causes duplicates. This approach prioritizes solutions with lower combined costs while using a constrained perturbation to explore the solution space efficiently.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on combined objective values\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n\n    # Hybrid local search: edge-swap with constrained perturbation\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Randomly select a segment to perturb\n    seg_start = np.random.randint(0, n - 2)\n    seg_length = np.random.randint(2, min(5, n - seg_start))\n    seg_end = seg_start + seg_length\n\n    # Reverse the segment (edge-swap)\n    new_solution[seg_start:seg_end] = new_solution[seg_start:seg_end][::-1]\n\n    # Ensure feasibility by checking for duplicates (though reversal should prevent this)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a simple swap if reversal causes issues\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 23,
        "algorithm": "The algorithm selects a solution from the archive based on a weighted combination of objectives (60% first objective, 40% second), then applies a hybrid local search: 70% chance for segment reversal (randomly reversing a small segment of the tour) or 30% chance for probabilistic insertion (moving a node to a new position). It ensures feasibility by validating the tour structure and falls back to a simple swap if the perturbation causes issues. The design prioritizes the first objective while introducing diversity through probabilistic operators.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution based on a weighted combination of objectives\n    def weighted_score(obj):\n        return 0.6 * obj[0] + 0.4 * obj[1]  # Weighted sum with higher emphasis on first objective\n\n    archive_sorted = sorted(archive, key=lambda x: weighted_score(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search: segment reversal with probabilistic insertion\n    if np.random.random() < 0.7:  # 70% chance for segment reversal\n        seg_start = np.random.randint(0, n - 2)\n        seg_length = np.random.randint(2, min(5, n - seg_start))\n        seg_end = seg_start + seg_length\n        new_solution[seg_start:seg_end] = new_solution[seg_start:seg_end][::-1]\n    else:  # 30% chance for probabilistic insertion\n        i, j = np.random.choice(n, 2, replace=False)\n        if i > j:\n            i, j = j, i\n        node = new_solution[i]\n        new_solution = np.concatenate([new_solution[:i], new_solution[i+1:j], [node], new_solution[j:]])\n\n    # Validate the tour structure\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a simple swap if the perturbation causes issues\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.6296512586818152,
            0.43353474140167236
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution based on a weighted combination of objectives\n    def weighted_score(obj):\n        return 0.6 * obj[0] + 0.4 * obj[1]  # Weighted sum with higher emphasis on first objective\n\n    archive_sorted = sorted(archive, key=lambda x: weighted_score(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search: segment reversal with probabilistic insertion\n    if np.random.random() < 0.7:  # 70% chance for segment reversal\n        seg_start = np.random.randint(0, n - 2)\n        seg_length = np.random.randint(2, min(5, n - seg_start))\n        seg_end = seg_start + seg_length\n        new_solution[seg_start:seg_end] = new_solution[seg_start:seg_end][::-1]\n    else:  # 30% chance for probabilistic insertion\n        i, j = np.random.choice(n, 2, replace=False)\n        if i > j:\n            i, j = j, i\n        node = new_solution[i]\n        new_solution = np.concatenate([new_solution[:i], new_solution[i+1:j], [node], new_solution[j:]])\n\n    # Validate the tour structure\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a simple swap if the perturbation causes issues\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects the best solution from the archive based on the sum of its two objectives, then applies a hybrid local search that reverses a randomly selected segment of the tour (edge-swap) to generate a neighbor solution, ensuring feasibility by falling back to a simple swap if the reversal causes duplicates. This approach prioritizes solutions with lower combined costs while using a constrained perturbation to explore the solution space efficiently.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on combined objective values\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n\n    # Hybrid local search: edge-swap with constrained perturbation\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Randomly select a segment to perturb\n    seg_start = np.random.randint(0, n - 2)\n    seg_length = np.random.randint(2, min(5, n - seg_start))\n    seg_end = seg_start + seg_length\n\n    # Reverse the segment (edge-swap)\n    new_solution[seg_start:seg_end] = new_solution[seg_start:seg_end][::-1]\n\n    # Ensure feasibility by checking for duplicates (though reversal should prevent this)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a simple swap if reversal causes issues\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 24,
        "algorithm": "The algorithm selects the best solution from the archive based on the sum of its two objectives, then applies a hybrid local search combining segment reversal and a biased random walk to generate a neighbor solution, ensuring feasibility by validating the tour structure and reverting to a simple swap if necessary. The selection prioritizes lower-cost solutions, while the local search explores modifications within a randomly selected segment, with a fallback to a basic swap to maintain validity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on combined objective values\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search: segment reversal with biased random walk\n    seg_start = np.random.randint(0, n - 3)\n    seg_length = np.random.randint(2, min(4, n - seg_start - 1))\n    seg_end = seg_start + seg_length\n\n    # Reverse the segment\n    new_solution[seg_start:seg_end] = new_solution[seg_start:seg_end][::-1]\n\n    # Apply biased random walk by moving nodes within the segment\n    if seg_length > 2:\n        walk_steps = np.random.randint(1, seg_length - 1)\n        for _ in range(walk_steps):\n            i = np.random.randint(seg_start, seg_end)\n            j = np.random.randint(seg_start, seg_end)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility by checking for duplicates\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a simple swap if reversal causes issues\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.7125380299139021,
            0.5089289546012878
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on combined objective values\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Hybrid local search: segment reversal with biased random walk\n    seg_start = np.random.randint(0, n - 3)\n    seg_length = np.random.randint(2, min(4, n - seg_start - 1))\n    seg_end = seg_start + seg_length\n\n    # Reverse the segment\n    new_solution[seg_start:seg_end] = new_solution[seg_start:seg_end][::-1]\n\n    # Apply biased random walk by moving nodes within the segment\n    if seg_length > 2:\n        walk_steps = np.random.randint(1, seg_length - 1)\n        for _ in range(walk_steps):\n            i = np.random.randint(seg_start, seg_end)\n            j = np.random.randint(seg_start, seg_end)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility by checking for duplicates\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a simple swap if reversal causes issues\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection of promising solutions using a combination of objective values and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Step 3: Hybrid local search combining segment reversal and adaptive edge insertion\n    # First perform segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Then perform adaptive edge insertion based on high combined distance\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on its distance\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_distances = [distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]] for i in candidates]\n                candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n                e = np.random.choice(candidates, p=candidate_weights)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 4: Additional local improvement with edge reversal\n    if n > 3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Reverse the segment between the two selected edges\n            if c1 < d1 and c2 > d2:  # Ensure proper segment selection\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### Keywords\n- **Adaptive local search**, **hybrid perturbation**, **cost-aware selection**, **feasibility preservation**, **exploration-exploitation balance**.\n\n### Advice\n- Combine **segment insertion** with **edge reversal** or **rotation** to diversify perturbations while preserving feasibility.\n- Use **weighted selection** based on Pareto dominance or crowding distance to prioritize promising solutions.\n- Introduce **conditional operators** (e.g., reverse segments only if they improve one objective) to avoid over-optimization.\n- Ensure **feasibility** by validating tours after perturbations (e.g., check for duplicates or missing nodes).\n\n### Avoid\n- Greedy, single-operator strategies (e.g., always using 2-opt or edge swaps).\n- Static perturbation sizes or probabilities (e.g., fixed segment lengths).\n- Ignoring objective trade-offs (e.g., always optimizing one objective at the expense of the other).\n\n### Explanation\nHybrid local search balances exploration (random segment operations) and exploitation (cost-aware edge prioritization). Adaptive selection and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while weighted selection focuses computational effort on high-potential regions. This approach generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 25,
        "algorithm": "The heuristic selects a solution from the archive using weighted randomness based on normalized objectives and crowding distance, then applies a hybrid local search combining adaptive segment rotation, probabilistic edge insertion, and conditional edge reversal to generate a neighbor solution while ensuring feasibility. The algorithm prioritizes segments with high combined distance in edge reversal and adaptively adjusts segment sizes for rotation, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on normalized objectives and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_weights = np.array([combined_distances[new_solution[c]][new_solution[i]] for i in candidates])\n            candidate_weights = candidate_weights / np.sum(candidate_weights)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional edge reversal\n    if n > 3:\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            if c1 < d1 and c2 > d2:\n                # Reverse segments if it improves at least one objective\n                original_cost1 = distance_matrix_1[new_solution[c1]][new_solution[d1]] + distance_matrix_1[new_solution[c2]][new_solution[d2]]\n                original_cost2 = distance_matrix_2[new_solution[c1]][new_solution[d1]] + distance_matrix_2[new_solution[c2]][new_solution[d2]]\n\n                temp_solution = new_solution.copy()\n                temp_solution[c1:d1+1] = temp_solution[c1:d1+1][::-1]\n                temp_solution[c2:d2+1] = temp_solution[c2:d2+1][::-1]\n\n                new_cost1 = distance_matrix_1[temp_solution[c1]][temp_solution[d1]] + distance_matrix_1[temp_solution[c2]][temp_solution[d2]]\n                new_cost2 = distance_matrix_2[temp_solution[c1]][temp_solution[d1]] + distance_matrix_2[temp_solution[c2]][temp_solution[d2]]\n\n                if (new_cost1 < original_cost1 and new_cost2 <= original_cost2) or \\\n                   (new_cost1 <= original_cost1 and new_cost2 < original_cost2):\n                    new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.911450101760233,
            0.2679750919342041
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on normalized objectives and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_weights = np.array([combined_distances[new_solution[c]][new_solution[i]] for i in candidates])\n            candidate_weights = candidate_weights / np.sum(candidate_weights)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional edge reversal\n    if n > 3:\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            if c1 < d1 and c2 > d2:\n                # Reverse segments if it improves at least one objective\n                original_cost1 = distance_matrix_1[new_solution[c1]][new_solution[d1]] + distance_matrix_1[new_solution[c2]][new_solution[d2]]\n                original_cost2 = distance_matrix_2[new_solution[c1]][new_solution[d1]] + distance_matrix_2[new_solution[c2]][new_solution[d2]]\n\n                temp_solution = new_solution.copy()\n                temp_solution[c1:d1+1] = temp_solution[c1:d1+1][::-1]\n                temp_solution[c2:d2+1] = temp_solution[c2:d2+1][::-1]\n\n                new_cost1 = distance_matrix_1[temp_solution[c1]][temp_solution[d1]] + distance_matrix_1[temp_solution[c2]][temp_solution[d2]]\n                new_cost2 = distance_matrix_2[temp_solution[c1]][temp_solution[d1]] + distance_matrix_2[temp_solution[c2]][temp_solution[d2]]\n\n                if (new_cost1 < original_cost1 and new_cost2 <= original_cost2) or \\\n                   (new_cost1 <= original_cost1 and new_cost2 < original_cost2):\n                    new_solution = temp_solution\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a non-dominated solution from the archive (prioritizing Pareto-optimal candidates) and applies a two-phase local search: first identifying high-quality segments (shortest in both objectives) and then reinserting them at random positions while ensuring feasibility through duplicate removal. If this fails, it defaults to a simple random swap. The method balances exploitation of good structures with controlled diversification while maintaining tour validity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with non-dominated objectives\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify high-quality segments\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            # Calculate segment quality based on both objectives\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            score = - (segment_length1 + segment_length2)  # Higher score for shorter segments\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reintegrate segment with dynamic boundary adjustment\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if all else fails\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 26,
        "algorithm": "The algorithm first selects a promising solution from the archive using a fast non-dominated sorting approach, then applies a segment-based local search by precomputing cumulative distances and evaluating segments of varying lengths for potential reinsertion, ensuring feasibility through a lightweight duplicate removal method and falling back to a random swap if needed. The critical design choices prioritize efficiency by precomputing segment scores and using array operations, while maintaining feasibility through intelligent segment reinsertion and a fallback mechanism.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Fast non-dominated selection using lexicographical sorting\n    objectives = np.array([obj for _, obj in archive])\n    sorted_idx = np.lexsort((objectives[:, 1], objectives[:, 0]))\n    non_dominated = [sorted_idx[0]]\n    for i in sorted_idx[1:]:\n        if not (objectives[i, 0] >= objectives[non_dominated[-1], 0] and\n                objectives[i, 1] >= objectives[non_dominated[-1], 1]):\n            non_dominated.append(i)\n\n    selected_idx = random.choice(non_dominated) if non_dominated else random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Precompute cumulative distances for efficiency\n    cum_dist1 = np.cumsum([distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)])\n    cum_dist2 = np.cumsum([distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)])\n\n    # Find best segment using sliding window\n    max_segment = min(10, n // 2)\n    best_score = float('-inf')\n    best_i, best_j = 0, 0\n    for i in range(n):\n        for j in range(i+2, min(i+max_segment, n)):\n            length1 = cum_dist1[j] - cum_dist1[i] + distance_matrix_1[new_solution[j], new_solution[i]]\n            length2 = cum_dist2[j] - cum_dist2[i] + distance_matrix_2[new_solution[j], new_solution[i]]\n            score = -(length1 + length2)\n            if score > best_score:\n                best_score, best_i, best_j = score, i, j\n\n    if best_score != float('-inf'):\n        segment = new_solution[best_i:best_j+1]\n        pos = random.randint(0, n - len(segment))\n        new_solution = np.concatenate([\n            new_solution[:pos],\n            segment,\n            new_solution[pos:pos + len(segment)],\n            new_solution[pos + len(segment):]\n        ])\n\n        # Fast duplicate removal\n        _, unique_indices = np.unique(new_solution, return_index=True)\n        if len(unique_indices) != n:\n            new_solution = new_solution[np.sort(unique_indices)]\n            missing = list(set(range(n)) - set(new_solution))\n            new_solution = np.concatenate([new_solution, missing])\n\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9654720904366615,
            0.7772645354270935
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Fast non-dominated selection using lexicographical sorting\n    objectives = np.array([obj for _, obj in archive])\n    sorted_idx = np.lexsort((objectives[:, 1], objectives[:, 0]))\n    non_dominated = [sorted_idx[0]]\n    for i in sorted_idx[1:]:\n        if not (objectives[i, 0] >= objectives[non_dominated[-1], 0] and\n                objectives[i, 1] >= objectives[non_dominated[-1], 1]):\n            non_dominated.append(i)\n\n    selected_idx = random.choice(non_dominated) if non_dominated else random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Precompute cumulative distances for efficiency\n    cum_dist1 = np.cumsum([distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)])\n    cum_dist2 = np.cumsum([distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)])\n\n    # Find best segment using sliding window\n    max_segment = min(10, n // 2)\n    best_score = float('-inf')\n    best_i, best_j = 0, 0\n    for i in range(n):\n        for j in range(i+2, min(i+max_segment, n)):\n            length1 = cum_dist1[j] - cum_dist1[i] + distance_matrix_1[new_solution[j], new_solution[i]]\n            length2 = cum_dist2[j] - cum_dist2[i] + distance_matrix_2[new_solution[j], new_solution[i]]\n            score = -(length1 + length2)\n            if score > best_score:\n                best_score, best_i, best_j = score, i, j\n\n    if best_score != float('-inf'):\n        segment = new_solution[best_i:best_j+1]\n        pos = random.randint(0, n - len(segment))\n        new_solution = np.concatenate([\n            new_solution[:pos],\n            segment,\n            new_solution[pos:pos + len(segment)],\n            new_solution[pos + len(segment):]\n        ])\n\n        # Fast duplicate removal\n        _, unique_indices = np.unique(new_solution, return_index=True)\n        if len(unique_indices) != n:\n            new_solution = new_solution[np.sort(unique_indices)]\n            missing = list(set(range(n)) - set(new_solution))\n            new_solution = np.concatenate([new_solution, missing])\n\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection of promising solutions using a combination of objective values and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Step 3: Hybrid local search combining segment reversal and adaptive edge insertion\n    # First perform segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Then perform adaptive edge insertion based on high combined distance\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on its distance\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_distances = [distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]] for i in candidates]\n                candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n                e = np.random.choice(candidates, p=candidate_weights)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 4: Additional local improvement with edge reversal\n    if n > 3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Reverse the segment between the two selected edges\n            if c1 < d1 and c2 > d2:  # Ensure proper segment selection\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe heuristic selects a random solution from the archive and applies a hybrid local search combining edge insertion and node swapping, prioritizing improvements that reduce the total tour length in both objective spaces while ensuring feasibility. The edge insertion randomly moves a node to a new position, and node swapping further refines the solution by swapping nodes if it improves the combined cost. The algorithm balances exploration (random selection) and exploitation (cost-based swapping) to generate high-quality neighbors.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not dominated by others)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and node swapping\n    n = len(new_solution)\n    if n < 4:\n        return new_solution  # Too small to apply operators\n\n    # Step 1: Edge insertion\n    i = np.random.randint(0, n)\n    j = np.random.randint(0, n)\n    while j == i or abs(j - i) == 1:\n        j = np.random.randint(0, n)\n\n    # Remove node at j and reinsert it after i\n    node = new_solution[j]\n    new_solution = np.concatenate([new_solution[:j], new_solution[j+1:]])\n    insert_pos = (i + 1) % len(new_solution)\n    new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Step 2: Node swapping (if beneficial)\n    if np.random.random() < 0.5:  # 50% chance to apply swapping\n        k = np.random.randint(0, len(new_solution))\n        l = np.random.randint(0, len(new_solution))\n        while k == l:\n            l = np.random.randint(0, len(new_solution))\n\n        # Calculate cost before and after swap\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n        temp_sol = new_solution.copy()\n        temp_sol[k], temp_sol[l] = temp_sol[l], temp_sol[k]\n        cost_after = calculate_cost(temp_sol, distance_matrix_1) + calculate_cost(temp_sol, distance_matrix_2)\n\n        if cost_after < cost_before:\n            new_solution = temp_sol\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords\n- **Adaptive local search**, **hybrid perturbation**, **cost-aware selection**, **feasibility preservation**, **exploration-exploitation balance**.\n\n### Advice\n- Combine **segment insertion** with **edge reversal** or **rotation** to diversify perturbations while preserving feasibility.\n- Use **weighted selection** based on Pareto dominance or crowding distance to prioritize promising solutions.\n- Introduce **conditional operators** (e.g., reverse segments only if they improve one objective) to avoid over-optimization.\n- Ensure **feasibility** by validating tours after perturbations (e.g., check for duplicates or missing nodes).\n\n### Avoid\n- Greedy, single-operator strategies (e.g., always using 2-opt or edge swaps).\n- Static perturbation sizes or probabilities (e.g., fixed segment lengths).\n- Ignoring objective trade-offs (e.g., always optimizing one objective at the expense of the other).\n\n### Explanation\nHybrid local search balances exploration (random segment operations) and exploitation (cost-aware edge prioritization). Adaptive selection and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while weighted selection focuses computational effort on high-potential regions. This approach generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 27,
        "algorithm": "The algorithm combines adaptive segment rotation with cost-aware edge reversal: it first selects a solution from the archive using a weighted approach that balances objective trade-offs and crowding distance, then applies a novel segment rotation operator that rotates a segment of nodes by a random angle while mapping them to the closest valid nodes in the instance, followed by a conditional edge reversal that prioritizes segments with high combined distance in both objectives to improve solution quality while maintaining feasibility through strict validation checks. The algorithm emphasizes balanced exploration (via rotation) and exploitation (via edge reversal) while ensuring feasibility through duplicate checks and fallback mechanisms.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on objective trade-off and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment rotation\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Rotate the segment by a random angle in the plane\n    segment = new_solution[a:b+1]\n    center = instance[segment].mean(axis=0)\n    angle = np.random.uniform(0, 2 * np.pi)\n\n    # Apply rotation to coordinates in both spaces\n    rotated_coords = []\n    for node in segment:\n        x1, y1, x2, y2 = instance[node]\n        # Rotate first space\n        dx1 = x1 - center[0]\n        dy1 = y1 - center[1]\n        x1_rot = center[0] + dx1 * np.cos(angle) - dy1 * np.sin(angle)\n        y1_rot = center[1] + dx1 * np.sin(angle) + dy1 * np.cos(angle)\n        # Rotate second space\n        dx2 = x2 - center[2]\n        dy2 = y2 - center[3]\n        x2_rot = center[2] + dx2 * np.cos(angle) - dy2 * np.sin(angle)\n        y2_rot = center[3] + dx2 * np.sin(angle) + dy2 * np.cos(angle)\n\n        # Find closest node to rotated coordinates\n        dists = np.sum((instance[:, :2] - np.array([x1_rot, y1_rot]))**2, axis=1) + \\\n                np.sum((instance[:, 2:] - np.array([x2_rot, y2_rot]))**2, axis=1)\n        closest_node = np.argmin(dists)\n        rotated_coords.append(closest_node)\n\n    # Ensure no duplicates (fallback to original if needed)\n    if len(set(rotated_coords)) == len(rotated_coords):\n        new_solution[a:b+1] = rotated_coords\n    else:\n        # Fallback to simple reversal if rotation causes duplicates\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Step 3: Conditional edge reversal based on high combined distance\n    if n > 3:\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            combined_dist = distance_matrix_1[u][v] + distance_matrix_2[u][v]\n            edges.append((i, (i+1)%n, combined_dist))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            c, d, _ = edges[0]\n            # Reverse the segment between c and d if it improves both objectives\n            original_cost1 = distance_matrix_1[new_solution[c]][new_solution[(c+1)%n]] + distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n            original_cost2 = distance_matrix_2[new_solution[c]][new_solution[(c+1)%n]] + distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n            temp_solution = new_solution.copy()\n            temp_solution[c+1:d+1] = temp_solution[c+1:d+1][::-1]\n\n            new_cost1 = distance_matrix_1[temp_solution[c]][temp_solution[(c+1)%n]] + distance_matrix_1[temp_solution[d]][temp_solution[(d+1)%n]]\n            new_cost2 = distance_matrix_2[temp_solution[c]][temp_solution[(c+1)%n]] + distance_matrix_2[temp_solution[d]][temp_solution[(d+1)%n]]\n\n            if new_cost1 + new_cost2 < original_cost1 + original_cost2:\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.6270145670552365,
            0.4180479049682617
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on objective trade-off and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment rotation\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Rotate the segment by a random angle in the plane\n    segment = new_solution[a:b+1]\n    center = instance[segment].mean(axis=0)\n    angle = np.random.uniform(0, 2 * np.pi)\n\n    # Apply rotation to coordinates in both spaces\n    rotated_coords = []\n    for node in segment:\n        x1, y1, x2, y2 = instance[node]\n        # Rotate first space\n        dx1 = x1 - center[0]\n        dy1 = y1 - center[1]\n        x1_rot = center[0] + dx1 * np.cos(angle) - dy1 * np.sin(angle)\n        y1_rot = center[1] + dx1 * np.sin(angle) + dy1 * np.cos(angle)\n        # Rotate second space\n        dx2 = x2 - center[2]\n        dy2 = y2 - center[3]\n        x2_rot = center[2] + dx2 * np.cos(angle) - dy2 * np.sin(angle)\n        y2_rot = center[3] + dx2 * np.sin(angle) + dy2 * np.cos(angle)\n\n        # Find closest node to rotated coordinates\n        dists = np.sum((instance[:, :2] - np.array([x1_rot, y1_rot]))**2, axis=1) + \\\n                np.sum((instance[:, 2:] - np.array([x2_rot, y2_rot]))**2, axis=1)\n        closest_node = np.argmin(dists)\n        rotated_coords.append(closest_node)\n\n    # Ensure no duplicates (fallback to original if needed)\n    if len(set(rotated_coords)) == len(rotated_coords):\n        new_solution[a:b+1] = rotated_coords\n    else:\n        # Fallback to simple reversal if rotation causes duplicates\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Step 3: Conditional edge reversal based on high combined distance\n    if n > 3:\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            combined_dist = distance_matrix_1[u][v] + distance_matrix_2[u][v]\n            edges.append((i, (i+1)%n, combined_dist))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            c, d, _ = edges[0]\n            # Reverse the segment between c and d if it improves both objectives\n            original_cost1 = distance_matrix_1[new_solution[c]][new_solution[(c+1)%n]] + distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n            original_cost2 = distance_matrix_2[new_solution[c]][new_solution[(c+1)%n]] + distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n            temp_solution = new_solution.copy()\n            temp_solution[c+1:d+1] = temp_solution[c+1:d+1][::-1]\n\n            new_cost1 = distance_matrix_1[temp_solution[c]][temp_solution[(c+1)%n]] + distance_matrix_1[temp_solution[d]][temp_solution[(d+1)%n]]\n            new_cost2 = distance_matrix_2[temp_solution[c]][temp_solution[(c+1)%n]] + distance_matrix_2[temp_solution[d]][temp_solution[(d+1)%n]]\n\n            if new_cost1 + new_cost2 < original_cost1 + original_cost2:\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The heuristic selects a random solution from the archive and applies a hybrid local search combining edge insertion and node swapping, prioritizing improvements that reduce the total tour length in both objective spaces while ensuring feasibility. The edge insertion randomly moves a node to a new position, and node swapping further refines the solution by swapping nodes if it improves the combined cost. The algorithm balances exploration (random selection) and exploitation (cost-based swapping) to generate high-quality neighbors.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not dominated by others)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and node swapping\n    n = len(new_solution)\n    if n < 4:\n        return new_solution  # Too small to apply operators\n\n    # Step 1: Edge insertion\n    i = np.random.randint(0, n)\n    j = np.random.randint(0, n)\n    while j == i or abs(j - i) == 1:\n        j = np.random.randint(0, n)\n\n    # Remove node at j and reinsert it after i\n    node = new_solution[j]\n    new_solution = np.concatenate([new_solution[:j], new_solution[j+1:]])\n    insert_pos = (i + 1) % len(new_solution)\n    new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Step 2: Node swapping (if beneficial)\n    if np.random.random() < 0.5:  # 50% chance to apply swapping\n        k = np.random.randint(0, len(new_solution))\n        l = np.random.randint(0, len(new_solution))\n        while k == l:\n            l = np.random.randint(0, len(new_solution))\n\n        # Calculate cost before and after swap\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n        temp_sol = new_solution.copy()\n        temp_sol[k], temp_sol[l] = temp_sol[l], temp_sol[k]\n        cost_after = calculate_cost(temp_sol, distance_matrix_1) + calculate_cost(temp_sol, distance_matrix_2)\n\n        if cost_after < cost_before:\n            new_solution = temp_sol\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 28,
        "algorithm": "The algorithm selects a random solution from the archive, applies a path reversal between two random segments, and optionally performs a node insertion if it improves the combined cost of both objectives. It prioritizes solutions with high potential for improvement by randomly choosing from the archive and evaluating the impact of changes on both objectives before accepting them. The method ensures feasibility by always maintaining a valid TSP tour structure.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not dominated by others)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution  # Too small to apply operators\n\n    # Step 1: Path reversal\n    i = np.random.randint(0, n)\n    j = np.random.randint(0, n)\n    while j == i or abs(j - i) == 1:\n        j = np.random.randint(0, n)\n\n    if i > j:\n        i, j = j, i\n\n    # Reverse the segment between i and j\n    new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Step 2: Node insertion (if beneficial)\n    if np.random.random() < 0.5:  # 50% chance to apply insertion\n        k = np.random.randint(0, len(new_solution))\n        node = new_solution[k]\n        new_solution = np.concatenate([new_solution[:k], new_solution[k+1:]])\n\n        # Insert node at a random position\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, node)\n\n        # Evaluate improvement\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        cost_before = calculate_cost(base_solution, distance_matrix_1) + calculate_cost(base_solution, distance_matrix_2)\n        cost_after = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n\n        if cost_after >= cost_before:\n            new_solution = base_solution  # Revert if no improvement\n\n    return new_solution\n\n",
        "score": [
            -0.8311419505900228,
            0.5634433627128601
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not dominated by others)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution  # Too small to apply operators\n\n    # Step 1: Path reversal\n    i = np.random.randint(0, n)\n    j = np.random.randint(0, n)\n    while j == i or abs(j - i) == 1:\n        j = np.random.randint(0, n)\n\n    if i > j:\n        i, j = j, i\n\n    # Reverse the segment between i and j\n    new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Step 2: Node insertion (if beneficial)\n    if np.random.random() < 0.5:  # 50% chance to apply insertion\n        k = np.random.randint(0, len(new_solution))\n        node = new_solution[k]\n        new_solution = np.concatenate([new_solution[:k], new_solution[k+1:]])\n\n        # Insert node at a random position\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, node)\n\n        # Evaluate improvement\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        cost_before = calculate_cost(base_solution, distance_matrix_1) + calculate_cost(base_solution, distance_matrix_2)\n        cost_after = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n\n        if cost_after >= cost_before:\n            new_solution = base_solution  # Revert if no improvement\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The heuristic selects a random solution from the archive and applies a hybrid local search combining edge insertion and node swapping, prioritizing improvements that reduce the total tour length in both objective spaces while ensuring feasibility. The edge insertion randomly moves a node to a new position, and node swapping further refines the solution by swapping nodes if it improves the combined cost. The algorithm balances exploration (random selection) and exploitation (cost-based swapping) to generate high-quality neighbors.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not dominated by others)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and node swapping\n    n = len(new_solution)\n    if n < 4:\n        return new_solution  # Too small to apply operators\n\n    # Step 1: Edge insertion\n    i = np.random.randint(0, n)\n    j = np.random.randint(0, n)\n    while j == i or abs(j - i) == 1:\n        j = np.random.randint(0, n)\n\n    # Remove node at j and reinsert it after i\n    node = new_solution[j]\n    new_solution = np.concatenate([new_solution[:j], new_solution[j+1:]])\n    insert_pos = (i + 1) % len(new_solution)\n    new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Step 2: Node swapping (if beneficial)\n    if np.random.random() < 0.5:  # 50% chance to apply swapping\n        k = np.random.randint(0, len(new_solution))\n        l = np.random.randint(0, len(new_solution))\n        while k == l:\n            l = np.random.randint(0, len(new_solution))\n\n        # Calculate cost before and after swap\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n        temp_sol = new_solution.copy()\n        temp_sol[k], temp_sol[l] = temp_sol[l], temp_sol[k]\n        cost_after = calculate_cost(temp_sol, distance_matrix_1) + calculate_cost(temp_sol, distance_matrix_2)\n\n        if cost_after < cost_before:\n            new_solution = temp_sol\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 29,
        "algorithm": "The algorithm selects a promising solution from the archive using tournament selection among non-dominated solutions, then applies a hybrid local search combining 3-opt and edge reversal to generate a neighbor solution, ensuring feasibility while balancing exploration and exploitation. The selection prioritizes non-dominated solutions, while the local search alternates between 3-opt (70% chance) and edge reversal to explore the solution space effectively. The cost function sums distances from both objectives to guide improvements.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection: pick 5 random solutions and select the non-dominated one\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_solutions = [archive[i][0] for i in selected_idx]\n    selected_objectives = [archive[i][1] for i in selected_idx]\n\n    # Find non-dominated solutions in the tournament\n    non_dominated = []\n    for i, obj in enumerate(selected_objectives):\n        dominated = False\n        for j, other_obj in enumerate(selected_objectives):\n            if i != j and other_obj[0] <= obj[0] and other_obj[1] <= obj[1] and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = selected_idx[np.random.choice(non_dominated)]\n    else:\n        selected_idx = selected_idx[np.random.choice(len(selected_idx))]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    # Hybrid local search: 3-opt and edge reversal\n    if np.random.random() < 0.7:  # 70% chance for 3-opt\n        a, b, c = sorted(np.random.choice(n, 3, replace=False))\n        # Try all 8 possible 3-opt moves\n        candidates = [\n            np.concatenate([new_solution[:a], new_solution[b:a-1:-1], new_solution[b+1:]]),\n            np.concatenate([new_solution[:a], new_solution[c:b-1:-1], new_solution[c+1:]]),\n            np.concatenate([new_solution[:b], new_solution[a:b-1:-1], new_solution[a+1:]]),\n            np.concatenate([new_solution[:b], new_solution[c:a-1:-1], new_solution[c+1:]]),\n            np.concatenate([new_solution[:c], new_solution[a:b-1:-1], new_solution[b+1:]]),\n            np.concatenate([new_solution[:c], new_solution[b:a-1:-1], new_solution[a+1:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c-1:-1], new_solution[a+1:]]),\n            np.concatenate([new_solution[:b], new_solution[a:c-1:-1], new_solution[b+1:]])\n        ]\n\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        best_cost = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n        for candidate in candidates:\n            cost = calculate_cost(candidate, distance_matrix_1) + calculate_cost(candidate, distance_matrix_2)\n            if cost < best_cost:\n                best_cost = cost\n                new_solution = candidate.copy()\n    else:  # Edge reversal operator\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        # Reverse the segment between a and b\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.7058194319104164,
            0.4825499653816223
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection: pick 5 random solutions and select the non-dominated one\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_solutions = [archive[i][0] for i in selected_idx]\n    selected_objectives = [archive[i][1] for i in selected_idx]\n\n    # Find non-dominated solutions in the tournament\n    non_dominated = []\n    for i, obj in enumerate(selected_objectives):\n        dominated = False\n        for j, other_obj in enumerate(selected_objectives):\n            if i != j and other_obj[0] <= obj[0] and other_obj[1] <= obj[1] and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = selected_idx[np.random.choice(non_dominated)]\n    else:\n        selected_idx = selected_idx[np.random.choice(len(selected_idx))]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        return new_solution\n\n    # Hybrid local search: 3-opt and edge reversal\n    if np.random.random() < 0.7:  # 70% chance for 3-opt\n        a, b, c = sorted(np.random.choice(n, 3, replace=False))\n        # Try all 8 possible 3-opt moves\n        candidates = [\n            np.concatenate([new_solution[:a], new_solution[b:a-1:-1], new_solution[b+1:]]),\n            np.concatenate([new_solution[:a], new_solution[c:b-1:-1], new_solution[c+1:]]),\n            np.concatenate([new_solution[:b], new_solution[a:b-1:-1], new_solution[a+1:]]),\n            np.concatenate([new_solution[:b], new_solution[c:a-1:-1], new_solution[c+1:]]),\n            np.concatenate([new_solution[:c], new_solution[a:b-1:-1], new_solution[b+1:]]),\n            np.concatenate([new_solution[:c], new_solution[b:a-1:-1], new_solution[a+1:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c-1:-1], new_solution[a+1:]]),\n            np.concatenate([new_solution[:b], new_solution[a:c-1:-1], new_solution[b+1:]])\n        ]\n\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        best_cost = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n        for candidate in candidates:\n            cost = calculate_cost(candidate, distance_matrix_1) + calculate_cost(candidate, distance_matrix_2)\n            if cost < best_cost:\n                best_cost = cost\n                new_solution = candidate.copy()\n    else:  # Edge reversal operator\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        # Reverse the segment between a and b\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection of promising solutions using a combination of objective values and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Step 3: Hybrid local search combining segment reversal and adaptive edge insertion\n    # First perform segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Then perform adaptive edge insertion based on high combined distance\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on its distance\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_distances = [distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]] for i in candidates]\n                candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n                e = np.random.choice(candidates, p=candidate_weights)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 4: Additional local improvement with edge reversal\n    if n > 3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Reverse the segment between the two selected edges\n            if c1 < d1 and c2 > d2:  # Ensure proper segment selection\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### Keywords\n- **Adaptive local search**, **hybrid perturbation**, **cost-aware selection**, **feasibility preservation**, **exploration-exploitation balance**.\n\n### Advice\n- Combine **segment insertion** with **edge reversal** or **rotation** to diversify perturbations while preserving feasibility.\n- Use **weighted selection** based on Pareto dominance or crowding distance to prioritize promising solutions.\n- Introduce **conditional operators** (e.g., reverse segments only if they improve one objective) to avoid over-optimization.\n- Ensure **feasibility** by validating tours after perturbations (e.g., check for duplicates or missing nodes).\n\n### Avoid\n- Greedy, single-operator strategies (e.g., always using 2-opt or edge swaps).\n- Static perturbation sizes or probabilities (e.g., fixed segment lengths).\n- Ignoring objective trade-offs (e.g., always optimizing one objective at the expense of the other).\n\n### Explanation\nHybrid local search balances exploration (random segment operations) and exploitation (cost-aware edge prioritization). Adaptive selection and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while weighted selection focuses computational effort on high-potential regions. This approach generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 30,
        "algorithm": "The algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "score": [
            -0.9815906601152675,
            0.2346944808959961
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection of promising solutions using a combination of objective values and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Step 3: Hybrid local search combining segment reversal and adaptive edge insertion\n    # First perform segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Then perform adaptive edge insertion based on high combined distance\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on its distance\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_distances = [distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]] for i in candidates]\n                candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n                e = np.random.choice(candidates, p=candidate_weights)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 4: Additional local improvement with edge reversal\n    if n > 3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Reverse the segment between the two selected edges\n            if c1 < d1 and c2 > d2:  # Ensure proper segment selection\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### Keywords\n- **Adaptive local search**, **hybrid perturbation**, **cost-aware selection**, **feasibility preservation**, **exploration-exploitation balance**.\n\n### Advice\n- Combine **segment insertion** with **edge reversal** or **rotation** to diversify perturbations while preserving feasibility.\n- Use **weighted selection** based on Pareto dominance or crowding distance to prioritize promising solutions.\n- Introduce **conditional operators** (e.g., reverse segments only if they improve one objective) to avoid over-optimization.\n- Ensure **feasibility** by validating tours after perturbations (e.g., check for duplicates or missing nodes).\n\n### Avoid\n- Greedy, single-operator strategies (e.g., always using 2-opt or edge swaps).\n- Static perturbation sizes or probabilities (e.g., fixed segment lengths).\n- Ignoring objective trade-offs (e.g., always optimizing one objective at the expense of the other).\n\n### Explanation\nHybrid local search balances exploration (random segment operations) and exploitation (cost-aware edge prioritization). Adaptive selection and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while weighted selection focuses computational effort on high-potential regions. This approach generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 30,
        "algorithm": "The algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "score": [
            -0.9815906601152675,
            0.2346944808959961
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a non-dominated solution from the archive (prioritizing Pareto-optimal candidates) and applies a two-phase local search: first identifying high-quality segments (shortest in both objectives) and then reinserting them at random positions while ensuring feasibility through duplicate removal. If this fails, it defaults to a simple random swap. The method balances exploitation of good structures with controlled diversification while maintaining tour validity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with non-dominated objectives\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify high-quality segments\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            # Calculate segment quality based on both objectives\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            score = - (segment_length1 + segment_length2)  # Higher score for shorter segments\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reintegrate segment with dynamic boundary adjustment\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if all else fails\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 31,
        "algorithm": "The algorithm selects a solution from the archive (preferring non-dominated ones) and performs a hybrid local search by identifying and reinserting the shortest segments from either objective space, then ensuring feasibility through uniqueness checks and random swaps if needed. The key design prioritizes segment optimization across both objectives while maintaining feasibility through careful reinsertion and fallback mechanisms.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute non-dominated solutions (O(n))\n    objectives = np.array([obj for _, obj in archive])\n    is_dominated = np.zeros(len(objectives), dtype=bool)\n    for i in range(len(objectives)):\n        if not is_dominated[i]:\n            for j in range(i + 1, len(objectives)):\n                if (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                    is_dominated[i] = True\n                    break\n    non_dominated = np.where(~is_dominated)[0]\n\n    # Select a solution (weighted random if non-dominated exists)\n    if len(non_dominated) > 0:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify shortest segments in each objective (O(n))\n    min_len1, min_len2 = float('inf'), float('inf')\n    best_i1, best_j1, best_i2, best_j2 = 0, 0, 0, 0\n\n    for i in range(n):\n        for j in range(i + 2, min(i + 10, n)):\n            # Compute segment lengths in both objectives\n            segment1 = new_solution[i:j+1]\n            segment2 = new_solution[i:j+1]\n\n            # Compute segment costs (O(1) per segment)\n            cost1 = sum(distance_matrix_1[segment1[k-1], segment1[k]] for k in range(1, len(segment1)))\n            cost2 = sum(distance_matrix_2[segment2[k-1], segment2[k]] for k in range(1, len(segment2)))\n\n            if cost1 < min_len1:\n                min_len1, best_i1, best_j1 = cost1, i, j\n            if cost2 < min_len2:\n                min_len2, best_i2, best_j2 = cost2, i, j\n\n    # Phase 2: Reinsert best segments (O(1))\n    if min_len1 < float('inf') or min_len2 < float('inf'):\n        best_i = best_i1 if min_len1 < min_len2 else best_i2\n        best_j = best_j1 if min_len1 < min_len2 else best_j2\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Reinsert at random position\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility (O(n))\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Fallback: Random swap (O(1))\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9237013952879708,
            2.9806190133094788
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute non-dominated solutions (O(n))\n    objectives = np.array([obj for _, obj in archive])\n    is_dominated = np.zeros(len(objectives), dtype=bool)\n    for i in range(len(objectives)):\n        if not is_dominated[i]:\n            for j in range(i + 1, len(objectives)):\n                if (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                    is_dominated[i] = True\n                    break\n    non_dominated = np.where(~is_dominated)[0]\n\n    # Select a solution (weighted random if non-dominated exists)\n    if len(non_dominated) > 0:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify shortest segments in each objective (O(n))\n    min_len1, min_len2 = float('inf'), float('inf')\n    best_i1, best_j1, best_i2, best_j2 = 0, 0, 0, 0\n\n    for i in range(n):\n        for j in range(i + 2, min(i + 10, n)):\n            # Compute segment lengths in both objectives\n            segment1 = new_solution[i:j+1]\n            segment2 = new_solution[i:j+1]\n\n            # Compute segment costs (O(1) per segment)\n            cost1 = sum(distance_matrix_1[segment1[k-1], segment1[k]] for k in range(1, len(segment1)))\n            cost2 = sum(distance_matrix_2[segment2[k-1], segment2[k]] for k in range(1, len(segment2)))\n\n            if cost1 < min_len1:\n                min_len1, best_i1, best_j1 = cost1, i, j\n            if cost2 < min_len2:\n                min_len2, best_i2, best_j2 = cost2, i, j\n\n    # Phase 2: Reinsert best segments (O(1))\n    if min_len1 < float('inf') or min_len2 < float('inf'):\n        best_i = best_i1 if min_len1 < min_len2 else best_i2\n        best_j = best_j1 if min_len1 < min_len2 else best_j2\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Reinsert at random position\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility (O(n))\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Fallback: Random swap (O(1))\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords\n- **Adaptive local search**, **hybrid perturbation**, **cost-aware selection**, **feasibility preservation**, **exploration-exploitation balance**.\n\n### Advice\n- Combine **segment insertion** with **edge reversal** or **rotation** to diversify perturbations while preserving feasibility.\n- Use **weighted selection** based on Pareto dominance or crowding distance to prioritize promising solutions.\n- Introduce **conditional operators** (e.g., reverse segments only if they improve one objective) to avoid over-optimization.\n- Ensure **feasibility** by validating tours after perturbations (e.g., check for duplicates or missing nodes).\n\n### Avoid\n- Greedy, single-operator strategies (e.g., always using 2-opt or edge swaps).\n- Static perturbation sizes or probabilities (e.g., fixed segment lengths).\n- Ignoring objective trade-offs (e.g., always optimizing one objective at the expense of the other).\n\n### Explanation\nHybrid local search balances exploration (random segment operations) and exploitation (cost-aware edge prioritization). Adaptive selection and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while weighted selection focuses computational effort on high-potential regions. This approach generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 32,
        "algorithm": "The algorithm combines Pareto-based selection with adaptive segment swapping and cost-aware edge prioritization, using dynamic segment validation to ensure feasibility while prioritizing edges based on combined objective weights. It selectively applies segment inversion only when it improves at least one objective, balancing exploration and exploitation through normalized cost weighting and probabilistic activation. The solution is always maintained as a valid TSP tour through careful segment manipulation and boundary checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based selection with crowding distance consideration\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive segment swapping\n    segment_length = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n    a = np.random.randint(0, n - segment_length + 1)\n    b = a + segment_length - 1\n    c = np.random.randint(0, n - segment_length + 1)\n    d = c + segment_length - 1\n\n    # Ensure segments don't overlap\n    if (a <= d and b >= c):\n        return new_solution\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    temp = new_solution[a:b+1].copy()\n    new_solution[a:b+1] = new_solution[c:d+1]\n    new_solution[c:d+1] = temp\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        temp = new_solution[a:b+1].copy()\n        new_solution[a:b+1] = new_solution[c:d+1]\n        new_solution[c:d+1] = temp\n\n    # Cost-aware edge prioritization\n    combined_weights = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n    edge_scores = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_scores.append(combined_weights[u][v])\n\n    edge_scores = np.array(edge_scores)\n    edge_scores = edge_scores / np.sum(edge_scores)\n    selected_edge = np.random.choice(n, p=edge_scores)\n    x = selected_edge\n    y = (selected_edge + 1) % n\n\n    # Conditional segment inversion\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 5, int(np.random.exponential(scale=1.0))))\n        e = np.random.randint(0, n - segment_size + 1)\n        f = e + segment_size - 1\n\n        original_segment_cost1 = distance_matrix_1[new_solution[e]][new_solution[(e-1)%n]] + distance_matrix_1[new_solution[f]][new_solution[(f+1)%n]]\n        original_segment_cost2 = distance_matrix_2[new_solution[e]][new_solution[(e-1)%n]] + distance_matrix_2[new_solution[f]][new_solution[(f+1)%n]]\n\n        inverted_segment = new_solution[e:f+1][::-1]\n        new_segment_cost1 = distance_matrix_1[inverted_segment[0]][new_solution[(e-1)%n]] + distance_matrix_1[inverted_segment[-1]][new_solution[(f+1)%n]]\n        new_segment_cost2 = distance_matrix_2[inverted_segment[0]][new_solution[(e-1)%n]] + distance_matrix_2[inverted_segment[-1]][new_solution[(f+1)%n]]\n\n        if (new_segment_cost1 < original_segment_cost1) or (new_segment_cost2 < original_segment_cost2):\n            new_solution[e:f+1] = inverted_segment\n\n    return new_solution\n\n",
        "score": [
            -0.8088753844191987,
            0.8278075456619263
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based selection with crowding distance consideration\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive segment swapping\n    segment_length = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n    a = np.random.randint(0, n - segment_length + 1)\n    b = a + segment_length - 1\n    c = np.random.randint(0, n - segment_length + 1)\n    d = c + segment_length - 1\n\n    # Ensure segments don't overlap\n    if (a <= d and b >= c):\n        return new_solution\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    temp = new_solution[a:b+1].copy()\n    new_solution[a:b+1] = new_solution[c:d+1]\n    new_solution[c:d+1] = temp\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        temp = new_solution[a:b+1].copy()\n        new_solution[a:b+1] = new_solution[c:d+1]\n        new_solution[c:d+1] = temp\n\n    # Cost-aware edge prioritization\n    combined_weights = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n    edge_scores = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_scores.append(combined_weights[u][v])\n\n    edge_scores = np.array(edge_scores)\n    edge_scores = edge_scores / np.sum(edge_scores)\n    selected_edge = np.random.choice(n, p=edge_scores)\n    x = selected_edge\n    y = (selected_edge + 1) % n\n\n    # Conditional segment inversion\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 5, int(np.random.exponential(scale=1.0))))\n        e = np.random.randint(0, n - segment_size + 1)\n        f = e + segment_size - 1\n\n        original_segment_cost1 = distance_matrix_1[new_solution[e]][new_solution[(e-1)%n]] + distance_matrix_1[new_solution[f]][new_solution[(f+1)%n]]\n        original_segment_cost2 = distance_matrix_2[new_solution[e]][new_solution[(e-1)%n]] + distance_matrix_2[new_solution[f]][new_solution[(f+1)%n]]\n\n        inverted_segment = new_solution[e:f+1][::-1]\n        new_segment_cost1 = distance_matrix_1[inverted_segment[0]][new_solution[(e-1)%n]] + distance_matrix_1[inverted_segment[-1]][new_solution[(f+1)%n]]\n        new_segment_cost2 = distance_matrix_2[inverted_segment[0]][new_solution[(e-1)%n]] + distance_matrix_2[inverted_segment[-1]][new_solution[(f+1)%n]]\n\n        if (new_segment_cost1 < original_segment_cost1) or (new_segment_cost2 < original_segment_cost2):\n            new_solution[e:f+1] = inverted_segment\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 33,
        "algorithm": "The algorithm combines adaptive segment swapping, objective-aware edge replacement, and conditional path inversion to generate high-quality neighbors from a selected solution. It prioritizes solutions with better combined objective values while considering diversity, and applies hybrid local search operators that balance exploration of both objectives, with segment inversion only when significant improvement is expected. The method ensures feasibility by carefully handling segment boundaries and avoiding node revisits.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Combined objective selection with diversity consideration\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for m in range(2):\n        sorted_indices = np.argsort(objectives[:, m])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], m] - objectives[sorted_indices[i-1], m]) / (objectives[sorted_indices[-1], m] - objectives[sorted_indices[0], m] + 1e-10)\n\n    combined_scores = np.sum(objectives, axis=1) - 0.3 * crowding_distances\n    selected_idx = np.argmin(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment swapping\n    segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    segment1 = new_solution[a:b+1]\n    segment2 = new_solution[c:d+1]\n    new_solution[a:b+1] = segment2\n    new_solution[c:d+1] = segment1\n\n    # Objective-aware edge replacement\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_scores = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_scores.append(combined_distances[u][v])\n\n        edge_scores = np.array(edge_scores)\n        edge_scores = edge_scores / np.sum(edge_scores)\n        selected_edge = np.random.choice(n, p=edge_scores)\n        x = selected_edge\n        y = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (x, y, (x-1)%n, (y+1)%n)]\n        if candidates:\n            candidate_scores = []\n            for i in candidates:\n                score = (distance_matrix_1[new_solution[x]][new_solution[i]] + distance_matrix_1[new_solution[i]][new_solution[y]] -\n                         distance_matrix_1[new_solution[x]][new_solution[y]])\n                score += (distance_matrix_2[new_solution[x]][new_solution[i]] + distance_matrix_2[new_solution[i]][new_solution[y]] -\n                          distance_matrix_2[new_solution[x]][new_solution[y]])\n                candidate_scores.append(score)\n\n            candidate_scores = np.array(candidate_scores)\n            candidate_scores = np.exp(-candidate_scores)\n            candidate_scores = candidate_scores / np.sum(candidate_scores)\n            z = np.random.choice(candidates, p=candidate_scores)\n            new_solution = np.concatenate([new_solution[:x+1], new_solution[z:z+1], new_solution[x+1:]])\n\n    # Conditional path inversion\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 5, int(np.random.exponential(scale=1.0))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = (distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] +\n                          distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]])\n        original_cost2 = (distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] +\n                          distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]])\n\n        inverted_segment = new_solution[a:b+1][::-1]\n        new_cost1 = (distance_matrix_1[inverted_segment[0]][new_solution[(a-1)%n]] +\n                    distance_matrix_1[inverted_segment[-1]][new_solution[(b+1)%n]])\n        new_cost2 = (distance_matrix_2[inverted_segment[0]][new_solution[(a-1)%n]] +\n                    distance_matrix_2[inverted_segment[-1]][new_solution[(b+1)%n]])\n\n        improvement_factor = 0.7\n        if ((new_cost1 < original_cost1 * improvement_factor) or\n            (new_cost2 < original_cost2 * improvement_factor)):\n            new_solution[a:b+1] = inverted_segment\n\n    return new_solution\n\n",
        "score": [
            -0.9197315059452067,
            0.6117097735404968
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Combined objective selection with diversity consideration\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for m in range(2):\n        sorted_indices = np.argsort(objectives[:, m])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            crowding_distances[sorted_indices[i]] += (objectives[sorted_indices[i+1], m] - objectives[sorted_indices[i-1], m]) / (objectives[sorted_indices[-1], m] - objectives[sorted_indices[0], m] + 1e-10)\n\n    combined_scores = np.sum(objectives, axis=1) - 0.3 * crowding_distances\n    selected_idx = np.argmin(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment swapping\n    segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    segment1 = new_solution[a:b+1]\n    segment2 = new_solution[c:d+1]\n    new_solution[a:b+1] = segment2\n    new_solution[c:d+1] = segment1\n\n    # Objective-aware edge replacement\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_scores = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_scores.append(combined_distances[u][v])\n\n        edge_scores = np.array(edge_scores)\n        edge_scores = edge_scores / np.sum(edge_scores)\n        selected_edge = np.random.choice(n, p=edge_scores)\n        x = selected_edge\n        y = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (x, y, (x-1)%n, (y+1)%n)]\n        if candidates:\n            candidate_scores = []\n            for i in candidates:\n                score = (distance_matrix_1[new_solution[x]][new_solution[i]] + distance_matrix_1[new_solution[i]][new_solution[y]] -\n                         distance_matrix_1[new_solution[x]][new_solution[y]])\n                score += (distance_matrix_2[new_solution[x]][new_solution[i]] + distance_matrix_2[new_solution[i]][new_solution[y]] -\n                          distance_matrix_2[new_solution[x]][new_solution[y]])\n                candidate_scores.append(score)\n\n            candidate_scores = np.array(candidate_scores)\n            candidate_scores = np.exp(-candidate_scores)\n            candidate_scores = candidate_scores / np.sum(candidate_scores)\n            z = np.random.choice(candidates, p=candidate_scores)\n            new_solution = np.concatenate([new_solution[:x+1], new_solution[z:z+1], new_solution[x+1:]])\n\n    # Conditional path inversion\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 5, int(np.random.exponential(scale=1.0))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = (distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] +\n                          distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]])\n        original_cost2 = (distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] +\n                          distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]])\n\n        inverted_segment = new_solution[a:b+1][::-1]\n        new_cost1 = (distance_matrix_1[inverted_segment[0]][new_solution[(a-1)%n]] +\n                    distance_matrix_1[inverted_segment[-1]][new_solution[(b+1)%n]])\n        new_cost2 = (distance_matrix_2[inverted_segment[0]][new_solution[(a-1)%n]] +\n                    distance_matrix_2[inverted_segment[-1]][new_solution[(b+1)%n]])\n\n        improvement_factor = 0.7\n        if ((new_cost1 < original_cost1 * improvement_factor) or\n            (new_cost2 < original_cost2 * improvement_factor)):\n            new_solution[a:b+1] = inverted_segment\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 34,
        "algorithm": "The algorithm selects promising solutions from the archive using Pareto-dominance-based tournament selection, then applies a hybrid local search combining adaptive segment inversion, objective-aware edge swapping, and probabilistic segment relocation to generate feasible neighbor solutions while balancing exploration and exploitation of the search space. The method prioritizes edge swaps based on combined objective distances and uses exponential segment sizes to adaptively explore different neighborhood structures, ensuring feasibility through careful segment manipulation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance based selection\n    tournament_size = min(7, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[0]\n    for idx in selected_indices[1:]:\n        if (archive[idx][1][0] <= archive[selected_idx][1][0] and archive[idx][1][1] < archive[selected_idx][1][1]) or \\\n           (archive[idx][1][0] < archive[selected_idx][1][0] and archive[idx][1][1] <= archive[selected_idx][1][1]):\n            selected_idx = idx\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment inversion\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2.0))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    if np.random.rand() < 0.4:\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Objective-aware edge swapping\n    if n > 3 and np.random.rand() < 0.6:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Probabilistic segment relocation\n    if n > 4 and np.random.rand() < 0.5:\n        segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.8))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n        segment = new_solution[a:b+1]\n        new_solution = np.concatenate([new_solution[:a], new_solution[b+1:]])\n        insert_pos = np.random.randint(0, len(new_solution) + 1)\n        new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    return new_solution\n\n",
        "score": [
            -0.7625572361912625,
            0.3170117735862732
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance based selection\n    tournament_size = min(7, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[0]\n    for idx in selected_indices[1:]:\n        if (archive[idx][1][0] <= archive[selected_idx][1][0] and archive[idx][1][1] < archive[selected_idx][1][1]) or \\\n           (archive[idx][1][0] < archive[selected_idx][1][0] and archive[idx][1][1] <= archive[selected_idx][1][1]):\n            selected_idx = idx\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment inversion\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2.0))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    if np.random.rand() < 0.4:\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Objective-aware edge swapping\n    if n > 3 and np.random.rand() < 0.6:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Probabilistic segment relocation\n    if n > 4 and np.random.rand() < 0.5:\n        segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.8))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n        segment = new_solution[a:b+1]\n        new_solution = np.concatenate([new_solution[:a], new_solution[b+1:]])\n        insert_pos = np.random.randint(0, len(new_solution) + 1)\n        new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe heuristic selects a random solution from the archive and applies a hybrid local search combining edge insertion and node swapping, prioritizing improvements that reduce the total tour length in both objective spaces while ensuring feasibility. The edge insertion randomly moves a node to a new position, and node swapping further refines the solution by swapping nodes if it improves the combined cost. The algorithm balances exploration (random selection) and exploitation (cost-based swapping) to generate high-quality neighbors.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not dominated by others)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and node swapping\n    n = len(new_solution)\n    if n < 4:\n        return new_solution  # Too small to apply operators\n\n    # Step 1: Edge insertion\n    i = np.random.randint(0, n)\n    j = np.random.randint(0, n)\n    while j == i or abs(j - i) == 1:\n        j = np.random.randint(0, n)\n\n    # Remove node at j and reinsert it after i\n    node = new_solution[j]\n    new_solution = np.concatenate([new_solution[:j], new_solution[j+1:]])\n    insert_pos = (i + 1) % len(new_solution)\n    new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Step 2: Node swapping (if beneficial)\n    if np.random.random() < 0.5:  # 50% chance to apply swapping\n        k = np.random.randint(0, len(new_solution))\n        l = np.random.randint(0, len(new_solution))\n        while k == l:\n            l = np.random.randint(0, len(new_solution))\n\n        # Calculate cost before and after swap\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n        temp_sol = new_solution.copy()\n        temp_sol[k], temp_sol[l] = temp_sol[l], temp_sol[k]\n        cost_after = calculate_cost(temp_sol, distance_matrix_1) + calculate_cost(temp_sol, distance_matrix_2)\n\n        if cost_after < cost_before:\n            new_solution = temp_sol\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords\n- **Adaptive local search**, **hybrid perturbation**, **cost-aware selection**, **feasibility preservation**, **exploration-exploitation balance**.\n\n### Advice\n- Combine **segment insertion** with **edge reversal** or **rotation** to diversify perturbations while preserving feasibility.\n- Use **weighted selection** based on Pareto dominance or crowding distance to prioritize promising solutions.\n- Introduce **conditional operators** (e.g., reverse segments only if they improve one objective) to avoid over-optimization.\n- Ensure **feasibility** by validating tours after perturbations (e.g., check for duplicates or missing nodes).\n\n### Avoid\n- Greedy, single-operator strategies (e.g., always using 2-opt or edge swaps).\n- Static perturbation sizes or probabilities (e.g., fixed segment lengths).\n- Ignoring objective trade-offs (e.g., always optimizing one objective at the expense of the other).\n\n### Explanation\nHybrid local search balances exploration (random segment operations) and exploitation (cost-aware edge prioritization). Adaptive selection and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while weighted selection focuses computational effort on high-potential regions. This approach generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 35,
        "algorithm": "The algorithm selects a promising solution from the archive using Pareto-based tournament selection, then applies a hybrid local search that combines adaptive segment rotation with cost-aware edge insertion and node swapping, prioritizing edges with higher combined weights from both objective spaces while ensuring feasibility through verification. It balances exploration through random segment operations and exploitation through cost-aware edge prioritization, with segment reversal and node swapping applied conditionally to improve solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Node swapping with cost improvement check\n    if n > 4 and np.random.rand() < 0.5:\n        k = np.random.randint(0, n)\n        l = np.random.randint(0, n)\n        while k == l or abs(k - l) == 1:\n            l = np.random.randint(0, n)\n\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n        temp_sol = new_solution.copy()\n        temp_sol[k], temp_sol[l] = temp_sol[l], temp_sol[k]\n        cost_after = calculate_cost(temp_sol, distance_matrix_1) + calculate_cost(temp_sol, distance_matrix_2)\n\n        if cost_after < cost_before:\n            new_solution = temp_sol\n\n    # Conditional segment reversal\n    if n > 5 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Verify feasibility\n    if len(np.unique(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -0.7373486584161918,
            0.27187418937683105
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Node swapping with cost improvement check\n    if n > 4 and np.random.rand() < 0.5:\n        k = np.random.randint(0, n)\n        l = np.random.randint(0, n)\n        while k == l or abs(k - l) == 1:\n            l = np.random.randint(0, n)\n\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n        temp_sol = new_solution.copy()\n        temp_sol[k], temp_sol[l] = temp_sol[l], temp_sol[k]\n        cost_after = calculate_cost(temp_sol, distance_matrix_1) + calculate_cost(temp_sol, distance_matrix_2)\n\n        if cost_after < cost_before:\n            new_solution = temp_sol\n\n    # Conditional segment reversal\n    if n > 5 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Verify feasibility\n    if len(np.unique(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 2 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### Keywords\n- **Adaptive multi-objective selection**, **hybrid segment-based perturbation**, **cost-aware edge prioritization**, **conditional feasibility checks**.\n\n### Advice\n- **Adaptive selection**: Use Pareto dominance or crowding distance to bias selection toward high-potential solutions.\n- **Hybrid local search**: Combine segment insertion, rotation, and conditional edge reversal to balance exploration and exploitation.\n- **Cost-aware prioritization**: Focus perturbations on edges with high normalized distance products in both objectives.\n- **Conditional feasibility**: Only apply operators if they improve at least one objective while ensuring no node is skipped or revisited.\n\n### Avoid\n- Static or greedy operators (e.g., fixed-length 2-opt).\n- Ignoring trade-offs between objectives (e.g., always optimizing one cost at the expense of the other).\n- Overly large perturbations that disrupt promising structures.\n- Non-adaptive selection mechanisms (e.g., uniform random selection).\n\n### Explanation\nThis approach ensures diversity and quality by adaptively selecting promising solutions and applying targeted perturbations. Cost-aware prioritization and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while hybrid operators balance exploration and exploitation. The method generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 36,
        "algorithm": "The algorithm selects a high-potential solution from the archive using Pareto-dominance tournament selection, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal, ensuring feasibility and balanced multi-objective optimization by prioritizing edge weights and improving at least one objective. It intelligently balances exploration and exploitation through probabilistic segment operations and cost-aware selection.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "score": [
            -0.8948467507881668,
            0.21143871545791626
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 2 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### Keywords\n- **Adaptive multi-objective selection**, **hybrid segment-based perturbation**, **cost-aware edge prioritization**, **conditional feasibility checks**.\n\n### Advice\n- **Adaptive selection**: Use Pareto dominance or crowding distance to bias selection toward high-potential solutions.\n- **Hybrid local search**: Combine segment insertion, rotation, and conditional edge reversal to balance exploration and exploitation.\n- **Cost-aware prioritization**: Focus perturbations on edges with high normalized distance products in both objectives.\n- **Conditional feasibility**: Only apply operators if they improve at least one objective while ensuring no node is skipped or revisited.\n\n### Avoid\n- Static or greedy operators (e.g., fixed-length 2-opt).\n- Ignoring trade-offs between objectives (e.g., always optimizing one cost at the expense of the other).\n- Overly large perturbations that disrupt promising structures.\n- Non-adaptive selection mechanisms (e.g., uniform random selection).\n\n### Explanation\nThis approach ensures diversity and quality by adaptively selecting promising solutions and applying targeted perturbations. Cost-aware prioritization and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while hybrid operators balance exploration and exploitation. The method generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 36,
        "algorithm": "The algorithm selects a high-potential solution from the archive using Pareto-dominance tournament selection, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal, ensuring feasibility and balanced multi-objective optimization by prioritizing edge weights and improving at least one objective. It intelligently balances exploration and exploitation through probabilistic segment operations and cost-aware selection.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "score": [
            -0.8948467507881668,
            0.21143871545791626
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a non-dominated solution from the archive (prioritizing Pareto-optimal candidates) and applies a two-phase local search: first identifying high-quality segments (shortest in both objectives) and then reinserting them at random positions while ensuring feasibility through duplicate removal. If this fails, it defaults to a simple random swap. The method balances exploitation of good structures with controlled diversification while maintaining tour validity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with non-dominated objectives\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify high-quality segments\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            # Calculate segment quality based on both objectives\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            score = - (segment_length1 + segment_length2)  # Higher score for shorter segments\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reintegrate segment with dynamic boundary adjustment\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if all else fails\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 37,
        "algorithm": "This algorithm selects a non-dominated solution from the archive using Pareto front detection, then applies a two-phase local search: Phase 1 identifies high-quality segments by precomputing cumulative distances, and Phase 2 reinserts the best segment at a random position while ensuring feasibility through direct duplicate removal, falling back to a simple swap if needed. The algorithm prioritizes minimizing both objectives by focusing on segments with low combined distance in both spaces, with a fallback mechanism to maintain feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Optimized non-dominated sorting\n    objectives = np.array([obj for _, obj in archive])\n    sorted_indices = np.lexsort((objectives[:, 1], objectives[:, 0]))\n    non_dominated = []\n    current_max = float('inf')\n\n    for idx in sorted_indices:\n        if objectives[idx][1] < current_max:\n            non_dominated.append(idx)\n            current_max = objectives[idx][1]\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Precompute cumulative distances for efficiency\n    cum_dist1 = np.zeros(n+1)\n    cum_dist2 = np.zeros(n+1)\n    for i in range(1, n):\n        cum_dist1[i] = cum_dist1[i-1] + distance_matrix_1[new_solution[i-1], new_solution[i]]\n        cum_dist2[i] = cum_dist2[i-1] + distance_matrix_2[new_solution[i-1], new_solution[i]]\n    cum_dist1[n] = cum_dist1[n-1] + distance_matrix_1[new_solution[-1], new_solution[0]]\n    cum_dist2[n] = cum_dist2[n-1] + distance_matrix_2[new_solution[-1], new_solution[0]]\n\n    # Phase 1: Identify high-quality segments with precomputed distances\n    best_score = float('-inf')\n    best_i, best_j = 0, 0\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):\n            segment_length1 = cum_dist1[j+1] - cum_dist1[i]\n            segment_length2 = cum_dist2[j+1] - cum_dist2[i]\n            score = - (segment_length1 + segment_length2)\n            if score > best_score:\n                best_score = score\n                best_i, best_j = i, j\n\n    if best_i != best_j:\n        best_segment = new_solution[best_i:best_j+1]\n        new_pos = random.randint(0, n - len(best_segment))\n\n        # Phase 2: Reintegrate segment and ensure feasibility\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Remove duplicates directly\n        unique_nodes, counts = np.unique(new_solution, return_counts=True)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Fallback to simple swap if needed\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.821616167049462,
            0.3836511969566345
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Optimized non-dominated sorting\n    objectives = np.array([obj for _, obj in archive])\n    sorted_indices = np.lexsort((objectives[:, 1], objectives[:, 0]))\n    non_dominated = []\n    current_max = float('inf')\n\n    for idx in sorted_indices:\n        if objectives[idx][1] < current_max:\n            non_dominated.append(idx)\n            current_max = objectives[idx][1]\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Precompute cumulative distances for efficiency\n    cum_dist1 = np.zeros(n+1)\n    cum_dist2 = np.zeros(n+1)\n    for i in range(1, n):\n        cum_dist1[i] = cum_dist1[i-1] + distance_matrix_1[new_solution[i-1], new_solution[i]]\n        cum_dist2[i] = cum_dist2[i-1] + distance_matrix_2[new_solution[i-1], new_solution[i]]\n    cum_dist1[n] = cum_dist1[n-1] + distance_matrix_1[new_solution[-1], new_solution[0]]\n    cum_dist2[n] = cum_dist2[n-1] + distance_matrix_2[new_solution[-1], new_solution[0]]\n\n    # Phase 1: Identify high-quality segments with precomputed distances\n    best_score = float('-inf')\n    best_i, best_j = 0, 0\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):\n            segment_length1 = cum_dist1[j+1] - cum_dist1[i]\n            segment_length2 = cum_dist2[j+1] - cum_dist2[i]\n            score = - (segment_length1 + segment_length2)\n            if score > best_score:\n                best_score = score\n                best_i, best_j = i, j\n\n    if best_i != best_j:\n        best_segment = new_solution[best_i:best_j+1]\n        new_pos = random.randint(0, n - len(best_segment))\n\n        # Phase 2: Reintegrate segment and ensure feasibility\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Remove duplicates directly\n        unique_nodes, counts = np.unique(new_solution, return_counts=True)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Fallback to simple swap if needed\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection of promising solutions using a combination of objective values and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Step 3: Hybrid local search combining segment reversal and adaptive edge insertion\n    # First perform segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Then perform adaptive edge insertion based on high combined distance\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on its distance\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_distances = [distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]] for i in candidates]\n                candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n                e = np.random.choice(candidates, p=candidate_weights)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 4: Additional local improvement with edge reversal\n    if n > 3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Reverse the segment between the two selected edges\n            if c1 < d1 and c2 > d2:  # Ensure proper segment selection\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a non-dominated solution from the archive (prioritizing Pareto-optimal candidates) and applies a two-phase local search: first identifying high-quality segments (shortest in both objectives) and then reinserting them at random positions while ensuring feasibility through duplicate removal. If this fails, it defaults to a simple random swap. The method balances exploitation of good structures with controlled diversification while maintaining tour validity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with non-dominated objectives\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify high-quality segments\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            # Calculate segment quality based on both objectives\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            score = - (segment_length1 + segment_length2)  # Higher score for shorter segments\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reintegrate segment with dynamic boundary adjustment\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if all else fails\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords\n- **Adaptive multi-objective selection**, **hybrid segment-based perturbation**, **cost-aware edge prioritization**, **conditional feasibility checks**.\n\n### Advice\n- **Adaptive selection**: Use Pareto dominance or crowding distance to bias selection toward high-potential solutions.\n- **Hybrid local search**: Combine segment insertion, rotation, and conditional edge reversal to balance exploration and exploitation.\n- **Cost-aware prioritization**: Focus perturbations on edges with high normalized distance products in both objectives.\n- **Conditional feasibility**: Only apply operators if they improve at least one objective while ensuring no node is skipped or revisited.\n\n### Avoid\n- Static or greedy operators (e.g., fixed-length 2-opt).\n- Ignoring trade-offs between objectives (e.g., always optimizing one cost at the expense of the other).\n- Overly large perturbations that disrupt promising structures.\n- Non-adaptive selection mechanisms (e.g., uniform random selection).\n\n### Explanation\nThis approach ensures diversity and quality by adaptively selecting promising solutions and applying targeted perturbations. Cost-aware prioritization and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while hybrid operators balance exploration and exploitation. The method generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 38,
        "algorithm": "This algorithm combines adaptive multi-objective selection with a hybrid local search strategy. It first selects a promising solution from the archive using Pareto dominance and crowding distance, then applies segment-based rotation prioritizing high-cost edges and conditional edge reversal to improve at least one objective while maintaining tour validity. The method dynamically adjusts segment sizes and edge selection, balancing exploration and exploitation while ensuring feasibility through conditional checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Adaptive selection combining Pareto dominance and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = np.random.choice(non_dominated)\n    else:\n        # Fallback to crowding distance if no non-dominated solutions\n        normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n        crowding_dist = np.sum(normalized_obj, axis=1)\n        weights = crowding_dist / np.sum(crowding_dist)\n        selected_idx = np.random.choice(len(archive), p=weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based rotation with cost-aware edge prioritization\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=3))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Identify high-cost edges within the segment\n    edges = []\n    for i in range(a, b):\n        u = new_solution[i]\n        v = new_solution[i+1]\n        edges.append((i, i+1, distance_matrix_1[u][v] * distance_matrix_2[u][v]))\n\n    if edges:\n        edges.sort(key=lambda x: -x[2])\n        best_edge = edges[0]\n        c, d = best_edge[0], best_edge[1]\n\n        # Rotate the segment around the high-cost edge\n        if c < d:\n            rotated_segment = np.roll(new_solution[c:d+1], shift=1)\n            new_solution[c:d+1] = rotated_segment\n\n    # Step 3: Conditional edge reversal with dynamic boundary adjustment\n    if n > 3:\n        # Select edges with high combined distance\n        all_edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            all_edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        all_edges.sort(key=lambda x: -x[2])\n        if len(all_edges) >= 2:\n            c1, d1 = all_edges[0][0], all_edges[0][1]\n            c2, d2 = all_edges[1][0], all_edges[1][1]\n\n            # Calculate potential improvement\n            def calculate_improvement(solution):\n                total1 = sum(distance_matrix_1[solution[i]][solution[(i+1)%n]] for i in range(n))\n                total2 = sum(distance_matrix_2[solution[i]][solution[(i+1)%n]] for i in range(n))\n                return total1, total2\n\n            original_cost1, original_cost2 = calculate_improvement(new_solution)\n\n            # Try reversal between c1 and d1\n            temp_solution = new_solution.copy()\n            temp_solution[c1:d1+1] = temp_solution[c1:d1+1][::-1]\n            new_cost1, new_cost2 = calculate_improvement(temp_solution)\n\n            if (new_cost1 < original_cost1 or new_cost2 < original_cost2):\n                new_solution = temp_solution\n\n            # Try reversal between c2 and d2 if not already done\n            if c1 != c2 and d1 != d2:\n                temp_solution = new_solution.copy()\n                temp_solution[c2:d2+1] = temp_solution[c2:d2+1][::-1]\n                new_cost1, new_cost2 = calculate_improvement(temp_solution)\n\n                if (new_cost1 < original_cost1 or new_cost2 < original_cost2):\n                    new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Reconstruct solution if duplicates exist\n        unique_nodes = np.unique(new_solution)\n        missing_nodes = [node for node in range(n) if node not in unique_nodes]\n        new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    return new_solution\n\n",
        "score": [
            -0.5824243746304656,
            1.1574422121047974
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Adaptive selection combining Pareto dominance and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = np.random.choice(non_dominated)\n    else:\n        # Fallback to crowding distance if no non-dominated solutions\n        normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n        crowding_dist = np.sum(normalized_obj, axis=1)\n        weights = crowding_dist / np.sum(crowding_dist)\n        selected_idx = np.random.choice(len(archive), p=weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based rotation with cost-aware edge prioritization\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=3))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Identify high-cost edges within the segment\n    edges = []\n    for i in range(a, b):\n        u = new_solution[i]\n        v = new_solution[i+1]\n        edges.append((i, i+1, distance_matrix_1[u][v] * distance_matrix_2[u][v]))\n\n    if edges:\n        edges.sort(key=lambda x: -x[2])\n        best_edge = edges[0]\n        c, d = best_edge[0], best_edge[1]\n\n        # Rotate the segment around the high-cost edge\n        if c < d:\n            rotated_segment = np.roll(new_solution[c:d+1], shift=1)\n            new_solution[c:d+1] = rotated_segment\n\n    # Step 3: Conditional edge reversal with dynamic boundary adjustment\n    if n > 3:\n        # Select edges with high combined distance\n        all_edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            all_edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        all_edges.sort(key=lambda x: -x[2])\n        if len(all_edges) >= 2:\n            c1, d1 = all_edges[0][0], all_edges[0][1]\n            c2, d2 = all_edges[1][0], all_edges[1][1]\n\n            # Calculate potential improvement\n            def calculate_improvement(solution):\n                total1 = sum(distance_matrix_1[solution[i]][solution[(i+1)%n]] for i in range(n))\n                total2 = sum(distance_matrix_2[solution[i]][solution[(i+1)%n]] for i in range(n))\n                return total1, total2\n\n            original_cost1, original_cost2 = calculate_improvement(new_solution)\n\n            # Try reversal between c1 and d1\n            temp_solution = new_solution.copy()\n            temp_solution[c1:d1+1] = temp_solution[c1:d1+1][::-1]\n            new_cost1, new_cost2 = calculate_improvement(temp_solution)\n\n            if (new_cost1 < original_cost1 or new_cost2 < original_cost2):\n                new_solution = temp_solution\n\n            # Try reversal between c2 and d2 if not already done\n            if c1 != c2 and d1 != d2:\n                temp_solution = new_solution.copy()\n                temp_solution[c2:d2+1] = temp_solution[c2:d2+1][::-1]\n                new_cost1, new_cost2 = calculate_improvement(temp_solution)\n\n                if (new_cost1 < original_cost1 or new_cost2 < original_cost2):\n                    new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Reconstruct solution if duplicates exist\n        unique_nodes = np.unique(new_solution)\n        missing_nodes = [node for node in range(n) if node not in unique_nodes]\n        new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a non-dominated solution from the archive (prioritizing Pareto-optimal candidates) and applies a two-phase local search: first identifying high-quality segments (shortest in both objectives) and then reinserting them at random positions while ensuring feasibility through duplicate removal. If this fails, it defaults to a simple random swap. The method balances exploitation of good structures with controlled diversification while maintaining tour validity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with non-dominated objectives\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify high-quality segments\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            # Calculate segment quality based on both objectives\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            score = - (segment_length1 + segment_length2)  # Higher score for shorter segments\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reintegrate segment with dynamic boundary adjustment\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if all else fails\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 39,
        "algorithm": "The algorithm first selects a solution from the archive by prioritizing those with high diversity in objective values, then applies a segment-based local search that combines path reversal and dynamic segment reinsertion to explore diverse neighborhoods while ensuring tour feasibility through careful boundary handling and duplicate removal. It scores segments based on normalized differences between objectives and reverses/reinserts the highest-scoring segment, with a fallback to 3-opt for robustness. The method emphasizes objective diversity and segment-level optimization while maintaining TSP feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high diversity in objectives\n    objectives = np.array([obj for _, obj in archive])\n    diversity_scores = []\n    for i in range(len(objectives)):\n        diversity = np.sum(np.abs(objectives[i] - objectives[(i+1)%len(objectives)]))\n        diversity_scores.append((diversity, i))\n\n    diversity_scores.sort(reverse=True)\n    selected_idx = diversity_scores[0][1] if diversity_scores else random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify diverse segments with complementary objectives\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+15, n)):  # Larger segment range\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            # Score based on normalized difference between objectives\n            score = (segment_length1 / (segment_length2 + 1e-6)) + (segment_length2 / (segment_length1 + 1e-6))\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reverse and reinsert with adaptive position\n        reversed_segment = best_segment[::-1]\n        insertion_pos = random.randint(0, n - len(reversed_segment))\n        new_solution = np.concatenate([\n            new_solution[:insertion_pos],\n            reversed_segment,\n            new_solution[insertion_pos + len(reversed_segment):]\n        ])\n\n        # Ensure feasibility\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Fallback to random 3-opt if needed\n    if len(np.unique(new_solution)) != n or random.random() < 0.1:\n        i, j, k = random.sample(range(n), 3)\n        new_solution[i:j] = new_solution[i:j][::-1]\n        new_solution[j:k] = new_solution[j:k][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.8168323292457775,
            6.296095430850983
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high diversity in objectives\n    objectives = np.array([obj for _, obj in archive])\n    diversity_scores = []\n    for i in range(len(objectives)):\n        diversity = np.sum(np.abs(objectives[i] - objectives[(i+1)%len(objectives)]))\n        diversity_scores.append((diversity, i))\n\n    diversity_scores.sort(reverse=True)\n    selected_idx = diversity_scores[0][1] if diversity_scores else random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify diverse segments with complementary objectives\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+15, n)):  # Larger segment range\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            # Score based on normalized difference between objectives\n            score = (segment_length1 / (segment_length2 + 1e-6)) + (segment_length2 / (segment_length1 + 1e-6))\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reverse and reinsert with adaptive position\n        reversed_segment = best_segment[::-1]\n        insertion_pos = random.randint(0, n - len(reversed_segment))\n        new_solution = np.concatenate([\n            new_solution[:insertion_pos],\n            reversed_segment,\n            new_solution[insertion_pos + len(reversed_segment):]\n        ])\n\n        # Ensure feasibility\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Fallback to random 3-opt if needed\n    if len(np.unique(new_solution)) != n or random.random() < 0.1:\n        i, j, k = random.sample(range(n), 3)\n        new_solution[i:j] = new_solution[i:j][::-1]\n        new_solution[j:k] = new_solution[j:k][::-1]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a non-dominated solution from the archive (prioritizing Pareto-optimal candidates) and applies a two-phase local search: first identifying high-quality segments (shortest in both objectives) and then reinserting them at random positions while ensuring feasibility through duplicate removal. If this fails, it defaults to a simple random swap. The method balances exploitation of good structures with controlled diversification while maintaining tour validity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with non-dominated objectives\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify high-quality segments\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            # Calculate segment quality based on both objectives\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            score = - (segment_length1 + segment_length2)  # Higher score for shorter segments\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reintegrate segment with dynamic boundary adjustment\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if all else fails\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 40,
        "algorithm": "The algorithm selects a non-dominated solution from the archive, applies a dynamic segment relocation strategy prioritizing balanced improvement in both objectives, and uses probabilistic segment merging with a repair mechanism to ensure feasibility while enhancing exploration. It weighs objective 1 (0.6) more than objective 2 (0.4) in segment scoring and dynamically adjusts segment boundaries with a 30% chance of merging adjacent segments. The repair mechanism reverses segments or reinserts missing nodes probabilistically to maintain tour validity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Dynamic segment selection with objective balancing\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+15, n)):\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            # Balanced score combining both objectives\n            score = - (0.6 * segment_length1 + 0.4 * segment_length2)\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Probabilistic segment merging\n        if random.random() < 0.3 and len(best_segment) > 2:\n            # Merge with adjacent segment\n            merge_pos = random.choice([best_i, best_j])\n            if merge_pos == best_i and best_i > 0:\n                merge_segment = new_solution[best_i-1:best_i+len(best_segment)]\n                best_segment = merge_segment\n                best_i -= 1\n            elif merge_pos == best_j and best_j < n-1:\n                merge_segment = new_solution[best_i:best_j+2]\n                best_segment = merge_segment\n                best_j += 1\n\n        # Dynamic relocation with boundary awareness\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Feasibility repair with segment reversal\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            if random.random() < 0.5:\n                # Reverse segment to fix duplicates\n                new_solution = np.concatenate([\n                    new_solution[:new_pos],\n                    best_segment[::-1],\n                    new_solution[new_pos:]\n                ])\n            else:\n                new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Enhanced fallback with segment inversion\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        if random.random() < 0.7:\n            new_solution[i:j] = new_solution[i:j][::-1]\n        else:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8912668191186754,
            6.873337984085083
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Dynamic segment selection with objective balancing\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+15, n)):\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            # Balanced score combining both objectives\n            score = - (0.6 * segment_length1 + 0.4 * segment_length2)\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Probabilistic segment merging\n        if random.random() < 0.3 and len(best_segment) > 2:\n            # Merge with adjacent segment\n            merge_pos = random.choice([best_i, best_j])\n            if merge_pos == best_i and best_i > 0:\n                merge_segment = new_solution[best_i-1:best_i+len(best_segment)]\n                best_segment = merge_segment\n                best_i -= 1\n            elif merge_pos == best_j and best_j < n-1:\n                merge_segment = new_solution[best_i:best_j+2]\n                best_segment = merge_segment\n                best_j += 1\n\n        # Dynamic relocation with boundary awareness\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Feasibility repair with segment reversal\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            if random.random() < 0.5:\n                # Reverse segment to fix duplicates\n                new_solution = np.concatenate([\n                    new_solution[:new_pos],\n                    best_segment[::-1],\n                    new_solution[new_pos:]\n                ])\n            else:\n                new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Enhanced fallback with segment inversion\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        if random.random() < 0.7:\n            new_solution[i:j] = new_solution[i:j][::-1]\n        else:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a non-dominated solution from the archive (prioritizing Pareto-optimal candidates) and applies a two-phase local search: first identifying high-quality segments (shortest in both objectives) and then reinserting them at random positions while ensuring feasibility through duplicate removal. If this fails, it defaults to a simple random swap. The method balances exploitation of good structures with controlled diversification while maintaining tour validity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with non-dominated objectives\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify high-quality segments\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            # Calculate segment quality based on both objectives\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            score = - (segment_length1 + segment_length2)  # Higher score for shorter segments\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reintegrate segment with dynamic boundary adjustment\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if all else fails\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords\n- **Adaptive multi-objective selection**, **hybrid segment-based perturbation**, **cost-aware edge prioritization**, **conditional feasibility checks**.\n\n### Advice\n- **Adaptive selection**: Use Pareto dominance or crowding distance to bias selection toward high-potential solutions.\n- **Hybrid local search**: Combine segment insertion, rotation, and conditional edge reversal to balance exploration and exploitation.\n- **Cost-aware prioritization**: Focus perturbations on edges with high normalized distance products in both objectives.\n- **Conditional feasibility**: Only apply operators if they improve at least one objective while ensuring no node is skipped or revisited.\n\n### Avoid\n- Static or greedy operators (e.g., fixed-length 2-opt).\n- Ignoring trade-offs between objectives (e.g., always optimizing one cost at the expense of the other).\n- Overly large perturbations that disrupt promising structures.\n- Non-adaptive selection mechanisms (e.g., uniform random selection).\n\n### Explanation\nThis approach ensures diversity and quality by adaptively selecting promising solutions and applying targeted perturbations. Cost-aware prioritization and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while hybrid operators balance exploration and exploitation. The method generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 41,
        "algorithm": "The heuristic selects a promising solution from the archive (prioritizing non-dominated ones), then applies a hybrid local search combining segment reversal and dynamic reinsertion of high-scoring segments (based on normalized distance products), while conditionally reversing edges to improve at least one objective. It ensures feasibility by removing duplicates and falls back to random swaps if needed. The algorithm balances exploration (random segment selection) and exploitation (cost-aware edge prioritization) while maintaining valid TSP tours.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize non-dominated solutions\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + cost-aware edge prioritization\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            normalized_score = - (segment_length1 * segment_length2)  # Higher score for shorter segments in both objectives\n            segment_scores.append((normalized_score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Dynamic reinsertion with feasibility check\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Conditional edge reversal based on cost improvement\n    if n > 3:\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        old_length1 = distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]]\n        new_length1 = distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]]\n        old_length2 = distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]\n        new_length2 = distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]\n\n        if (new_length1 < old_length1 or new_length2 < old_length2):\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9532634060346503,
            3.9698342084884644
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize non-dominated solutions\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + cost-aware edge prioritization\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            normalized_score = - (segment_length1 * segment_length2)  # Higher score for shorter segments in both objectives\n            segment_scores.append((normalized_score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Dynamic reinsertion with feasibility check\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Conditional edge reversal based on cost improvement\n    if n > 3:\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        old_length1 = distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]]\n        new_length1 = distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]]\n        old_length2 = distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]\n        new_length2 = distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]\n\n        if (new_length1 < old_length1 or new_length2 < old_length2):\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a high-potential solution from the archive using Pareto-dominance tournament selection, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal, ensuring feasibility and balanced multi-objective optimization by prioritizing edge weights and improving at least one objective. It intelligently balances exploration and exploitation through probabilistic segment operations and cost-aware selection.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: ### Keywords\n- **Adaptive local search**, **hybrid perturbation**, **cost-aware selection**, **feasibility preservation**, **exploration-exploitation balance**.\n\n### Advice\n- Combine **segment insertion** with **edge reversal** or **rotation** to diversify perturbations while preserving feasibility.\n- Use **weighted selection** based on Pareto dominance or crowding distance to prioritize promising solutions.\n- Introduce **conditional operators** (e.g., reverse segments only if they improve one objective) to avoid over-optimization.\n- Ensure **feasibility** by validating tours after perturbations (e.g., check for duplicates or missing nodes).\n\n### Avoid\n- Greedy, single-operator strategies (e.g., always using 2-opt or edge swaps).\n- Static perturbation sizes or probabilities (e.g., fixed segment lengths).\n- Ignoring objective trade-offs (e.g., always optimizing one objective at the expense of the other).\n\n### Explanation\nHybrid local search balances exploration (random segment operations) and exploitation (cost-aware edge prioritization). Adaptive selection and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while weighted selection focuses computational effort on high-potential regions. This approach generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 42,
        "algorithm": "The algorithm first selects a promising solution from the archive using Pareto-dominance tournament selection with crowding distance as a tiebreaker, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while ensuring feasibility and balancing multi-objective optimization by prioritizing edge weights and improving at least one objective. The method intelligently balances exploration and exploitation by adaptively selecting segment sizes, directions, and insertion points based on combined objective costs, while conditionally accepting reversals only when they improve at least one objective.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance tournament selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        # Use crowding distance if no Pareto solutions\n        crowding_distances = []\n        for idx in selected_indices:\n            left = right = None\n            sorted_costs = sorted([archive[i][1][0] for i in selected_indices])\n            pos = sorted_costs.index(archive[idx][1][0])\n            if pos > 0:\n                left = sorted_costs[pos-1]\n            if pos < len(sorted_costs)-1:\n                right = sorted_costs[pos+1]\n            crowding_distances.append((right - left) if left is not None and right is not None else float('inf'))\n\n        selected_idx = selected_indices[np.argmax(crowding_distances)]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size and direction\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    direction = np.random.choice([-1, 1])  # Reverse or rotate\n    if direction == -1:\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n    else:\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with objective balance\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            # Balance between objectives\n            candidate_distances = []\n            for i in candidates:\n                node = new_solution[i]\n                cost1 = distance_matrix_1[new_solution[c]][node] + distance_matrix_1[node][new_solution[d]]\n                cost2 = distance_matrix_2[new_solution[c]][node] + distance_matrix_2[node][new_solution[d]]\n                candidate_distances.append((cost1 + cost2) / 2)  # Average cost\n\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        # Accept if improves at least one objective\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "score": [
            -0.9182703674646959,
            0.2522774338722229
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance tournament selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        # Use crowding distance if no Pareto solutions\n        crowding_distances = []\n        for idx in selected_indices:\n            left = right = None\n            sorted_costs = sorted([archive[i][1][0] for i in selected_indices])\n            pos = sorted_costs.index(archive[idx][1][0])\n            if pos > 0:\n                left = sorted_costs[pos-1]\n            if pos < len(sorted_costs)-1:\n                right = sorted_costs[pos+1]\n            crowding_distances.append((right - left) if left is not None and right is not None else float('inf'))\n\n        selected_idx = selected_indices[np.argmax(crowding_distances)]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size and direction\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    direction = np.random.choice([-1, 1])  # Reverse or rotate\n    if direction == -1:\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n    else:\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with objective balance\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            # Balance between objectives\n            candidate_distances = []\n            for i in candidates:\n                node = new_solution[i]\n                cost1 = distance_matrix_1[new_solution[c]][node] + distance_matrix_1[node][new_solution[d]]\n                cost2 = distance_matrix_2[new_solution[c]][node] + distance_matrix_2[node][new_solution[d]]\n                candidate_distances.append((cost1 + cost2) / 2)  # Average cost\n\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        # Accept if improves at least one objective\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a non-dominated solution from the archive (prioritizing Pareto-optimal candidates) and applies a two-phase local search: first identifying high-quality segments (shortest in both objectives) and then reinserting them at random positions while ensuring feasibility through duplicate removal. If this fails, it defaults to a simple random swap. The method balances exploitation of good structures with controlled diversification while maintaining tour validity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with non-dominated objectives\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Phase 1: Identify high-quality segments\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            # Calculate segment quality based on both objectives\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            score = - (segment_length1 + segment_length2)  # Higher score for shorter segments\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Phase 2: Reintegrate segment with dynamic boundary adjustment\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if all else fails\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 43,
        "algorithm": "The algorithm randomly selects a solution from the archive, evaluates segments of limited length (up to 10 nodes) by their combined cost in both objectives, and attempts to reinsert the best segment at a random position while ensuring feasibility. If the reinsertion fails, it falls back to a single random swap, balancing exploration and exploitation with minimal computational overhead. The segment scoring prioritizes cost reduction, while the randomness in selection and reinsertion position avoids local optima.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Randomly select any solution (faster than non-dominated sorting)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Precompute segment quality scores from archive (if available) or compute once\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length\n            # Use precomputed scores if available, otherwise compute\n            if selected_idx < len(archive) and hasattr(archive[selected_idx], 'segment_scores'):\n                score = archive[selected_idx].segment_scores.get((i,j), 0)\n            else:\n                segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n                segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n                segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n                segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n                score = - (segment_length1 + segment_length2)\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Simplified reinsertion with immediate duplicate check\n        new_pos = random.randint(0, n - len(best_segment))\n        temp_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Quick feasibility check\n        if len(np.unique(temp_solution)) == n:\n            new_solution = temp_solution\n        else:\n            # Fallback to single swap if reinsertion fails\n            i, j = random.sample(range(n), 2)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9101780438356015,
            2.9884093403816223
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Randomly select any solution (faster than non-dominated sorting)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Precompute segment quality scores from archive (if available) or compute once\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length\n            # Use precomputed scores if available, otherwise compute\n            if selected_idx < len(archive) and hasattr(archive[selected_idx], 'segment_scores'):\n                score = archive[selected_idx].segment_scores.get((i,j), 0)\n            else:\n                segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n                segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n                segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n                segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n                score = - (segment_length1 + segment_length2)\n            segment_scores.append((score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Simplified reinsertion with immediate duplicate check\n        new_pos = random.randint(0, n - len(best_segment))\n        temp_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Quick feasibility check\n        if len(np.unique(temp_solution)) == n:\n            new_solution = temp_solution\n        else:\n            # Fallback to single swap if reinsertion fails\n            i, j = random.sample(range(n), 2)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using fitness-based probability (prioritizing solutions with lower combined objective costs) and applies a hybrid local search combining node shift and segment rotation to generate a neighbor while ensuring feasibility. The fitness scores are computed as the inverse of the sum of objectives, and the selection is probabilistic. The local search randomly shifts a node to a new position and rotates a segment of the tour to explore the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores (inverse of objective values)\n    objectives = np.array([obj for _, obj in archive])\n    fitness_scores = 1 / (objectives[:, 0] + objectives[:, 1] + 1e-6)  # Small epsilon to avoid division by zero\n    selection_probs = fitness_scores / np.sum(fitness_scores)\n\n    # Select a solution with probability proportional to fitness\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: node shift and segment rotation\n    # Shift a random node to a new position\n    node_to_shift = np.random.randint(0, n)\n    new_position = np.random.randint(0, n)\n    while new_position == node_to_shift:\n        new_position = np.random.randint(0, n)\n\n    shifted_node = new_solution[node_to_shift]\n    new_solution = np.concatenate([\n        new_solution[:node_to_shift],\n        new_solution[node_to_shift+1:new_position+1],\n        [shifted_node],\n        new_solution[new_position+1:]\n    ])\n\n    # Rotate a random segment\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    rotation_amount = np.random.randint(1, b - a + 1)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords\n- **Adaptive local search**, **hybrid perturbation**, **cost-aware selection**, **feasibility preservation**, **exploration-exploitation balance**.\n\n### Advice\n- Combine **segment insertion** with **edge reversal** or **rotation** to diversify perturbations while preserving feasibility.\n- Use **weighted selection** based on Pareto dominance or crowding distance to prioritize promising solutions.\n- Introduce **conditional operators** (e.g., reverse segments only if they improve one objective) to avoid over-optimization.\n- Ensure **feasibility** by validating tours after perturbations (e.g., check for duplicates or missing nodes).\n\n### Avoid\n- Greedy, single-operator strategies (e.g., always using 2-opt or edge swaps).\n- Static perturbation sizes or probabilities (e.g., fixed segment lengths).\n- Ignoring objective trade-offs (e.g., always optimizing one objective at the expense of the other).\n\n### Explanation\nHybrid local search balances exploration (random segment operations) and exploitation (cost-aware edge prioritization). Adaptive selection and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while weighted selection focuses computational effort on high-potential regions. This approach generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 44,
        "algorithm": "The algorithm combines Pareto-based selection with adaptive segment reversal and conditional node insertion, prioritizing solutions with balanced objective improvements while dynamically adjusting segment sizes and validating tour feasibility. It selects promising solutions using crowding distance, applies segment reversal only if it improves both objectives, and conditionally inserts nodes only when beneficial, ensuring valid TSP tours throughout. The method balances exploration via probabilistic segment operations and exploitation through cost-aware node placement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based selection with crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    pareto_front = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]):\n                if objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]:\n                    dominated = True\n                    break\n        if not dominated:\n            pareto_front.append(i)\n\n    if not pareto_front:\n        pareto_front = list(range(len(archive)))\n\n    # Select based on crowding distance\n    if len(pareto_front) > 1:\n        crowding = np.zeros(len(pareto_front))\n        for m in range(2):\n            sorted_idx = np.argsort(objectives[pareto_front, m])\n            crowding[sorted_idx[0]] = crowding[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pareto_front)-1):\n                crowding[sorted_idx[i]] += (objectives[pareto_front[sorted_idx[i+1]], m] - objectives[pareto_front[sorted_idx[i-1]], m]) / (objectives[pareto_front[sorted_idx[-1]], m] - objectives[pareto_front[sorted_idx[0]], m] + 1e-6)\n\n        selected_idx = pareto_front[np.argmax(crowding)]\n    else:\n        selected_idx = pareto_front[0]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment reversal with quality check\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2.0))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Calculate original and reversed segment costs\n    original_cost = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(a, b+1)) + sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(a, b+1))\n    reversed_segment = np.flip(new_solution[a:b+1])\n    reversed_cost = sum(distance_matrix_1[reversed_segment[i]][reversed_segment[(i+1)%segment_size]] for i in range(segment_size)) + sum(distance_matrix_2[reversed_segment[i]][reversed_segment[(i+1)%segment_size]] for i in range(segment_size))\n\n    # Conditional reversal\n    if reversed_cost < original_cost:\n        new_solution[a:b+1] = reversed_segment\n\n    # Conditional node insertion\n    if n > 3:\n        # Select a node to potentially insert elsewhere\n        node_to_move = np.random.randint(0, n)\n        candidates = [i for i in range(n) if i not in {node_to_move, (node_to_move-1)%n, (node_to_move+1)%n}]\n\n        if candidates:\n            # Calculate insertion costs\n            insertion_costs = []\n            for pos in candidates:\n                # Cost of removing the node\n                remove_cost = distance_matrix_1[new_solution[pos]][new_solution[(pos+1)%n]] + distance_matrix_2[new_solution[pos]][new_solution[(pos+1)%n]]\n                # Cost of inserting the node at new position\n                insert_cost = distance_matrix_1[new_solution[node_to_move]][new_solution[pos]] + distance_matrix_1[new_solution[pos]][new_solution[(pos+1)%n]] + distance_matrix_2[new_solution[node_to_move]][new_solution[pos]] + distance_matrix_2[new_solution[pos]][new_solution[(pos+1)%n]]\n                insertion_costs.append(insert_cost - remove_cost)\n\n            best_pos = candidates[np.argmin(insertion_costs)]\n            if insertion_costs[np.argmin(insertion_costs)] < 0:  # Only insert if it improves\n                node_value = new_solution[node_to_move]\n                new_solution = np.concatenate([\n                    new_solution[:node_to_move],\n                    new_solution[node_to_move+1:best_pos+1],\n                    [node_value],\n                    new_solution[best_pos+1:]\n                ])\n\n    # Feasibility check\n    if len(np.unique(new_solution)) != n:\n        return base_solution  # Fallback to original if invalid\n\n    return new_solution\n\n",
        "score": [
            -0.511310502100538,
            8.27335774898529
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based selection with crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    pareto_front = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]):\n                if objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]:\n                    dominated = True\n                    break\n        if not dominated:\n            pareto_front.append(i)\n\n    if not pareto_front:\n        pareto_front = list(range(len(archive)))\n\n    # Select based on crowding distance\n    if len(pareto_front) > 1:\n        crowding = np.zeros(len(pareto_front))\n        for m in range(2):\n            sorted_idx = np.argsort(objectives[pareto_front, m])\n            crowding[sorted_idx[0]] = crowding[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pareto_front)-1):\n                crowding[sorted_idx[i]] += (objectives[pareto_front[sorted_idx[i+1]], m] - objectives[pareto_front[sorted_idx[i-1]], m]) / (objectives[pareto_front[sorted_idx[-1]], m] - objectives[pareto_front[sorted_idx[0]], m] + 1e-6)\n\n        selected_idx = pareto_front[np.argmax(crowding)]\n    else:\n        selected_idx = pareto_front[0]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment reversal with quality check\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2.0))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Calculate original and reversed segment costs\n    original_cost = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(a, b+1)) + sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(a, b+1))\n    reversed_segment = np.flip(new_solution[a:b+1])\n    reversed_cost = sum(distance_matrix_1[reversed_segment[i]][reversed_segment[(i+1)%segment_size]] for i in range(segment_size)) + sum(distance_matrix_2[reversed_segment[i]][reversed_segment[(i+1)%segment_size]] for i in range(segment_size))\n\n    # Conditional reversal\n    if reversed_cost < original_cost:\n        new_solution[a:b+1] = reversed_segment\n\n    # Conditional node insertion\n    if n > 3:\n        # Select a node to potentially insert elsewhere\n        node_to_move = np.random.randint(0, n)\n        candidates = [i for i in range(n) if i not in {node_to_move, (node_to_move-1)%n, (node_to_move+1)%n}]\n\n        if candidates:\n            # Calculate insertion costs\n            insertion_costs = []\n            for pos in candidates:\n                # Cost of removing the node\n                remove_cost = distance_matrix_1[new_solution[pos]][new_solution[(pos+1)%n]] + distance_matrix_2[new_solution[pos]][new_solution[(pos+1)%n]]\n                # Cost of inserting the node at new position\n                insert_cost = distance_matrix_1[new_solution[node_to_move]][new_solution[pos]] + distance_matrix_1[new_solution[pos]][new_solution[(pos+1)%n]] + distance_matrix_2[new_solution[node_to_move]][new_solution[pos]] + distance_matrix_2[new_solution[pos]][new_solution[(pos+1)%n]]\n                insertion_costs.append(insert_cost - remove_cost)\n\n            best_pos = candidates[np.argmin(insertion_costs)]\n            if insertion_costs[np.argmin(insertion_costs)] < 0:  # Only insert if it improves\n                node_value = new_solution[node_to_move]\n                new_solution = np.concatenate([\n                    new_solution[:node_to_move],\n                    new_solution[node_to_move+1:best_pos+1],\n                    [node_value],\n                    new_solution[best_pos+1:]\n                ])\n\n    # Feasibility check\n    if len(np.unique(new_solution)) != n:\n        return base_solution  # Fallback to original if invalid\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using fitness-based probability (prioritizing solutions with lower combined objective costs) and applies a hybrid local search combining node shift and segment rotation to generate a neighbor while ensuring feasibility. The fitness scores are computed as the inverse of the sum of objectives, and the selection is probabilistic. The local search randomly shifts a node to a new position and rotates a segment of the tour to explore the solution space.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores (inverse of objective values)\n    objectives = np.array([obj for _, obj in archive])\n    fitness_scores = 1 / (objectives[:, 0] + objectives[:, 1] + 1e-6)  # Small epsilon to avoid division by zero\n    selection_probs = fitness_scores / np.sum(fitness_scores)\n\n    # Select a solution with probability proportional to fitness\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: node shift and segment rotation\n    # Shift a random node to a new position\n    node_to_shift = np.random.randint(0, n)\n    new_position = np.random.randint(0, n)\n    while new_position == node_to_shift:\n        new_position = np.random.randint(0, n)\n\n    shifted_node = new_solution[node_to_shift]\n    new_solution = np.concatenate([\n        new_solution[:node_to_shift],\n        new_solution[node_to_shift+1:new_position+1],\n        [shifted_node],\n        new_solution[new_position+1:]\n    ])\n\n    # Rotate a random segment\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    rotation_amount = np.random.randint(1, b - a + 1)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 45,
        "algorithm": "The algorithm selects a solution from the archive based on a fitness score that balances both objectives, then applies a hybrid local search combining edge insertion and segment reversal to generate a neighbor solution while ensuring feasibility. The selection prioritizes solutions with lower combined objective values, and the local search randomly modifies the tour by inserting or reversing segments. The weights for balancing objectives are randomly chosen between 0.3 and 0.7, giving more emphasis to one objective at a time.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores (weighted sum of objectives)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.random.uniform(0.3, 0.7)  # Random weight for balancing objectives\n    fitness_scores = (weights * objectives[:, 0] + (1 - weights) * objectives[:, 1])\n    selection_probs = np.exp(-fitness_scores) / np.sum(np.exp(-fitness_scores))\n\n    # Select a solution with probability proportional to fitness\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: edge insertion and segment reversal\n    # Step 1: Edge insertion\n    i, j = np.random.choice(n, 2, replace=False)\n    if i > j:\n        i, j = j, i\n    if j - i > 1:\n        # Insert node at j-1 between i and j\n        node = new_solution[j]\n        new_solution = np.concatenate([\n            new_solution[:i+1],\n            [node],\n            new_solution[i+1:j],\n            new_solution[j+1:]\n        ])\n\n    # Step 2: Segment reversal\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    if b - a > 1:\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.7890622491294126,
            0.5127695798873901
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores (weighted sum of objectives)\n    objectives = np.array([obj for _, obj in archive])\n    weights = np.random.uniform(0.3, 0.7)  # Random weight for balancing objectives\n    fitness_scores = (weights * objectives[:, 0] + (1 - weights) * objectives[:, 1])\n    selection_probs = np.exp(-fitness_scores) / np.sum(np.exp(-fitness_scores))\n\n    # Select a solution with probability proportional to fitness\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: edge insertion and segment reversal\n    # Step 1: Edge insertion\n    i, j = np.random.choice(n, 2, replace=False)\n    if i > j:\n        i, j = j, i\n    if j - i > 1:\n        # Insert node at j-1 between i and j\n        node = new_solution[j]\n        new_solution = np.concatenate([\n            new_solution[:i+1],\n            [node],\n            new_solution[i+1:j],\n            new_solution[j+1:]\n        ])\n\n    # Step 2: Segment reversal\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    if b - a > 1:\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using fitness-based probability (prioritizing solutions with lower combined objective costs) and applies a hybrid local search combining node shift and segment rotation to generate a neighbor while ensuring feasibility. The fitness scores are computed as the inverse of the sum of objectives, and the selection is probabilistic. The local search randomly shifts a node to a new position and rotates a segment of the tour to explore the solution space.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores (inverse of objective values)\n    objectives = np.array([obj for _, obj in archive])\n    fitness_scores = 1 / (objectives[:, 0] + objectives[:, 1] + 1e-6)  # Small epsilon to avoid division by zero\n    selection_probs = fitness_scores / np.sum(fitness_scores)\n\n    # Select a solution with probability proportional to fitness\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: node shift and segment rotation\n    # Shift a random node to a new position\n    node_to_shift = np.random.randint(0, n)\n    new_position = np.random.randint(0, n)\n    while new_position == node_to_shift:\n        new_position = np.random.randint(0, n)\n\n    shifted_node = new_solution[node_to_shift]\n    new_solution = np.concatenate([\n        new_solution[:node_to_shift],\n        new_solution[node_to_shift+1:new_position+1],\n        [shifted_node],\n        new_solution[new_position+1:]\n    ])\n\n    # Rotate a random segment\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    rotation_amount = np.random.randint(1, b - a + 1)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 46,
        "algorithm": "The algorithm selects a promising solution from the archive with probability proportional to the inverse of its combined objective costs, then applies a hybrid local search combining segment reversal and inversion to generate a neighbor solution while ensuring feasibility. The fitness-based selection prioritizes lower-cost solutions, and the local search explores the solution space by randomly reversing and inverting segments of the tour.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores (inverse of objective values)\n    objectives = np.array([obj for _, obj in archive])\n    fitness_scores = 1 / (objectives[:, 0] + objectives[:, 1] + 1e-6)  # Small epsilon to avoid division by zero\n    selection_probs = fitness_scores / np.sum(fitness_scores)\n\n    # Select a solution with probability proportional to fitness\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: segment reversal and inversion\n    # Reverse a random segment\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Invert a random segment (swap nodes symmetrically)\n    c, d = sorted(np.random.choice(n, 2, replace=False))\n    segment = new_solution[c:d+1]\n    new_solution[c:d+1] = segment[::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.8476328768630838,
            0.501218318939209
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores (inverse of objective values)\n    objectives = np.array([obj for _, obj in archive])\n    fitness_scores = 1 / (objectives[:, 0] + objectives[:, 1] + 1e-6)  # Small epsilon to avoid division by zero\n    selection_probs = fitness_scores / np.sum(fitness_scores)\n\n    # Select a solution with probability proportional to fitness\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: segment reversal and inversion\n    # Reverse a random segment\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Invert a random segment (swap nodes symmetrically)\n    c, d = sorted(np.random.choice(n, 2, replace=False))\n    segment = new_solution[c:d+1]\n    new_solution[c:d+1] = segment[::-1]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using fitness-based probability (prioritizing solutions with lower combined objective costs) and applies a hybrid local search combining node shift and segment rotation to generate a neighbor while ensuring feasibility. The fitness scores are computed as the inverse of the sum of objectives, and the selection is probabilistic. The local search randomly shifts a node to a new position and rotates a segment of the tour to explore the solution space.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores (inverse of objective values)\n    objectives = np.array([obj for _, obj in archive])\n    fitness_scores = 1 / (objectives[:, 0] + objectives[:, 1] + 1e-6)  # Small epsilon to avoid division by zero\n    selection_probs = fitness_scores / np.sum(fitness_scores)\n\n    # Select a solution with probability proportional to fitness\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: node shift and segment rotation\n    # Shift a random node to a new position\n    node_to_shift = np.random.randint(0, n)\n    new_position = np.random.randint(0, n)\n    while new_position == node_to_shift:\n        new_position = np.random.randint(0, n)\n\n    shifted_node = new_solution[node_to_shift]\n    new_solution = np.concatenate([\n        new_solution[:node_to_shift],\n        new_solution[node_to_shift+1:new_position+1],\n        [shifted_node],\n        new_solution[new_position+1:]\n    ])\n\n    # Rotate a random segment\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    rotation_amount = np.random.randint(1, b - a + 1)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            ### Keywords\n- **Adaptive local search**, **hybrid perturbation**, **cost-aware selection**, **feasibility preservation**, **exploration-exploitation balance**.\n\n### Advice\n- Combine **segment insertion** with **edge reversal** or **rotation** to diversify perturbations while preserving feasibility.\n- Use **weighted selection** based on Pareto dominance or crowding distance to prioritize promising solutions.\n- Introduce **conditional operators** (e.g., reverse segments only if they improve one objective) to avoid over-optimization.\n- Ensure **feasibility** by validating tours after perturbations (e.g., check for duplicates or missing nodes).\n\n### Avoid\n- Greedy, single-operator strategies (e.g., always using 2-opt or edge swaps).\n- Static perturbation sizes or probabilities (e.g., fixed segment lengths).\n- Ignoring objective trade-offs (e.g., always optimizing one objective at the expense of the other).\n\n### Explanation\nHybrid local search balances exploration (random segment operations) and exploitation (cost-aware edge prioritization). Adaptive selection and conditional operators prevent premature convergence. Feasibility checks guarantee valid tours, while weighted selection focuses computational effort on high-potential regions. This approach generalizes better than dominated heuristics by avoiding rigid or overly greedy strategies.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 47,
        "algorithm": "The algorithm selects a promising solution from the archive using weighted probabilistic selection based on fitness scores and linear weights, then applies a hybrid local search with adaptive segment reversal, rotation, and edge insertion operations, ensuring feasibility and potentially improving at least one objective. Selection probabilities favor higher-indexed solutions with better fitness, while the local search dynamically chooses among operators with different probabilities and adaptive parameters.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores and selection weights\n    objectives = np.array([obj for _, obj in archive])\n    fitness_scores = 1 / (objectives[:, 0] + objectives[:, 1] + 1e-6)\n    weights = np.linspace(0.1, 1.0, len(archive))\n    selection_probs = fitness_scores * weights\n    selection_probs = selection_probs / np.sum(selection_probs)\n\n    # Select a solution with probability proportional to combined scores\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search with adaptive operators\n    operator = np.random.choice(['reverse', 'rotate', 'insert'], p=[0.4, 0.3, 0.3])\n\n    if operator == 'reverse':\n        # Segment reversal with conditional improvement check\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        segment = new_solution[a:b+1]\n        reversed_segment = segment[::-1]\n\n        # Check if reversal improves at least one objective\n        current_cost1 = sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n))\n        current_cost2 = sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n))\n\n        temp_solution = new_solution.copy()\n        temp_solution[a:b+1] = reversed_segment\n        new_cost1 = sum(distance_matrix_1[temp_solution[i-1], temp_solution[i]] for i in range(n))\n        new_cost2 = sum(distance_matrix_2[temp_solution[i-1], temp_solution[i]] for i in range(n))\n\n        if (new_cost1 < current_cost1) or (new_cost2 < current_cost2):\n            new_solution = temp_solution\n\n    elif operator == 'rotate':\n        # Segment rotation with adaptive rotation amount\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        segment_length = b - a + 1\n        rotation_amount = np.random.randint(1, min(segment_length, 5))  # Limit rotation amount\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    else:  # 'insert'\n        # Edge insertion with cost-aware selection\n        if n > 3:\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n            while c == d or (c == d - 1 and d == c + 1):\n                c, d = sorted(np.random.choice(n, 2, replace=False))\n\n            # Check if insertion improves at least one objective\n            current_cost1 = sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n))\n\n            temp_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n            new_cost1 = sum(distance_matrix_1[temp_solution[i-1], temp_solution[i]] for i in range(n))\n            new_cost2 = sum(distance_matrix_2[temp_solution[i-1], temp_solution[i]] for i in range(n))\n\n            if (new_cost1 < current_cost1) or (new_cost2 < current_cost2):\n                new_solution = temp_solution\n\n    # Ensure feasibility by checking for duplicates\n    if len(np.unique(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -0.8066191706634137,
            0.649675726890564
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate fitness scores and selection weights\n    objectives = np.array([obj for _, obj in archive])\n    fitness_scores = 1 / (objectives[:, 0] + objectives[:, 1] + 1e-6)\n    weights = np.linspace(0.1, 1.0, len(archive))\n    selection_probs = fitness_scores * weights\n    selection_probs = selection_probs / np.sum(selection_probs)\n\n    # Select a solution with probability proportional to combined scores\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search with adaptive operators\n    operator = np.random.choice(['reverse', 'rotate', 'insert'], p=[0.4, 0.3, 0.3])\n\n    if operator == 'reverse':\n        # Segment reversal with conditional improvement check\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        segment = new_solution[a:b+1]\n        reversed_segment = segment[::-1]\n\n        # Check if reversal improves at least one objective\n        current_cost1 = sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n))\n        current_cost2 = sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n))\n\n        temp_solution = new_solution.copy()\n        temp_solution[a:b+1] = reversed_segment\n        new_cost1 = sum(distance_matrix_1[temp_solution[i-1], temp_solution[i]] for i in range(n))\n        new_cost2 = sum(distance_matrix_2[temp_solution[i-1], temp_solution[i]] for i in range(n))\n\n        if (new_cost1 < current_cost1) or (new_cost2 < current_cost2):\n            new_solution = temp_solution\n\n    elif operator == 'rotate':\n        # Segment rotation with adaptive rotation amount\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        segment_length = b - a + 1\n        rotation_amount = np.random.randint(1, min(segment_length, 5))  # Limit rotation amount\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    else:  # 'insert'\n        # Edge insertion with cost-aware selection\n        if n > 3:\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n            while c == d or (c == d - 1 and d == c + 1):\n                c, d = sorted(np.random.choice(n, 2, replace=False))\n\n            # Check if insertion improves at least one objective\n            current_cost1 = sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n))\n\n            temp_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n            new_cost1 = sum(distance_matrix_1[temp_solution[i-1], temp_solution[i]] for i in range(n))\n            new_cost2 = sum(distance_matrix_2[temp_solution[i-1], temp_solution[i]] for i in range(n))\n\n            if (new_cost1 < current_cost1) or (new_cost2 < current_cost2):\n                new_solution = temp_solution\n\n    # Ensure feasibility by checking for duplicates\n    if len(np.unique(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a high-potential solution from the archive using Pareto-dominance tournament selection, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal, ensuring feasibility and balanced multi-objective optimization by prioritizing edge weights and improving at least one objective. It intelligently balances exploration and exploitation through probabilistic segment operations and cost-aware selection.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 48,
        "algorithm": "The algorithm selects a promising solution from the archive using a hybrid Pareto-dominance and cost-aware tournament selection, then applies a novel local search strategy combining adaptive segment rotation, cost-balanced edge insertion, and probabilistic segment reversal with objective improvement checks to generate high-quality neighbor solutions while maintaining feasibility. The selection prioritizes solutions on the Pareto front, while the local search balances improvements across both objectives by considering both costs and their relative differences.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid Pareto-dominance and cost-aware tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        # Select from pareto front with probability proportional to inverse sum of objectives\n        weights = [1/(archive[i][1][0] + archive[i][1][1] + 1e-6) for i in pareto_front]\n        weights = np.array(weights) / np.sum(weights)\n        selected_idx = np.random.choice(pareto_front, p=weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with cost-balancing\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Calculate segment cost in both objectives\n    segment_cost1 = sum(distance_matrix_1[new_solution[i]][new_solution[i+1]] for i in range(a, b))\n    segment_cost2 = sum(distance_matrix_2[new_solution[i]][new_solution[i+1]] for i in range(a, b))\n\n    # Determine rotation direction based on cost balance\n    if segment_cost1 > segment_cost2:\n        rotation = np.random.randint(1, segment_size)\n    else:\n        rotation = np.random.randint(1, segment_size) * -1\n\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-balanced edge insertion\n    if n > 3:\n        # Calculate edge weights based on both objectives\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            cost1 = distance_matrix_1[u][v]\n            cost2 = distance_matrix_2[u][v]\n            # Weighted combination of both objectives\n            weight = (cost1 + cost2) * (1 + abs(cost1 - cost2))\n            edge_weights.append(weight)\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            # Calculate insertion costs for both objectives\n            candidate_costs = []\n            for i in candidates:\n                u = new_solution[c]\n                v = new_solution[i]\n                w = new_solution[d]\n                cost1 = distance_matrix_1[u][v] + distance_matrix_1[v][w]\n                cost2 = distance_matrix_2[u][v] + distance_matrix_2[v][w]\n                # Balance between both objectives\n                candidate_costs.append((cost1 + cost2) * (1 + abs(cost1 - cost2)))\n\n            candidate_weights = np.array(candidate_costs) / np.sum(candidate_costs)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Probabilistic segment reversal with improvement checks\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        # Only reverse if it improves at least one objective\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "score": [
            -0.9171522634716247,
            0.3112887740135193
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid Pareto-dominance and cost-aware tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        # Select from pareto front with probability proportional to inverse sum of objectives\n        weights = [1/(archive[i][1][0] + archive[i][1][1] + 1e-6) for i in pareto_front]\n        weights = np.array(weights) / np.sum(weights)\n        selected_idx = np.random.choice(pareto_front, p=weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with cost-balancing\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Calculate segment cost in both objectives\n    segment_cost1 = sum(distance_matrix_1[new_solution[i]][new_solution[i+1]] for i in range(a, b))\n    segment_cost2 = sum(distance_matrix_2[new_solution[i]][new_solution[i+1]] for i in range(a, b))\n\n    # Determine rotation direction based on cost balance\n    if segment_cost1 > segment_cost2:\n        rotation = np.random.randint(1, segment_size)\n    else:\n        rotation = np.random.randint(1, segment_size) * -1\n\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-balanced edge insertion\n    if n > 3:\n        # Calculate edge weights based on both objectives\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            cost1 = distance_matrix_1[u][v]\n            cost2 = distance_matrix_2[u][v]\n            # Weighted combination of both objectives\n            weight = (cost1 + cost2) * (1 + abs(cost1 - cost2))\n            edge_weights.append(weight)\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            # Calculate insertion costs for both objectives\n            candidate_costs = []\n            for i in candidates:\n                u = new_solution[c]\n                v = new_solution[i]\n                w = new_solution[d]\n                cost1 = distance_matrix_1[u][v] + distance_matrix_1[v][w]\n                cost2 = distance_matrix_2[u][v] + distance_matrix_2[v][w]\n                # Balance between both objectives\n                candidate_costs.append((cost1 + cost2) * (1 + abs(cost1 - cost2)))\n\n            candidate_weights = np.array(candidate_costs) / np.sum(candidate_costs)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Probabilistic segment reversal with improvement checks\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        # Only reverse if it improves at least one objective\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The heuristic selects a promising solution from the archive (prioritizing non-dominated ones), then applies a hybrid local search combining segment reversal and dynamic reinsertion of high-scoring segments (based on normalized distance products), while conditionally reversing edges to improve at least one objective. It ensures feasibility by removing duplicates and falls back to random swaps if needed. The algorithm balances exploration (random segment selection) and exploitation (cost-aware edge prioritization) while maintaining valid TSP tours.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize non-dominated solutions\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + cost-aware edge prioritization\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            normalized_score = - (segment_length1 * segment_length2)  # Higher score for shorter segments in both objectives\n            segment_scores.append((normalized_score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Dynamic reinsertion with feasibility check\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Conditional edge reversal based on cost improvement\n    if n > 3:\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        old_length1 = distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]]\n        new_length1 = distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]]\n        old_length2 = distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]\n        new_length2 = distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]\n\n        if (new_length1 < old_length1 or new_length2 < old_length2):\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 49,
        "algorithm": "The algorithm selects a random solution from the archive and applies a segment reversal operator to edges with significant improvement potential in either objective space, prioritizing edges where the difference in distance is below a threshold (-0.1). If the reversal improves at least one objective, it is performed; otherwise, a random swap is used as a fallback to maintain feasibility. This approach balances exploration and exploitation by focusing on high-impact local changes while ensuring solution validity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Fast random selection\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Lightweight segment reversal targeting high-scoring edges\n    if n > 3:\n        # Precompute edge differences for all edges\n        edge_diff1 = distance_matrix_1[new_solution[:-1], new_solution[1:]] - distance_matrix_1[new_solution[:-1], new_solution[1:]]\n        edge_diff2 = distance_matrix_2[new_solution[:-1], new_solution[1:]] - distance_matrix_2[new_solution[:-1], new_solution[1:]]\n\n        # Find edges with significant improvement potential\n        candidate_edges = []\n        for i in range(n-1):\n            if edge_diff1[i] < -0.1 or edge_diff2[i] < -0.1:  # Threshold for potential improvement\n                candidate_edges.append(i)\n\n        if candidate_edges:\n            # Select a random candidate edge\n            a = random.choice(candidate_edges)\n            b = a + 1\n\n            # Reverse segment if it improves at least one objective\n            old_length1 = distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b-1], new_solution[b]]\n            new_length1 = distance_matrix_1[new_solution[a-1], new_solution[b-1]] + distance_matrix_1[new_solution[a], new_solution[b]]\n            old_length2 = distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b-1], new_solution[b]]\n            new_length2 = distance_matrix_2[new_solution[a-1], new_solution[b-1]] + distance_matrix_2[new_solution[a], new_solution[b]]\n\n            if (new_length1 < old_length1 or new_length2 < old_length2):\n                new_solution[a:b] = new_solution[a:b][::-1]\n\n    # Final lightweight check\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.7109661277602934,
            2.644393503665924
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Fast random selection\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Lightweight segment reversal targeting high-scoring edges\n    if n > 3:\n        # Precompute edge differences for all edges\n        edge_diff1 = distance_matrix_1[new_solution[:-1], new_solution[1:]] - distance_matrix_1[new_solution[:-1], new_solution[1:]]\n        edge_diff2 = distance_matrix_2[new_solution[:-1], new_solution[1:]] - distance_matrix_2[new_solution[:-1], new_solution[1:]]\n\n        # Find edges with significant improvement potential\n        candidate_edges = []\n        for i in range(n-1):\n            if edge_diff1[i] < -0.1 or edge_diff2[i] < -0.1:  # Threshold for potential improvement\n                candidate_edges.append(i)\n\n        if candidate_edges:\n            # Select a random candidate edge\n            a = random.choice(candidate_edges)\n            b = a + 1\n\n            # Reverse segment if it improves at least one objective\n            old_length1 = distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b-1], new_solution[b]]\n            new_length1 = distance_matrix_1[new_solution[a-1], new_solution[b-1]] + distance_matrix_1[new_solution[a], new_solution[b]]\n            old_length2 = distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b-1], new_solution[b]]\n            new_length2 = distance_matrix_2[new_solution[a-1], new_solution[b-1]] + distance_matrix_2[new_solution[a], new_solution[b]]\n\n            if (new_length1 < old_length1 or new_length2 < old_length2):\n                new_solution[a:b] = new_solution[a:b][::-1]\n\n    # Final lightweight check\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection of promising solutions using a combination of objective values and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Step 3: Hybrid local search combining segment reversal and adaptive edge insertion\n    # First perform segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Then perform adaptive edge insertion based on high combined distance\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on its distance\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_distances = [distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]] for i in candidates]\n                candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n                e = np.random.choice(candidates, p=candidate_weights)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 4: Additional local improvement with edge reversal\n    if n > 3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Reverse the segment between the two selected edges\n            if c1 < d1 and c2 > d2:  # Ensure proper segment selection\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive using weighted random selection (prioritizing lower-cost solutions) and applies a hybrid local search combining segment reversal, edge insertion, and conditional node swapping (only if beneficial for both objectives). It ensures feasibility by validating the solution and falling back to segment reversal if duplicates occur. The method balances exploration (via random operations) and exploitation (via cost-aware swaps) while maintaining valid TSP tours.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values\n    objectives = np.array([sum(obj) for _, obj in archive])\n    weights = 1 / (objectives + 1e-6)  # Inverse of combined cost\n    weights /= weights.sum()\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + edge insertion + node swapping\n    if n > 3:\n        # Segment reversal\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n        # Edge insertion\n        if n > 4:\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n            while c == d or (c == a and d == b):\n                c, d = sorted(np.random.choice(n, 2, replace=False))\n            new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n        # Node swapping (if beneficial)\n        if np.random.random() < 0.3:  # Lower probability to balance exploration\n            k, l = np.random.choice(n, 2, replace=False)\n            temp_solution = new_solution.copy()\n            temp_solution[k], temp_solution[l] = temp_solution[l], temp_solution[k]\n\n            # Calculate cost before and after swap\n            def calculate_cost(sol, dist_mat):\n                total = 0\n                for idx in range(len(sol)):\n                    total += dist_mat[sol[idx-1], sol[idx]]\n                return total\n\n            cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n            cost_after = calculate_cost(temp_solution, distance_matrix_1) + calculate_cost(temp_solution, distance_matrix_2)\n\n            if cost_after < cost_before:\n                new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if duplicates exist\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 50,
        "algorithm": "The algorithm combines Pareto dominance-based selection with a novel \"segment rotation and insertion\" operator, prioritizing non-dominated solutions or those with higher crowding distance in the archive. It then applies adaptive segment rotation (determined by combined edge distances in both objectives) and targeted edge insertion (only if it improves at least one objective), ensuring feasibility through validation and fallback to segment reversal. The approach balances exploration and exploitation by focusing on high-distance segments and edges while maintaining tour validity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto dominance-based selection\n    objectives = np.array([obj for _, obj in archive])\n    fronts = []\n    dominated_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and all(objectives[i] >= objectives[j]):\n                dominated_counts[i] += 1\n        if dominated_counts[i] == 0:\n            fronts.append(i)\n\n    if not fronts:\n        # Fallback to crowding distance if no non-dominated solutions\n        normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n        crowding_dist = np.sum(normalized_obj, axis=1)\n        weights = crowding_dist / np.sum(crowding_dist)\n        selected_idx = np.random.choice(len(archive), p=weights)\n    else:\n        # Select from non-dominated front\n        selected_idx = np.random.choice(fronts)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Segment rotation based on combined edge distance\n    segment_size = min(3, max(2, int(np.random.normal(loc=n/4, scale=n/8))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Calculate combined distance of the segment\n    segment_dist = 0\n    for i in range(a, b+1):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        segment_dist += distance_matrix_1[u][v] + distance_matrix_2[u][v]\n\n    # Rotate the segment if it has high combined distance\n    if segment_dist > np.mean([distance_matrix_1[u][v] + distance_matrix_2[u][v] for u, v in zip(new_solution[:-1], new_solution[1:])]):\n        rotation = np.random.randint(1, segment_size)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Targeted edge insertion\n    if n > 4:\n        # Find edges with high combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a node that can improve at least one objective\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                best_candidate = None\n                min_improvement = 0\n\n                for e in candidates:\n                    temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n                    def calculate_cost(sol, dist_mat):\n                        total = 0\n                        for idx in range(len(sol)):\n                            total += dist_mat[sol[idx-1], sol[idx]]\n                        return total\n\n                    cost1_before = calculate_cost(new_solution, distance_matrix_1)\n                    cost2_before = calculate_cost(new_solution, distance_matrix_2)\n                    cost1_after = calculate_cost(temp_solution, distance_matrix_1)\n                    cost2_after = calculate_cost(temp_solution, distance_matrix_2)\n\n                    if (cost1_after < cost1_before) or (cost2_after < cost2_before):\n                        improvement = (cost1_before - cost1_after) + (cost2_before - cost2_after)\n                        if improvement > min_improvement:\n                            min_improvement = improvement\n                            best_candidate = e\n\n                if best_candidate is not None:\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[best_candidate:best_candidate+1], new_solution[c+1:]])\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.823759743759606,
            5.466605961322784
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto dominance-based selection\n    objectives = np.array([obj for _, obj in archive])\n    fronts = []\n    dominated_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and all(objectives[i] >= objectives[j]):\n                dominated_counts[i] += 1\n        if dominated_counts[i] == 0:\n            fronts.append(i)\n\n    if not fronts:\n        # Fallback to crowding distance if no non-dominated solutions\n        normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n        crowding_dist = np.sum(normalized_obj, axis=1)\n        weights = crowding_dist / np.sum(crowding_dist)\n        selected_idx = np.random.choice(len(archive), p=weights)\n    else:\n        # Select from non-dominated front\n        selected_idx = np.random.choice(fronts)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Segment rotation based on combined edge distance\n    segment_size = min(3, max(2, int(np.random.normal(loc=n/4, scale=n/8))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Calculate combined distance of the segment\n    segment_dist = 0\n    for i in range(a, b+1):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        segment_dist += distance_matrix_1[u][v] + distance_matrix_2[u][v]\n\n    # Rotate the segment if it has high combined distance\n    if segment_dist > np.mean([distance_matrix_1[u][v] + distance_matrix_2[u][v] for u, v in zip(new_solution[:-1], new_solution[1:])]):\n        rotation = np.random.randint(1, segment_size)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Targeted edge insertion\n    if n > 4:\n        # Find edges with high combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a node that can improve at least one objective\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                best_candidate = None\n                min_improvement = 0\n\n                for e in candidates:\n                    temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n                    def calculate_cost(sol, dist_mat):\n                        total = 0\n                        for idx in range(len(sol)):\n                            total += dist_mat[sol[idx-1], sol[idx]]\n                        return total\n\n                    cost1_before = calculate_cost(new_solution, distance_matrix_1)\n                    cost2_before = calculate_cost(new_solution, distance_matrix_2)\n                    cost1_after = calculate_cost(temp_solution, distance_matrix_1)\n                    cost2_after = calculate_cost(temp_solution, distance_matrix_2)\n\n                    if (cost1_after < cost1_before) or (cost2_after < cost2_before):\n                        improvement = (cost1_before - cost1_after) + (cost2_before - cost2_after)\n                        if improvement > min_improvement:\n                            min_improvement = improvement\n                            best_candidate = e\n\n                if best_candidate is not None:\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[best_candidate:best_candidate+1], new_solution[c+1:]])\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive using weighted random selection (prioritizing lower-cost solutions) and applies a hybrid local search combining segment reversal, edge insertion, and conditional node swapping (only if beneficial for both objectives). It ensures feasibility by validating the solution and falling back to segment reversal if duplicates occur. The method balances exploration (via random operations) and exploitation (via cost-aware swaps) while maintaining valid TSP tours.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values\n    objectives = np.array([sum(obj) for _, obj in archive])\n    weights = 1 / (objectives + 1e-6)  # Inverse of combined cost\n    weights /= weights.sum()\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + edge insertion + node swapping\n    if n > 3:\n        # Segment reversal\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n        # Edge insertion\n        if n > 4:\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n            while c == d or (c == a and d == b):\n                c, d = sorted(np.random.choice(n, 2, replace=False))\n            new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n        # Node swapping (if beneficial)\n        if np.random.random() < 0.3:  # Lower probability to balance exploration\n            k, l = np.random.choice(n, 2, replace=False)\n            temp_solution = new_solution.copy()\n            temp_solution[k], temp_solution[l] = temp_solution[l], temp_solution[k]\n\n            # Calculate cost before and after swap\n            def calculate_cost(sol, dist_mat):\n                total = 0\n                for idx in range(len(sol)):\n                    total += dist_mat[sol[idx-1], sol[idx]]\n                return total\n\n            cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n            cost_after = calculate_cost(temp_solution, distance_matrix_1) + calculate_cost(temp_solution, distance_matrix_2)\n\n            if cost_after < cost_before:\n                new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if duplicates exist\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 51,
        "algorithm": "The algorithm selects solutions from the archive using a non-linear objective-based selection that prioritizes lower combined costs while maintaining diversity, then applies a hybrid local search combining segment reversal, edge insertion, and objective-aware node swapping, with a fallback to modified 2-opt to ensure feasibility. It evaluates neighbor solutions based on cost improvements in both objectives and accepts changes only if they show significant or simultaneous improvements in both. The selection process weights solutions with better combined objectives more heavily, while the local search operators focus on exploring different tour structures while maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Non-linear objective-based selection (prioritize solutions with lower combined cost but also diversity)\n    objectives = np.array([(obj[0] + obj[1]) * (1 + 0.1 * min(obj[0], obj[1]) / max(obj[0], obj[1])) for _, obj in archive])\n    weights = 1 / (objectives + 1e-6)\n    weights /= weights.sum()\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + edge insertion + objective-aware node swapping\n    if n > 3:\n        # Segment reversal\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n        # Edge insertion\n        if n > 4:\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n            while c == d or (c == a and d == b):\n                c, d = sorted(np.random.choice(n, 2, replace=False))\n            new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n        # Objective-aware node swapping\n        k, l = np.random.choice(n, 2, replace=False)\n        temp_solution = new_solution.copy()\n        temp_solution[k], temp_solution[l] = temp_solution[l], temp_solution[k]\n\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        cost1_before = calculate_cost(new_solution, distance_matrix_1)\n        cost2_before = calculate_cost(new_solution, distance_matrix_2)\n        cost1_after = calculate_cost(temp_solution, distance_matrix_1)\n        cost2_after = calculate_cost(temp_solution, distance_matrix_2)\n\n        # Improved acceptance criterion: both costs must improve or at least one improves significantly\n        if (cost1_after < cost1_before and cost2_after < cost2_before) or \\\n           (cost1_after < 0.9 * cost1_before and cost2_after < cost2_before) or \\\n           (cost1_after < cost1_before and cost2_after < 0.9 * cost2_before):\n            new_solution = temp_solution\n\n    # Ensure feasibility with modified 2-opt fallback\n    if len(np.unique(new_solution)) != n:\n        # Find two non-adjacent edges to swap\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        while abs(i - j) == 1:\n            i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.809522278184696,
            0.5804353356361389
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Non-linear objective-based selection (prioritize solutions with lower combined cost but also diversity)\n    objectives = np.array([(obj[0] + obj[1]) * (1 + 0.1 * min(obj[0], obj[1]) / max(obj[0], obj[1])) for _, obj in archive])\n    weights = 1 / (objectives + 1e-6)\n    weights /= weights.sum()\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + edge insertion + objective-aware node swapping\n    if n > 3:\n        # Segment reversal\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n        # Edge insertion\n        if n > 4:\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n            while c == d or (c == a and d == b):\n                c, d = sorted(np.random.choice(n, 2, replace=False))\n            new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n        # Objective-aware node swapping\n        k, l = np.random.choice(n, 2, replace=False)\n        temp_solution = new_solution.copy()\n        temp_solution[k], temp_solution[l] = temp_solution[l], temp_solution[k]\n\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        cost1_before = calculate_cost(new_solution, distance_matrix_1)\n        cost2_before = calculate_cost(new_solution, distance_matrix_2)\n        cost1_after = calculate_cost(temp_solution, distance_matrix_1)\n        cost2_after = calculate_cost(temp_solution, distance_matrix_2)\n\n        # Improved acceptance criterion: both costs must improve or at least one improves significantly\n        if (cost1_after < cost1_before and cost2_after < cost2_before) or \\\n           (cost1_after < 0.9 * cost1_before and cost2_after < cost2_before) or \\\n           (cost1_after < cost1_before and cost2_after < 0.9 * cost2_before):\n            new_solution = temp_solution\n\n    # Ensure feasibility with modified 2-opt fallback\n    if len(np.unique(new_solution)) != n:\n        # Find two non-adjacent edges to swap\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        while abs(i - j) == 1:\n            i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a solution from the archive using weighted random selection (prioritizing lower-cost solutions) and applies a hybrid local search combining segment reversal, edge insertion, and conditional node swapping (only if beneficial for both objectives). It ensures feasibility by validating the solution and falling back to segment reversal if duplicates occur. The method balances exploration (via random operations) and exploitation (via cost-aware swaps) while maintaining valid TSP tours.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values\n    objectives = np.array([sum(obj) for _, obj in archive])\n    weights = 1 / (objectives + 1e-6)  # Inverse of combined cost\n    weights /= weights.sum()\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + edge insertion + node swapping\n    if n > 3:\n        # Segment reversal\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n        # Edge insertion\n        if n > 4:\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n            while c == d or (c == a and d == b):\n                c, d = sorted(np.random.choice(n, 2, replace=False))\n            new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n        # Node swapping (if beneficial)\n        if np.random.random() < 0.3:  # Lower probability to balance exploration\n            k, l = np.random.choice(n, 2, replace=False)\n            temp_solution = new_solution.copy()\n            temp_solution[k], temp_solution[l] = temp_solution[l], temp_solution[k]\n\n            # Calculate cost before and after swap\n            def calculate_cost(sol, dist_mat):\n                total = 0\n                for idx in range(len(sol)):\n                    total += dist_mat[sol[idx-1], sol[idx]]\n                return total\n\n            cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n            cost_after = calculate_cost(temp_solution, distance_matrix_1) + calculate_cost(temp_solution, distance_matrix_2)\n\n            if cost_after < cost_before:\n                new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if duplicates exist\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 52,
        "algorithm": "The algorithm selects promising solutions from an archive using Pareto dominance and crowding distance, then applies a hybrid local search combining segment reversal, node insertion, and an objective-aware 2-opt that considers both objectives simultaneously to generate improved neighbor solutions while ensuring feasibility. The selection prioritizes solutions on the Pareto front with high crowding distance, while the local search probabilistically applies different operators to explore the solution space, with the 2-opt variant explicitly balancing both objectives during edge reversal. The algorithm maintains feasibility through validation and fallback mechanisms.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using Pareto dominance and crowding distance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Identify Pareto front solutions\n    pareto_indices = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_indices.append(i)\n\n    if pareto_indices:\n        # Select from Pareto front using crowding distance\n        pareto_objectives = objectives[pareto_indices]\n        crowding_distances = np.zeros(len(pareto_indices))\n\n        for m in range(2):  # For each objective\n            sorted_indices = np.argsort(pareto_objectives[:, m])\n            crowding_distances[sorted_indices[0]] = np.inf\n            crowding_distances[sorted_indices[-1]] = np.inf\n            for i in range(1, len(pareto_indices)-1):\n                crowding_distances[sorted_indices[i]] += (pareto_objectives[sorted_indices[i+1], m] - pareto_objectives[sorted_indices[i-1], m]) / (pareto_objectives[sorted_indices[-1], m] - pareto_objectives[sorted_indices[0], m] + 1e-6)\n\n        selected_idx = pareto_indices[np.argmax(crowding_distances)]\n    else:\n        # Fallback to weighted selection if no Pareto front exists\n        weights = np.exp(-np.sum(objectives, axis=1))\n        weights /= weights.sum()\n        selected_idx = np.random.choice(len(archive), p=weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + node insertion + objective-aware 2-opt\n    if n > 3:\n        # Segment reversal with probability 0.5\n        if np.random.random() < 0.5:\n            a, b = sorted(np.random.choice(n, 2, replace=False))\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n        # Node insertion with probability 0.4\n        if n > 4 and np.random.random() < 0.4:\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n            while c == d:\n                c, d = sorted(np.random.choice(n, 2, replace=False))\n            new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n        # Objective-aware 2-opt\n        if n > 4:\n            i, j = sorted(np.random.choice(n, 2, replace=False))\n            while j - i < 2:\n                i, j = sorted(np.random.choice(n, 2, replace=False))\n\n            # Create two possible new tours\n            option1 = np.concatenate([new_solution[:i], new_solution[i:j][::-1], new_solution[j:]])\n            option2 = np.concatenate([new_solution[:i], new_solution[j-1:i-1:-1], new_solution[j:]])\n\n            # Calculate costs for both options\n            def calculate_cost(sol):\n                cost1 = sum(distance_matrix_1[sol[k-1], sol[k]] for k in range(len(sol)))\n                cost2 = sum(distance_matrix_2[sol[k-1], sol[k]] for k in range(len(sol)))\n                return cost1 + cost2\n\n            current_cost = calculate_cost(new_solution)\n            cost1 = calculate_cost(option1)\n            cost2 = calculate_cost(option2)\n\n            # Select the best option if it improves both objectives\n            if cost1 < current_cost and cost2 < current_cost:\n                if cost1 < cost2:\n                    new_solution = option1\n                else:\n                    new_solution = option2\n            elif cost1 < current_cost:\n                new_solution = option1\n            elif cost2 < current_cost:\n                new_solution = option2\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if duplicates exist\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.5934610947093228,
            2.470510482788086
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution using Pareto dominance and crowding distance\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Identify Pareto front solutions\n    pareto_indices = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_indices.append(i)\n\n    if pareto_indices:\n        # Select from Pareto front using crowding distance\n        pareto_objectives = objectives[pareto_indices]\n        crowding_distances = np.zeros(len(pareto_indices))\n\n        for m in range(2):  # For each objective\n            sorted_indices = np.argsort(pareto_objectives[:, m])\n            crowding_distances[sorted_indices[0]] = np.inf\n            crowding_distances[sorted_indices[-1]] = np.inf\n            for i in range(1, len(pareto_indices)-1):\n                crowding_distances[sorted_indices[i]] += (pareto_objectives[sorted_indices[i+1], m] - pareto_objectives[sorted_indices[i-1], m]) / (pareto_objectives[sorted_indices[-1], m] - pareto_objectives[sorted_indices[0], m] + 1e-6)\n\n        selected_idx = pareto_indices[np.argmax(crowding_distances)]\n    else:\n        # Fallback to weighted selection if no Pareto front exists\n        weights = np.exp(-np.sum(objectives, axis=1))\n        weights /= weights.sum()\n        selected_idx = np.random.choice(len(archive), p=weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + node insertion + objective-aware 2-opt\n    if n > 3:\n        # Segment reversal with probability 0.5\n        if np.random.random() < 0.5:\n            a, b = sorted(np.random.choice(n, 2, replace=False))\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n        # Node insertion with probability 0.4\n        if n > 4 and np.random.random() < 0.4:\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n            while c == d:\n                c, d = sorted(np.random.choice(n, 2, replace=False))\n            new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n        # Objective-aware 2-opt\n        if n > 4:\n            i, j = sorted(np.random.choice(n, 2, replace=False))\n            while j - i < 2:\n                i, j = sorted(np.random.choice(n, 2, replace=False))\n\n            # Create two possible new tours\n            option1 = np.concatenate([new_solution[:i], new_solution[i:j][::-1], new_solution[j:]])\n            option2 = np.concatenate([new_solution[:i], new_solution[j-1:i-1:-1], new_solution[j:]])\n\n            # Calculate costs for both options\n            def calculate_cost(sol):\n                cost1 = sum(distance_matrix_1[sol[k-1], sol[k]] for k in range(len(sol)))\n                cost2 = sum(distance_matrix_2[sol[k-1], sol[k]] for k in range(len(sol)))\n                return cost1 + cost2\n\n            current_cost = calculate_cost(new_solution)\n            cost1 = calculate_cost(option1)\n            cost2 = calculate_cost(option2)\n\n            # Select the best option if it improves both objectives\n            if cost1 < current_cost and cost2 < current_cost:\n                if cost1 < cost2:\n                    new_solution = option1\n                else:\n                    new_solution = option2\n            elif cost1 < current_cost:\n                new_solution = option1\n            elif cost2 < current_cost:\n                new_solution = option2\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if duplicates exist\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using weighted random selection (prioritizing lower-cost solutions) and applies a hybrid local search combining segment reversal, edge insertion, and conditional node swapping (only if beneficial for both objectives). It ensures feasibility by validating the solution and falling back to segment reversal if duplicates occur. The method balances exploration (via random operations) and exploitation (via cost-aware swaps) while maintaining valid TSP tours.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values\n    objectives = np.array([sum(obj) for _, obj in archive])\n    weights = 1 / (objectives + 1e-6)  # Inverse of combined cost\n    weights /= weights.sum()\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + edge insertion + node swapping\n    if n > 3:\n        # Segment reversal\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n        # Edge insertion\n        if n > 4:\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n            while c == d or (c == a and d == b):\n                c, d = sorted(np.random.choice(n, 2, replace=False))\n            new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n        # Node swapping (if beneficial)\n        if np.random.random() < 0.3:  # Lower probability to balance exploration\n            k, l = np.random.choice(n, 2, replace=False)\n            temp_solution = new_solution.copy()\n            temp_solution[k], temp_solution[l] = temp_solution[l], temp_solution[k]\n\n            # Calculate cost before and after swap\n            def calculate_cost(sol, dist_mat):\n                total = 0\n                for idx in range(len(sol)):\n                    total += dist_mat[sol[idx-1], sol[idx]]\n                return total\n\n            cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n            cost_after = calculate_cost(temp_solution, distance_matrix_1) + calculate_cost(temp_solution, distance_matrix_2)\n\n            if cost_after < cost_before:\n                new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment reversal if duplicates exist\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 53,
        "algorithm": "The algorithm selects a promising solution from the archive using weighted random selection based on the product of inverse objectives, then applies a hybrid local search combining segment rotation, conditional edge reversal, and segment-based mutation to generate a neighbor solution while ensuring feasibility through validation and random restarts. It prioritizes solutions with lower combined costs and balances exploration with exploitation through randomness in segment/edge choices and cost-aware conditions.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on product of inverse objectives\n    objectives = np.array([obj[0] * obj[1] for _, obj in archive])\n    weights = 1 / (objectives + 1e-6)\n    weights /= weights.sum()\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Calculate current cost\n    def calculate_cost(sol, dist_mat):\n        total = 0\n        for idx in range(len(sol)):\n            total += dist_mat[sol[idx-1], sol[idx]]\n        return total\n\n    current_cost1 = calculate_cost(new_solution, distance_matrix_1)\n    current_cost2 = calculate_cost(new_solution, distance_matrix_2)\n\n    if n > 3:\n        # Segment rotation\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n        # Conditional edge reversal\n        if n > 4:\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n            temp_solution = new_solution.copy()\n            temp_solution[c:d+1] = temp_solution[c:d+1][::-1]\n\n            temp_cost1 = calculate_cost(temp_solution, distance_matrix_1)\n            temp_cost2 = calculate_cost(temp_solution, distance_matrix_2)\n\n            if temp_cost1 < current_cost1 or temp_cost2 < current_cost2:\n                new_solution = temp_solution\n                current_cost1 = temp_cost1\n                current_cost2 = temp_cost2\n\n        # Segment-based mutation\n        if n > 5 and np.random.random() < 0.4:\n            x, y = sorted(np.random.choice(n, 2, replace=False))\n            while abs(y - x) < 2:\n                x, y = sorted(np.random.choice(n, 2, replace=False))\n\n            temp_solution = new_solution.copy()\n            segment = temp_solution[x:y]\n            temp_solution = np.concatenate([temp_solution[:x], temp_solution[y:], segment])\n\n            temp_cost1 = calculate_cost(temp_solution, distance_matrix_1)\n            temp_cost2 = calculate_cost(temp_solution, distance_matrix_2)\n\n            if temp_cost1 < current_cost1 or temp_cost2 < current_cost2:\n                new_solution = temp_solution\n                current_cost1 = temp_cost1\n                current_cost2 = temp_cost2\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment rotation\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Random restart with low probability\n    if np.random.random() < 0.05:\n        np.random.shuffle(new_solution)\n\n    return new_solution\n\n",
        "score": [
            -0.8206382268807482,
            0.6468149423599243
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on product of inverse objectives\n    objectives = np.array([obj[0] * obj[1] for _, obj in archive])\n    weights = 1 / (objectives + 1e-6)\n    weights /= weights.sum()\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Calculate current cost\n    def calculate_cost(sol, dist_mat):\n        total = 0\n        for idx in range(len(sol)):\n            total += dist_mat[sol[idx-1], sol[idx]]\n        return total\n\n    current_cost1 = calculate_cost(new_solution, distance_matrix_1)\n    current_cost2 = calculate_cost(new_solution, distance_matrix_2)\n\n    if n > 3:\n        # Segment rotation\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n        # Conditional edge reversal\n        if n > 4:\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n            temp_solution = new_solution.copy()\n            temp_solution[c:d+1] = temp_solution[c:d+1][::-1]\n\n            temp_cost1 = calculate_cost(temp_solution, distance_matrix_1)\n            temp_cost2 = calculate_cost(temp_solution, distance_matrix_2)\n\n            if temp_cost1 < current_cost1 or temp_cost2 < current_cost2:\n                new_solution = temp_solution\n                current_cost1 = temp_cost1\n                current_cost2 = temp_cost2\n\n        # Segment-based mutation\n        if n > 5 and np.random.random() < 0.4:\n            x, y = sorted(np.random.choice(n, 2, replace=False))\n            while abs(y - x) < 2:\n                x, y = sorted(np.random.choice(n, 2, replace=False))\n\n            temp_solution = new_solution.copy()\n            segment = temp_solution[x:y]\n            temp_solution = np.concatenate([temp_solution[:x], temp_solution[y:], segment])\n\n            temp_cost1 = calculate_cost(temp_solution, distance_matrix_1)\n            temp_cost2 = calculate_cost(temp_solution, distance_matrix_2)\n\n            if temp_cost1 < current_cost1 or temp_cost2 < current_cost2:\n                new_solution = temp_solution\n                current_cost1 = temp_cost1\n                current_cost2 = temp_cost2\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to segment rotation\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Random restart with low probability\n    if np.random.random() < 0.05:\n        np.random.shuffle(new_solution)\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a high-potential solution from the archive using Pareto-dominance tournament selection, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal, ensuring feasibility and balanced multi-objective optimization by prioritizing edge weights and improving at least one objective. It intelligently balances exploration and exploitation through probabilistic segment operations and cost-aware selection.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 54,
        "algorithm": "The algorithm combines adaptive Pareto selection with a hybrid local search that prioritizes segment rotation, cost-aware edge insertion, and conditional segment reversal, while ensuring feasibility through probabilistic segment operations and edge weighting. It balances exploration and exploitation by dynamically adjusting segment sizes and using combined distance metrics to guide multi-objective improvements. The method intelligently selects edges and segments based on their potential for reducing tour lengths in both objective spaces, with segment reversal only applied when it improves at least one objective.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "score": [
            -0.8547295562960665,
            0.20903760194778442
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a high-potential solution from the archive using Pareto-dominance tournament selection, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal, ensuring feasibility and balanced multi-objective optimization by prioritizing edge weights and improving at least one objective. It intelligently balances exploration and exploitation through probabilistic segment operations and cost-aware selection.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 54,
        "algorithm": "The algorithm combines adaptive Pareto selection with a hybrid local search that prioritizes segment rotation, cost-aware edge insertion, and conditional segment reversal, while ensuring feasibility through probabilistic segment operations and edge weighting. It balances exploration and exploitation by dynamically adjusting segment sizes and using combined distance metrics to guide multi-objective improvements. The method intelligently selects edges and segments based on their potential for reducing tour lengths in both objective spaces, with segment reversal only applied when it improves at least one objective.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "score": [
            -0.8547295562960665,
            0.20903760194778442
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The heuristic selects a promising solution from the archive (prioritizing non-dominated ones), then applies a hybrid local search combining segment reversal and dynamic reinsertion of high-scoring segments (based on normalized distance products), while conditionally reversing edges to improve at least one objective. It ensures feasibility by removing duplicates and falls back to random swaps if needed. The algorithm balances exploration (random segment selection) and exploitation (cost-aware edge prioritization) while maintaining valid TSP tours.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize non-dominated solutions\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + cost-aware edge prioritization\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            normalized_score = - (segment_length1 * segment_length2)  # Higher score for shorter segments in both objectives\n            segment_scores.append((normalized_score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Dynamic reinsertion with feasibility check\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Conditional edge reversal based on cost improvement\n    if n > 3:\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        old_length1 = distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]]\n        new_length1 = distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]]\n        old_length2 = distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]\n        new_length2 = distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]\n\n        if (new_length1 < old_length1 or new_length2 < old_length2):\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 55,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Fast selection: prioritize non-dominated solutions\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    selected_idx = random.choice(non_dominated) if non_dominated else random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Optimized local search: limited segment reversal\n    if n > 3:\n        i, j = sorted(random.sample(range(n), 2))\n        if j - i > 1:  # Only consider segments of length > 1\n            segment = new_solution[i:j+1]\n            new_pos = random.randint(0, n - len(segment))\n            new_solution = np.concatenate([\n                new_solution[:new_pos],\n                segment,\n                new_solution[new_pos:new_pos + len(segment)],\n                new_solution[new_pos + len(segment):]\n            ])\n\n    # Fast edge reversal\n    if n > 3:\n        a, b = sorted(random.sample(range(n), 2))\n        if (distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] <\n            distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]]) or \\\n           (distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]] <\n            distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]):\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Final check\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.5161068297150934,
            0.23146343231201172
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Fast selection: prioritize non-dominated solutions\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    selected_idx = random.choice(non_dominated) if non_dominated else random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Optimized local search: limited segment reversal\n    if n > 3:\n        i, j = sorted(random.sample(range(n), 2))\n        if j - i > 1:  # Only consider segments of length > 1\n            segment = new_solution[i:j+1]\n            new_pos = random.randint(0, n - len(segment))\n            new_solution = np.concatenate([\n                new_solution[:new_pos],\n                segment,\n                new_solution[new_pos:new_pos + len(segment)],\n                new_solution[new_pos + len(segment):]\n            ])\n\n    # Fast edge reversal\n    if n > 3:\n        a, b = sorted(random.sample(range(n), 2))\n        if (distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]] <\n            distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]]) or \\\n           (distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]] <\n            distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]):\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Final check\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 56,
        "algorithm": "The algorithm combines Pareto-dominance selection with a hybrid local search that adaptively applies segment-based mutations (rotation or reversal) while ensuring feasibility through probabilistic edge relocations prioritizing high-distance edges across both objectives. It balances exploration through randomness and exploitation through conditional improvement checks, using variable-length segments and combined distance metrics to guide perturbations. The selection process dynamically identifies non-dominated solutions, and the perturbation phase employs weighted probabilities to relocate edges, ensuring valid TSP tours while favoring improvements in the combined objective space.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance based selection\n    non_dominated = []\n    for i, (sol, obj) in enumerate(archive):\n        dominated = False\n        for j, (_, other_obj) in enumerate(archive):\n            if i != j and (other_obj[0] <= obj[0] and other_obj[1] <= obj[1] and (other_obj[0] < obj[0] or other_obj[1] < obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if not non_dominated:\n        non_dominated = list(range(len(archive)))\n\n    selected_idx = np.random.choice(non_dominated)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment operation (rotation or reversal)\n    segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    if np.random.random() < 0.5:\n        # Rotation\n        rotation = np.random.randint(1, segment_size)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n    else:\n        # Reversal\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Conditional improvement check\n    old_cost1 = sum(distance_matrix_1[base_solution[i]][base_solution[(i+1)%n]] for i in range(n))\n    old_cost2 = sum(distance_matrix_2[base_solution[i]][base_solution[(i+1)%n]] for i in range(n))\n    new_cost1 = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n    new_cost2 = sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n\n    if (new_cost1 > old_cost1 and new_cost2 > old_cost2):\n        new_solution = base_solution.copy()\n\n    # Probabilistic edge relocation\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            probs = np.array([combined_distances[new_solution[c]][new_solution[i]] *\n                            combined_distances[new_solution[i]][new_solution[d]]\n                            for i in candidates])\n            probs = probs / np.sum(probs)\n            e = np.random.choice(candidates, p=probs)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "score": [
            -0.8298033909321214,
            0.48912107944488525
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance based selection\n    non_dominated = []\n    for i, (sol, obj) in enumerate(archive):\n        dominated = False\n        for j, (_, other_obj) in enumerate(archive):\n            if i != j and (other_obj[0] <= obj[0] and other_obj[1] <= obj[1] and (other_obj[0] < obj[0] or other_obj[1] < obj[1])):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if not non_dominated:\n        non_dominated = list(range(len(archive)))\n\n    selected_idx = np.random.choice(non_dominated)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment operation (rotation or reversal)\n    segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    if np.random.random() < 0.5:\n        # Rotation\n        rotation = np.random.randint(1, segment_size)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n    else:\n        # Reversal\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Conditional improvement check\n    old_cost1 = sum(distance_matrix_1[base_solution[i]][base_solution[(i+1)%n]] for i in range(n))\n    old_cost2 = sum(distance_matrix_2[base_solution[i]][base_solution[(i+1)%n]] for i in range(n))\n    new_cost1 = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n    new_cost2 = sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n\n    if (new_cost1 > old_cost1 and new_cost2 > old_cost2):\n        new_solution = base_solution.copy()\n\n    # Probabilistic edge relocation\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            probs = np.array([combined_distances[new_solution[c]][new_solution[i]] *\n                            combined_distances[new_solution[i]][new_solution[d]]\n                            for i in candidates])\n            probs = probs / np.sum(probs)\n            e = np.random.choice(candidates, p=probs)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        This heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 57,
        "algorithm": "The algorithm selects a solution from the archive using quality-weighted random selection (prioritizing solutions with lower total costs) and then applies a hybrid local search: adaptive segment inversion (randomly flipping or rolling segments of the tour) and probabilistic node reinsertion (removing and reinserting nodes based on their contribution to both objectives). It ensures feasibility by carefully preserving the tour structure while allowing controlled modifications.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Quality-weighted random selection\n    weights = np.array([1.0 / (1.0 + sum(obj)) for _, obj in archive])\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment inversion\n    segment_size = max(2, min(n // 4, int(np.random.exponential(scale=2.0))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    direction = np.random.choice([-1, 1])\n    new_solution[a:b+1] = np.flip(new_solution[a:b+1]) if direction == -1 else np.roll(new_solution[a:b+1], 1)\n\n    # Probabilistic node reinsertion\n    if n > 3:\n        node_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            w = new_solution[(i-1)%n]\n            node_weights.append((distance_matrix_1[u][v] + distance_matrix_2[u][v]) *\n                              (distance_matrix_1[w][u] + distance_matrix_2[w][u]))\n\n        node_weights = np.array(node_weights)\n        node_weights = node_weights / np.sum(node_weights)\n\n        selected_node = np.random.choice(n, p=node_weights)\n        if selected_node != 0 and selected_node != n-1:\n            removed_node = new_solution[selected_node]\n            new_solution = np.concatenate([new_solution[:selected_node], new_solution[selected_node+1:]])\n            insert_pos = np.random.randint(1, n-1)\n            new_solution = np.concatenate([new_solution[:insert_pos], [removed_node], new_solution[insert_pos:]])\n\n    return new_solution\n\n",
        "score": [
            -0.8251626989534038,
            0.5704270005226135
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Quality-weighted random selection\n    weights = np.array([1.0 / (1.0 + sum(obj)) for _, obj in archive])\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment inversion\n    segment_size = max(2, min(n // 4, int(np.random.exponential(scale=2.0))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    direction = np.random.choice([-1, 1])\n    new_solution[a:b+1] = np.flip(new_solution[a:b+1]) if direction == -1 else np.roll(new_solution[a:b+1], 1)\n\n    # Probabilistic node reinsertion\n    if n > 3:\n        node_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            w = new_solution[(i-1)%n]\n            node_weights.append((distance_matrix_1[u][v] + distance_matrix_2[u][v]) *\n                              (distance_matrix_1[w][u] + distance_matrix_2[w][u]))\n\n        node_weights = np.array(node_weights)\n        node_weights = node_weights / np.sum(node_weights)\n\n        selected_node = np.random.choice(n, p=node_weights)\n        if selected_node != 0 and selected_node != n-1:\n            removed_node = new_solution[selected_node]\n            new_solution = np.concatenate([new_solution[:selected_node], new_solution[selected_node+1:]])\n            insert_pos = np.random.randint(1, n-1)\n            new_solution = np.concatenate([new_solution[:insert_pos], [removed_node], new_solution[insert_pos:]])\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        This heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 58,
        "algorithm": "The algorithm selects a promising solution from the archive using rank-based selection, then applies a hybrid local search combining segment inversion with probabilistic edge swapping, prioritizing edges with high individual objective distances and low combined distance products. It ensures feasibility by maintaining a valid tour structure while exploring the solution space more effectively than standard 2-opt. The selection emphasizes solutions with better combined objectives, while the local search balances exploration of high-potential segments with exploitation of promising edge swaps.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Rank-based selection\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    selection_prob = np.linspace(1.0, 0.1, len(sorted_archive))\n    selection_prob = selection_prob / np.sum(selection_prob)\n    selected_idx = np.random.choice(len(sorted_archive), p=selection_prob)\n    base_solution = sorted_archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Segment inversion\n    segment_size = max(2, min(n // 2, int(np.random.normal(loc=n/4, scale=n/6))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Probabilistic edge swapping\n    if n > 3:\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            weight = distance_matrix_1[u][v] * distance_matrix_2[u][v] / (distance_matrix_1[u][v] + distance_matrix_2[u][v] + 1e-6)\n            edge_weights.append(weight)\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([1.0 / (distance_matrix_1[new_solution[c]][new_solution[i]] +\n                                        distance_matrix_2[new_solution[c]][new_solution[i]] +\n                                        distance_matrix_1[new_solution[i]][new_solution[d]] +\n                                        distance_matrix_2[new_solution[i]][new_solution[d]] + 1e-6)\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "score": [
            -0.8954405443494639,
            0.3103737235069275
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Rank-based selection\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0] + x[1][1]))\n    selection_prob = np.linspace(1.0, 0.1, len(sorted_archive))\n    selection_prob = selection_prob / np.sum(selection_prob)\n    selected_idx = np.random.choice(len(sorted_archive), p=selection_prob)\n    base_solution = sorted_archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Segment inversion\n    segment_size = max(2, min(n // 2, int(np.random.normal(loc=n/4, scale=n/6))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Probabilistic edge swapping\n    if n > 3:\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            weight = distance_matrix_1[u][v] * distance_matrix_2[u][v] / (distance_matrix_1[u][v] + distance_matrix_2[u][v] + 1e-6)\n            edge_weights.append(weight)\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([1.0 / (distance_matrix_1[new_solution[c]][new_solution[i]] +\n                                        distance_matrix_2[new_solution[c]][new_solution[i]] +\n                                        distance_matrix_1[new_solution[i]][new_solution[d]] +\n                                        distance_matrix_2[new_solution[i]][new_solution[d]] + 1e-6)\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 3 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 59,
        "algorithm": "The algorithm selects a promising solution from the archive using weighted random selection that prioritizes non-dominated solutions with lower combined objective values, then applies a hybrid local search combining adaptive segment rotation (with segment size proportional to solution quality) and conditional edge insertion (only if it improves at least one objective). The rotation prioritizes high-distance segments, while the insertion targets high-distance edges, ensuring feasibility by maintaining valid TSP tours throughout.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values and Pareto dominance\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Lower combined objective is better\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n        # Boost weight for non-dominated solutions\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and (other_obj[0] <= obj[0] and other_obj[1] <= obj[1]) and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            weights[i] *= 1.5\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment quality based on combined distance\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score += distance_matrix_1[u][v] * distance_matrix_2[u][v]\n        segment_scores.append((a, b, score))\n\n    # Select segment to rotate with highest score\n    segment_scores.sort(key=lambda x: -x[2])\n    if segment_scores:\n        a, b, _ = segment_scores[0]\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional edge insertion\n    if n > 3:\n        # Find edges with high combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d if it improves at least one objective\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                for e in candidates:\n                    temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n                    temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n                       temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n                        new_solution = temp_solution\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.977285410367772,
            1.0264369249343872
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values and Pareto dominance\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Lower combined objective is better\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n        # Boost weight for non-dominated solutions\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and (other_obj[0] <= obj[0] and other_obj[1] <= obj[1]) and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            weights[i] *= 1.5\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment quality based on combined distance\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score += distance_matrix_1[u][v] * distance_matrix_2[u][v]\n        segment_scores.append((a, b, score))\n\n    # Select segment to rotate with highest score\n    segment_scores.sort(key=lambda x: -x[2])\n    if segment_scores:\n        a, b, _ = segment_scores[0]\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional edge insertion\n    if n > 3:\n        # Find edges with high combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d if it improves at least one objective\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                for e in candidates:\n                    temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n                    temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n                       temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n                        new_solution = temp_solution\n                        break\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a high-potential solution from the archive using Pareto-dominance tournament selection, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal, ensuring feasibility and balanced multi-objective optimization by prioritizing edge weights and improving at least one objective. It intelligently balances exploration and exploitation through probabilistic segment operations and cost-aware selection.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive Pareto selection with a hybrid local search that prioritizes segment rotation, cost-aware edge insertion, and conditional segment reversal, while ensuring feasibility through probabilistic segment operations and edge weighting. It balances exploration and exploitation by dynamically adjusting segment sizes and using combined distance metrics to guide multi-objective improvements. The method intelligently selects edges and segments based on their potential for reducing tour lengths in both objective spaces, with segment reversal only applied when it improves at least one objective.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 60,
        "algorithm": "The algorithm combines adaptive Pareto-based selection with a hybrid local search that dynamically balances segment rotation, cost-aware edge insertion, and conditional segment reversal, prioritizing solutions with high crowding distance in the Pareto front and using multi-objective improvement criteria to ensure feasible, high-quality solutions. It employs probabilistic segment operations with adaptive sizes and directions, favoring cost-aware edge insertions and conditional reversals when they improve at least one objective without worsening the other. The selection process prioritizes non-dominated solutions, while the local search focuses on improving both objectives through segment manipulation and edge operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        # Select solution with highest crowding distance in Pareto front\n        crowding_distances = []\n        for idx in pareto_front:\n            left, right = None, None\n            sorted_solutions = sorted(pareto_front, key=lambda x: archive[x][1][0])\n            pos = sorted_solutions.index(idx)\n            if pos > 0:\n                left = archive[sorted_solutions[pos-1]][1][0]\n            if pos < len(sorted_solutions)-1:\n                right = archive[sorted_solutions[pos+1]][1][0]\n            if left is None:\n                left = archive[sorted_solutions[pos]][1][0]\n            if right is None:\n                right = archive[sorted_solutions[pos]][1][0]\n            cd1 = right - left\n\n            sorted_solutions = sorted(pareto_front, key=lambda x: archive[x][1][1])\n            pos = sorted_solutions.index(idx)\n            if pos > 0:\n                left = archive[sorted_solutions[pos-1]][1][1]\n            if pos < len(sorted_solutions)-1:\n                right = archive[sorted_solutions[pos+1]][1][1]\n            if left is None:\n                left = archive[sorted_solutions[pos]][1][1]\n            if right is None:\n                right = archive[sorted_solutions[pos]][1][1]\n            cd2 = right - left\n\n            crowding_distances.append(cd1 + cd2)\n\n        selected_idx = pareto_front[np.argmax(crowding_distances)]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size and direction\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation_direction = np.random.choice([-1, 1])\n    rotation = np.random.randint(1, segment_size)\n    if rotation_direction == -1:\n        rotation = -rotation\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with multi-objective weighting\n    if n > 3:\n        combined_distances = (distance_matrix_1 + distance_matrix_2) / 2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = []\n            for i in candidates:\n                dist1 = distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_1[new_solution[i]][new_solution[d]]\n                dist2 = distance_matrix_2[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[i]][new_solution[d]]\n                candidate_distances.append((dist1 + dist2) / 2)\n\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1 and new_cost2 <= original_cost2) or (new_cost1 <= original_cost1 and new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "score": [
            -0.9351328302931913,
            0.2623704671859741
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        # Select solution with highest crowding distance in Pareto front\n        crowding_distances = []\n        for idx in pareto_front:\n            left, right = None, None\n            sorted_solutions = sorted(pareto_front, key=lambda x: archive[x][1][0])\n            pos = sorted_solutions.index(idx)\n            if pos > 0:\n                left = archive[sorted_solutions[pos-1]][1][0]\n            if pos < len(sorted_solutions)-1:\n                right = archive[sorted_solutions[pos+1]][1][0]\n            if left is None:\n                left = archive[sorted_solutions[pos]][1][0]\n            if right is None:\n                right = archive[sorted_solutions[pos]][1][0]\n            cd1 = right - left\n\n            sorted_solutions = sorted(pareto_front, key=lambda x: archive[x][1][1])\n            pos = sorted_solutions.index(idx)\n            if pos > 0:\n                left = archive[sorted_solutions[pos-1]][1][1]\n            if pos < len(sorted_solutions)-1:\n                right = archive[sorted_solutions[pos+1]][1][1]\n            if left is None:\n                left = archive[sorted_solutions[pos]][1][1]\n            if right is None:\n                right = archive[sorted_solutions[pos]][1][1]\n            cd2 = right - left\n\n            crowding_distances.append(cd1 + cd2)\n\n        selected_idx = pareto_front[np.argmax(crowding_distances)]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size and direction\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation_direction = np.random.choice([-1, 1])\n    rotation = np.random.randint(1, segment_size)\n    if rotation_direction == -1:\n        rotation = -rotation\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with multi-objective weighting\n    if n > 3:\n        combined_distances = (distance_matrix_1 + distance_matrix_2) / 2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = []\n            for i in candidates:\n                dist1 = distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_1[new_solution[i]][new_solution[d]]\n                dist2 = distance_matrix_2[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[i]][new_solution[d]]\n                candidate_distances.append((dist1 + dist2) / 2)\n\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1 and new_cost2 <= original_cost2) or (new_cost1 <= original_cost1 and new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The heuristic selects a promising solution from the archive (prioritizing non-dominated ones), then applies a hybrid local search combining segment reversal and dynamic reinsertion of high-scoring segments (based on normalized distance products), while conditionally reversing edges to improve at least one objective. It ensures feasibility by removing duplicates and falls back to random swaps if needed. The algorithm balances exploration (random segment selection) and exploitation (cost-aware edge prioritization) while maintaining valid TSP tours.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize non-dominated solutions\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + cost-aware edge prioritization\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            normalized_score = - (segment_length1 * segment_length2)  # Higher score for shorter segments in both objectives\n            segment_scores.append((normalized_score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Dynamic reinsertion with feasibility check\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Conditional edge reversal based on cost improvement\n    if n > 3:\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        old_length1 = distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]]\n        new_length1 = distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]]\n        old_length2 = distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]\n        new_length2 = distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]\n\n        if (new_length1 < old_length1 or new_length2 < old_length2):\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 61,
        "algorithm": "The algorithm prioritizes non-dominated solutions from the archive, precomputes segment scores with early termination to identify promising local improvements, and uses a bitmask for efficient feasibility checks while applying conditional edge reversals with cached improvements. It balances exploration and exploitation by adaptively selecting segments and edges, ensuring valid TSP tours while targeting multi-objective optimization. The structure emphasizes heuristic selection, segment-based local search, and fallback mechanisms for robustness.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize non-dominated solutions\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    selected_idx = random.choice(non_dominated) if non_dominated else random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Precompute segment scores with early termination\n    segment_scores = []\n    max_segments = min(20, n)  # Limit segments for efficiency\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_scores.append((-(segment_length1 * segment_length2), i, j))\n            if len(segment_scores) >= max_segments:\n                break\n        if len(segment_scores) >= max_segments:\n            break\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Faster feasibility check using bitmask\n        visited = 0\n        for node in new_solution:\n            if visited & (1 << node):\n                break\n            visited |= (1 << node)\n        else:\n            if visited == (1 << n) - 1:\n                return new_solution\n\n    # Conditional edge reversal with cached improvements\n    if n > 3:\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        old_length1 = distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]]\n        new_length1 = distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]]\n        old_length2 = distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]\n        new_length2 = distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]\n\n        if (new_length1 < old_length1 or new_length2 < old_length2):\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9370099828706753,
            1.1645241975784302
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize non-dominated solutions\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    selected_idx = random.choice(non_dominated) if non_dominated else random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Precompute segment scores with early termination\n    segment_scores = []\n    max_segments = min(20, n)  # Limit segments for efficiency\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_scores.append((-(segment_length1 * segment_length2), i, j))\n            if len(segment_scores) >= max_segments:\n                break\n        if len(segment_scores) >= max_segments:\n            break\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Faster feasibility check using bitmask\n        visited = 0\n        for node in new_solution:\n            if visited & (1 << node):\n                break\n            visited |= (1 << node)\n        else:\n            if visited == (1 << n) - 1:\n                return new_solution\n\n    # Conditional edge reversal with cached improvements\n    if n > 3:\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        old_length1 = distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]]\n        new_length1 = distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]]\n        old_length2 = distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]\n        new_length2 = distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]\n\n        if (new_length1 < old_length1 or new_length2 < old_length2):\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection of promising solutions using a combination of objective values and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Step 3: Hybrid local search combining segment reversal and adaptive edge insertion\n    # First perform segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Then perform adaptive edge insertion based on high combined distance\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on its distance\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_distances = [distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]] for i in candidates]\n                candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n                e = np.random.choice(candidates, p=candidate_weights)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 4: Additional local improvement with edge reversal\n    if n > 3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Reverse the segment between the two selected edges\n            if c1 < d1 and c2 > d2:  # Ensure proper segment selection\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 62,
        "algorithm": "The algorithm combines adaptive Pareto-based selection with a hybrid local search that dynamically applies segment rotation, cost-aware edge swapping, and conditional path inversion, prioritizing solutions with higher crowding distance while ensuring feasibility through probabilistic segment selection and quality checks. It balances exploration and exploitation by probabilistically applying operators only when they improve at least one objective, avoiding static operators to maintain diversity. The approach dynamically adjusts perturbation sizes and weights based on edge and segment costs, emphasizing non-dominated solutions while preserving feasibility through careful segment manipulation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with quality check\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=1.8))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Calculate original and rotated costs\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n    rotated_segment = np.roll(new_solution[a:b+1], np.random.randint(1, segment_size))\n    rotated_cost1 = distance_matrix_1[rotated_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[rotated_segment[-1]][new_solution[(b+1)%n]]\n    rotated_cost2 = distance_matrix_2[rotated_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[rotated_segment[-1]][new_solution[(b+1)%n]]\n\n    if (rotated_cost1 < original_cost1) or (rotated_cost2 < original_cost2):\n        new_solution[a:b+1] = rotated_segment\n\n    # Cost-aware edge swapping\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n\n            # Calculate original and swapped costs\n            original_cost1 = combined_distances[new_solution[c]][new_solution[d]]\n            original_cost2 = combined_distances[new_solution[c]][new_solution[d]]\n            swapped_cost1 = combined_distances[new_solution[c]][new_solution[e]] + combined_distances[new_solution[e]][new_solution[d]]\n            swapped_cost2 = combined_distances[new_solution[c]][new_solution[e]] + combined_distances[new_solution[e]][new_solution[d]]\n\n            if (swapped_cost1 < original_cost1) or (swapped_cost2 < original_cost2):\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional path inversion with dominance check\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        inverted_segment = new_solution[a:b+1][::-1]\n        inverted_cost1 = distance_matrix_1[inverted_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[inverted_segment[-1]][new_solution[(b+1)%n]]\n        inverted_cost2 = distance_matrix_2[inverted_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[inverted_segment[-1]][new_solution[(b+1)%n]]\n\n        if (inverted_cost1 < original_cost1 and inverted_cost2 <= original_cost2) or (inverted_cost2 < original_cost2 and inverted_cost1 <= original_cost1):\n            new_solution[a:b+1] = inverted_segment\n\n    return new_solution\n\n",
        "score": [
            -0.7222211540522361,
            0.7900120615959167
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with quality check\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=1.8))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Calculate original and rotated costs\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n    rotated_segment = np.roll(new_solution[a:b+1], np.random.randint(1, segment_size))\n    rotated_cost1 = distance_matrix_1[rotated_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[rotated_segment[-1]][new_solution[(b+1)%n]]\n    rotated_cost2 = distance_matrix_2[rotated_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[rotated_segment[-1]][new_solution[(b+1)%n]]\n\n    if (rotated_cost1 < original_cost1) or (rotated_cost2 < original_cost2):\n        new_solution[a:b+1] = rotated_segment\n\n    # Cost-aware edge swapping\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n\n            # Calculate original and swapped costs\n            original_cost1 = combined_distances[new_solution[c]][new_solution[d]]\n            original_cost2 = combined_distances[new_solution[c]][new_solution[d]]\n            swapped_cost1 = combined_distances[new_solution[c]][new_solution[e]] + combined_distances[new_solution[e]][new_solution[d]]\n            swapped_cost2 = combined_distances[new_solution[c]][new_solution[e]] + combined_distances[new_solution[e]][new_solution[d]]\n\n            if (swapped_cost1 < original_cost1) or (swapped_cost2 < original_cost2):\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional path inversion with dominance check\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        inverted_segment = new_solution[a:b+1][::-1]\n        inverted_cost1 = distance_matrix_1[inverted_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[inverted_segment[-1]][new_solution[(b+1)%n]]\n        inverted_cost2 = distance_matrix_2[inverted_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[inverted_segment[-1]][new_solution[(b+1)%n]]\n\n        if (inverted_cost1 < original_cost1 and inverted_cost2 <= original_cost2) or (inverted_cost2 < original_cost2 and inverted_cost1 <= original_cost1):\n            new_solution[a:b+1] = inverted_segment\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        None\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection of promising solutions using a combination of objective values and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Step 3: Hybrid local search combining segment reversal and adaptive edge insertion\n    # First perform segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Then perform adaptive edge insertion based on high combined distance\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on its distance\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_distances = [distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]] for i in candidates]\n                candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n                e = np.random.choice(candidates, p=candidate_weights)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 4: Additional local improvement with edge reversal\n    if n > 3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Reverse the segment between the two selected edges\n            if c1 < d1 and c2 > d2:  # Ensure proper segment selection\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 63,
        "algorithm": "The algorithm selects a promising solution from an archive using quality-aware probabilistic selection, then applies a hybrid local search combining adaptive segment reversal, distance-based edge insertion, and a novel edge-swapping mechanism to generate high-quality neighbors while maintaining feasibility. It prioritizes segments with high combined distance for potential reversal, inserts nodes between high-distance edges to improve connectivity, and swaps non-adjacent edges based on their combined distance to explore diverse neighborhoods. The approach balances exploration and exploitation by adaptively adjusting segment sizes and leveraging both objective spaces to guide the search.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Quality-aware selection with adaptive weighting\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    quality_scores = 1 / (1 + np.sum(normalized_obj, axis=1))\n    weights = quality_scores / np.sum(quality_scores)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution diversity\n    segment_size = max(2, min(n // 3, int(np.random.normal(loc=n/4, scale=n/6))))\n    segment_size = max(2, min(segment_size, n - 2))\n\n    # Step 3: Hybrid local search combining segment reversal and edge swapping\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Reverse segment with probability based on its combined distance\n    segment_dist = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] + distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(a, b+1))\n    if np.random.rand() < 0.7 + 0.3 * (segment_dist / (np.sum(distance_matrix_1) + np.sum(distance_matrix_2))):\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Step 4: Distance-based edge insertion\n    if n > 3:\n        # Find edges with high combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a node between c and d based on its potential improvement\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_scores = []\n                for i in candidates:\n                    # Calculate potential improvement\n                    original_dist = distance_matrix_1[new_solution[c]][new_solution[d]] + distance_matrix_2[new_solution[c]][new_solution[d]]\n                    new_dist1 = distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]]\n                    new_dist2 = distance_matrix_1[new_solution[i]][new_solution[d]] + distance_matrix_2[new_solution[i]][new_solution[d]]\n                    improvement = original_dist - (new_dist1 + new_dist2)\n                    candidate_scores.append(improvement)\n\n                if any(s > 0 for s in candidate_scores):\n                    candidate_scores = np.array(candidate_scores)\n                    candidate_scores[candidate_scores <= 0] = 0\n                    candidate_weights = candidate_scores / np.sum(candidate_scores)\n                    e = np.random.choice(candidates, p=candidate_weights)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 5: Novel edge-swapping mechanism\n    if n > 4:\n        # Select two edges to swap based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 4:\n            # Select two non-adjacent edges\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            if abs(c1 - c2) > 1 and abs(d1 - d2) > 1:\n                # Perform edge swap\n                segment1 = new_solution[c1:d1+1]\n                segment2 = new_solution[c2:d2+1]\n                new_solution = np.concatenate([\n                    new_solution[:c1],\n                    segment2,\n                    new_solution[d1+1:c2],\n                    segment1,\n                    new_solution[d2+1:]\n                ])\n\n    return new_solution\n\n",
        "score": [
            -0.798235604148227,
            0.6924383640289307
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Quality-aware selection with adaptive weighting\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    quality_scores = 1 / (1 + np.sum(normalized_obj, axis=1))\n    weights = quality_scores / np.sum(quality_scores)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution diversity\n    segment_size = max(2, min(n // 3, int(np.random.normal(loc=n/4, scale=n/6))))\n    segment_size = max(2, min(segment_size, n - 2))\n\n    # Step 3: Hybrid local search combining segment reversal and edge swapping\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Reverse segment with probability based on its combined distance\n    segment_dist = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] + distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(a, b+1))\n    if np.random.rand() < 0.7 + 0.3 * (segment_dist / (np.sum(distance_matrix_1) + np.sum(distance_matrix_2))):\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Step 4: Distance-based edge insertion\n    if n > 3:\n        # Find edges with high combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a node between c and d based on its potential improvement\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_scores = []\n                for i in candidates:\n                    # Calculate potential improvement\n                    original_dist = distance_matrix_1[new_solution[c]][new_solution[d]] + distance_matrix_2[new_solution[c]][new_solution[d]]\n                    new_dist1 = distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]]\n                    new_dist2 = distance_matrix_1[new_solution[i]][new_solution[d]] + distance_matrix_2[new_solution[i]][new_solution[d]]\n                    improvement = original_dist - (new_dist1 + new_dist2)\n                    candidate_scores.append(improvement)\n\n                if any(s > 0 for s in candidate_scores):\n                    candidate_scores = np.array(candidate_scores)\n                    candidate_scores[candidate_scores <= 0] = 0\n                    candidate_weights = candidate_scores / np.sum(candidate_scores)\n                    e = np.random.choice(candidates, p=candidate_weights)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 5: Novel edge-swapping mechanism\n    if n > 4:\n        # Select two edges to swap based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 4:\n            # Select two non-adjacent edges\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            if abs(c1 - c2) > 1 and abs(d1 - d2) > 1:\n                # Perform edge swap\n                segment1 = new_solution[c1:d1+1]\n                segment2 = new_solution[c2:d2+1]\n                new_solution = np.concatenate([\n                    new_solution[:c1],\n                    segment2,\n                    new_solution[d1+1:c2],\n                    segment1,\n                    new_solution[d2+1:]\n                ])\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        None\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection of promising solutions using a combination of objective values and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Step 3: Hybrid local search combining segment reversal and adaptive edge insertion\n    # First perform segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Then perform adaptive edge insertion based on high combined distance\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on its distance\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_distances = [distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]] for i in candidates]\n                candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n                e = np.random.choice(candidates, p=candidate_weights)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 4: Additional local improvement with edge reversal\n    if n > 3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Reverse the segment between the two selected edges\n            if c1 < d1 and c2 > d2:  # Ensure proper segment selection\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 64,
        "algorithm": "The algorithm combines adaptive segment reversal, probabilistic edge insertion, and objective-balanced edge selection to generate high-quality neighbor solutions by prioritizing segments and edges that improve both objectives simultaneously while maintaining feasibility. It intelligently selects solutions from the archive based on combined objective performance and applies novel local search operators with segment size adaptation and probabilistic edge insertion to explore the solution space effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution based on combined objective performance\n    objectives = np.array([obj for _, obj in archive])\n    combined_obj = objectives[:, 0] + objectives[:, 1]\n    weights = combined_obj / np.sum(combined_obj)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution length and objective diversity\n    segment_size = max(2, min(n // 3, int(np.random.normal(loc=n/4, scale=n/8))))\n\n    # Step 3: Objective-balanced segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Calculate objective improvement potential\n    before_cost = (distance_matrix_1[new_solution[a-1]][new_solution[a]] +\n                   distance_matrix_2[new_solution[a-1]][new_solution[a]] +\n                   distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] +\n                   distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]])\n\n    after_cost = (distance_matrix_1[new_solution[a-1]][new_solution[b]] +\n                  distance_matrix_2[new_solution[a-1]][new_solution[b]] +\n                  distance_matrix_1[new_solution[a]][new_solution[(b+1)%n]] +\n                  distance_matrix_2[new_solution[a]][new_solution[(b+1)%n]])\n\n    if after_cost < before_cost:\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Step 4: Probabilistic edge insertion with objective-aware selection\n    if n > 3:\n        # Calculate edge importance based on both objectives\n        edge_scores = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score = (distance_matrix_1[u][v] + distance_matrix_2[u][v]) * (1 + np.random.normal(0, 0.2))\n            edge_scores.append((i, score))\n\n        edge_scores.sort(key=lambda x: -x[1])\n        if edge_scores:\n            # Select top 20% edges for potential insertion points\n            threshold = edge_scores[max(1, len(edge_scores)//5)][1]\n            insertion_points = [i for i, score in edge_scores if score >= threshold]\n\n            if insertion_points:\n                c = np.random.choice(insertion_points)\n                d = (c + 1) % n\n\n                # Select insertion node based on combined distance improvement\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    candidate_scores = []\n                    for e in candidates:\n                        before = (distance_matrix_1[new_solution[c]][new_solution[d]] +\n                                 distance_matrix_2[new_solution[c]][new_solution[d]])\n                        after = (distance_matrix_1[new_solution[c]][new_solution[e]] +\n                                distance_matrix_2[new_solution[c]][new_solution[e]] +\n                                distance_matrix_1[new_solution[e]][new_solution[d]] +\n                                distance_matrix_2[new_solution[e]][new_solution[d]])\n                        candidate_scores.append((e, before - after))\n\n                    candidate_scores.sort(key=lambda x: -x[1])\n                    if candidate_scores:\n                        e = candidate_scores[0][0]\n                        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 5: Final edge optimization with objective balancing\n    if n > 3:\n        # Select edges with high combined distance and reverse them if beneficial\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[1])\n        if len(edges) >= 2:\n            c1, score1 = edges[0]\n            c2, score2 = edges[1]\n\n            # Reverse the segment between the two selected edges if it improves both objectives\n            if c1 < c2:\n                before_cost = (distance_matrix_1[new_solution[c1]][new_solution[(c1+1)%n]] +\n                             distance_matrix_2[new_solution[c1]][new_solution[(c1+1)%n]] +\n                             distance_matrix_1[new_solution[c2]][new_solution[(c2+1)%n]] +\n                             distance_matrix_2[new_solution[c2]][new_solution[(c2+1)%n]])\n\n                after_cost = (distance_matrix_1[new_solution[c1]][new_solution[c2]] +\n                            distance_matrix_2[new_solution[c1]][new_solution[c2]] +\n                            distance_matrix_1[new_solution[(c1+1)%n]][new_solution[(c2+1)%n]] +\n                            distance_matrix_2[new_solution[(c1+1)%n]][new_solution[(c2+1)%n]])\n\n                if after_cost < before_cost:\n                    new_solution[c1+1:c2+1] = new_solution[c1+1:c2+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.8124861842850923,
            0.4295007586479187
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution based on combined objective performance\n    objectives = np.array([obj for _, obj in archive])\n    combined_obj = objectives[:, 0] + objectives[:, 1]\n    weights = combined_obj / np.sum(combined_obj)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution length and objective diversity\n    segment_size = max(2, min(n // 3, int(np.random.normal(loc=n/4, scale=n/8))))\n\n    # Step 3: Objective-balanced segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Calculate objective improvement potential\n    before_cost = (distance_matrix_1[new_solution[a-1]][new_solution[a]] +\n                   distance_matrix_2[new_solution[a-1]][new_solution[a]] +\n                   distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] +\n                   distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]])\n\n    after_cost = (distance_matrix_1[new_solution[a-1]][new_solution[b]] +\n                  distance_matrix_2[new_solution[a-1]][new_solution[b]] +\n                  distance_matrix_1[new_solution[a]][new_solution[(b+1)%n]] +\n                  distance_matrix_2[new_solution[a]][new_solution[(b+1)%n]])\n\n    if after_cost < before_cost:\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Step 4: Probabilistic edge insertion with objective-aware selection\n    if n > 3:\n        # Calculate edge importance based on both objectives\n        edge_scores = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score = (distance_matrix_1[u][v] + distance_matrix_2[u][v]) * (1 + np.random.normal(0, 0.2))\n            edge_scores.append((i, score))\n\n        edge_scores.sort(key=lambda x: -x[1])\n        if edge_scores:\n            # Select top 20% edges for potential insertion points\n            threshold = edge_scores[max(1, len(edge_scores)//5)][1]\n            insertion_points = [i for i, score in edge_scores if score >= threshold]\n\n            if insertion_points:\n                c = np.random.choice(insertion_points)\n                d = (c + 1) % n\n\n                # Select insertion node based on combined distance improvement\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    candidate_scores = []\n                    for e in candidates:\n                        before = (distance_matrix_1[new_solution[c]][new_solution[d]] +\n                                 distance_matrix_2[new_solution[c]][new_solution[d]])\n                        after = (distance_matrix_1[new_solution[c]][new_solution[e]] +\n                                distance_matrix_2[new_solution[c]][new_solution[e]] +\n                                distance_matrix_1[new_solution[e]][new_solution[d]] +\n                                distance_matrix_2[new_solution[e]][new_solution[d]])\n                        candidate_scores.append((e, before - after))\n\n                    candidate_scores.sort(key=lambda x: -x[1])\n                    if candidate_scores:\n                        e = candidate_scores[0][0]\n                        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 5: Final edge optimization with objective balancing\n    if n > 3:\n        # Select edges with high combined distance and reverse them if beneficial\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[1])\n        if len(edges) >= 2:\n            c1, score1 = edges[0]\n            c2, score2 = edges[1]\n\n            # Reverse the segment between the two selected edges if it improves both objectives\n            if c1 < c2:\n                before_cost = (distance_matrix_1[new_solution[c1]][new_solution[(c1+1)%n]] +\n                             distance_matrix_2[new_solution[c1]][new_solution[(c1+1)%n]] +\n                             distance_matrix_1[new_solution[c2]][new_solution[(c2+1)%n]] +\n                             distance_matrix_2[new_solution[c2]][new_solution[(c2+1)%n]])\n\n                after_cost = (distance_matrix_1[new_solution[c1]][new_solution[c2]] +\n                            distance_matrix_2[new_solution[c1]][new_solution[c2]] +\n                            distance_matrix_1[new_solution[(c1+1)%n]][new_solution[(c2+1)%n]] +\n                            distance_matrix_2[new_solution[(c1+1)%n]][new_solution[(c2+1)%n]])\n\n                if after_cost < before_cost:\n                    new_solution[c1+1:c2+1] = new_solution[c1+1:c2+1][::-1]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 3 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection of promising solutions using a combination of objective values and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Step 3: Hybrid local search combining segment reversal and adaptive edge insertion\n    # First perform segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Then perform adaptive edge insertion based on high combined distance\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on its distance\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_distances = [distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]] for i in candidates]\n                candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n                e = np.random.choice(candidates, p=candidate_weights)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 4: Additional local improvement with edge reversal\n    if n > 3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Reverse the segment between the two selected edges\n            if c1 < d1 and c2 > d2:  # Ensure proper segment selection\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 65,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Pareto-dominance based selection with adaptive weights\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(archive)\n    dominance_counts = np.zeros(n_solutions)\n\n    for i in range(n_solutions):\n        for j in range(n_solutions):\n            if i == j:\n                continue\n            if (objectives[i][0] <= objectives[j][0] and objectives[i][1] < objectives[j][1]) or \\\n               (objectives[i][0] < objectives[j][0] and objectives[i][1] <= objectives[j][1]):\n                dominance_counts[i] += 1\n\n    # Normalize dominance counts and combine with objective values\n    normalized_dominance = dominance_counts / (np.max(dominance_counts) + 1e-10)\n    normalized_obj = (np.max(objectives, axis=0) - objectives) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    combined_scores = 0.7 * normalized_dominance + 0.3 * np.sum(normalized_obj, axis=1)\n    weights = combined_scores / np.sum(combined_scores)\n    selected_idx = np.random.choice(n_solutions, p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality and problem size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=3))))\n\n    # Step 3: Hybrid local search combining segment rotation and cost-aware edge insertion\n    # First perform segment rotation\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation_amount = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    # Then perform cost-aware edge insertion\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a node that would improve at least one objective\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                # Evaluate insertion candidates based on potential improvement\n                best_candidate = None\n                best_improvement = 0\n\n                for candidate in candidates:\n                    # Original edges\n                    u1, v1 = new_solution[c], new_solution[(c+1)%n]\n                    u2, v2 = new_solution[(d-1)%n], new_solution[d]\n\n                    # New edges if candidate is inserted\n                    new_u1, new_v1 = new_solution[c], new_solution[candidate]\n                    new_u2, new_v2 = new_solution[candidate], new_solution[(c+1)%n]\n\n                    # Calculate potential improvement\n                    original_cost = distance_matrix_1[u1][v1] + distance_matrix_2[u1][v1] + distance_matrix_1[u2][v2] + distance_matrix_2[u2][v2]\n                    new_cost = distance_matrix_1[new_u1][new_v1] + distance_matrix_2[new_u1][new_v1] + distance_matrix_1[new_u2][new_v2] + distance_matrix_2[new_u2][new_v2]\n\n                    improvement = original_cost - new_cost\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_candidate = candidate\n\n                if best_candidate is not None:\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[best_candidate:best_candidate+1], new_solution[c+1:]])\n\n    # Step 4: Conditional edge reversal if it improves at least one objective\n    if n > 3:\n        # Select two edges to reverse\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v], distance_matrix_2[u][v]))\n\n        if len(edges) >= 2:\n            # Find the worst edges in each objective\n            edges_obj1 = sorted(edges, key=lambda x: -x[2])\n            edges_obj2 = sorted(edges, key=lambda x: -x[3])\n\n            worst_edge1 = edges_obj1[0]\n            worst_edge2 = edges_obj2[0]\n\n            # Reverse the segments between these edges\n            c1, d1 = worst_edge1[0], worst_edge1[1]\n            c2, d2 = worst_edge2[0], worst_edge2[1]\n\n            if c1 < d1 and c2 < d2:\n                # Calculate original and new costs for both objectives\n                original_cost1 = distance_matrix_1[new_solution[c1]][new_solution[d1]] + distance_matrix_1[new_solution[c2]][new_solution[d2]]\n                original_cost2 = distance_matrix_2[new_solution[c1]][new_solution[d1]] + distance_matrix_2[new_solution[c2]][new_solution[d2]]\n\n                # Reverse the segments\n                temp_solution = new_solution.copy()\n                temp_solution[c1:d1+1] = temp_solution[c1:d1+1][::-1]\n                temp_solution[c2:d2+1] = temp_solution[c2:d2+1][::-1]\n\n                new_cost1 = distance_matrix_1[temp_solution[c1]][temp_solution[d1]] + distance_matrix_1[temp_solution[c2]][temp_solution[d2]]\n                new_cost2 = distance_matrix_2[temp_solution[c1]][temp_solution[d1]] + distance_matrix_2[temp_solution[c2]][temp_solution[d2]]\n\n                # Only accept if at least one objective improves\n                if new_cost1 < original_cost1 or new_cost2 < original_cost2:\n                    new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.921133263377076,
            11.590057671070099
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Pareto-dominance based selection with adaptive weights\n    objectives = np.array([obj for _, obj in archive])\n    n_solutions = len(archive)\n    dominance_counts = np.zeros(n_solutions)\n\n    for i in range(n_solutions):\n        for j in range(n_solutions):\n            if i == j:\n                continue\n            if (objectives[i][0] <= objectives[j][0] and objectives[i][1] < objectives[j][1]) or \\\n               (objectives[i][0] < objectives[j][0] and objectives[i][1] <= objectives[j][1]):\n                dominance_counts[i] += 1\n\n    # Normalize dominance counts and combine with objective values\n    normalized_dominance = dominance_counts / (np.max(dominance_counts) + 1e-10)\n    normalized_obj = (np.max(objectives, axis=0) - objectives) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    combined_scores = 0.7 * normalized_dominance + 0.3 * np.sum(normalized_obj, axis=1)\n    weights = combined_scores / np.sum(combined_scores)\n    selected_idx = np.random.choice(n_solutions, p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality and problem size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=3))))\n\n    # Step 3: Hybrid local search combining segment rotation and cost-aware edge insertion\n    # First perform segment rotation\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation_amount = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation_amount)\n\n    # Then perform cost-aware edge insertion\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a node that would improve at least one objective\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                # Evaluate insertion candidates based on potential improvement\n                best_candidate = None\n                best_improvement = 0\n\n                for candidate in candidates:\n                    # Original edges\n                    u1, v1 = new_solution[c], new_solution[(c+1)%n]\n                    u2, v2 = new_solution[(d-1)%n], new_solution[d]\n\n                    # New edges if candidate is inserted\n                    new_u1, new_v1 = new_solution[c], new_solution[candidate]\n                    new_u2, new_v2 = new_solution[candidate], new_solution[(c+1)%n]\n\n                    # Calculate potential improvement\n                    original_cost = distance_matrix_1[u1][v1] + distance_matrix_2[u1][v1] + distance_matrix_1[u2][v2] + distance_matrix_2[u2][v2]\n                    new_cost = distance_matrix_1[new_u1][new_v1] + distance_matrix_2[new_u1][new_v1] + distance_matrix_1[new_u2][new_v2] + distance_matrix_2[new_u2][new_v2]\n\n                    improvement = original_cost - new_cost\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_candidate = candidate\n\n                if best_candidate is not None:\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[best_candidate:best_candidate+1], new_solution[c+1:]])\n\n    # Step 4: Conditional edge reversal if it improves at least one objective\n    if n > 3:\n        # Select two edges to reverse\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v], distance_matrix_2[u][v]))\n\n        if len(edges) >= 2:\n            # Find the worst edges in each objective\n            edges_obj1 = sorted(edges, key=lambda x: -x[2])\n            edges_obj2 = sorted(edges, key=lambda x: -x[3])\n\n            worst_edge1 = edges_obj1[0]\n            worst_edge2 = edges_obj2[0]\n\n            # Reverse the segments between these edges\n            c1, d1 = worst_edge1[0], worst_edge1[1]\n            c2, d2 = worst_edge2[0], worst_edge2[1]\n\n            if c1 < d1 and c2 < d2:\n                # Calculate original and new costs for both objectives\n                original_cost1 = distance_matrix_1[new_solution[c1]][new_solution[d1]] + distance_matrix_1[new_solution[c2]][new_solution[d2]]\n                original_cost2 = distance_matrix_2[new_solution[c1]][new_solution[d1]] + distance_matrix_2[new_solution[c2]][new_solution[d2]]\n\n                # Reverse the segments\n                temp_solution = new_solution.copy()\n                temp_solution[c1:d1+1] = temp_solution[c1:d1+1][::-1]\n                temp_solution[c2:d2+1] = temp_solution[c2:d2+1][::-1]\n\n                new_cost1 = distance_matrix_1[temp_solution[c1]][temp_solution[d1]] + distance_matrix_1[temp_solution[c2]][temp_solution[d2]]\n                new_cost2 = distance_matrix_2[temp_solution[c1]][temp_solution[d1]] + distance_matrix_2[temp_solution[c2]][temp_solution[d2]]\n\n                # Only accept if at least one objective improves\n                if new_cost1 < original_cost1 or new_cost2 < original_cost2:\n                    new_solution = temp_solution\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a high-potential solution from the archive using Pareto-dominance tournament selection, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal, ensuring feasibility and balanced multi-objective optimization by prioritizing edge weights and improving at least one objective. It intelligently balances exploration and exploitation through probabilistic segment operations and cost-aware selection.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive Pareto selection with a hybrid local search that prioritizes segment rotation, cost-aware edge insertion, and conditional segment reversal, while ensuring feasibility through probabilistic segment operations and edge weighting. It balances exploration and exploitation by dynamically adjusting segment sizes and using combined distance metrics to guide multi-objective improvements. The method intelligently selects edges and segments based on their potential for reducing tour lengths in both objective spaces, with segment reversal only applied when it improves at least one objective.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 66,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    # Calculate crowding distance for Pareto front\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    # Build Pareto front\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "score": [
            -0.9394738245470493,
            0.2026417851448059
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    # Calculate crowding distance for Pareto front\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    # Build Pareto front\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a high-potential solution from the archive using Pareto-dominance tournament selection, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal, ensuring feasibility and balanced multi-objective optimization by prioritizing edge weights and improving at least one objective. It intelligently balances exploration and exploitation through probabilistic segment operations and cost-aware selection.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive Pareto selection with a hybrid local search that prioritizes segment rotation, cost-aware edge insertion, and conditional segment reversal, while ensuring feasibility through probabilistic segment operations and edge weighting. It balances exploration and exploitation by dynamically adjusting segment sizes and using combined distance metrics to guide multi-objective improvements. The method intelligently selects edges and segments based on their potential for reducing tour lengths in both objective spaces, with segment reversal only applied when it improves at least one objective.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 66,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    # Calculate crowding distance for Pareto front\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    # Build Pareto front\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "score": [
            -0.9394738245470493,
            0.2026417851448059
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    # Calculate crowding distance for Pareto front\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    # Build Pareto front\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The heuristic selects a promising solution from the archive (prioritizing non-dominated ones), then applies a hybrid local search combining segment reversal and dynamic reinsertion of high-scoring segments (based on normalized distance products), while conditionally reversing edges to improve at least one objective. It ensures feasibility by removing duplicates and falls back to random swaps if needed. The algorithm balances exploration (random segment selection) and exploitation (cost-aware edge prioritization) while maintaining valid TSP tours.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize non-dominated solutions\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + cost-aware edge prioritization\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            normalized_score = - (segment_length1 * segment_length2)  # Higher score for shorter segments in both objectives\n            segment_scores.append((normalized_score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Dynamic reinsertion with feasibility check\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Conditional edge reversal based on cost improvement\n    if n > 3:\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        old_length1 = distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]]\n        new_length1 = distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]]\n        old_length2 = distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]\n        new_length2 = distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]\n\n        if (new_length1 < old_length1 or new_length2 < old_length2):\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 67,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Optimized solution selection: prioritize non-dominated solutions with O(n) complexity\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = non_dominated[0] if len(non_dominated) == 1 else random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Optimized hybrid local search: reduced segment evaluation and simplified reinsertion\n    if n > 3:\n        # Random segment selection instead of exhaustive evaluation\n        i = random.randint(0, n-3)\n        j = random.randint(i+2, min(i+5, n-1))  # Limit segment length to 5 nodes\n\n        # Simplified segment reversal with feasibility check\n        segment = new_solution[i:j+1]\n        if len(segment) > 1:\n            new_solution[i:j+1] = segment[::-1]\n\n        # Conditional edge reversal based on cost improvement\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        old_length1 = distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]]\n        new_length1 = distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]]\n        old_length2 = distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]\n        new_length2 = distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]\n\n        if (new_length1 < old_length1 or new_length2 < old_length2):\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.9038973139355244,
            0.6960431337356567
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Optimized solution selection: prioritize non-dominated solutions with O(n) complexity\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = non_dominated[0] if len(non_dominated) == 1 else random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Optimized hybrid local search: reduced segment evaluation and simplified reinsertion\n    if n > 3:\n        # Random segment selection instead of exhaustive evaluation\n        i = random.randint(0, n-3)\n        j = random.randint(i+2, min(i+5, n-1))  # Limit segment length to 5 nodes\n\n        # Simplified segment reversal with feasibility check\n        segment = new_solution[i:j+1]\n        if len(segment) > 1:\n            new_solution[i:j+1] = segment[::-1]\n\n        # Conditional edge reversal based on cost improvement\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        old_length1 = distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]]\n        new_length1 = distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]]\n        old_length2 = distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]\n        new_length2 = distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]\n\n        if (new_length1 < old_length1 or new_length2 < old_length2):\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection of promising solutions using a combination of objective values and crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Step 3: Hybrid local search combining segment reversal and adaptive edge insertion\n    # First perform segment reversal\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Then perform adaptive edge insertion based on high combined distance\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d with probability based on its distance\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                candidate_distances = [distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[c]][new_solution[i]] for i in candidates]\n                candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n                e = np.random.choice(candidates, p=candidate_weights)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Step 4: Additional local improvement with edge reversal\n    if n > 3:\n        # Select two edges to reverse based on their combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            # Reverse the segment between the two selected edges\n            if c1 < d1 and c2 > d2:  # Ensure proper segment selection\n                new_solution[c1:d1+1] = new_solution[c1:d1+1][::-1]\n                new_solution[c2:d2+1] = new_solution[c2:d2+1][::-1]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using weighted random selection that prioritizes non-dominated solutions with lower combined objective values, then applies a hybrid local search combining adaptive segment rotation (with segment size proportional to solution quality) and conditional edge insertion (only if it improves at least one objective). The rotation prioritizes high-distance segments, while the insertion targets high-distance edges, ensuring feasibility by maintaining valid TSP tours throughout.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values and Pareto dominance\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Lower combined objective is better\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n        # Boost weight for non-dominated solutions\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and (other_obj[0] <= obj[0] and other_obj[1] <= obj[1]) and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            weights[i] *= 1.5\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment quality based on combined distance\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score += distance_matrix_1[u][v] * distance_matrix_2[u][v]\n        segment_scores.append((a, b, score))\n\n    # Select segment to rotate with highest score\n    segment_scores.sort(key=lambda x: -x[2])\n    if segment_scores:\n        a, b, _ = segment_scores[0]\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional edge insertion\n    if n > 3:\n        # Find edges with high combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d if it improves at least one objective\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                for e in candidates:\n                    temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n                    temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n                       temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n                        new_solution = temp_solution\n                        break\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 68,
        "algorithm": "This algorithm combines adaptive solution selection with a hybrid perturbation strategy, prioritizing non-dominated solutions and using objective balance to guide segment rotation, conditional edge reversal, or adaptive insertion. It intelligently selects perturbations (rotation, reversal, or insertion) based on solution quality and dynamically adjusts the intensity of changes to explore promising regions while ensuring feasibility. The method balances exploration and exploitation by focusing on high-distance segments and using coordinate information to guide improvements in both objective spaces.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection based on combined objective values and Pareto dominance\n    weights = np.zeros(len(archive))\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    for i, (sol, obj) in enumerate(archive):\n        weights[i] = 1.0 / (1.0 + np.sum(normalized_obj[i]))\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and (other_obj[0] <= obj[0] and other_obj[1] <= obj[1]) and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            weights[i] *= 1.5\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Determine perturbation type based on solution quality and objective balance\n    obj_balance = objectives[selected_idx][0] / (objectives[selected_idx][0] + objectives[selected_idx][1] + 1e-10)\n    perturbation_type = np.random.choice(['rotation', 'reversal', 'insertion'], p=[0.4, 0.3, 0.3])\n\n    if perturbation_type == 'rotation':\n        # Segment rotation with adaptive size based on objective balance\n        segment_size = max(2, min(n // 3, int(np.random.normal(loc=n//4, scale=n//6))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    elif perturbation_type == 'reversal':\n        # Conditional edge reversal based on objective improvement\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            if c1 < d1 and c2 > d2:\n                temp_solution = new_solution.copy()\n                temp_solution[c1:d1+1] = temp_solution[c1:d1+1][::-1]\n                temp_solution[c2:d2+1] = temp_solution[c2:d2+1][::-1]\n\n                temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n\n                if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n                   temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n                    new_solution = temp_solution\n\n    elif perturbation_type == 'insertion':\n        # Adaptive insertion guided by instance coordinates\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            c, d = edges[0][0], edges[0][1]\n            candidates = [i for i in range(n) if i not in (c, d)]\n\n            if candidates:\n                # Calculate direction vector between edge endpoints\n                u_coords = instance[new_solution[c]]\n                v_coords = instance[new_solution[d]]\n                direction = (v_coords[2] - u_coords[2], v_coords[3] - u_coords[3])\n\n                # Select candidate node closest to the direction\n                candidate_coords = [instance[new_solution[i]] for i in candidates]\n                candidate_directions = [(coords[2] - u_coords[2], coords[3] - u_coords[3]) for coords in candidate_coords]\n                dot_products = [direction[0]*cd[0] + direction[1]*cd[1] for cd in candidate_directions]\n                best_candidate = candidates[np.argmax(dot_products)]\n\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[best_candidate:best_candidate+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "score": [
            -0.7117970885597468,
            0.8704461455345154
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection based on combined objective values and Pareto dominance\n    weights = np.zeros(len(archive))\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    for i, (sol, obj) in enumerate(archive):\n        weights[i] = 1.0 / (1.0 + np.sum(normalized_obj[i]))\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and (other_obj[0] <= obj[0] and other_obj[1] <= obj[1]) and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            weights[i] *= 1.5\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Determine perturbation type based on solution quality and objective balance\n    obj_balance = objectives[selected_idx][0] / (objectives[selected_idx][0] + objectives[selected_idx][1] + 1e-10)\n    perturbation_type = np.random.choice(['rotation', 'reversal', 'insertion'], p=[0.4, 0.3, 0.3])\n\n    if perturbation_type == 'rotation':\n        # Segment rotation with adaptive size based on objective balance\n        segment_size = max(2, min(n // 3, int(np.random.normal(loc=n//4, scale=n//6))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    elif perturbation_type == 'reversal':\n        # Conditional edge reversal based on objective improvement\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if len(edges) >= 2:\n            c1, d1 = edges[0][0], edges[0][1]\n            c2, d2 = edges[1][0], edges[1][1]\n\n            if c1 < d1 and c2 > d2:\n                temp_solution = new_solution.copy()\n                temp_solution[c1:d1+1] = temp_solution[c1:d1+1][::-1]\n                temp_solution[c2:d2+1] = temp_solution[c2:d2+1][::-1]\n\n                temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n\n                if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n                   temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n                    new_solution = temp_solution\n\n    elif perturbation_type == 'insertion':\n        # Adaptive insertion guided by instance coordinates\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            c, d = edges[0][0], edges[0][1]\n            candidates = [i for i in range(n) if i not in (c, d)]\n\n            if candidates:\n                # Calculate direction vector between edge endpoints\n                u_coords = instance[new_solution[c]]\n                v_coords = instance[new_solution[d]]\n                direction = (v_coords[2] - u_coords[2], v_coords[3] - u_coords[3])\n\n                # Select candidate node closest to the direction\n                candidate_coords = [instance[new_solution[i]] for i in candidates]\n                candidate_directions = [(coords[2] - u_coords[2], coords[3] - u_coords[3]) for coords in candidate_coords]\n                dot_products = [direction[0]*cd[0] + direction[1]*cd[1] for cd in candidate_directions]\n                best_candidate = candidates[np.argmax(dot_products)]\n\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[best_candidate:best_candidate+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using weighted random selection that prioritizes non-dominated solutions with lower combined objective values, then applies a hybrid local search combining adaptive segment rotation (with segment size proportional to solution quality) and conditional edge insertion (only if it improves at least one objective). The rotation prioritizes high-distance segments, while the insertion targets high-distance edges, ensuring feasibility by maintaining valid TSP tours throughout.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values and Pareto dominance\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Lower combined objective is better\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n        # Boost weight for non-dominated solutions\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and (other_obj[0] <= obj[0] and other_obj[1] <= obj[1]) and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            weights[i] *= 1.5\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment quality based on combined distance\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score += distance_matrix_1[u][v] * distance_matrix_2[u][v]\n        segment_scores.append((a, b, score))\n\n    # Select segment to rotate with highest score\n    segment_scores.sort(key=lambda x: -x[2])\n    if segment_scores:\n        a, b, _ = segment_scores[0]\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional edge insertion\n    if n > 3:\n        # Find edges with high combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d if it improves at least one objective\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                for e in candidates:\n                    temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n                    temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n                       temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n                        new_solution = temp_solution\n                        break\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 69,
        "algorithm": "The algorithm selects a solution from the archive using a quality-weighted random selection that prioritizes solutions with high combined objective values and low dominance counts, then applies a hybrid local search combining adaptive segment reversal (with segment size determined by a novel quality metric) and conditional edge swapping (only if it improves at least one objective), while ensuring tour feasibility through careful edge validation and segment boundary checks. The selection process emphasizes solutions with better combined objective values and fewer dominated solutions, while the local search focuses on reversing high-quality segments and swapping edges that improve at least one objective, with segment sizes and swap candidates determined dynamically based on the solution's characteristics.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance counts and quality scores\n    dominance_counts = np.zeros(len(archive))\n    quality_scores = np.zeros(len(archive))\n\n    for i, (sol_i, obj_i) in enumerate(archive):\n        for j, (sol_j, obj_j) in enumerate(archive):\n            if i != j:\n                if (obj_j[0] <= obj_i[0] and obj_j[1] <= obj_i[1]) and (obj_j[0] < obj_i[0] or obj_j[1] < obj_i[1]):\n                    dominance_counts[i] += 1\n        quality_scores[i] = (obj_i[0] + obj_i[1]) / (1 + dominance_counts[i])\n\n    # Weighted selection based on quality scores\n    weights = quality_scores / np.sum(quality_scores)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment quality based on combined distance and dominance\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(n // 2, int(np.random.normal(loc=n/4, scale=n/8))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score += (distance_matrix_1[u][v] + distance_matrix_2[u][v]) * (1 + quality_scores[selected_idx])\n        segment_scores.append((a, b, score))\n\n    # Select segment to reverse with highest score\n    segment_scores.sort(key=lambda x: -x[2])\n    if segment_scores:\n        a, b, _ = segment_scores[0]\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Conditional edge swapping\n    if n > 3:\n        # Find edges with high combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Swap two random nodes between c and d if it improves at least one objective\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if len(candidates) >= 2:\n                for _ in range(10):  # Try multiple swaps\n                    i, j = np.random.choice(candidates, size=2, replace=False)\n                    if i > j:\n                        i, j = j, i\n                    temp_solution = new_solution.copy()\n                    temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n\n                    temp_obj1 = sum(distance_matrix_1[temp_solution[k]][temp_solution[(k+1)%n]] for k in range(n))\n                    temp_obj2 = sum(distance_matrix_2[temp_solution[k]][temp_solution[(k+1)%n]] for k in range(n))\n\n                    if temp_obj1 <= sum(distance_matrix_1[new_solution[k]][new_solution[(k+1)%n]] for k in range(n)) or \\\n                       temp_obj2 <= sum(distance_matrix_2[new_solution[k]][new_solution[(k+1)%n]] for k in range(n)):\n                        new_solution = temp_solution\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.8277896922328567,
            1.508348524570465
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance counts and quality scores\n    dominance_counts = np.zeros(len(archive))\n    quality_scores = np.zeros(len(archive))\n\n    for i, (sol_i, obj_i) in enumerate(archive):\n        for j, (sol_j, obj_j) in enumerate(archive):\n            if i != j:\n                if (obj_j[0] <= obj_i[0] and obj_j[1] <= obj_i[1]) and (obj_j[0] < obj_i[0] or obj_j[1] < obj_i[1]):\n                    dominance_counts[i] += 1\n        quality_scores[i] = (obj_i[0] + obj_i[1]) / (1 + dominance_counts[i])\n\n    # Weighted selection based on quality scores\n    weights = quality_scores / np.sum(quality_scores)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment quality based on combined distance and dominance\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(n // 2, int(np.random.normal(loc=n/4, scale=n/8))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score += (distance_matrix_1[u][v] + distance_matrix_2[u][v]) * (1 + quality_scores[selected_idx])\n        segment_scores.append((a, b, score))\n\n    # Select segment to reverse with highest score\n    segment_scores.sort(key=lambda x: -x[2])\n    if segment_scores:\n        a, b, _ = segment_scores[0]\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Conditional edge swapping\n    if n > 3:\n        # Find edges with high combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Swap two random nodes between c and d if it improves at least one objective\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if len(candidates) >= 2:\n                for _ in range(10):  # Try multiple swaps\n                    i, j = np.random.choice(candidates, size=2, replace=False)\n                    if i > j:\n                        i, j = j, i\n                    temp_solution = new_solution.copy()\n                    temp_solution[i], temp_solution[j] = temp_solution[j], temp_solution[i]\n\n                    temp_obj1 = sum(distance_matrix_1[temp_solution[k]][temp_solution[(k+1)%n]] for k in range(n))\n                    temp_obj2 = sum(distance_matrix_2[temp_solution[k]][temp_solution[(k+1)%n]] for k in range(n))\n\n                    if temp_obj1 <= sum(distance_matrix_1[new_solution[k]][new_solution[(k+1)%n]] for k in range(n)) or \\\n                       temp_obj2 <= sum(distance_matrix_2[new_solution[k]][new_solution[(k+1)%n]] for k in range(n)):\n                        new_solution = temp_solution\n                        break\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using weighted random selection that prioritizes non-dominated solutions with lower combined objective values, then applies a hybrid local search combining adaptive segment rotation (with segment size proportional to solution quality) and conditional edge insertion (only if it improves at least one objective). The rotation prioritizes high-distance segments, while the insertion targets high-distance edges, ensuring feasibility by maintaining valid TSP tours throughout.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values and Pareto dominance\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Lower combined objective is better\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n        # Boost weight for non-dominated solutions\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and (other_obj[0] <= obj[0] and other_obj[1] <= obj[1]) and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            weights[i] *= 1.5\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment quality based on combined distance\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score += distance_matrix_1[u][v] * distance_matrix_2[u][v]\n        segment_scores.append((a, b, score))\n\n    # Select segment to rotate with highest score\n    segment_scores.sort(key=lambda x: -x[2])\n    if segment_scores:\n        a, b, _ = segment_scores[0]\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional edge insertion\n    if n > 3:\n        # Find edges with high combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d if it improves at least one objective\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                for e in candidates:\n                    temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n                    temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n                       temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n                        new_solution = temp_solution\n                        break\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 70,
        "algorithm": "The algorithm selects a solution from the archive using diversity-aware weighted selection, prioritizing solutions with high objective variance and combined objective values, then applies a hybrid local search combining adaptive segment reversal (with segment size determined by objective imbalance) and conditional node swapping (only if it improves both objectives), ensuring feasibility by maintaining valid TSP tours throughout. The selection weights favor solutions with high variance and combined objective values, while the local search prioritizes segments and nodes with significant objective imbalance, ensuring both objectives are improved when possible.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Diversity-aware weighted selection\n    weights = np.zeros(len(archive))\n    objectives = np.array([obj for _, obj in archive])\n    mean_obj = np.mean(objectives, axis=0)\n    variance = np.var(objectives, axis=0)\n\n    for i, (_, obj) in enumerate(archive):\n        # Higher weight for solutions with high objective variance\n        weights[i] = np.sum((obj - mean_obj) ** 2) / np.sum(variance + 1e-6)\n        # Boost weight for solutions with high combined objective values\n        weights[i] *= (1.0 + np.sum(obj) / np.sum(mean_obj + 1e-6))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment quality based on objective imbalance\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(n // 3, int(np.random.exponential(scale=3))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            obj1 = distance_matrix_1[u][v]\n            obj2 = distance_matrix_2[u][v]\n            score += abs(obj1 - obj2) / (obj1 + obj2 + 1e-6)\n        segment_scores.append((a, b, score))\n\n    # Select segment to reverse with highest score\n    if segment_scores:\n        segment_scores.sort(key=lambda x: -x[2])\n        a, b, _ = segment_scores[0]\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Conditional node swapping\n    if n > 3:\n        # Find nodes with high objective imbalance\n        nodes = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            obj1 = distance_matrix_1[u][v]\n            obj2 = distance_matrix_2[u][v]\n            nodes.append((i, abs(obj1 - obj2) / (obj1 + obj2 + 1e-6)))\n\n        nodes.sort(key=lambda x: -x[1])\n        if nodes:\n            best_node = nodes[0][0]\n            candidates = [i for i in range(n) if i != best_node and abs(i - best_node) > 1]\n            if candidates:\n                for j in candidates:\n                    temp_solution = new_solution.copy()\n                    temp_solution[best_node], temp_solution[j] = temp_solution[j], temp_solution[best_node]\n                    temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    current_obj1 = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n                    current_obj2 = sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n                    if temp_obj1 <= current_obj1 and temp_obj2 <= current_obj2:\n                        new_solution = temp_solution\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.7643328851721451,
            6.062287509441376
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Diversity-aware weighted selection\n    weights = np.zeros(len(archive))\n    objectives = np.array([obj for _, obj in archive])\n    mean_obj = np.mean(objectives, axis=0)\n    variance = np.var(objectives, axis=0)\n\n    for i, (_, obj) in enumerate(archive):\n        # Higher weight for solutions with high objective variance\n        weights[i] = np.sum((obj - mean_obj) ** 2) / np.sum(variance + 1e-6)\n        # Boost weight for solutions with high combined objective values\n        weights[i] *= (1.0 + np.sum(obj) / np.sum(mean_obj + 1e-6))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment quality based on objective imbalance\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(n // 3, int(np.random.exponential(scale=3))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            obj1 = distance_matrix_1[u][v]\n            obj2 = distance_matrix_2[u][v]\n            score += abs(obj1 - obj2) / (obj1 + obj2 + 1e-6)\n        segment_scores.append((a, b, score))\n\n    # Select segment to reverse with highest score\n    if segment_scores:\n        segment_scores.sort(key=lambda x: -x[2])\n        a, b, _ = segment_scores[0]\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Conditional node swapping\n    if n > 3:\n        # Find nodes with high objective imbalance\n        nodes = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            obj1 = distance_matrix_1[u][v]\n            obj2 = distance_matrix_2[u][v]\n            nodes.append((i, abs(obj1 - obj2) / (obj1 + obj2 + 1e-6)))\n\n        nodes.sort(key=lambda x: -x[1])\n        if nodes:\n            best_node = nodes[0][0]\n            candidates = [i for i in range(n) if i != best_node and abs(i - best_node) > 1]\n            if candidates:\n                for j in candidates:\n                    temp_solution = new_solution.copy()\n                    temp_solution[best_node], temp_solution[j] = temp_solution[j], temp_solution[best_node]\n                    temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    current_obj1 = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n                    current_obj2 = sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n                    if temp_obj1 <= current_obj1 and temp_obj2 <= current_obj2:\n                        new_solution = temp_solution\n                        break\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using weighted random selection that prioritizes non-dominated solutions with lower combined objective values, then applies a hybrid local search combining adaptive segment rotation (with segment size proportional to solution quality) and conditional edge insertion (only if it improves at least one objective). The rotation prioritizes high-distance segments, while the insertion targets high-distance edges, ensuring feasibility by maintaining valid TSP tours throughout.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values and Pareto dominance\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Lower combined objective is better\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n        # Boost weight for non-dominated solutions\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and (other_obj[0] <= obj[0] and other_obj[1] <= obj[1]) and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            weights[i] *= 1.5\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment quality based on combined distance\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score += distance_matrix_1[u][v] * distance_matrix_2[u][v]\n        segment_scores.append((a, b, score))\n\n    # Select segment to rotate with highest score\n    segment_scores.sort(key=lambda x: -x[2])\n    if segment_scores:\n        a, b, _ = segment_scores[0]\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional edge insertion\n    if n > 3:\n        # Find edges with high combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d if it improves at least one objective\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                for e in candidates:\n                    temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n                    temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n                       temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n                        new_solution = temp_solution\n                        break\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThis heuristic selects a promising solution from the archive using tournament selection biased toward lower total costs, then applies a hybrid local search combining adaptive segment rotation (with variable segment size and rotation) and probabilistic edge relocation (prioritizing edges with high normalized distance products from both objectives). The method ensures feasibility by maintaining a valid TSP tour throughout all operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Tournament selection with quality bias\n    tournament_size = min(5, len(archive))\n    selected_idx = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_idx[np.argmin([np.sum(archive[i][1]) for i in selected_idx])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Probabilistic edge relocation\n    if n > 3:\n        normalized_distances = (distance_matrix_1 + distance_matrix_2) / (np.max(distance_matrix_1) + np.max(distance_matrix_2))\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(normalized_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        if n > 3:\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                probs = np.array([normalized_distances[new_solution[c]][new_solution[i]] *\n                                normalized_distances[new_solution[i]][new_solution[d]]\n                                for i in candidates])\n                probs = probs / np.sum(probs)\n                e = np.random.choice(candidates, p=probs)\n                new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 71,
        "algorithm": "The algorithm first selects a solution from the archive using weighted random selection that prioritizes non-dominated solutions with lower combined objective values, then applies a hybrid local search combining adaptive segment rotation (targeting high-distance segments) and conditional edge reversal (only if it improves at least one objective), ensuring feasibility through probabilistic edge reversal and segment reversal operations. The selection weights are boosted for non-dominated solutions, and segment sizes are adaptively determined based on solution quality and instance size.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values and Pareto dominance\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Lower combined objective is better\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n        # Boost weight for non-dominated solutions\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and (other_obj[0] <= obj[0] and other_obj[1] <= obj[1]) and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            weights[i] *= 1.5\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment quality based on combined distance product\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score += distance_matrix_1[u][v] * distance_matrix_2[u][v]\n        segment_scores.append((a, b, score))\n\n    # Select segment to rotate with highest score\n    segment_scores.sort(key=lambda x: -x[2])\n    if segment_scores:\n        a, b, _ = segment_scores[0]\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional edge reversal\n    if n > 3:\n        # Find edges with high combined distance product\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] * distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Reverse the segment between c and d if it improves at least one objective\n            temp_solution = new_solution.copy()\n            temp_solution[c:d+1] = new_solution[c:d+1][::-1]\n            temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n            temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n\n            if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n               temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n                new_solution = temp_solution\n\n    # Probabilistic edge reversal based on both objectives\n    if n > 4 and np.random.random() < 0.3:\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(distance_matrix_1[u][v] * distance_matrix_2[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        # Reverse the edge if it improves at least one objective\n        temp_solution = new_solution.copy()\n        temp_solution[c], temp_solution[d] = temp_solution[d], temp_solution[c]\n        temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n        temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n\n        if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n           temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.7722951072645385,
            1.0483579635620117
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values and Pareto dominance\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Lower combined objective is better\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n        # Boost weight for non-dominated solutions\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and (other_obj[0] <= obj[0] and other_obj[1] <= obj[1]) and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            weights[i] *= 1.5\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment quality based on combined distance product\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score += distance_matrix_1[u][v] * distance_matrix_2[u][v]\n        segment_scores.append((a, b, score))\n\n    # Select segment to rotate with highest score\n    segment_scores.sort(key=lambda x: -x[2])\n    if segment_scores:\n        a, b, _ = segment_scores[0]\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional edge reversal\n    if n > 3:\n        # Find edges with high combined distance product\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] * distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Reverse the segment between c and d if it improves at least one objective\n            temp_solution = new_solution.copy()\n            temp_solution[c:d+1] = new_solution[c:d+1][::-1]\n            temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n            temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n\n            if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n               temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n                new_solution = temp_solution\n\n    # Probabilistic edge reversal based on both objectives\n    if n > 4 and np.random.random() < 0.3:\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(distance_matrix_1[u][v] * distance_matrix_2[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        # Reverse the edge if it improves at least one objective\n        temp_solution = new_solution.copy()\n        temp_solution[c], temp_solution[d] = temp_solution[d], temp_solution[c]\n        temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n        temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n\n        if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n           temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 2 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    # Calculate crowding distance for Pareto front\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    # Build Pareto front\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s a concise response with 4 bullet points:\n\n- **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 72,
        "algorithm": "The algorithm combines Pareto-frontier selection with a weighted crowding distance to prioritize diverse, non-dominated solutions, then applies a hybrid local search featuring cost-sensitive edge exchanges, adaptive segment rotations, and conditional segment reversals to balance exploration and exploitation while ensuring feasibility. The method emphasizes edge weights based on combined objective distances and dynamically adjusts segment sizes for effective perturbation, with segment reversal only applied when it improves at least one objective.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-frontier selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_weighted_crowding(solutions):\n        distances = np.zeros(len(solutions))\n        weights = np.array([sol[1][0] + sol[1][1] for sol in solutions])\n        weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(len(solutions)) / len(solutions)\n\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in solutions])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(solutions)-1):\n                distances[sorted_idx[i]] += weights[sorted_idx[i]] * (solutions[sorted_idx[i+1]][1][m] - solutions[sorted_idx[i-1]][1][m]) / (max(solutions[sorted_idx[-1]][1][m], solutions[sorted_idx[0]][1][m]) - min(solutions[sorted_idx[-1]][1][m], solutions[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_weighted_crowding(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Cost-sensitive edge exchange\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights) if np.sum(edge_weights) > 0 else np.ones(n) / n\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances) if np.sum(candidate_distances) > 0 else np.ones(len(candidates)) / len(candidates)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Adaptive segment rotation with dynamic segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "score": [
            -0.9584489430097116,
            0.22718602418899536
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-frontier selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_weighted_crowding(solutions):\n        distances = np.zeros(len(solutions))\n        weights = np.array([sol[1][0] + sol[1][1] for sol in solutions])\n        weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(len(solutions)) / len(solutions)\n\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in solutions])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(solutions)-1):\n                distances[sorted_idx[i]] += weights[sorted_idx[i]] * (solutions[sorted_idx[i+1]][1][m] - solutions[sorted_idx[i-1]][1][m]) / (max(solutions[sorted_idx[-1]][1][m], solutions[sorted_idx[0]][1][m]) - min(solutions[sorted_idx[-1]][1][m], solutions[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_weighted_crowding(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Cost-sensitive edge exchange\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights) if np.sum(edge_weights) > 0 else np.ones(n) / n\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances) if np.sum(candidate_distances) > 0 else np.ones(len(candidates)) / len(candidates)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Adaptive segment rotation with dynamic segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The heuristic selects a promising solution from the archive (prioritizing non-dominated ones), then applies a hybrid local search combining segment reversal and dynamic reinsertion of high-scoring segments (based on normalized distance products), while conditionally reversing edges to improve at least one objective. It ensures feasibility by removing duplicates and falls back to random swaps if needed. The algorithm balances exploration (random segment selection) and exploitation (cost-aware edge prioritization) while maintaining valid TSP tours.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize non-dominated solutions\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n\n    if non_dominated:\n        selected_idx = random.choice(non_dominated)\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal + cost-aware edge prioritization\n    segment_scores = []\n    for i in range(n):\n        for j in range(i+2, min(i+10, n)):  # Limit segment length for efficiency\n            segment_length1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length1 += distance_matrix_1[new_solution[j], new_solution[i]] if j+1 < n else 0\n            segment_length2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(i, j+1))\n            segment_length2 += distance_matrix_2[new_solution[j], new_solution[i]] if j+1 < n else 0\n            normalized_score = - (segment_length1 * segment_length2)  # Higher score for shorter segments in both objectives\n            segment_scores.append((normalized_score, i, j))\n\n    if segment_scores:\n        segment_scores.sort(reverse=True)\n        _, best_i, best_j = segment_scores[0]\n        best_segment = new_solution[best_i:best_j+1]\n\n        # Dynamic reinsertion with feasibility check\n        new_pos = random.randint(0, n - len(best_segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            best_segment,\n            new_solution[new_pos:new_pos + len(best_segment)],\n            new_solution[new_pos + len(best_segment):]\n        ])\n\n        # Ensure feasibility by removing duplicates\n        unique_nodes = np.unique(new_solution)\n        if len(unique_nodes) != n:\n            missing_nodes = [node for node in range(n) if node not in unique_nodes]\n            new_solution = np.concatenate([unique_nodes, missing_nodes])\n\n    # Conditional edge reversal based on cost improvement\n    if n > 3:\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        old_length1 = distance_matrix_1[new_solution[a-1], new_solution[a]] + distance_matrix_1[new_solution[b], new_solution[(b+1)%n]]\n        new_length1 = distance_matrix_1[new_solution[a-1], new_solution[b]] + distance_matrix_1[new_solution[a], new_solution[(b+1)%n]]\n        old_length2 = distance_matrix_2[new_solution[a-1], new_solution[a]] + distance_matrix_2[new_solution[b], new_solution[(b+1)%n]]\n        new_length2 = distance_matrix_2[new_solution[a-1], new_solution[b]] + distance_matrix_2[new_solution[a], new_solution[(b+1)%n]]\n\n        if (new_length1 < old_length1 or new_length2 < old_length2):\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 73,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Simplified selection: choose the first non-dominated solution or random\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n            break  # Take the first non-dominated solution\n\n    if non_dominated:\n        selected_idx = non_dominated[0]\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Simplified local search: random segment swap\n    if n > 3:\n        i, j = sorted(random.sample(range(n), 2))\n        segment = new_solution[i:j+1]\n        new_pos = random.randint(0, n - len(segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            segment,\n            new_solution[new_pos:new_pos + len(segment)],\n            new_solution[new_pos + len(segment):]\n        ])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8296198028975874,
            0.25041520595550537
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Simplified selection: choose the first non-dominated solution or random\n    objectives = np.array([obj for _, obj in archive])\n    non_dominated = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append(i)\n            break  # Take the first non-dominated solution\n\n    if non_dominated:\n        selected_idx = non_dominated[0]\n    else:\n        selected_idx = random.randint(0, len(archive) - 1)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Simplified local search: random segment swap\n    if n > 3:\n        i, j = sorted(random.sample(range(n), 2))\n        segment = new_solution[i:j+1]\n        new_pos = random.randint(0, n - len(segment))\n        new_solution = np.concatenate([\n            new_solution[:new_pos],\n            segment,\n            new_solution[new_pos:new_pos + len(segment)],\n            new_solution[new_pos + len(segment):]\n        ])\n\n    # Final check and fallback\n    if len(np.unique(new_solution)) != n:\n        i, j = random.sample(range(n), 2)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm combines adaptive Pareto selection with a hybrid local search that prioritizes segment rotation, cost-aware edge insertion, and conditional segment reversal, while ensuring feasibility through probabilistic segment operations and edge weighting. It balances exploration and exploitation by dynamically adjusting segment sizes and using combined distance metrics to guide multi-objective improvements. The method intelligently selects edges and segments based on their potential for reducing tour lengths in both objective spaces, with segment reversal only applied when it improves at least one objective.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion\n    segment_size = max(2, min(n // 3, int(np.random.normal(loc=n//4, scale=n//6))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with dynamic range\n    reversal_range = max(2, min(n // 2, int(np.random.exponential(scale=n//3))))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s a concise response with 4 bullet points:\n\n- **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 74,
        "algorithm": "The algorithm combines diversity-aware selection with a hybrid local search that alternates between probabilistic segment swaps and cost-sensitive edge flips, prioritizing solutions with lower combined normalized objectives while ensuring feasibility through adaptive segment sizes and deterministic edge selection. It first selects a solution based on objective correlations and weights, then applies segment swaps only if they improve at least one objective, followed by edge flips based on multi-objective distance metrics, with edge selection probabilities proportional to combined distances. The method balances exploration and exploitation by dynamically adjusting segment sizes and edge selection criteria.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Diversity-aware selection based on objective correlations\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    obj_correlations = np.corrcoef(normalized_obj.T)[0, 1]\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1) * (1 - abs(obj_correlations)))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Step 2: Probabilistic segment swapping with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=np.log(n//4), sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(c - a) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Check if swap improves at least one objective\n    def compute_cost(solution, dist_matrix):\n        cost = 0\n        for i in range(n):\n            cost += dist_matrix[solution[i]][solution[(i+1)%n]]\n        return cost\n\n    original_cost1 = compute_cost(new_solution, distance_matrix_1)\n    original_cost2 = compute_cost(new_solution, distance_matrix_2)\n\n    temp_solution = new_solution.copy()\n    temp_solution[a:b+1], temp_solution[c:d+1] = temp_solution[c:d+1], temp_solution[a:b+1]\n    new_cost1 = compute_cost(temp_solution, distance_matrix_1)\n    new_cost2 = compute_cost(temp_solution, distance_matrix_2)\n\n    if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n        new_solution = temp_solution\n\n    # Step 3: Cost-sensitive edge flipping\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    a, b = selected_edge, (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (a, b, (a-1)%n, (b+1)%n)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[a]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[b]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        c = np.random.choice(candidates, p=candidate_weights)\n\n        # Flip edge if it improves at least one objective\n        temp_solution = new_solution.copy()\n        temp_solution[b] = new_solution[c]\n        new_cost1 = compute_cost(temp_solution, distance_matrix_1)\n        new_cost2 = compute_cost(temp_solution, distance_matrix_2)\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.8588250327772223,
            0.49132633209228516
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Diversity-aware selection based on objective correlations\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    obj_correlations = np.corrcoef(normalized_obj.T)[0, 1]\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1) * (1 - abs(obj_correlations)))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Step 2: Probabilistic segment swapping with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=np.log(n//4), sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(c - a) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Check if swap improves at least one objective\n    def compute_cost(solution, dist_matrix):\n        cost = 0\n        for i in range(n):\n            cost += dist_matrix[solution[i]][solution[(i+1)%n]]\n        return cost\n\n    original_cost1 = compute_cost(new_solution, distance_matrix_1)\n    original_cost2 = compute_cost(new_solution, distance_matrix_2)\n\n    temp_solution = new_solution.copy()\n    temp_solution[a:b+1], temp_solution[c:d+1] = temp_solution[c:d+1], temp_solution[a:b+1]\n    new_cost1 = compute_cost(temp_solution, distance_matrix_1)\n    new_cost2 = compute_cost(temp_solution, distance_matrix_2)\n\n    if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n        new_solution = temp_solution\n\n    # Step 3: Cost-sensitive edge flipping\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    a, b = selected_edge, (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (a, b, (a-1)%n, (b+1)%n)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[a]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[b]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        c = np.random.choice(candidates, p=candidate_weights)\n\n        # Flip edge if it improves at least one objective\n        temp_solution = new_solution.copy()\n        temp_solution[b] = new_solution[c]\n        new_cost1 = compute_cost(temp_solution, distance_matrix_1)\n        new_cost2 = compute_cost(temp_solution, distance_matrix_2)\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution = temp_solution\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion\n    segment_size = max(2, min(n // 3, int(np.random.normal(loc=n//4, scale=n//6))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with dynamic range\n    reversal_range = max(2, min(n // 2, int(np.random.exponential(scale=n//3))))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 75,
        "algorithm": "The algorithm combines adaptive solution selection with a hybrid local search that dynamically alternates between segment-based reinsertion and edge-based reversal, using quality-aware perturbation mechanisms that adjust segment sizes and reversal ranges based on normalized objective values, while ensuring feasibility through deterministic validation checks. It prioritizes solutions with lower combined objective scores (weighted randomly between 0.5 and 1.0) and dynamically scales perturbation sizes inversely with solution quality, balancing exploration and exploitation. The algorithm ensures feasibility by validating all moves through complete tour reconstruction and cost evaluation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Quality-aware solution selection\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Normalize objectives and compute quality scores\n    min_obj = np.min(objectives, axis=0)\n    max_obj = np.max(objectives, axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n\n    # Combine objectives with adaptive weights\n    obj_weights = 0.5 + 0.5 * np.random.random(2)  # Random weights between 0.5 and 1.0\n    combined_scores = np.dot(normalized_obj, obj_weights)\n    selection_probs = np.exp(-combined_scores) / np.sum(np.exp(-combined_scores))\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion with quality feedback\n    avg_obj = np.mean(normalized_obj[selected_idx])\n    segment_size = max(2, min(n // 2, int(np.random.normal(loc=n//3, scale=n//5) * (1 - avg_obj))))\n\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    remaining = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n\n    # Find optimal insertion position based on both objectives\n    min_total_cost = float('inf')\n    best_pos = 0\n\n    for i in range(len(remaining) - segment_size + 2):\n        candidate = np.concatenate([remaining[:i], segment, remaining[i:]])\n\n        # Calculate total cost in both objective spaces\n        cost1 = sum(distance_matrix_1[candidate[i], candidate[i+1]] for i in range(n-1))\n        cost1 += distance_matrix_1[candidate[-1], candidate[0]]\n\n        cost2 = sum(distance_matrix_2[candidate[i], candidate[i+1]] for i in range(n-1))\n        cost2 += distance_matrix_2[candidate[-1], candidate[0]]\n\n        total_cost = cost1 + cost2\n\n        if total_cost < min_total_cost:\n            min_total_cost = total_cost\n            best_pos = i\n\n    new_solution = np.concatenate([remaining[:best_pos], segment, remaining[best_pos:]])\n\n    # Step 3: Edge-based reversal with adaptive range\n    reversal_range = max(2, min(n // 2, int(np.random.exponential(scale=n//4) * (1 - avg_obj))))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n\n    # Evaluate reversal impact\n    original_cost = (sum(distance_matrix_1[new_solution[i], new_solution[i+1]] for i in range(n-1)) +\n                     distance_matrix_1[new_solution[-1], new_solution[0]] +\n                     sum(distance_matrix_2[new_solution[i], new_solution[i+1]] for i in range(n-1)) +\n                     distance_matrix_2[new_solution[-1], new_solution[0]])\n\n    reversed_segment = new_solution[c:d+1][::-1]\n    candidate = np.concatenate([new_solution[:c], reversed_segment, new_solution[d+1:]])\n\n    reversed_cost = (sum(distance_matrix_1[candidate[i], candidate[i+1]] for i in range(n-1)) +\n                     distance_matrix_1[candidate[-1], candidate[0]] +\n                     sum(distance_matrix_2[candidate[i], candidate[i+1]] for i in range(n-1)) +\n                     distance_matrix_2[candidate[-1], candidate[0]])\n\n    if reversed_cost < original_cost:\n        new_solution = candidate\n\n    return new_solution\n\n",
        "score": [
            -0.8186468588549398,
            2.4691901803016663
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Quality-aware solution selection\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Normalize objectives and compute quality scores\n    min_obj = np.min(objectives, axis=0)\n    max_obj = np.max(objectives, axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n\n    # Combine objectives with adaptive weights\n    obj_weights = 0.5 + 0.5 * np.random.random(2)  # Random weights between 0.5 and 1.0\n    combined_scores = np.dot(normalized_obj, obj_weights)\n    selection_probs = np.exp(-combined_scores) / np.sum(np.exp(-combined_scores))\n    selected_idx = np.random.choice(len(archive), p=selection_probs)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion with quality feedback\n    avg_obj = np.mean(normalized_obj[selected_idx])\n    segment_size = max(2, min(n // 2, int(np.random.normal(loc=n//3, scale=n//5) * (1 - avg_obj))))\n\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    remaining = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n\n    # Find optimal insertion position based on both objectives\n    min_total_cost = float('inf')\n    best_pos = 0\n\n    for i in range(len(remaining) - segment_size + 2):\n        candidate = np.concatenate([remaining[:i], segment, remaining[i:]])\n\n        # Calculate total cost in both objective spaces\n        cost1 = sum(distance_matrix_1[candidate[i], candidate[i+1]] for i in range(n-1))\n        cost1 += distance_matrix_1[candidate[-1], candidate[0]]\n\n        cost2 = sum(distance_matrix_2[candidate[i], candidate[i+1]] for i in range(n-1))\n        cost2 += distance_matrix_2[candidate[-1], candidate[0]]\n\n        total_cost = cost1 + cost2\n\n        if total_cost < min_total_cost:\n            min_total_cost = total_cost\n            best_pos = i\n\n    new_solution = np.concatenate([remaining[:best_pos], segment, remaining[best_pos:]])\n\n    # Step 3: Edge-based reversal with adaptive range\n    reversal_range = max(2, min(n // 2, int(np.random.exponential(scale=n//4) * (1 - avg_obj))))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n\n    # Evaluate reversal impact\n    original_cost = (sum(distance_matrix_1[new_solution[i], new_solution[i+1]] for i in range(n-1)) +\n                     distance_matrix_1[new_solution[-1], new_solution[0]] +\n                     sum(distance_matrix_2[new_solution[i], new_solution[i+1]] for i in range(n-1)) +\n                     distance_matrix_2[new_solution[-1], new_solution[0]])\n\n    reversed_segment = new_solution[c:d+1][::-1]\n    candidate = np.concatenate([new_solution[:c], reversed_segment, new_solution[d+1:]])\n\n    reversed_cost = (sum(distance_matrix_1[candidate[i], candidate[i+1]] for i in range(n-1)) +\n                     distance_matrix_1[candidate[-1], candidate[0]] +\n                     sum(distance_matrix_2[candidate[i], candidate[i+1]] for i in range(n-1)) +\n                     distance_matrix_2[candidate[-1], candidate[0]])\n\n    if reversed_cost < original_cost:\n        new_solution = candidate\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion\n    segment_size = max(2, min(n // 3, int(np.random.normal(loc=n//4, scale=n//6))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with dynamic range\n    reversal_range = max(2, min(n // 2, int(np.random.exponential(scale=n//3))))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 76,
        "algorithm": "The algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization. The algorithm selects a base solution from the archive using weighted random selection based on normalized objectives, then applies segment reinsertion, edge reversal, and optional node swaps to generate a neighbor solution while maintaining tour validity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion with adaptive size\n    segment_size = max(3, min(n // 2, int(np.random.lognormal(mean=np.log(n//3), sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with probabilistic range selection\n    reversal_range = max(3, min(n // 3, int(np.random.pareto(a=2) + 2)))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node swap for additional diversification\n    if np.random.rand() < 0.3:\n        swap_pos1, swap_pos2 = np.random.choice(n, size=2, replace=False)\n        new_solution[swap_pos1], new_solution[swap_pos2] = new_solution[swap_pos2], new_solution[swap_pos1]\n\n    return new_solution\n\n",
        "score": [
            -0.9397043057940806,
            0.4917113780975342
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion with adaptive size\n    segment_size = max(3, min(n // 2, int(np.random.lognormal(mean=np.log(n//3), sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with probabilistic range selection\n    reversal_range = max(3, min(n // 3, int(np.random.pareto(a=2) + 2)))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node swap for additional diversification\n    if np.random.rand() < 0.3:\n        swap_pos1, swap_pos2 = np.random.choice(n, size=2, replace=False)\n        new_solution[swap_pos1], new_solution[swap_pos2] = new_solution[swap_pos2], new_solution[swap_pos1]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 3 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion\n    segment_size = max(2, min(n // 3, int(np.random.normal(loc=n//4, scale=n//6))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with dynamic range\n    reversal_range = max(2, min(n // 2, int(np.random.exponential(scale=n//3))))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s a concise response with 4 bullet points:\n\n- **Keywords**: Adaptive selection, hybrid perturbation, cost-aware operators, Pareto dominance, segment-based mutation.\n- **Advice**: Combine weighted selection (e.g., Pareto dominance) with segment rotation/insertion to balance exploration/exploitation. Use conditional edge reversal only if it improves at least one objective.\n- **Avoid**: Static operators (e.g., fixed-length 2-opt), greedy single-objective optimization, and non-adaptive selection.\n- **Explanation**: This approach ensures diversity by adaptively selecting high-potential solutions and applying targeted perturbations, while feasibility checks guarantee valid tours.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 77,
        "algorithm": "The algorithm first selects a promising solution from the archive using Pareto dominance-based weighting (prioritizing solutions with lower combined normalized objectives), then applies a hybrid local search combining adaptive segment rotation (with segment sizes determined probabilistically) and conditional edge reversal (only if it improves at least one objective), ensuring feasibility by carefully selecting segments and edges. The selection prioritizes high-potential solutions, while the hybrid search explores diverse modifications while targeting improvements.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto dominance-based weighted selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 2, int(np.random.normal(loc=n//3, scale=n//6))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    rotated_segment = np.roll(segment, np.random.randint(1, segment_size))\n    new_solution[a:a+segment_size] = rotated_segment\n\n    # Conditional edge reversal\n    if n > 3:\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            cost1 = distance_matrix_1[u][v]\n            cost2 = distance_matrix_2[u][v]\n            edges.append((i, (i+1)%n, cost1, cost2))\n\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            for j in range(i+2, n):\n                x = new_solution[j]\n                y = new_solution[(j+1)%n]\n                if i != j and (i+1)%n != j and (j+1)%n != i:\n                    # Calculate potential new edges\n                    new_cost1 = distance_matrix_1[u][x] + distance_matrix_1[y][v]\n                    new_cost2 = distance_matrix_2[u][x] + distance_matrix_2[y][v]\n                    old_cost1 = distance_matrix_1[u][v] + distance_matrix_1[x][y]\n                    old_cost2 = distance_matrix_2[u][v] + distance_matrix_2[x][y]\n\n                    if (new_cost1 < old_cost1 or new_cost2 < old_cost2):\n                        # Perform edge reversal\n                        new_solution[i+1:j+1] = new_solution[i+1:j+1][::-1]\n                        break\n\n    return new_solution\n\n",
        "score": [
            -0.7822738956692921,
            0.8334804177284241
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto dominance-based weighted selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 2, int(np.random.normal(loc=n//3, scale=n//6))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    rotated_segment = np.roll(segment, np.random.randint(1, segment_size))\n    new_solution[a:a+segment_size] = rotated_segment\n\n    # Conditional edge reversal\n    if n > 3:\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            cost1 = distance_matrix_1[u][v]\n            cost2 = distance_matrix_2[u][v]\n            edges.append((i, (i+1)%n, cost1, cost2))\n\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            for j in range(i+2, n):\n                x = new_solution[j]\n                y = new_solution[(j+1)%n]\n                if i != j and (i+1)%n != j and (j+1)%n != i:\n                    # Calculate potential new edges\n                    new_cost1 = distance_matrix_1[u][x] + distance_matrix_1[y][v]\n                    new_cost2 = distance_matrix_2[u][x] + distance_matrix_2[y][v]\n                    old_cost1 = distance_matrix_1[u][v] + distance_matrix_1[x][y]\n                    old_cost2 = distance_matrix_2[u][v] + distance_matrix_2[x][y]\n\n                    if (new_cost1 < old_cost1 or new_cost2 < old_cost2):\n                        # Perform edge reversal\n                        new_solution[i+1:j+1] = new_solution[i+1:j+1][::-1]\n                        break\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    # Calculate crowding distance for Pareto front\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    # Build Pareto front\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines Pareto-frontier selection with a weighted crowding distance to prioritize diverse, non-dominated solutions, then applies a hybrid local search featuring cost-sensitive edge exchanges, adaptive segment rotations, and conditional segment reversals to balance exploration and exploitation while ensuring feasibility. The method emphasizes edge weights based on combined objective distances and dynamically adjusts segment sizes for effective perturbation, with segment reversal only applied when it improves at least one objective.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-frontier selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_weighted_crowding(solutions):\n        distances = np.zeros(len(solutions))\n        weights = np.array([sol[1][0] + sol[1][1] for sol in solutions])\n        weights = weights / np.sum(weights) if np.sum(weights) > 0 else np.ones(len(solutions)) / len(solutions)\n\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in solutions])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(solutions)-1):\n                distances[sorted_idx[i]] += weights[sorted_idx[i]] * (solutions[sorted_idx[i+1]][1][m] - solutions[sorted_idx[i-1]][1][m]) / (max(solutions[sorted_idx[-1]][1][m], solutions[sorted_idx[0]][1][m]) - min(solutions[sorted_idx[-1]][1][m], solutions[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_weighted_crowding(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Cost-sensitive edge exchange\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights) if np.sum(edge_weights) > 0 else np.ones(n) / n\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances) if np.sum(candidate_distances) > 0 else np.ones(len(candidates)) / len(candidates)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Adaptive segment rotation with dynamic segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s a refined heuristic design addressing the bi-objective TSP challenge:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\n```python\nimport numpy as np\nimport random\n\ndef select_neighbor(archive, objectives):\n    # Step 1: Adaptive Pareto selection\n    nondominated = [i for i in range(len(archive)) if not any(\n        all(objectives[i][k] >= objectives[j][k] for k in range(2)) and\n        any(objectives[i][k] > objectives[j][k] for k in range(2))\n        for j in range(len(archive)) if j != i\n    )]\n\n    # Step 2: Weighted selection (crowding distance)\n    if len(nondominated) > 1:\n        selected_idx = random.choices(\n            nondominated,\n            weights=[sum(objectives[i]) for i in nondominated],\n            k=1\n        )[0]\n    else:\n        selected_idx = random.choice(nondominated)\n\n    tour = archive[selected_idx].copy()\n    n = len(tour)\n\n    # Step 3: Hybrid local search\n    # Segment rotation\n    a, b = sorted(random.sample(range(n), 2))\n    segment = tour[a:b]\n    if random.random() < 0.5:  # Reverse with 50% probability\n        segment = segment[::-1]\n    else:  # Rotate by random offset\n        offset = random.randint(1, len(segment)-1)\n        segment = segment[offset:] + segment[:offset]\n    new_tour = np.concatenate([tour[:a], segment, tour[b:]])\n\n    # Conditional edge reversal\n    for _ in range(2):  # Try 2 random edges\n        i, j = sorted(random.sample(range(n), 2))\n        if (objectives[selected_idx][0] * objectives[selected_idx][1] >\n            (objectives[selected_idx][0] + objectives[selected_idx][1]) / 2):\n            new_tour[i:j] = new_tour[i:j][::-1]  # Reverse if cost-sensitive\n\n    # Feasibility check\n    if len(set(new_tour)) != n:\n        return tour  # Revert if invalid\n    return new_tour\n```\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 78,
        "algorithm": "This algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "score": [
            -0.9643742433955875,
            0.20593953132629395
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using weighted random selection that prioritizes non-dominated solutions with lower combined objective values, then applies a hybrid local search combining adaptive segment rotation (with segment size proportional to solution quality) and conditional edge insertion (only if it improves at least one objective). The rotation prioritizes high-distance segments, while the insertion targets high-distance edges, ensuring feasibility by maintaining valid TSP tours throughout.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values and Pareto dominance\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Lower combined objective is better\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n        # Boost weight for non-dominated solutions\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and (other_obj[0] <= obj[0] and other_obj[1] <= obj[1]) and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            weights[i] *= 1.5\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment quality based on combined distance\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score += distance_matrix_1[u][v] * distance_matrix_2[u][v]\n        segment_scores.append((a, b, score))\n\n    # Select segment to rotate with highest score\n    segment_scores.sort(key=lambda x: -x[2])\n    if segment_scores:\n        a, b, _ = segment_scores[0]\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional edge insertion\n    if n > 3:\n        # Find edges with high combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d if it improves at least one objective\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                for e in candidates:\n                    temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n                    temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n                       temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n                        new_solution = temp_solution\n                        break\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 79,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute combined weights for selection\n    weights = np.array([1.0 / (1.0 + np.sum(obj)) for sol, obj in archive])\n    is_nondominated = np.ones(len(archive), dtype=bool)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (archive[j][1][0] <= archive[i][1][0] and archive[j][1][1] <= archive[i][1][1]) and (archive[j][1][0] < archive[i][1][0] or archive[j][1][1] < archive[i][1][1]):\n                is_nondominated[i] = False\n                break\n    weights[is_nondominated] *= 1.5\n    weights /= np.sum(weights)\n\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Optimized segment selection and rotation\n    max_segment_size = min(n // 2, 10)\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(max_segment_size, int(np.random.exponential(scale=2))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score += distance_matrix_1[u][v] + distance_matrix_2[u][v]\n        segment_scores.append((a, b, score))\n\n    segment_scores.sort(key=lambda x: -x[2])\n    if segment_scores:\n        a, b, _ = segment_scores[0]\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Optimized edge insertion\n    if n > 3:\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            c, d, _ = edges[0]\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                e = np.random.choice(candidates)\n                temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n                temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n                   temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n                    new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.878815255385339,
            0.6705710291862488
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute combined weights for selection\n    weights = np.array([1.0 / (1.0 + np.sum(obj)) for sol, obj in archive])\n    is_nondominated = np.ones(len(archive), dtype=bool)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (archive[j][1][0] <= archive[i][1][0] and archive[j][1][1] <= archive[i][1][1]) and (archive[j][1][0] < archive[i][1][0] or archive[j][1][1] < archive[i][1][1]):\n                is_nondominated[i] = False\n                break\n    weights[is_nondominated] *= 1.5\n    weights /= np.sum(weights)\n\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Optimized segment selection and rotation\n    max_segment_size = min(n // 2, 10)\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(max_segment_size, int(np.random.exponential(scale=2))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score += distance_matrix_1[u][v] + distance_matrix_2[u][v]\n        segment_scores.append((a, b, score))\n\n    segment_scores.sort(key=lambda x: -x[2])\n    if segment_scores:\n        a, b, _ = segment_scores[0]\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Optimized edge insertion\n    if n > 3:\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            c, d, _ = edges[0]\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                e = np.random.choice(candidates)\n                temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n                temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n                   temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n                    new_solution = temp_solution\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThis algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s a refined heuristic design addressing the bi-objective TSP challenge:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\n```python\nimport numpy as np\nimport random\n\ndef select_neighbor(archive, objectives):\n    # Step 1: Adaptive Pareto selection\n    nondominated = [i for i in range(len(archive)) if not any(\n        all(objectives[i][k] >= objectives[j][k] for k in range(2)) and\n        any(objectives[i][k] > objectives[j][k] for k in range(2))\n        for j in range(len(archive)) if j != i\n    )]\n\n    # Step 2: Weighted selection (crowding distance)\n    if len(nondominated) > 1:\n        selected_idx = random.choices(\n            nondominated,\n            weights=[sum(objectives[i]) for i in nondominated],\n            k=1\n        )[0]\n    else:\n        selected_idx = random.choice(nondominated)\n\n    tour = archive[selected_idx].copy()\n    n = len(tour)\n\n    # Step 3: Hybrid local search\n    # Segment rotation\n    a, b = sorted(random.sample(range(n), 2))\n    segment = tour[a:b]\n    if random.random() < 0.5:  # Reverse with 50% probability\n        segment = segment[::-1]\n    else:  # Rotate by random offset\n        offset = random.randint(1, len(segment)-1)\n        segment = segment[offset:] + segment[:offset]\n    new_tour = np.concatenate([tour[:a], segment, tour[b:]])\n\n    # Conditional edge reversal\n    for _ in range(2):  # Try 2 random edges\n        i, j = sorted(random.sample(range(n), 2))\n        if (objectives[selected_idx][0] * objectives[selected_idx][1] >\n            (objectives[selected_idx][0] + objectives[selected_idx][1]) / 2):\n            new_tour[i:j] = new_tour[i:j][::-1]  # Reverse if cost-sensitive\n\n    # Feasibility check\n    if len(set(new_tour)) != n:\n        return tour  # Revert if invalid\n    return new_tour\n```\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 80,
        "algorithm": "The algorithm combines adaptive Pareto selection with crowding distance to prioritize non-dominated, well-distributed solutions, then applies a hybrid local search that alternates between segment rotations (for large-scale perturbations) and edge insertions (for targeted improvements), weighted by combined edge distances from both objectives. It ensures feasibility through validation and conditional edge reversals, with operation probabilities dynamically adjusted based on problem size. The selection and search balance exploration (via Pareto dominance) and exploitation (via weighted edge operations), while maintaining tour validity through multi-step checks.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with crowding distance\n    objectives = [obj for _, obj in archive]\n    nondominated = []\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and all(objectives[i][k] >= objectives[j][k] for k in range(2)) and any(objectives[i][k] > objectives[j][k] for k in range(2)):\n                dominated = True\n                break\n        if not dominated:\n            nondominated.append(i)\n\n    if not nondominated:\n        selected_idx = np.argmin([sum(obj) for _, obj in archive])\n    else:\n        if len(nondominated) > 1:\n            crowding_distances = np.zeros(len(nondominated))\n            for m in range(2):\n                sorted_idx = np.argsort([objectives[i][m] for i in nondominated])\n                crowding_distances[sorted_idx[0]] = crowding_distances[sorted_idx[-1]] = float('inf')\n                for i in range(1, len(nondominated)-1):\n                    crowding_distances[sorted_idx[i]] += (objectives[nondominated[sorted_idx[i+1]]][m] - objectives[nondominated[sorted_idx[i-1]]][m]) / (objectives[nondominated[sorted_idx[-1]]][m] - objectives[nondominated[sorted_idx[0]]][m] + 1e-10)\n            selected_idx = nondominated[np.argmax(crowding_distances)]\n        else:\n            selected_idx = nondominated[0]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation or edge insertion based on probability\n    operation_prob = 0.7 if n > 5 else 0.5\n    if np.random.rand() < operation_prob:\n        # Segment rotation\n        segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n        rotation = np.random.randint(1, segment_size)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n    else:\n        # Edge insertion\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = np.array([combined_distances[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)])\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] + combined_distances[new_solution[i]][new_solution[d]] for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Multi-step validation\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    # Conditional edge reversal\n    if n > 4 and np.random.rand() < 0.4:\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        original_cost1 = distance_matrix_1[new_solution[i]][new_solution[(i-1)%n]] + distance_matrix_1[new_solution[j]][new_solution[(j+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[i]][new_solution[(i-1)%n]] + distance_matrix_2[new_solution[j]][new_solution[(j+1)%n]]\n\n        reversed_segment = new_solution[i:j+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(i-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(j+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(i-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(j+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[i:j+1] = reversed_segment\n\n    return new_solution\n\n",
        "score": [
            -0.7351790344165975,
            0.8454586863517761
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with crowding distance\n    objectives = [obj for _, obj in archive]\n    nondominated = []\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and all(objectives[i][k] >= objectives[j][k] for k in range(2)) and any(objectives[i][k] > objectives[j][k] for k in range(2)):\n                dominated = True\n                break\n        if not dominated:\n            nondominated.append(i)\n\n    if not nondominated:\n        selected_idx = np.argmin([sum(obj) for _, obj in archive])\n    else:\n        if len(nondominated) > 1:\n            crowding_distances = np.zeros(len(nondominated))\n            for m in range(2):\n                sorted_idx = np.argsort([objectives[i][m] for i in nondominated])\n                crowding_distances[sorted_idx[0]] = crowding_distances[sorted_idx[-1]] = float('inf')\n                for i in range(1, len(nondominated)-1):\n                    crowding_distances[sorted_idx[i]] += (objectives[nondominated[sorted_idx[i+1]]][m] - objectives[nondominated[sorted_idx[i-1]]][m]) / (objectives[nondominated[sorted_idx[-1]]][m] - objectives[nondominated[sorted_idx[0]]][m] + 1e-10)\n            selected_idx = nondominated[np.argmax(crowding_distances)]\n        else:\n            selected_idx = nondominated[0]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation or edge insertion based on probability\n    operation_prob = 0.7 if n > 5 else 0.5\n    if np.random.rand() < operation_prob:\n        # Segment rotation\n        segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n        rotation = np.random.randint(1, segment_size)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n    else:\n        # Edge insertion\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = np.array([combined_distances[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)])\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] + combined_distances[new_solution[i]][new_solution[d]] for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Multi-step validation\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    # Conditional edge reversal\n    if n > 4 and np.random.rand() < 0.4:\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        original_cost1 = distance_matrix_1[new_solution[i]][new_solution[(i-1)%n]] + distance_matrix_1[new_solution[j]][new_solution[(j+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[i]][new_solution[(i-1)%n]] + distance_matrix_2[new_solution[j]][new_solution[(j+1)%n]]\n\n        reversed_segment = new_solution[i:j+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(i-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(j+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(i-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(j+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[i:j+1] = reversed_segment\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        This algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 81,
        "algorithm": "This algorithm combines adaptive Pareto front selection with dynamic segment swaps, cost-weighted edge operations, and probabilistic segment insertions to generate high-quality neighbors by prioritizing solutions with lower Pareto ranks and using multi-objective-aware local search operations that balance exploration and exploitation. It dynamically adjusts segment sizes and insertion probabilities while maintaining feasibility, with cost-sensitive prioritization of edges and segments to guide the search toward improved solutions. The algorithm avoids 2-opt by using segment-based operations and multi-objective improvement checks to explore the solution space more effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto front selection with dynamic ranking\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_pareto_rank(pop):\n        ranks = np.zeros(len(pop))\n        for i in range(len(pop)):\n            for j in range(len(pop)):\n                if i == j:\n                    continue\n                if (pop[j][1][0] <= pop[i][1][0] and pop[j][1][1] <= pop[i][1][1]) and \\\n                   (pop[j][1][0] < pop[i][1][0] or pop[j][1][1] < pop[i][1][1]):\n                    ranks[i] += 1\n        return ranks\n\n    ranks = calculate_pareto_rank([archive[i] for i in selected_indices])\n    selected_idx = selected_indices[np.argmin(ranks)]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with cost-sensitive prioritization\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=1.0))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    segment_cost = 0\n    for i in range(a, b+1):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        segment_cost += combined_distances[u][v]\n\n    if segment_cost > 0:\n        swap_prob = 1.0 / (1.0 + np.exp(-0.1 * (segment_cost - np.mean(combined_distances))))\n\n        if np.random.rand() < swap_prob:\n            c = np.random.randint(0, n - segment_size + 1)\n            d = c + segment_size - 1\n            new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1].copy(), new_solution[a:b+1].copy()\n\n    # Cost-weighted edge selection and insertion\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    if np.sum(edge_weights) > 0:\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if len(candidates) > 1:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Probabilistic segment insertion with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 3, int(np.random.exponential(scale=0.8))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        segment = new_solution[a:b+1]\n        c = np.random.randint(0, n - segment_size + 1)\n        if c != a:\n            new_solution = np.concatenate([new_solution[:a], new_solution[b+1:c], segment, new_solution[c:]])\n\n            new_cost1 = distance_matrix_1[new_solution[(c-1)%n]][new_solution[c]] + distance_matrix_1[new_solution[c+len(segment)-1]][new_solution[(c+len(segment))%n]]\n            new_cost2 = distance_matrix_2[new_solution[(c-1)%n]][new_solution[c]] + distance_matrix_2[new_solution[c+len(segment)-1]][new_solution[(c+len(segment))%n]]\n\n            if (new_cost1 < original_cost1 and new_cost2 <= original_cost2 + 0.05) or \\\n               (new_cost2 < original_cost2 and new_cost1 <= original_cost1 + 0.05):\n                pass\n            else:\n                new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7602850140527084,
            0.5249034762382507
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto front selection with dynamic ranking\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_pareto_rank(pop):\n        ranks = np.zeros(len(pop))\n        for i in range(len(pop)):\n            for j in range(len(pop)):\n                if i == j:\n                    continue\n                if (pop[j][1][0] <= pop[i][1][0] and pop[j][1][1] <= pop[i][1][1]) and \\\n                   (pop[j][1][0] < pop[i][1][0] or pop[j][1][1] < pop[i][1][1]):\n                    ranks[i] += 1\n        return ranks\n\n    ranks = calculate_pareto_rank([archive[i] for i in selected_indices])\n    selected_idx = selected_indices[np.argmin(ranks)]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with cost-sensitive prioritization\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=1.0))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    segment_cost = 0\n    for i in range(a, b+1):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        segment_cost += combined_distances[u][v]\n\n    if segment_cost > 0:\n        swap_prob = 1.0 / (1.0 + np.exp(-0.1 * (segment_cost - np.mean(combined_distances))))\n\n        if np.random.rand() < swap_prob:\n            c = np.random.randint(0, n - segment_size + 1)\n            d = c + segment_size - 1\n            new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1].copy(), new_solution[a:b+1].copy()\n\n    # Cost-weighted edge selection and insertion\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    if np.sum(edge_weights) > 0:\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if len(candidates) > 1:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Probabilistic segment insertion with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 3, int(np.random.exponential(scale=0.8))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        segment = new_solution[a:b+1]\n        c = np.random.randint(0, n - segment_size + 1)\n        if c != a:\n            new_solution = np.concatenate([new_solution[:a], new_solution[b+1:c], segment, new_solution[c:]])\n\n            new_cost1 = distance_matrix_1[new_solution[(c-1)%n]][new_solution[c]] + distance_matrix_1[new_solution[c+len(segment)-1]][new_solution[(c+len(segment))%n]]\n            new_cost2 = distance_matrix_2[new_solution[(c-1)%n]][new_solution[c]] + distance_matrix_2[new_solution[c+len(segment)-1]][new_solution[(c+len(segment))%n]]\n\n            if (new_cost1 < original_cost1 and new_cost2 <= original_cost2 + 0.05) or \\\n               (new_cost2 < original_cost2 and new_cost1 <= original_cost1 + 0.05):\n                pass\n            else:\n                new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        This algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 82,
        "algorithm": "This algorithm employs adaptive multi-objective selection with probabilistic dominance checks to choose promising solutions from an archive, then applies dynamic segment swaps and cost-sensitive edge insertions to generate improved neighbors while maintaining feasibility. It prioritizes solutions with better objective values but occasionally selects non-dominated ones with a small probability, and uses lognormal-distributed segment sizes for adaptive exploration. The local search combines segment swaps (if they improve at least one objective) with edge insertions weighted by combined distance costs to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1]) or \\\n           (current[1][0] <= best[1][0] and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.2:  # Small chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=0.5, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    # Cost-sensitive edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "score": [
            -0.8671557199544548,
            0.18115627765655518
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1]) or \\\n           (current[1][0] <= best[1][0] and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.2:  # Small chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=0.5, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    # Cost-sensitive edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        This algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 82,
        "algorithm": "This algorithm employs adaptive multi-objective selection with probabilistic dominance checks to choose promising solutions from an archive, then applies dynamic segment swaps and cost-sensitive edge insertions to generate improved neighbors while maintaining feasibility. It prioritizes solutions with better objective values but occasionally selects non-dominated ones with a small probability, and uses lognormal-distributed segment sizes for adaptive exploration. The local search combines segment swaps (if they improve at least one objective) with edge insertions weighted by combined distance costs to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1]) or \\\n           (current[1][0] <= best[1][0] and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.2:  # Small chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=0.5, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    # Cost-sensitive edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "score": [
            -0.8671557199544548,
            0.18115627765655518
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1]) or \\\n           (current[1][0] <= best[1][0] and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.2:  # Small chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=0.5, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    # Cost-sensitive edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThis algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion\n    segment_size = max(2, min(n // 3, int(np.random.normal(loc=n//4, scale=n//6))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with dynamic range\n    reversal_range = max(2, min(n // 2, int(np.random.exponential(scale=n//3))))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s a refined heuristic design addressing the bi-objective TSP challenge:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\n```python\nimport numpy as np\nimport random\n\ndef select_neighbor(archive, objectives):\n    # Step 1: Adaptive Pareto selection\n    nondominated = [i for i in range(len(archive)) if not any(\n        all(objectives[i][k] >= objectives[j][k] for k in range(2)) and\n        any(objectives[i][k] > objectives[j][k] for k in range(2))\n        for j in range(len(archive)) if j != i\n    )]\n\n    # Step 2: Weighted selection (crowding distance)\n    if len(nondominated) > 1:\n        selected_idx = random.choices(\n            nondominated,\n            weights=[sum(objectives[i]) for i in nondominated],\n            k=1\n        )[0]\n    else:\n        selected_idx = random.choice(nondominated)\n\n    tour = archive[selected_idx].copy()\n    n = len(tour)\n\n    # Step 3: Hybrid local search\n    # Segment rotation\n    a, b = sorted(random.sample(range(n), 2))\n    segment = tour[a:b]\n    if random.random() < 0.5:  # Reverse with 50% probability\n        segment = segment[::-1]\n    else:  # Rotate by random offset\n        offset = random.randint(1, len(segment)-1)\n        segment = segment[offset:] + segment[:offset]\n    new_tour = np.concatenate([tour[:a], segment, tour[b:]])\n\n    # Conditional edge reversal\n    for _ in range(2):  # Try 2 random edges\n        i, j = sorted(random.sample(range(n), 2))\n        if (objectives[selected_idx][0] * objectives[selected_idx][1] >\n            (objectives[selected_idx][0] + objectives[selected_idx][1]) / 2):\n            new_tour[i:j] = new_tour[i:j][::-1]  # Reverse if cost-sensitive\n\n    # Feasibility check\n    if len(set(new_tour)) != n:\n        return tour  # Revert if invalid\n    return new_tour\n```\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 83,
        "algorithm": "The algorithm combines adaptive Pareto selection with weighted crowding distance to prioritize diverse solutions, then applies a hybrid local search that dynamically rotates segments, cost-sensitively prioritizes edges, and conditionally reverses segments when improving at least one objective, ensuring feasibility through strict validation. The approach balances exploration via random segment operations and exploitation via cost-aware prioritization, with dynamic segment sizes and operation probabilities adjusted based on solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -0.966911917358781,
            0.21160852909088135
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    # Calculate crowding distance for Pareto front\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    # Build Pareto front\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThis algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s a refined heuristic design for the bi-objective TSP:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\n```python\nimport numpy as np\nimport random\n\ndef select_neighbor(archive, objectives):\n    # Step 1: Adaptive Pareto selection\n    nondominated = [i for i in range(len(archive)) if not any(\n        all(objectives[i][k] >= objectives[j][k] for k in range(2)) and\n        any(objectives[i][k] > objectives[j][k] for k in range(2))\n        for j in range(len(archive)) if j != i\n    )]\n\n    # Step 2: Weighted selection (crowding distance)\n    if len(nondominated) > 1:\n        selected_idx = random.choices(\n            nondominated,\n            weights=[sum(objectives[i]) for i in nondominated],\n            k=1\n        )[0]\n    else:\n        selected_idx = random.choice(nondominated)\n\n    tour = archive[selected_idx].copy()\n    n = len(tour)\n\n    # Step 3: Hybrid local search\n    # Segment rotation\n    a, b = sorted(random.sample(range(n), 2))\n    segment = tour[a:b]\n    if random.random() < 0.5:  # Reverse with 50% probability\n        segment = segment[::-1]\n    else:  # Rotate by random offset\n        offset = random.randint(1, len(segment)-1)\n        segment = segment[offset:] + segment[:offset]\n    new_tour = np.concatenate([tour[:a], segment, tour[b:]])\n\n    # Conditional edge reversal\n    for _ in range(2):  # Try 2 random edges\n        i, j = sorted(random.sample(range(n), 2))\n        if (objectives[selected_idx][0] * objectives[selected_idx][1] >\n            (objectives[selected_idx][0] + objectives[selected_idx][1]) / 2):\n            new_tour[i:j] = new_tour[i:j][::-1]  # Reverse if cost-sensitive\n\n    # Feasibility check\n    if len(set(new_tour)) != n:\n        return tour  # Revert if invalid\n    return new_tour\n```\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 84,
        "algorithm": "This heuristic combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic operations weighted by edge costs in both objectives, and conditionally reverses segments only when they improve at least one objective, while ensuring feasibility through strict checks. The algorithm balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -1.0211110153860687,
            0.3061484694480896
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 3 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    # Calculate crowding distance for Pareto front\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    # Build Pareto front\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThis algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s a refined heuristic design for the bi-objective TSP:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\n```python\nimport numpy as np\nimport random\n\ndef select_neighbor(archive, objectives):\n    # Step 1: Adaptive Pareto selection\n    nondominated = [i for i in range(len(archive)) if not any(\n        all(objectives[i][k] >= objectives[j][k] for k in range(2)) and\n        any(objectives[i][k] > objectives[j][k] for k in range(2))\n        for j in range(len(archive)) if j != i\n    )]\n\n    # Step 2: Weighted selection (crowding distance)\n    if len(nondominated) > 1:\n        selected_idx = random.choices(\n            nondominated,\n            weights=[sum(objectives[i]) for i in nondominated],\n            k=1\n        )[0]\n    else:\n        selected_idx = random.choice(nondominated)\n\n    tour = archive[selected_idx].copy()\n    n = len(tour)\n\n    # Step 3: Hybrid local search\n    # Segment rotation\n    a, b = sorted(random.sample(range(n), 2))\n    segment = tour[a:b]\n    if random.random() < 0.5:  # Reverse with 50% probability\n        segment = segment[::-1]\n    else:  # Rotate by random offset\n        offset = random.randint(1, len(segment)-1)\n        segment = segment[offset:] + segment[:offset]\n    new_tour = np.concatenate([tour[:a], segment, tour[b:]])\n\n    # Conditional edge reversal\n    for _ in range(2):  # Try 2 random edges\n        i, j = sorted(random.sample(range(n), 2))\n        if (objectives[selected_idx][0] * objectives[selected_idx][1] >\n            (objectives[selected_idx][0] + objectives[selected_idx][1]) / 2):\n            new_tour[i:j] = new_tour[i:j][::-1]  # Reverse if cost-sensitive\n\n    # Feasibility check\n    if len(set(new_tour)) != n:\n        return tour  # Revert if invalid\n    return new_tour\n```\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 84,
        "algorithm": "This heuristic combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic operations weighted by edge costs in both objectives, and conditionally reverses segments only when they improve at least one objective, while ensuring feasibility through strict checks. The algorithm balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -1.0211110153860687,
            0.3061484694480896
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using weighted random selection that prioritizes non-dominated solutions with lower combined objective values, then applies a hybrid local search combining adaptive segment rotation (with segment size proportional to solution quality) and conditional edge insertion (only if it improves at least one objective). The rotation prioritizes high-distance segments, while the insertion targets high-distance edges, ensuring feasibility by maintaining valid TSP tours throughout.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values and Pareto dominance\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Lower combined objective is better\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n        # Boost weight for non-dominated solutions\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and (other_obj[0] <= obj[0] and other_obj[1] <= obj[1]) and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            weights[i] *= 1.5\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment quality based on combined distance\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score += distance_matrix_1[u][v] * distance_matrix_2[u][v]\n        segment_scores.append((a, b, score))\n\n    # Select segment to rotate with highest score\n    segment_scores.sort(key=lambda x: -x[2])\n    if segment_scores:\n        a, b, _ = segment_scores[0]\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional edge insertion\n    if n > 3:\n        # Find edges with high combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d if it improves at least one objective\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                for e in candidates:\n                    temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n                    temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n                       temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n                        new_solution = temp_solution\n                        break\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 85,
        "algorithm": "The algorithm first selects a promising solution from the archive using weighted random selection based on Pareto ranks and combined objectives, then applies a hybrid local search combining segment rotation with a single best edge insertion, prioritizing edges with higher combined quality scores in both objective spaces while ensuring feasibility. It emphasizes non-dominated solutions and balances exploration of high-quality segments with targeted edge improvements.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute Pareto ranks and combined objectives\n    objectives = [obj for _, obj in archive]\n    n_solutions = len(archive)\n    pareto_ranks = np.zeros(n_solutions, dtype=int)\n\n    for i in range(n_solutions):\n        for j in range(n_solutions):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                pareto_ranks[i] += 1\n\n    # Weighted selection\n    weights = np.array([1.0 / (1.0 + sum(obj)) for obj in objectives])\n    weights[pareto_ranks == 0] *= 1.5\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(n_solutions, p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Fast segment rotation\n    segment_size = min(3, n // 2)\n    a = np.random.randint(0, n - segment_size)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Precompute edge qualities\n    edge_qualities = np.zeros(n)\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_qualities[i] = distance_matrix_1[u][v] + distance_matrix_2[u][v]\n\n    # Single best edge insertion\n    if n > 3:\n        c = np.argmax(edge_qualities)\n        d = (c + 1) % n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            e = np.random.choice(candidates)\n            temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n            temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n            temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n            current_obj1 = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n            current_obj2 = sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n            if temp_obj1 <= current_obj1 or temp_obj2 <= current_obj2:\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.651253326161916,
            0.4967203140258789
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute Pareto ranks and combined objectives\n    objectives = [obj for _, obj in archive]\n    n_solutions = len(archive)\n    pareto_ranks = np.zeros(n_solutions, dtype=int)\n\n    for i in range(n_solutions):\n        for j in range(n_solutions):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                pareto_ranks[i] += 1\n\n    # Weighted selection\n    weights = np.array([1.0 / (1.0 + sum(obj)) for obj in objectives])\n    weights[pareto_ranks == 0] *= 1.5\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(n_solutions, p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Fast segment rotation\n    segment_size = min(3, n // 2)\n    a = np.random.randint(0, n - segment_size)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Precompute edge qualities\n    edge_qualities = np.zeros(n)\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_qualities[i] = distance_matrix_1[u][v] + distance_matrix_2[u][v]\n\n    # Single best edge insertion\n    if n > 3:\n        c = np.argmax(edge_qualities)\n        d = (c + 1) % n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            e = np.random.choice(candidates)\n            temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n            temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n            temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n            current_obj1 = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n            current_obj2 = sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n            if temp_obj1 <= current_obj1 or temp_obj2 <= current_obj2:\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm combines adaptive Pareto selection with a hybrid local search that prioritizes segment rotation, cost-aware edge insertion, and conditional segment reversal, while ensuring feasibility through probabilistic segment operations and edge weighting. It balances exploration and exploitation by dynamically adjusting segment sizes and using combined distance metrics to guide multi-objective improvements. The method intelligently selects edges and segments based on their potential for reducing tour lengths in both objective spaces, with segment reversal only applied when it improves at least one objective.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(idx)\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        selected_idx = np.random.choice(pareto_front)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization. The algorithm selects a base solution from the archive using weighted random selection based on normalized objectives, then applies segment reinsertion, edge reversal, and optional node swaps to generate a neighbor solution while maintaining tour validity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion with adaptive size\n    segment_size = max(3, min(n // 2, int(np.random.lognormal(mean=np.log(n//3), sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with probabilistic range selection\n    reversal_range = max(3, min(n // 3, int(np.random.pareto(a=2) + 2)))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node swap for additional diversification\n    if np.random.rand() < 0.3:\n        swap_pos1, swap_pos2 = np.random.choice(n, size=2, replace=False)\n        new_solution[swap_pos1], new_solution[swap_pos2] = new_solution[swap_pos2], new_solution[swap_pos1]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s a refined heuristic design for the bi-objective TSP:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\n```python\nimport numpy as np\nimport random\n\ndef select_neighbor(archive, objectives):\n    # Step 1: Adaptive Pareto selection\n    nondominated = [i for i in range(len(archive)) if not any(\n        all(objectives[i][k] >= objectives[j][k] for k in range(2)) and\n        any(objectives[i][k] > objectives[j][k] for k in range(2))\n        for j in range(len(archive)) if j != i\n    )]\n\n    # Step 2: Weighted selection (crowding distance)\n    if len(nondominated) > 1:\n        selected_idx = random.choices(\n            nondominated,\n            weights=[sum(objectives[i]) for i in nondominated],\n            k=1\n        )[0]\n    else:\n        selected_idx = random.choice(nondominated)\n\n    tour = archive[selected_idx].copy()\n    n = len(tour)\n\n    # Step 3: Hybrid local search\n    # Segment rotation\n    a, b = sorted(random.sample(range(n), 2))\n    segment = tour[a:b]\n    if random.random() < 0.5:  # Reverse with 50% probability\n        segment = segment[::-1]\n    else:  # Rotate by random offset\n        offset = random.randint(1, len(segment)-1)\n        segment = segment[offset:] + segment[:offset]\n    new_tour = np.concatenate([tour[:a], segment, tour[b:]])\n\n    # Conditional edge reversal\n    for _ in range(2):  # Try 2 random edges\n        i, j = sorted(random.sample(range(n), 2))\n        if (objectives[selected_idx][0] * objectives[selected_idx][1] >\n            (objectives[selected_idx][0] + objectives[selected_idx][1]) / 2):\n            new_tour[i:j] = new_tour[i:j][::-1]  # Reverse if cost-sensitive\n\n    # Feasibility check\n    if len(set(new_tour)) != n:\n        return tour  # Revert if invalid\n    return new_tour\n```\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 86,
        "algorithm": "The algorithm combines adaptive Pareto selection with a hybrid local search strategy that alternates between dynamic segment reinsertion and cost-sensitive edge reversal, prioritizing solutions with high combined normalized objectives while ensuring feasibility through conditional checks. It dynamically balances exploration and exploitation by adjusting segment sizes and reversal ranges based on solution quality, and avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments. The selection process favors solutions with high crowding distance in the objective space, while the local search operators are guided by combined distance metrics to improve multi-objective tour quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment-based reinsertion with probabilistic size adjustment\n    segment_size = max(2, min(n // 2, int(np.random.lognormal(mean=np.log(n//4), sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Cost-sensitive edge reversal with probabilistic intensity\n    if np.random.rand() < 0.4:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        # Reverse segment between selected edge and another edge with high cost\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n\n            # Determine reversal segment\n            start = min(c, e)\n            end = max(c, e)\n            if start != end:\n                new_solution[start:end+1] = new_solution[start:end+1][::-1]\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -0.9405313661205567,
            0.5392786860466003
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    crowding_dist = np.sum(normalized_obj, axis=1)\n    weights = crowding_dist / np.sum(crowding_dist)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment-based reinsertion with probabilistic size adjustment\n    segment_size = max(2, min(n // 2, int(np.random.lognormal(mean=np.log(n//4), sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Cost-sensitive edge reversal with probabilistic intensity\n    if np.random.rand() < 0.4:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        # Reverse segment between selected edge and another edge with high cost\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n\n            # Determine reversal segment\n            start = min(c, e)\n            end = max(c, e)\n            if start != end:\n                new_solution[start:end+1] = new_solution[start:end+1][::-1]\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization. The algorithm selects a base solution from the archive using weighted random selection based on normalized objectives, then applies segment reinsertion, edge reversal, and optional node swaps to generate a neighbor solution while maintaining tour validity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion with adaptive size\n    segment_size = max(3, min(n // 2, int(np.random.lognormal(mean=np.log(n//3), sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with probabilistic range selection\n    reversal_range = max(3, min(n // 3, int(np.random.pareto(a=2) + 2)))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node swap for additional diversification\n    if np.random.rand() < 0.3:\n        swap_pos1, swap_pos2 = np.random.choice(n, size=2, replace=False)\n        new_solution[swap_pos1], new_solution[swap_pos2] = new_solution[swap_pos2], new_solution[swap_pos1]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 87,
        "algorithm": "The algorithm selects a promising solution from the archive using a quality-aware probabilistic model that balances objective values and diversity, then applies a hybrid local search combining probabilistic segment reordering and dynamic edge exchange. Perturbation intensity is adaptive to solution quality, while deterministic validation ensures feasibility. The method prioritizes non-dominated solutions (lower combined objectives) but retains diversity through segment exchanges, with node consistency enforced post-operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Quality-aware selection with diversity consideration\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    diversity_scores = np.array([np.std(np.where(sol == np.arange(len(sol))[:, None], 1, 0)) for sol in solutions])\n    weights = (1.0 / (1.0 + np.sum(normalized_obj, axis=1))) * (1.0 + diversity_scores)\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Step 2: Probabilistic segment reordering\n    segment_size = max(2, min(n // 3, int(np.random.pareto(a=1.5) + 1)))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Dynamic edge exchange with quality-based probability\n    obj1, obj2 = archive[selected_idx][1]\n    total_obj = obj1 + obj2\n    exchange_prob = 0.5 * (1 - (total_obj / (np.max(objectives[:, 0] + objectives[:, 1]) + 1e-10)))\n\n    if np.random.rand() < exchange_prob:\n        exchange_size = max(2, min(n // 4, int(np.random.lognormal(mean=0, sigma=0.5))))\n        b = np.random.randint(0, n - exchange_size + 1)\n        c = np.random.randint(0, n - exchange_size + 1)\n        if b != c:\n            segment1 = new_solution[b:b+exchange_size]\n            segment2 = new_solution[c:c+exchange_size]\n            new_solution = np.concatenate([\n                new_solution[:b], segment2, new_solution[b+exchange_size:c], segment1, new_solution[c+exchange_size:]\n            ])\n\n    # Step 4: Node consistency enforcement\n    unique, counts = np.unique(new_solution, return_counts=True)\n    duplicates = unique[counts > 1]\n    for dup in duplicates:\n        missing = np.setdiff1d(np.arange(n), new_solution)\n        if len(missing) > 0:\n            replace_pos = np.where(new_solution == dup)[0][1]\n            new_solution[replace_pos] = np.random.choice(missing)\n\n    return new_solution\n\n",
        "score": [
            -0.8316381525840719,
            1.2227272391319275
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Quality-aware selection with diversity consideration\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    diversity_scores = np.array([np.std(np.where(sol == np.arange(len(sol))[:, None], 1, 0)) for sol in solutions])\n    weights = (1.0 / (1.0 + np.sum(normalized_obj, axis=1))) * (1.0 + diversity_scores)\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Step 2: Probabilistic segment reordering\n    segment_size = max(2, min(n // 3, int(np.random.pareto(a=1.5) + 1)))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Dynamic edge exchange with quality-based probability\n    obj1, obj2 = archive[selected_idx][1]\n    total_obj = obj1 + obj2\n    exchange_prob = 0.5 * (1 - (total_obj / (np.max(objectives[:, 0] + objectives[:, 1]) + 1e-10)))\n\n    if np.random.rand() < exchange_prob:\n        exchange_size = max(2, min(n // 4, int(np.random.lognormal(mean=0, sigma=0.5))))\n        b = np.random.randint(0, n - exchange_size + 1)\n        c = np.random.randint(0, n - exchange_size + 1)\n        if b != c:\n            segment1 = new_solution[b:b+exchange_size]\n            segment2 = new_solution[c:c+exchange_size]\n            new_solution = np.concatenate([\n                new_solution[:b], segment2, new_solution[b+exchange_size:c], segment1, new_solution[c+exchange_size:]\n            ])\n\n    # Step 4: Node consistency enforcement\n    unique, counts = np.unique(new_solution, return_counts=True)\n    duplicates = unique[counts > 1]\n    for dup in duplicates:\n        missing = np.setdiff1d(np.arange(n), new_solution)\n        if len(missing) > 0:\n            replace_pos = np.where(new_solution == dup)[0][1]\n            new_solution[replace_pos] = np.random.choice(missing)\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization. The algorithm selects a base solution from the archive using weighted random selection based on normalized objectives, then applies segment reinsertion, edge reversal, and optional node swaps to generate a neighbor solution while maintaining tour validity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion with adaptive size\n    segment_size = max(3, min(n // 2, int(np.random.lognormal(mean=np.log(n//3), sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with probabilistic range selection\n    reversal_range = max(3, min(n // 3, int(np.random.pareto(a=2) + 2)))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node swap for additional diversification\n    if np.random.rand() < 0.3:\n        swap_pos1, swap_pos2 = np.random.choice(n, size=2, replace=False)\n        new_solution[swap_pos1], new_solution[swap_pos2] = new_solution[swap_pos2], new_solution[swap_pos1]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 88,
        "algorithm": "The algorithm selects promising solutions from the archive using weighted random selection based on normalized objectives, then applies adaptive segment-based perturbation, multi-phase edge reversal, and optional node insertion to generate a new neighbor solution while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and dynamically adjusts perturbation intensity based on solution quality, using probabilistic segment sizes and deterministic reversal phases. The method combines segment-based modifications with edge reversal and selective node insertion to explore the solution space effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives with different weighting scheme\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment-based perturbation with probabilistic segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=n/5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Multi-phase edge reversal with deterministic range adjustment\n    reversal_phases = [max(2, min(n // 4, int(n / (i+1)))) for i in range(3)]\n    for phase in reversal_phases:\n        c = np.random.randint(0, n - phase + 1)\n        d = c + phase - 1\n        new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node insertion with quality-based probability\n    if np.random.rand() < 0.4 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        insert_node = np.random.choice(new_solution)\n        new_solution = np.delete(new_solution, np.where(new_solution == insert_node)[0][0])\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, insert_node)\n\n    return new_solution\n\n",
        "score": [
            -0.993894301084022,
            0.4981873631477356
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives with different weighting scheme\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment-based perturbation with probabilistic segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=n/5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Multi-phase edge reversal with deterministic range adjustment\n    reversal_phases = [max(2, min(n // 4, int(n / (i+1)))) for i in range(3)]\n    for phase in reversal_phases:\n        c = np.random.randint(0, n - phase + 1)\n        d = c + phase - 1\n        new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node insertion with quality-based probability\n    if np.random.rand() < 0.4 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        insert_node = np.random.choice(new_solution)\n        new_solution = np.delete(new_solution, np.where(new_solution == insert_node)[0][0])\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, insert_node)\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization. The algorithm selects a base solution from the archive using weighted random selection based on normalized objectives, then applies segment reinsertion, edge reversal, and optional node swaps to generate a neighbor solution while maintaining tour validity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion with adaptive size\n    segment_size = max(3, min(n // 2, int(np.random.lognormal(mean=np.log(n//3), sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with probabilistic range selection\n    reversal_range = max(3, min(n // 3, int(np.random.pareto(a=2) + 2)))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node swap for additional diversification\n    if np.random.rand() < 0.3:\n        swap_pos1, swap_pos2 = np.random.choice(n, size=2, replace=False)\n        new_solution[swap_pos1], new_solution[swap_pos2] = new_solution[swap_pos2], new_solution[swap_pos1]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion\n    segment_size = max(2, min(n // 3, int(np.random.normal(loc=n//4, scale=n//6))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with dynamic range\n    reversal_range = max(2, min(n // 2, int(np.random.exponential(scale=n//3))))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s a refined heuristic design for the bi-objective TSP:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\n```python\nimport numpy as np\nimport random\n\ndef select_neighbor(archive, objectives):\n    # Step 1: Adaptive Pareto selection\n    nondominated = [i for i in range(len(archive)) if not any(\n        all(objectives[i][k] >= objectives[j][k] for k in range(2)) and\n        any(objectives[i][k] > objectives[j][k] for k in range(2))\n        for j in range(len(archive)) if j != i\n    )]\n\n    # Step 2: Weighted selection (crowding distance)\n    if len(nondominated) > 1:\n        selected_idx = random.choices(\n            nondominated,\n            weights=[sum(objectives[i]) for i in nondominated],\n            k=1\n        )[0]\n    else:\n        selected_idx = random.choice(nondominated)\n\n    tour = archive[selected_idx].copy()\n    n = len(tour)\n\n    # Step 3: Hybrid local search\n    # Segment rotation\n    a, b = sorted(random.sample(range(n), 2))\n    segment = tour[a:b]\n    if random.random() < 0.5:  # Reverse with 50% probability\n        segment = segment[::-1]\n    else:  # Rotate by random offset\n        offset = random.randint(1, len(segment)-1)\n        segment = segment[offset:] + segment[:offset]\n    new_tour = np.concatenate([tour[:a], segment, tour[b:]])\n\n    # Conditional edge reversal\n    for _ in range(2):  # Try 2 random edges\n        i, j = sorted(random.sample(range(n), 2))\n        if (objectives[selected_idx][0] * objectives[selected_idx][1] >\n            (objectives[selected_idx][0] + objectives[selected_idx][1]) / 2):\n            new_tour[i:j] = new_tour[i:j][::-1]  # Reverse if cost-sensitive\n\n    # Feasibility check\n    if len(set(new_tour)) != n:\n        return tour  # Revert if invalid\n    return new_tour\n```\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 89,
        "algorithm": "The algorithm selects a promising solution from the archive using adaptive Pareto selection with weighted random choice, then applies a hybrid local search that alternates between segment-based rotation (random reversal or rotation) and cost-sensitive edge reversal (only for high combined distance edges), dynamically adjusting segment sizes and ensuring feasibility through validation checks. The method prioritizes solutions with balanced objectives and leverages both segment manipulation and edge-based improvements to generate high-quality neighbors.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Adaptive Pareto selection with weighted random choice\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    nondominated = [i for i in range(len(archive)) if not any(\n        all(objectives[i][k] >= objectives[j][k] for k in range(2)) and\n        any(objectives[i][k] > objectives[j][k] for k in range(2))\n        for j in range(len(archive)) if j != i\n    )]\n\n    if nondominated:\n        selected_idx = np.random.choice(nondominated, p=weights[nondominated]/np.sum(weights[nondominated]))\n    else:\n        selected_idx = np.random.choice(len(archive), p=weights/np.sum(weights))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Step 2: Hybrid local search with dynamic segment rotation\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=n//4))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n\n    if np.random.rand() < 0.5:\n        segment = segment[::-1]  # Reverse with 50% probability\n    else:\n        offset = np.random.randint(1, len(segment))\n        segment = np.concatenate([segment[offset:], segment[:offset]])  # Rotate\n\n    new_solution = np.concatenate([new_solution[:a], segment, new_solution[a+segment_size:]])\n\n    # Step 3: Cost-sensitive edge reversal\n    for _ in range(2):  # Try 2 random edges\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        u, v = new_solution[i], new_solution[(i+1)%n]\n        cost1 = distance_matrix_1[u][v] + distance_matrix_2[u][v]\n        u, v = new_solution[j], new_solution[(j+1)%n]\n        cost2 = distance_matrix_1[u][v] + distance_matrix_2[u][v]\n\n        if cost1 * cost2 > (cost1 + cost2) / 2:  # If high combined cost\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]  # Reverse segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution  # Revert if invalid\n\n    return new_solution\n\n",
        "score": [
            -0.811629713030745,
            1.071391999721527
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Adaptive Pareto selection with weighted random choice\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    nondominated = [i for i in range(len(archive)) if not any(\n        all(objectives[i][k] >= objectives[j][k] for k in range(2)) and\n        any(objectives[i][k] > objectives[j][k] for k in range(2))\n        for j in range(len(archive)) if j != i\n    )]\n\n    if nondominated:\n        selected_idx = np.random.choice(nondominated, p=weights[nondominated]/np.sum(weights[nondominated]))\n    else:\n        selected_idx = np.random.choice(len(archive), p=weights/np.sum(weights))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Step 2: Hybrid local search with dynamic segment rotation\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=n//4))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n\n    if np.random.rand() < 0.5:\n        segment = segment[::-1]  # Reverse with 50% probability\n    else:\n        offset = np.random.randint(1, len(segment))\n        segment = np.concatenate([segment[offset:], segment[:offset]])  # Rotate\n\n    new_solution = np.concatenate([new_solution[:a], segment, new_solution[a+segment_size:]])\n\n    # Step 3: Cost-sensitive edge reversal\n    for _ in range(2):  # Try 2 random edges\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        u, v = new_solution[i], new_solution[(i+1)%n]\n        cost1 = distance_matrix_1[u][v] + distance_matrix_2[u][v]\n        u, v = new_solution[j], new_solution[(j+1)%n]\n        cost2 = distance_matrix_1[u][v] + distance_matrix_2[u][v]\n\n        if cost1 * cost2 > (cost1 + cost2) / 2:  # If high combined cost\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]  # Reverse segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution  # Revert if invalid\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    # Calculate crowding distance for Pareto front\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    # Build Pareto front\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThis algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThis algorithm employs adaptive multi-objective selection with probabilistic dominance checks to choose promising solutions from an archive, then applies dynamic segment swaps and cost-sensitive edge insertions to generate improved neighbors while maintaining feasibility. It prioritizes solutions with better objective values but occasionally selects non-dominated ones with a small probability, and uses lognormal-distributed segment sizes for adaptive exploration. The local search combines segment swaps (if they improve at least one objective) with edge insertions weighted by combined distance costs to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1]) or \\\n           (current[1][0] <= best[1][0] and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.2:  # Small chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=0.5, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    # Cost-sensitive edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive Pareto selection with weighted crowding distance to prioritize diverse solutions, then applies a hybrid local search that dynamically rotates segments, cost-sensitively prioritizes edges, and conditionally reverses segments when improving at least one objective, ensuring feasibility through strict validation. The approach balances exploration via random segment operations and exploitation via cost-aware prioritization, with dynamic segment sizes and operation probabilities adjusted based on solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThis heuristic combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic operations weighted by edge costs in both objectives, and conditionally reverses segments only when they improve at least one objective, while ensuring feasibility through strict checks. The algorithm balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined response with 4 bullet points:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\nThe key innovation is combining *adaptive Pareto selection* with *hybrid segment-rotation* and *cost-sensitive edge prioritization*, while rigorously avoiding static or overly greedy operators. This ensures both exploration and exploitation while maintaining feasibility.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 90,
        "algorithm": "The algorithm combines adaptive Pareto selection with a hybrid local search that prioritizes dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals, ensuring feasibility through strict validation. It intelligently selects solutions from the archive using weighted crowding distance and applies multi-objective-aware operators that balance improvements in both objective spaces while maintaining tour validity. The approach dynamically adjusts segment sizes and operation probabilities to explore the solution space effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -0.9092254104733437,
            0.32239651679992676
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using weighted random selection that prioritizes non-dominated solutions with lower combined objective values, then applies a hybrid local search combining adaptive segment rotation (with segment size proportional to solution quality) and conditional edge insertion (only if it improves at least one objective). The rotation prioritizes high-distance segments, while the insertion targets high-distance edges, ensuring feasibility by maintaining valid TSP tours throughout.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on combined objective values and Pareto dominance\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Lower combined objective is better\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n        # Boost weight for non-dominated solutions\n        dominated = False\n        for j, (other_sol, other_obj) in enumerate(archive):\n            if i != j and (other_obj[0] <= obj[0] and other_obj[1] <= obj[1]) and (other_obj[0] < obj[0] or other_obj[1] < obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            weights[i] *= 1.5\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Calculate segment quality based on combined distance\n    segment_scores = []\n    for a in range(n):\n        segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n        b = min(a + segment_size - 1, n - 1)\n        score = 0\n        for i in range(a, b):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            score += distance_matrix_1[u][v] * distance_matrix_2[u][v]\n        segment_scores.append((a, b, score))\n\n    # Select segment to rotate with highest score\n    segment_scores.sort(key=lambda x: -x[2])\n    if segment_scores:\n        a, b, _ = segment_scores[0]\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional edge insertion\n    if n > 3:\n        # Find edges with high combined distance\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d if it improves at least one objective\n            candidates = [i for i in range(n) if i not in (c, d)]\n            if candidates:\n                for e in candidates:\n                    temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n                    temp_obj1 = sum(distance_matrix_1[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    temp_obj2 = sum(distance_matrix_2[temp_solution[i]][temp_solution[(i+1)%n]] for i in range(n))\n                    if temp_obj1 <= sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)) or \\\n                       temp_obj2 <= sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n)):\n                        new_solution = temp_solution\n                        break\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 91,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute combined objectives and identify non-dominated solutions\n    objectives = [obj for _, obj in archive]\n    combined = [sum(obj) for obj in objectives]\n    is_dominated = [False] * len(archive)\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                is_dominated[i] = True\n                break\n\n    # Weighted selection with precomputed values\n    weights = np.zeros(len(archive))\n    for i in range(len(archive)):\n        weights[i] = 1.0 / (1.0 + combined[i]) * (1.5 if not is_dominated[i] else 1.0)\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Precompute combined distances for all edges\n    edge_distances = np.zeros(n)\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_distances[i] = distance_matrix_1[u][v] + distance_matrix_2[u][v]\n\n    # Select segment to rotate with highest combined distance\n    max_score = -1\n    best_segment = (0, 1)\n    for a in range(n):\n        segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n        b = min(a + segment_size - 1, n - 1)\n        score = np.sum(edge_distances[a:b+1])\n        if score > max_score:\n            max_score = score\n            best_segment = (a, b)\n\n    a, b = best_segment\n    if a < b:\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional edge insertion with precomputed distances\n    if n > 3:\n        max_edge_idx = np.argmax(edge_distances)\n        c = max_edge_idx\n        d = (max_edge_idx + 1) % n\n\n        # Precompute current total distances\n        current_obj1 = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n        current_obj2 = sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n\n        # Try inserting each candidate\n        candidates = [i for i in range(n) if i not in (c, d)]\n        for e in candidates:\n            temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n            temp_obj1 = current_obj1 - (distance_matrix_1[new_solution[c]][new_solution[d]] +\n                                        distance_matrix_1[new_solution[(c-1)%n]][new_solution[c]]) + \\\n                        (distance_matrix_1[new_solution[(c-1)%n]][new_solution[e]] +\n                         distance_matrix_1[new_solution[e]][new_solution[c]] +\n                         distance_matrix_1[new_solution[c]][new_solution[d]])\n            temp_obj2 = current_obj2 - (distance_matrix_2[new_solution[c]][new_solution[d]] +\n                                        distance_matrix_2[new_solution[(c-1)%n]][new_solution[c]]) + \\\n                        (distance_matrix_2[new_solution[(c-1)%n]][new_solution[e]] +\n                         distance_matrix_2[new_solution[e]][new_solution[c]] +\n                         distance_matrix_2[new_solution[c]][new_solution[d]])\n\n            if temp_obj1 <= current_obj1 or temp_obj2 <= current_obj2:\n                new_solution = temp_solution\n                break\n\n    return new_solution\n\n",
        "score": [
            -0.7256556235665902,
            0.8149281740188599
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute combined objectives and identify non-dominated solutions\n    objectives = [obj for _, obj in archive]\n    combined = [sum(obj) for obj in objectives]\n    is_dominated = [False] * len(archive)\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j][0] <= objectives[i][0] and objectives[j][1] <= objectives[i][1]) and (objectives[j][0] < objectives[i][0] or objectives[j][1] < objectives[i][1]):\n                is_dominated[i] = True\n                break\n\n    # Weighted selection with precomputed values\n    weights = np.zeros(len(archive))\n    for i in range(len(archive)):\n        weights[i] = 1.0 / (1.0 + combined[i]) * (1.5 if not is_dominated[i] else 1.0)\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Precompute combined distances for all edges\n    edge_distances = np.zeros(n)\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_distances[i] = distance_matrix_1[u][v] + distance_matrix_2[u][v]\n\n    # Select segment to rotate with highest combined distance\n    max_score = -1\n    best_segment = (0, 1)\n    for a in range(n):\n        segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n        b = min(a + segment_size - 1, n - 1)\n        score = np.sum(edge_distances[a:b+1])\n        if score > max_score:\n            max_score = score\n            best_segment = (a, b)\n\n    a, b = best_segment\n    if a < b:\n        rotation = np.random.randint(1, b - a + 1)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Conditional edge insertion with precomputed distances\n    if n > 3:\n        max_edge_idx = np.argmax(edge_distances)\n        c = max_edge_idx\n        d = (max_edge_idx + 1) % n\n\n        # Precompute current total distances\n        current_obj1 = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n        current_obj2 = sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n\n        # Try inserting each candidate\n        candidates = [i for i in range(n) if i not in (c, d)]\n        for e in candidates:\n            temp_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n            temp_obj1 = current_obj1 - (distance_matrix_1[new_solution[c]][new_solution[d]] +\n                                        distance_matrix_1[new_solution[(c-1)%n]][new_solution[c]]) + \\\n                        (distance_matrix_1[new_solution[(c-1)%n]][new_solution[e]] +\n                         distance_matrix_1[new_solution[e]][new_solution[c]] +\n                         distance_matrix_1[new_solution[c]][new_solution[d]])\n            temp_obj2 = current_obj2 - (distance_matrix_2[new_solution[c]][new_solution[d]] +\n                                        distance_matrix_2[new_solution[(c-1)%n]][new_solution[c]]) + \\\n                        (distance_matrix_2[new_solution[(c-1)%n]][new_solution[e]] +\n                         distance_matrix_2[new_solution[e]][new_solution[c]] +\n                         distance_matrix_2[new_solution[c]][new_solution[d]])\n\n            if temp_obj1 <= current_obj1 or temp_obj2 <= current_obj2:\n                new_solution = temp_solution\n                break\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThis heuristic combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic operations weighted by edge costs in both objectives, and conditionally reverses segments only when they improve at least one objective, while ensuring feasibility through strict checks. The algorithm balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects promising solutions from the archive using weighted random selection based on normalized objectives, then applies adaptive segment-based perturbation, multi-phase edge reversal, and optional node insertion to generate a new neighbor solution while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and dynamically adjusts perturbation intensity based on solution quality, using probabilistic segment sizes and deterministic reversal phases. The method combines segment-based modifications with edge reversal and selective node insertion to explore the solution space effectively.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives with different weighting scheme\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment-based perturbation with probabilistic segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=n/5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Multi-phase edge reversal with deterministic range adjustment\n    reversal_phases = [max(2, min(n // 4, int(n / (i+1)))) for i in range(3)]\n    for phase in reversal_phases:\n        c = np.random.randint(0, n - phase + 1)\n        d = c + phase - 1\n        new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node insertion with quality-based probability\n    if np.random.rand() < 0.4 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        insert_node = np.random.choice(new_solution)\n        new_solution = np.delete(new_solution, np.where(new_solution == insert_node)[0][0])\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, insert_node)\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined response with 4 bullet points:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\nThe key innovation is combining *adaptive Pareto selection* with *hybrid segment-rotation* and *cost-sensitive edge prioritization*, while rigorously avoiding static or overly greedy operators. This ensures both exploration and exploitation while maintaining feasibility.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 92,
        "algorithm": "The algorithm employs a multi-stage adaptive selection process that first identifies promising solutions in the archive using normalized objective weights, then applies dynamic segment-shuffling and edge-prioritization to generate neighbors, followed by conditional segment inversions that improve at least one objective, all while maintaining feasibility through validation and repair mechanisms. It prioritizes edges with high normalized distance products across both objectives and selectively applies segment inversions based on cost improvements, with segment sizes determined probabilistically.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Multi-stage adaptive selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment-shuffling with probabilistic segment sizes\n    segment_sizes = [max(2, min(n // 2, int(np.random.exponential(scale=n/4)))) for _ in range(3)]\n    for size in segment_sizes:\n        if size >= n:\n            continue\n        a = np.random.randint(0, n - size + 1)\n        segment = new_solution[a:a+size]\n        np.random.shuffle(segment)\n        new_solution[a:a+size] = segment\n\n    # Edge prioritization with normalized distance products\n    edge_scores = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        score = (distance_matrix_1[u][v] * distance_matrix_2[u][v]) / (np.mean(distance_matrix_1) * np.mean(distance_matrix_2))\n        edge_scores.append(score)\n\n    edge_scores = np.array(edge_scores)\n    edge_scores = edge_scores / np.sum(edge_scores)\n    selected_edge = np.random.choice(n, p=edge_scores)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    # Conditional segment inversion\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 3, int(np.random.exponential(scale=n/5))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check and repair\n    if len(set(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        duplicates = [x for x in new_solution if list(new_solution).count(x) > 1]\n        for dup in duplicates:\n            pos = np.where(new_solution == dup)[0][1]\n            new_solution[pos] = missing.pop()\n\n    return new_solution\n\n",
        "score": [
            -0.7927814898536165,
            1.0909544825553894
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Multi-stage adaptive selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment-shuffling with probabilistic segment sizes\n    segment_sizes = [max(2, min(n // 2, int(np.random.exponential(scale=n/4)))) for _ in range(3)]\n    for size in segment_sizes:\n        if size >= n:\n            continue\n        a = np.random.randint(0, n - size + 1)\n        segment = new_solution[a:a+size]\n        np.random.shuffle(segment)\n        new_solution[a:a+size] = segment\n\n    # Edge prioritization with normalized distance products\n    edge_scores = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        score = (distance_matrix_1[u][v] * distance_matrix_2[u][v]) / (np.mean(distance_matrix_1) * np.mean(distance_matrix_2))\n        edge_scores.append(score)\n\n    edge_scores = np.array(edge_scores)\n    edge_scores = edge_scores / np.sum(edge_scores)\n    selected_edge = np.random.choice(n, p=edge_scores)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    # Conditional segment inversion\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 3, int(np.random.exponential(scale=n/5))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check and repair\n    if len(set(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        duplicates = [x for x in new_solution if list(new_solution).count(x) > 1]\n        for dup in duplicates:\n            pos = np.where(new_solution == dup)[0][1]\n            new_solution[pos] = missing.pop()\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the archive using weighted random selection based on normalized objectives, then applies adaptive segment-based perturbation, multi-phase edge reversal, and optional node insertion to generate a new neighbor solution while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and dynamically adjusts perturbation intensity based on solution quality, using probabilistic segment sizes and deterministic reversal phases. The method combines segment-based modifications with edge reversal and selective node insertion to explore the solution space effectively.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives with different weighting scheme\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment-based perturbation with probabilistic segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=n/5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Multi-phase edge reversal with deterministic range adjustment\n    reversal_phases = [max(2, min(n // 4, int(n / (i+1)))) for i in range(3)]\n    for phase in reversal_phases:\n        c = np.random.randint(0, n - phase + 1)\n        d = c + phase - 1\n        new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node insertion with quality-based probability\n    if np.random.rand() < 0.4 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        insert_node = np.random.choice(new_solution)\n        new_solution = np.delete(new_solution, np.where(new_solution == insert_node)[0][0])\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, insert_node)\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 93,
        "algorithm": "The algorithm combines fitness-based and diversity-aware selection to choose a promising solution from the archive, then applies an adaptive multi-segment perturbation strategy with probabilistic segment sizes and deterministic edge exchanges, followed by a quality-based node relocation step that prioritizes high-improvement moves. It balances exploration (diversity) and exploitation (fitness) while ensuring feasibility through careful segment manipulation and edge exchanges. The method prioritizes solutions with better normalized objectives and higher diversity scores, using exponential scaling for segment sizes and deterministic phases for edge exchanges.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Hybrid selection combining fitness and diversity\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    fitness_score = np.exp(-0.7 * np.sum(normalized_obj, axis=1))\n\n    # Calculate diversity score based on Hamming distance\n    diversity_scores = []\n    for i, (sol, _) in enumerate(archive):\n        avg_dist = np.mean([np.sum(sol != other_sol) for j, (other_sol, _) in enumerate(archive) if j != i])\n        diversity_scores.append(avg_dist)\n    diversity_scores = np.array(diversity_scores)\n    diversity_scores = (diversity_scores - np.min(diversity_scores)) / (np.max(diversity_scores) - np.min(diversity_scores) + 1e-10)\n\n    combined_scores = 0.6 * fitness_score + 0.4 * diversity_scores\n    combined_scores = combined_scores / np.sum(combined_scores)\n    selected_idx = np.random.choice(len(archive), p=combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Step 2: Adaptive multi-segment perturbation\n    num_segments = np.random.randint(2, min(4, n // 3 + 1))\n    segment_sizes = []\n    remaining = n\n    for _ in range(num_segments - 1):\n        size = max(2, min(remaining - 2, int(np.random.exponential(scale=n / (4 * num_segments)))))\n        segment_sizes.append(size)\n        remaining -= size\n    segment_sizes.append(remaining)\n\n    # Shuffle segments and reassemble\n    segments = []\n    start = 0\n    for size in segment_sizes:\n        segments.append(new_solution[start:start+size])\n        start += size\n    np.random.shuffle(segments)\n    new_solution = np.concatenate(segments)\n\n    # Step 3: Dynamic edge exchange mechanism\n    exchange_phases = [max(3, min(n // 5, int(n / (i+2)))) for i in range(2)]\n    for phase in exchange_phases:\n        a = np.random.randint(0, n - phase + 1)\n        b = np.random.randint(0, n - phase + 1)\n        if a != b:\n            temp = new_solution[a:a+phase].copy()\n            new_solution[a:a+phase] = new_solution[b:b+phase]\n            new_solution[b:b+phase] = temp\n\n    # Step 4: Quality-based node relocation\n    if np.random.rand() < 0.5 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        # Calculate potential improvement for each node\n        improvements = []\n        for i in range(n):\n            current_cost = distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[i-1], new_solution[i]]\n            if i == n-1:\n                next_cost = distance_matrix_1[new_solution[i], new_solution[0]] + distance_matrix_2[new_solution[i], new_solution[0]]\n            else:\n                next_cost = distance_matrix_1[new_solution[i], new_solution[i+1]] + distance_matrix_2[new_solution[i], new_solution[i+1]]\n\n            # Try inserting node at different positions\n            min_improvement = 0\n            for j in range(n):\n                if j != i and j != i-1 and (i != n-1 or j != 0):\n                    if j == 0:\n                        new_cost = distance_matrix_1[new_solution[-1], new_solution[i]] + distance_matrix_2[new_solution[-1], new_solution[i]]\n                    else:\n                        new_cost = distance_matrix_1[new_solution[j-1], new_solution[i]] + distance_matrix_2[new_solution[j-1], new_solution[i]]\n                    if j == n-1:\n                        new_cost += distance_matrix_1[new_solution[i], new_solution[0]] + distance_matrix_2[new_solution[i], new_solution[0]]\n                    else:\n                        new_cost += distance_matrix_1[new_solution[i], new_solution[j+1]] + distance_matrix_2[new_solution[i], new_solution[j+1]]\n\n                    improvement = (current_cost + next_cost) - new_cost\n                    if improvement > min_improvement:\n                        min_improvement = improvement\n            improvements.append(min_improvement)\n\n        # Relocate the node with highest potential improvement\n        if any(im > 0 for im in improvements):\n            best_node = np.argmax(improvements)\n            node = new_solution[best_node]\n            new_solution = np.delete(new_solution, best_node)\n            best_pos = -1\n            best_improvement = -float('inf')\n\n            for j in range(n-1):\n                if j != best_node and j != best_node-1 and (best_node != n-1 or j != 0):\n                    if j == 0:\n                        new_cost = distance_matrix_1[new_solution[-1], node] + distance_matrix_2[new_solution[-1], node]\n                    else:\n                        new_cost = distance_matrix_1[new_solution[j-1], node] + distance_matrix_2[new_solution[j-1], node]\n                    if j == n-2:\n                        new_cost += distance_matrix_1[node, new_solution[0]] + distance_matrix_2[node, new_solution[0]]\n                    else:\n                        new_cost += distance_matrix_1[node, new_solution[j+1]] + distance_matrix_2[node, new_solution[j+1]]\n\n                    original_cost = distance_matrix_1[new_solution[j], new_solution[j+1]] + distance_matrix_2[new_solution[j], new_solution[j+1]]\n                    improvement = original_cost - new_cost\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_pos = j\n\n            if best_pos != -1:\n                new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
        "score": [
            -0.7147365339032437,
            1.6561226844787598
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Hybrid selection combining fitness and diversity\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    fitness_score = np.exp(-0.7 * np.sum(normalized_obj, axis=1))\n\n    # Calculate diversity score based on Hamming distance\n    diversity_scores = []\n    for i, (sol, _) in enumerate(archive):\n        avg_dist = np.mean([np.sum(sol != other_sol) for j, (other_sol, _) in enumerate(archive) if j != i])\n        diversity_scores.append(avg_dist)\n    diversity_scores = np.array(diversity_scores)\n    diversity_scores = (diversity_scores - np.min(diversity_scores)) / (np.max(diversity_scores) - np.min(diversity_scores) + 1e-10)\n\n    combined_scores = 0.6 * fitness_score + 0.4 * diversity_scores\n    combined_scores = combined_scores / np.sum(combined_scores)\n    selected_idx = np.random.choice(len(archive), p=combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        return new_solution\n\n    # Step 2: Adaptive multi-segment perturbation\n    num_segments = np.random.randint(2, min(4, n // 3 + 1))\n    segment_sizes = []\n    remaining = n\n    for _ in range(num_segments - 1):\n        size = max(2, min(remaining - 2, int(np.random.exponential(scale=n / (4 * num_segments)))))\n        segment_sizes.append(size)\n        remaining -= size\n    segment_sizes.append(remaining)\n\n    # Shuffle segments and reassemble\n    segments = []\n    start = 0\n    for size in segment_sizes:\n        segments.append(new_solution[start:start+size])\n        start += size\n    np.random.shuffle(segments)\n    new_solution = np.concatenate(segments)\n\n    # Step 3: Dynamic edge exchange mechanism\n    exchange_phases = [max(3, min(n // 5, int(n / (i+2)))) for i in range(2)]\n    for phase in exchange_phases:\n        a = np.random.randint(0, n - phase + 1)\n        b = np.random.randint(0, n - phase + 1)\n        if a != b:\n            temp = new_solution[a:a+phase].copy()\n            new_solution[a:a+phase] = new_solution[b:b+phase]\n            new_solution[b:b+phase] = temp\n\n    # Step 4: Quality-based node relocation\n    if np.random.rand() < 0.5 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        # Calculate potential improvement for each node\n        improvements = []\n        for i in range(n):\n            current_cost = distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[i-1], new_solution[i]]\n            if i == n-1:\n                next_cost = distance_matrix_1[new_solution[i], new_solution[0]] + distance_matrix_2[new_solution[i], new_solution[0]]\n            else:\n                next_cost = distance_matrix_1[new_solution[i], new_solution[i+1]] + distance_matrix_2[new_solution[i], new_solution[i+1]]\n\n            # Try inserting node at different positions\n            min_improvement = 0\n            for j in range(n):\n                if j != i and j != i-1 and (i != n-1 or j != 0):\n                    if j == 0:\n                        new_cost = distance_matrix_1[new_solution[-1], new_solution[i]] + distance_matrix_2[new_solution[-1], new_solution[i]]\n                    else:\n                        new_cost = distance_matrix_1[new_solution[j-1], new_solution[i]] + distance_matrix_2[new_solution[j-1], new_solution[i]]\n                    if j == n-1:\n                        new_cost += distance_matrix_1[new_solution[i], new_solution[0]] + distance_matrix_2[new_solution[i], new_solution[0]]\n                    else:\n                        new_cost += distance_matrix_1[new_solution[i], new_solution[j+1]] + distance_matrix_2[new_solution[i], new_solution[j+1]]\n\n                    improvement = (current_cost + next_cost) - new_cost\n                    if improvement > min_improvement:\n                        min_improvement = improvement\n            improvements.append(min_improvement)\n\n        # Relocate the node with highest potential improvement\n        if any(im > 0 for im in improvements):\n            best_node = np.argmax(improvements)\n            node = new_solution[best_node]\n            new_solution = np.delete(new_solution, best_node)\n            best_pos = -1\n            best_improvement = -float('inf')\n\n            for j in range(n-1):\n                if j != best_node and j != best_node-1 and (best_node != n-1 or j != 0):\n                    if j == 0:\n                        new_cost = distance_matrix_1[new_solution[-1], node] + distance_matrix_2[new_solution[-1], node]\n                    else:\n                        new_cost = distance_matrix_1[new_solution[j-1], node] + distance_matrix_2[new_solution[j-1], node]\n                    if j == n-2:\n                        new_cost += distance_matrix_1[node, new_solution[0]] + distance_matrix_2[node, new_solution[0]]\n                    else:\n                        new_cost += distance_matrix_1[node, new_solution[j+1]] + distance_matrix_2[node, new_solution[j+1]]\n\n                    original_cost = distance_matrix_1[new_solution[j], new_solution[j+1]] + distance_matrix_2[new_solution[j], new_solution[j+1]]\n                    improvement = original_cost - new_cost\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_pos = j\n\n            if best_pos != -1:\n                new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the archive using weighted random selection based on normalized objectives, then applies adaptive segment-based perturbation, multi-phase edge reversal, and optional node insertion to generate a new neighbor solution while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and dynamically adjusts perturbation intensity based on solution quality, using probabilistic segment sizes and deterministic reversal phases. The method combines segment-based modifications with edge reversal and selective node insertion to explore the solution space effectively.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives with different weighting scheme\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment-based perturbation with probabilistic segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=n/5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Multi-phase edge reversal with deterministic range adjustment\n    reversal_phases = [max(2, min(n // 4, int(n / (i+1)))) for i in range(3)]\n    for phase in reversal_phases:\n        c = np.random.randint(0, n - phase + 1)\n        d = c + phase - 1\n        new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node insertion with quality-based probability\n    if np.random.rand() < 0.4 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        insert_node = np.random.choice(new_solution)\n        new_solution = np.delete(new_solution, np.where(new_solution == insert_node)[0][0])\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, insert_node)\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 94,
        "algorithm": "The algorithm selects promising solutions from the archive using weighted random selection based on normalized objectives, then applies dynamic segment-based perturbation, probabilistic edge reversal, and adaptive node reinsertion to generate a new neighbor solution while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and dynamically adjusts perturbation intensity based on solution quality, favoring more aggressive modifications for worse solutions. The method avoids standard 2-opt by combining segment relocations, phased reversals, and selective reinsertions to explore the search space effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.3 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=n/4))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    reversal_phases = [max(2, min(n // 3, int(n / (i+2)))) for i in range(2)]\n    for phase in reversal_phases:\n        c = np.random.randint(0, n - phase + 1)\n        d = c + phase - 1\n        if np.random.rand() < 0.6:\n            new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    if np.random.rand() < 0.5 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        nodes_to_reinsert = np.random.choice(new_solution, size=min(2, n//5), replace=False)\n        for node in nodes_to_reinsert:\n            new_solution = np.delete(new_solution, np.where(new_solution == node)[0][0])\n            insert_pos = np.random.randint(0, len(new_solution))\n            new_solution = np.insert(new_solution, insert_pos, node)\n\n    return new_solution\n\n",
        "score": [
            -0.8513303610135133,
            0.48792535066604614
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.3 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=n/4))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    reversal_phases = [max(2, min(n // 3, int(n / (i+2)))) for i in range(2)]\n    for phase in reversal_phases:\n        c = np.random.randint(0, n - phase + 1)\n        d = c + phase - 1\n        if np.random.rand() < 0.6:\n            new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    if np.random.rand() < 0.5 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        nodes_to_reinsert = np.random.choice(new_solution, size=min(2, n//5), replace=False)\n        for node in nodes_to_reinsert:\n            new_solution = np.delete(new_solution, np.where(new_solution == node)[0][0])\n            insert_pos = np.random.randint(0, len(new_solution))\n            new_solution = np.insert(new_solution, insert_pos, node)\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 5 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions from the archive using weighted random selection based on normalized objectives, then applies adaptive segment-based perturbation, multi-phase edge reversal, and optional node insertion to generate a new neighbor solution while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and dynamically adjusts perturbation intensity based on solution quality, using probabilistic segment sizes and deterministic reversal phases. The method combines segment-based modifications with edge reversal and selective node insertion to explore the solution space effectively.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives with different weighting scheme\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment-based perturbation with probabilistic segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=n/5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Multi-phase edge reversal with deterministic range adjustment\n    reversal_phases = [max(2, min(n // 4, int(n / (i+1)))) for i in range(3)]\n    for phase in reversal_phases:\n        c = np.random.randint(0, n - phase + 1)\n        d = c + phase - 1\n        new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node insertion with quality-based probability\n    if np.random.rand() < 0.4 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        insert_node = np.random.choice(new_solution)\n        new_solution = np.delete(new_solution, np.where(new_solution == insert_node)[0][0])\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, insert_node)\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization. The algorithm selects a base solution from the archive using weighted random selection based on normalized objectives, then applies segment reinsertion, edge reversal, and optional node swaps to generate a neighbor solution while maintaining tour validity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion with adaptive size\n    segment_size = max(3, min(n // 2, int(np.random.lognormal(mean=np.log(n//3), sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with probabilistic range selection\n    reversal_range = max(3, min(n // 3, int(np.random.pareto(a=2) + 2)))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node swap for additional diversification\n    if np.random.rand() < 0.3:\n        swap_pos1, swap_pos2 = np.random.choice(n, size=2, replace=False)\n        new_solution[swap_pos1], new_solution[swap_pos2] = new_solution[swap_pos2], new_solution[swap_pos1]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion\n    segment_size = max(2, min(n // 3, int(np.random.normal(loc=n//4, scale=n//6))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with dynamic range\n    reversal_range = max(2, min(n // 2, int(np.random.exponential(scale=n//3))))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined response with 4 bullet points:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\nThe key innovation is combining *adaptive Pareto selection* with *hybrid segment-rotation* and *cost-sensitive edge prioritization*, while rigorously avoiding static or overly greedy operators. This ensures both exploration and exploitation while maintaining feasibility.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 95,
        "algorithm": "The algorithm selects a promising solution from the archive using a weighted Pareto tournament, where solutions are prioritized based on normalized objective values and Pareto efficiency. It then applies a hybrid local search combining adaptive segment rotations and conditional edge reversals, prioritizing high-cost edges in both objective spaces, while optionally inserting nodes with quality-based probabilities to maintain feasibility. The method dynamically adjusts segment sizes and reversal ranges to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted Pareto selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    pareto_weights = np.zeros(len(archive))\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and np.all(objectives[j] <= objectives[i]) and np.any(objectives[j] < objectives[i]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_weights[i] = 1.0 / (1.0 + np.sum(normalized_obj[i]))\n    if np.sum(pareto_weights) == 0:\n        pareto_weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    pareto_weights = pareto_weights / np.sum(pareto_weights)\n    selected_idx = np.random.choice(len(archive), p=pareto_weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment rotation with random length\n    segment_size = max(2, min(n // 2, int(np.random.lognormal(mean=np.log(n/4), sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Conditional edge reversal based on cost-sensitive prioritization\n    edges = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        cost_product = distance_matrix_1[u][v] * distance_matrix_2[u][v]\n        edges.append((i, (i+1)%n, cost_product))\n    edges.sort(key=lambda x: -x[2])\n    if edges:\n        best_edge = edges[0]\n        c = best_edge[0]\n        d = best_edge[1]\n        if d == 0:\n            d = n\n        if d - c > 2:\n            reversal_range = max(2, min(d - c - 1, int(np.random.exponential(scale=(d - c)/3))))\n            e = np.random.randint(c, d - reversal_range + 1)\n            f = e + reversal_range - 1\n            new_solution[e:f+1] = new_solution[e:f+1][::-1]\n\n    # Step 4: Optional node insertion with quality-based probability\n    if np.random.rand() < 0.3 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        insert_node = np.random.choice(new_solution)\n        new_solution = np.delete(new_solution, np.where(new_solution == insert_node)[0][0])\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, insert_node)\n\n    return new_solution\n\n",
        "score": [
            -0.9261407900044285,
            1.9663107991218567
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted Pareto selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    pareto_weights = np.zeros(len(archive))\n    for i in range(len(archive)):\n        dominated = False\n        for j in range(len(archive)):\n            if i != j and np.all(objectives[j] <= objectives[i]) and np.any(objectives[j] < objectives[i]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_weights[i] = 1.0 / (1.0 + np.sum(normalized_obj[i]))\n    if np.sum(pareto_weights) == 0:\n        pareto_weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    pareto_weights = pareto_weights / np.sum(pareto_weights)\n    selected_idx = np.random.choice(len(archive), p=pareto_weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment rotation with random length\n    segment_size = max(2, min(n // 2, int(np.random.lognormal(mean=np.log(n/4), sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Conditional edge reversal based on cost-sensitive prioritization\n    edges = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        cost_product = distance_matrix_1[u][v] * distance_matrix_2[u][v]\n        edges.append((i, (i+1)%n, cost_product))\n    edges.sort(key=lambda x: -x[2])\n    if edges:\n        best_edge = edges[0]\n        c = best_edge[0]\n        d = best_edge[1]\n        if d == 0:\n            d = n\n        if d - c > 2:\n            reversal_range = max(2, min(d - c - 1, int(np.random.exponential(scale=(d - c)/3))))\n            e = np.random.randint(c, d - reversal_range + 1)\n            f = e + reversal_range - 1\n            new_solution[e:f+1] = new_solution[e:f+1][::-1]\n\n    # Step 4: Optional node insertion with quality-based probability\n    if np.random.rand() < 0.3 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        insert_node = np.random.choice(new_solution)\n        new_solution = np.delete(new_solution, np.where(new_solution == insert_node)[0][0])\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, insert_node)\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    # Calculate crowding distance for Pareto front\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    # Build Pareto front\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThis algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThis algorithm employs adaptive multi-objective selection with probabilistic dominance checks to choose promising solutions from an archive, then applies dynamic segment swaps and cost-sensitive edge insertions to generate improved neighbors while maintaining feasibility. It prioritizes solutions with better objective values but occasionally selects non-dominated ones with a small probability, and uses lognormal-distributed segment sizes for adaptive exploration. The local search combines segment swaps (if they improve at least one objective) with edge insertions weighted by combined distance costs to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1]) or \\\n           (current[1][0] <= best[1][0] and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.2:  # Small chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=0.5, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    # Cost-sensitive edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive Pareto selection with weighted crowding distance to prioritize diverse solutions, then applies a hybrid local search that dynamically rotates segments, cost-sensitively prioritizes edges, and conditionally reverses segments when improving at least one objective, ensuring feasibility through strict validation. The approach balances exploration via random segment operations and exploitation via cost-aware prioritization, with dynamic segment sizes and operation probabilities adjusted based on solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThis heuristic combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic operations weighted by edge costs in both objectives, and conditionally reverses segments only when they improve at least one objective, while ensuring feasibility through strict checks. The algorithm balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 96,
        "algorithm": "This algorithm combines adaptive Pareto selection with a novel hybrid local search that dynamically rotates segments, prioritizes edges based on combined objective costs, and conditionally reverses segments while maintaining feasibility. It uses probabilistic dominance checks, multi-objective weighting, and crowding distance to intelligently select promising solutions from the archive, then applies these operations to generate high-quality neighbors while ensuring the solution remains a valid TSP tour. The approach balances exploration and exploitation by dynamically adjusting segment sizes, rotation amounts, and edge selection probabilities based on both objective spaces.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with probabilistic dominance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size and multi-objective weighting\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.2 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.2 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -0.899217082763976,
            0.29997825622558594
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with probabilistic dominance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size and multi-objective weighting\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.2 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.2 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the archive using weighted random selection based on normalized objectives, then applies adaptive segment-based perturbation, multi-phase edge reversal, and optional node insertion to generate a new neighbor solution while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and dynamically adjusts perturbation intensity based on solution quality, using probabilistic segment sizes and deterministic reversal phases. The method combines segment-based modifications with edge reversal and selective node insertion to explore the solution space effectively.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives with different weighting scheme\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment-based perturbation with probabilistic segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=n/5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Multi-phase edge reversal with deterministic range adjustment\n    reversal_phases = [max(2, min(n // 4, int(n / (i+1)))) for i in range(3)]\n    for phase in reversal_phases:\n        c = np.random.randint(0, n - phase + 1)\n        d = c + phase - 1\n        new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node insertion with quality-based probability\n    if np.random.rand() < 0.4 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        insert_node = np.random.choice(new_solution)\n        new_solution = np.delete(new_solution, np.where(new_solution == insert_node)[0][0])\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, insert_node)\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 97,
        "algorithm": "The algorithm selects a promising solution from the archive using weighted random selection based on normalized objective values, then applies a fast segment-based perturbation (randomly moving a segment of nodes) followed by a single edge reversal phase (reversing a segment of nodes) to generate a neighbor solution while ensuring feasibility. The selection prioritizes solutions with lower combined normalized objectives, while the local search uses adaptive segment sizes to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Simplified weighted selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1 / (1 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Fast segment-based perturbation\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=n/4))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Single edge reversal phase\n    reversal_size = max(2, min(n // 3, int(n / 2)))\n    c = np.random.randint(0, n - reversal_size + 1)\n    d = c + reversal_size - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.7629184537533412,
            0.4933466911315918
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Simplified weighted selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1 / (1 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Fast segment-based perturbation\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=n/4))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Single edge reversal phase\n    reversal_size = max(2, min(n // 3, int(n / 2)))\n    c = np.random.randint(0, n - reversal_size + 1)\n    d = c + reversal_size - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 98,
        "algorithm": "The algorithm implements a multi-phase approach for the bi-objective TSP, first selecting promising solutions via Pareto-dominance and hypervolume-based weighting, then applying a hybrid local search combining dynamic segment swapping (randomly exchanging variable-length segments) and adaptive edge flipping (probabilistically reversing edges based on combined distance improvements). It prioritizes exploration through exponential segment length selection and exploitation through weighted edge flipping, while maintaining feasibility through valid TSP tour operations. The selection process favors non-dominated solutions, and the local search dynamically balances segment lengths and edge improvements to navigate the trade-off between objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Non-dominated sorting and hypervolume-based selection\n    fronts = []\n    dominated_counts = [0] * len(archive)\n    domination_sets = [[] for _ in range(len(archive))]\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            if (archive[i][1][0] <= archive[j][1][0] and archive[i][1][1] <= archive[j][1][1] and\n                (archive[i][1][0] < archive[j][1][0] or archive[i][1][1] < archive[j][1][1])):\n                domination_sets[i].append(j)\n            elif (archive[j][1][0] <= archive[i][1][0] and archive[j][1][1] <= archive[i][1][1] and\n                  (archive[j][1][0] < archive[i][1][0] or archive[j][1][1] < archive[i][1][1])):\n                dominated_counts[i] += 1\n\n        if dominated_counts[i] == 0:\n            fronts.append([i])\n\n    current_front = 0\n    while len(fronts) <= current_front and fronts[current_front]:\n        next_front = []\n        for i in fronts[current_front]:\n            for j in domination_sets[i]:\n                dominated_counts[j] -= 1\n                if dominated_counts[j] == 0:\n                    next_front.append(j)\n        fronts.append(next_front)\n        current_front += 1\n\n    # Select from the first front with probability proportional to hypervolume contribution\n    if fronts[0]:\n        selected_idx = np.random.choice(fronts[0])\n    else:\n        selected_idx = np.random.choice(len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swapping\n    segment_length = max(2, min(n // 2, int(np.random.exponential(scale=2.0))))\n    a = np.random.randint(0, n - segment_length + 1)\n    b = a + segment_length - 1\n\n    # Find a non-adjacent segment to swap with\n    candidates = [i for i in range(n) if i not in range(a, b+1) and i + segment_length - 1 < n]\n    if candidates:\n        c = np.random.choice(candidates)\n        d = c + segment_length - 1\n\n        # Swap segments\n        temp = new_solution[a:b+1].copy()\n        new_solution[a:b+1] = new_solution[c:d+1]\n        new_solution[c:d+1] = temp\n\n    # Adaptive edge flipping\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_improvements = []\n\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        u_prev = new_solution[(i-1)%n]\n        v_next = new_solution[(i+2)%n]\n\n        original_cost = combined_distances[u_prev][u] + combined_distances[u][v] + combined_distances[v][v_next]\n        flipped_cost = combined_distances[u_prev][v] + combined_distances[v][u] + combined_distances[u][v_next]\n\n        edge_improvements.append(original_cost - flipped_cost)\n\n    edge_improvements = np.array(edge_improvements)\n    positive_improvements = edge_improvements > 0\n    if np.any(positive_improvements):\n        selected_edges = np.where(positive_improvements)[0]\n        flip_probabilities = edge_improvements[selected_edges] / np.sum(edge_improvements[selected_edges])\n        selected_edge = np.random.choice(selected_edges, p=flip_probabilities)\n\n        # Flip the selected edge\n        new_solution[selected_edge], new_solution[(selected_edge+1)%n] = new_solution[(selected_edge+1)%n], new_solution[selected_edge]\n\n    return new_solution\n\n",
        "score": [
            -0.9306749582412148,
            0.6224082112312317
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Non-dominated sorting and hypervolume-based selection\n    fronts = []\n    dominated_counts = [0] * len(archive)\n    domination_sets = [[] for _ in range(len(archive))]\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            if (archive[i][1][0] <= archive[j][1][0] and archive[i][1][1] <= archive[j][1][1] and\n                (archive[i][1][0] < archive[j][1][0] or archive[i][1][1] < archive[j][1][1])):\n                domination_sets[i].append(j)\n            elif (archive[j][1][0] <= archive[i][1][0] and archive[j][1][1] <= archive[i][1][1] and\n                  (archive[j][1][0] < archive[i][1][0] or archive[j][1][1] < archive[i][1][1])):\n                dominated_counts[i] += 1\n\n        if dominated_counts[i] == 0:\n            fronts.append([i])\n\n    current_front = 0\n    while len(fronts) <= current_front and fronts[current_front]:\n        next_front = []\n        for i in fronts[current_front]:\n            for j in domination_sets[i]:\n                dominated_counts[j] -= 1\n                if dominated_counts[j] == 0:\n                    next_front.append(j)\n        fronts.append(next_front)\n        current_front += 1\n\n    # Select from the first front with probability proportional to hypervolume contribution\n    if fronts[0]:\n        selected_idx = np.random.choice(fronts[0])\n    else:\n        selected_idx = np.random.choice(len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swapping\n    segment_length = max(2, min(n // 2, int(np.random.exponential(scale=2.0))))\n    a = np.random.randint(0, n - segment_length + 1)\n    b = a + segment_length - 1\n\n    # Find a non-adjacent segment to swap with\n    candidates = [i for i in range(n) if i not in range(a, b+1) and i + segment_length - 1 < n]\n    if candidates:\n        c = np.random.choice(candidates)\n        d = c + segment_length - 1\n\n        # Swap segments\n        temp = new_solution[a:b+1].copy()\n        new_solution[a:b+1] = new_solution[c:d+1]\n        new_solution[c:d+1] = temp\n\n    # Adaptive edge flipping\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_improvements = []\n\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        u_prev = new_solution[(i-1)%n]\n        v_next = new_solution[(i+2)%n]\n\n        original_cost = combined_distances[u_prev][u] + combined_distances[u][v] + combined_distances[v][v_next]\n        flipped_cost = combined_distances[u_prev][v] + combined_distances[v][u] + combined_distances[u][v_next]\n\n        edge_improvements.append(original_cost - flipped_cost)\n\n    edge_improvements = np.array(edge_improvements)\n    positive_improvements = edge_improvements > 0\n    if np.any(positive_improvements):\n        selected_edges = np.where(positive_improvements)[0]\n        flip_probabilities = edge_improvements[selected_edges] / np.sum(edge_improvements[selected_edges])\n        selected_edge = np.random.choice(selected_edges, p=flip_probabilities)\n\n        # Flip the selected edge\n        new_solution[selected_edge], new_solution[(selected_edge+1)%n] = new_solution[(selected_edge+1)%n], new_solution[selected_edge]\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThis algorithm employs adaptive multi-objective selection with probabilistic dominance checks to choose promising solutions from an archive, then applies dynamic segment swaps and cost-sensitive edge insertions to generate improved neighbors while maintaining feasibility. It prioritizes solutions with better objective values but occasionally selects non-dominated ones with a small probability, and uses lognormal-distributed segment sizes for adaptive exploration. The local search combines segment swaps (if they improve at least one objective) with edge insertions weighted by combined distance costs to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1]) or \\\n           (current[1][0] <= best[1][0] and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.2:  # Small chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=0.5, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    # Cost-sensitive edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThis heuristic combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic operations weighted by edge costs in both objectives, and conditionally reverses segments only when they improve at least one objective, while ensuring feasibility through strict checks. The algorithm balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 99,
        "algorithm": "The algorithm combines adaptive Pareto selection with a hybrid local search that prioritizes solutions with high crowding distances on the Pareto front, then applies dynamic segment inversions and cost-aware edge prioritization to generate neighbors while ensuring feasibility through strict validation checks. It alternates between probabilistically inverting variable-length segments (only if they improve at least one objective) and inserting nodes based on their normalized distance products in both objective spaces, dynamically adjusting segment sizes and operation probabilities to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment inversion with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n    inverted_segment = new_solution[a:b+1][::-1]\n    new_cost1 = distance_matrix_1[inverted_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[inverted_segment[-1]][new_solution[(b+1)%n]]\n    new_cost2 = distance_matrix_2[inverted_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[inverted_segment[-1]][new_solution[(b+1)%n]]\n\n    if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n        new_solution[a:b+1] = inverted_segment\n\n    # Cost-aware edge prioritization and insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    normalized_distances = (distance_matrix_1 / np.max(distance_matrix_1)) * (distance_matrix_2 / np.max(distance_matrix_2))\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * normalized_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             normalized_distances[new_solution[c]][new_solution[i]] *\n                             normalized_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -0.9180145110012888,
            0.26334691047668457
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment inversion with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n    inverted_segment = new_solution[a:b+1][::-1]\n    new_cost1 = distance_matrix_1[inverted_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[inverted_segment[-1]][new_solution[(b+1)%n]]\n    new_cost2 = distance_matrix_2[inverted_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[inverted_segment[-1]][new_solution[(b+1)%n]]\n\n    if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n        new_solution[a:b+1] = inverted_segment\n\n    # Cost-aware edge prioritization and insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    normalized_distances = (distance_matrix_1 / np.max(distance_matrix_1)) * (distance_matrix_2 / np.max(distance_matrix_2))\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * normalized_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             normalized_distances[new_solution[c]][new_solution[i]] *\n                             normalized_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        This heuristic combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic operations weighted by edge costs in both objectives, and conditionally reverses segments only when they improve at least one objective, while ensuring feasibility through strict checks. The algorithm balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 100,
        "algorithm": "This algorithm combines adaptive multi-objective selection with a novel hybrid local search that prioritizes solutions with better hypervolume contributions, using dynamic node clustering, cost-aware edge insertion, and probabilistic segment swaps to generate high-quality neighbors while ensuring feasibility through validation checks. It emphasizes solutions with high hypervolume scores in a tournament selection and applies weighted operations that balance both objective costs, with probabilistic acceptance to escape local optima. The algorithm dynamically adjusts cluster sizes and segment lengths using exponential distributions to maintain diversity while ensuring the generated tours remain valid.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive hypervolume-based selection\n    def calculate_hypervolume(solutions):\n        # Simple hypervolume approximation\n        sorted_sols = sorted(solutions, key=lambda x: (x[1][0], x[1][1]))\n        hv = 0.0\n        ref_point = (max(s[1][0] for s in solutions), max(s[1][1] for s in solutions))\n        for i, sol in enumerate(sorted_sols):\n            if i == 0:\n                hv += (ref_point[0] - sol[1][0]) * (ref_point[1] - sol[1][1])\n            else:\n                hv += (ref_point[0] - sol[1][0]) * (sorted_sols[i-1][1][1] - sol[1][1])\n        return hv\n\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    tournament_sols = [archive[i] for i in selected_indices]\n\n    hv = calculate_hypervolume(tournament_sols)\n    selected_idx = np.argmax([(s[1][0]*s[1][1])/hv if hv > 0 else 0 for s in tournament_sols])\n    base_solution = archive[selected_indices[selected_idx]][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic node clustering and cost-aware edge insertion\n    cluster_size = max(2, min(n // 4, int(np.random.exponential(scale=1.5))))\n    clusters = []\n    for i in range(0, n, cluster_size):\n        clusters.append(new_solution[i:i+cluster_size])\n\n    if len(clusters) > 1:\n        # Select two distinct clusters\n        c1, c2 = np.random.choice(len(clusters), size=2, replace=False)\n        cluster1 = clusters[c1]\n        cluster2 = clusters[c2]\n\n        # Calculate insertion costs\n        def insertion_cost(cluster, pos):\n            prev_node = new_solution[pos-1] if pos > 0 else new_solution[-1]\n            next_node = new_solution[pos] if pos < n else new_solution[0]\n            cost1 = (distance_matrix_1[prev_node][cluster[0]] +\n                    distance_matrix_1[cluster[-1]][next_node])\n            cost2 = (distance_matrix_2[prev_node][cluster[0]] +\n                    distance_matrix_2[cluster[-1]][next_node])\n            return (cost1 + cost2) * (1 + 0.2 * (cost1 / cost2))\n\n        # Find best insertion positions\n        min_cost = float('inf')\n        best_pos = -1\n        for pos in range(n):\n            if pos in range(c1*cluster_size, (c1+1)*cluster_size) or pos in range(c2*cluster_size, (c2+1)*cluster_size):\n                continue\n            cost = insertion_cost(cluster1, pos)\n            if cost < min_cost:\n                min_cost = cost\n                best_pos = pos\n\n        if best_pos != -1:\n            # Insert cluster1 at best_pos\n            new_solution = np.concatenate([\n                new_solution[:best_pos],\n                cluster1,\n                new_solution[best_pos:]\n            ])\n\n    # Probabilistic segment swap with cost improvement check\n    if n > 4 and np.random.rand() < 0.4:\n        seg_size = max(2, min(n // 5, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - seg_size + 1)\n        b = a + seg_size - 1\n        c = np.random.randint(0, n - seg_size + 1)\n        d = c + seg_size - 1\n\n        original_cost1 = (distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] +\n                          distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] +\n                          distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] +\n                          distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]])\n        original_cost2 = (distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] +\n                          distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] +\n                          distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] +\n                          distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]])\n\n        swapped = new_solution.copy()\n        swapped[a:b+1], swapped[c:d+1] = swapped[c:d+1], swapped[a:b+1]\n\n        new_cost1 = (distance_matrix_1[swapped[a]][swapped[(a-1)%n]] +\n                     distance_matrix_1[swapped[b]][swapped[(b+1)%n]] +\n                     distance_matrix_1[swapped[c]][swapped[(c-1)%n]] +\n                     distance_matrix_1[swapped[d]][swapped[(d+1)%n]])\n        new_cost2 = (distance_matrix_2[swapped[a]][swapped[(a-1)%n]] +\n                     distance_matrix_2[swapped[b]][swapped[(b+1)%n]] +\n                     distance_matrix_2[swapped[c]][swapped[(c-1)%n]] +\n                     distance_matrix_2[swapped[d]][swapped[(d+1)%n]])\n\n        if (new_cost1 < original_cost1 and new_cost2 < original_cost2) or \\\n           (new_cost1 < original_cost1 and np.random.rand() < 0.3) or \\\n           (new_cost2 < original_cost2 and np.random.rand() < 0.3):\n            new_solution = swapped\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -0.932229927001694,
            0.2676836848258972
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive hypervolume-based selection\n    def calculate_hypervolume(solutions):\n        # Simple hypervolume approximation\n        sorted_sols = sorted(solutions, key=lambda x: (x[1][0], x[1][1]))\n        hv = 0.0\n        ref_point = (max(s[1][0] for s in solutions), max(s[1][1] for s in solutions))\n        for i, sol in enumerate(sorted_sols):\n            if i == 0:\n                hv += (ref_point[0] - sol[1][0]) * (ref_point[1] - sol[1][1])\n            else:\n                hv += (ref_point[0] - sol[1][0]) * (sorted_sols[i-1][1][1] - sol[1][1])\n        return hv\n\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    tournament_sols = [archive[i] for i in selected_indices]\n\n    hv = calculate_hypervolume(tournament_sols)\n    selected_idx = np.argmax([(s[1][0]*s[1][1])/hv if hv > 0 else 0 for s in tournament_sols])\n    base_solution = archive[selected_indices[selected_idx]][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic node clustering and cost-aware edge insertion\n    cluster_size = max(2, min(n // 4, int(np.random.exponential(scale=1.5))))\n    clusters = []\n    for i in range(0, n, cluster_size):\n        clusters.append(new_solution[i:i+cluster_size])\n\n    if len(clusters) > 1:\n        # Select two distinct clusters\n        c1, c2 = np.random.choice(len(clusters), size=2, replace=False)\n        cluster1 = clusters[c1]\n        cluster2 = clusters[c2]\n\n        # Calculate insertion costs\n        def insertion_cost(cluster, pos):\n            prev_node = new_solution[pos-1] if pos > 0 else new_solution[-1]\n            next_node = new_solution[pos] if pos < n else new_solution[0]\n            cost1 = (distance_matrix_1[prev_node][cluster[0]] +\n                    distance_matrix_1[cluster[-1]][next_node])\n            cost2 = (distance_matrix_2[prev_node][cluster[0]] +\n                    distance_matrix_2[cluster[-1]][next_node])\n            return (cost1 + cost2) * (1 + 0.2 * (cost1 / cost2))\n\n        # Find best insertion positions\n        min_cost = float('inf')\n        best_pos = -1\n        for pos in range(n):\n            if pos in range(c1*cluster_size, (c1+1)*cluster_size) or pos in range(c2*cluster_size, (c2+1)*cluster_size):\n                continue\n            cost = insertion_cost(cluster1, pos)\n            if cost < min_cost:\n                min_cost = cost\n                best_pos = pos\n\n        if best_pos != -1:\n            # Insert cluster1 at best_pos\n            new_solution = np.concatenate([\n                new_solution[:best_pos],\n                cluster1,\n                new_solution[best_pos:]\n            ])\n\n    # Probabilistic segment swap with cost improvement check\n    if n > 4 and np.random.rand() < 0.4:\n        seg_size = max(2, min(n // 5, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - seg_size + 1)\n        b = a + seg_size - 1\n        c = np.random.randint(0, n - seg_size + 1)\n        d = c + seg_size - 1\n\n        original_cost1 = (distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] +\n                          distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] +\n                          distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] +\n                          distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]])\n        original_cost2 = (distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] +\n                          distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] +\n                          distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] +\n                          distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]])\n\n        swapped = new_solution.copy()\n        swapped[a:b+1], swapped[c:d+1] = swapped[c:d+1], swapped[a:b+1]\n\n        new_cost1 = (distance_matrix_1[swapped[a]][swapped[(a-1)%n]] +\n                     distance_matrix_1[swapped[b]][swapped[(b+1)%n]] +\n                     distance_matrix_1[swapped[c]][swapped[(c-1)%n]] +\n                     distance_matrix_1[swapped[d]][swapped[(d+1)%n]])\n        new_cost2 = (distance_matrix_2[swapped[a]][swapped[(a-1)%n]] +\n                     distance_matrix_2[swapped[b]][swapped[(b+1)%n]] +\n                     distance_matrix_2[swapped[c]][swapped[(c-1)%n]] +\n                     distance_matrix_2[swapped[d]][swapped[(d+1)%n]])\n\n        if (new_cost1 < original_cost1 and new_cost2 < original_cost2) or \\\n           (new_cost1 < original_cost1 and np.random.rand() < 0.3) or \\\n           (new_cost2 < original_cost2 and np.random.rand() < 0.3):\n            new_solution = swapped\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        This heuristic combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic operations weighted by edge costs in both objectives, and conditionally reverses segments only when they improve at least one objective, while ensuring feasibility through strict checks. The algorithm balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 101,
        "algorithm": "The algorithm combines adaptive solution selection with a hybrid local search that prioritizes cost-balanced operations, using dynamic segment swaps, edge insertions, and probabilistic inversions while maintaining feasibility through validation checks. It intelligently selects solutions with improvement potential and applies multi-objective-aware perturbations, favoring balanced cost reductions in both spaces while occasionally allowing exploratory moves. The method dynamically adjusts segment sizes and operation probabilities to balance exploitation and exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Enhanced solution selection with cost improvement potential\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[0]\n\n    # Select solution with best improvement potential\n    for idx in selected_indices[1:]:\n        current_improvement = (archive[selected_idx][1][0] + archive[selected_idx][1][1]) - (archive[idx][1][0] + archive[idx][1][1])\n        if current_improvement > 0:\n            selected_idx = idx\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with cost-based selection\n    segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.0))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Calculate cost difference for the swap\n    original_cost1 = (distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] +\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] +\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] +\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]])\n    original_cost2 = (distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] +\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] +\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] +\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]])\n\n    swapped_segment = new_solution[a:b+1].copy()\n    new_solution[a:b+1] = new_solution[c:d+1]\n    new_solution[c:d+1] = swapped_segment\n\n    new_cost1 = (distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] +\n                 distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] +\n                 distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] +\n                 distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]])\n    new_cost2 = (distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] +\n                 distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] +\n                 distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] +\n                 distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]])\n\n    if (new_cost1 >= original_cost1 and new_cost2 >= original_cost2) and not np.random.rand() < 0.2:\n        new_solution = base_solution.copy()\n\n    # Cost-balanced edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.2 * abs(distance_matrix_1[u][v] - distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                              combined_distances[new_solution[i]][new_solution[d]] *\n                              (1 + 0.2 * abs(distance_matrix_1[new_solution[c]][new_solution[i]] - distance_matrix_2[new_solution[c]][new_solution[i]]))\n                              for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Probabilistic segment inversion with cost balance\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 5, int(np.random.exponential(scale=1.0))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)) or np.random.rand() < 0.15:\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -0.7575546249244214,
            0.2892845869064331
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Enhanced solution selection with cost improvement potential\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[0]\n\n    # Select solution with best improvement potential\n    for idx in selected_indices[1:]:\n        current_improvement = (archive[selected_idx][1][0] + archive[selected_idx][1][1]) - (archive[idx][1][0] + archive[idx][1][1])\n        if current_improvement > 0:\n            selected_idx = idx\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with cost-based selection\n    segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.0))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Calculate cost difference for the swap\n    original_cost1 = (distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] +\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] +\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] +\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]])\n    original_cost2 = (distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] +\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] +\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] +\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]])\n\n    swapped_segment = new_solution[a:b+1].copy()\n    new_solution[a:b+1] = new_solution[c:d+1]\n    new_solution[c:d+1] = swapped_segment\n\n    new_cost1 = (distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] +\n                 distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] +\n                 distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] +\n                 distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]])\n    new_cost2 = (distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] +\n                 distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] +\n                 distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] +\n                 distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]])\n\n    if (new_cost1 >= original_cost1 and new_cost2 >= original_cost2) and not np.random.rand() < 0.2:\n        new_solution = base_solution.copy()\n\n    # Cost-balanced edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.2 * abs(distance_matrix_1[u][v] - distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                              combined_distances[new_solution[i]][new_solution[d]] *\n                              (1 + 0.2 * abs(distance_matrix_1[new_solution[c]][new_solution[i]] - distance_matrix_2[new_solution[c]][new_solution[i]]))\n                              for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Probabilistic segment inversion with cost balance\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 5, int(np.random.exponential(scale=1.0))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)) or np.random.rand() < 0.15:\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 5 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThis heuristic combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic operations weighted by edge costs in both objectives, and conditionally reverses segments only when they improve at least one objective, while ensuring feasibility through strict checks. The algorithm balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThis algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion\n    segment_size = max(2, min(n // 3, int(np.random.normal(loc=n//4, scale=n//6))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with dynamic range\n    reversal_range = max(2, min(n // 2, int(np.random.exponential(scale=n//3))))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 102,
        "algorithm": "The algorithm selects promising solutions from the archive using adaptive Pareto selection with weighted crowding distance, then applies a hybrid local search combining dynamic segment rotations and cost-sensitive edge prioritization to generate high-quality neighbors while ensuring feasibility through strict checks. It prioritizes edges with high combined distances and conditionally applies segment reversals only when they improve at least one objective, with dynamic segment sizes and weighted random selections balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        weights = np.array([1.0 / (1.0 + np.sum(obj)) for _, obj in archive])\n        weights = weights / np.sum(weights)\n        selected_idx = np.random.choice(len(archive), p=weights)\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / (distance_matrix_2[u][v] + 1e-10))))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / (distance_matrix_2[new_solution[c]][new_solution[i]] + 1e-10)))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -0.9364186986980304,
            0.3132675290107727
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        weights = np.array([1.0 / (1.0 + np.sum(obj)) for _, obj in archive])\n        weights = weights / np.sum(weights)\n        selected_idx = np.random.choice(len(archive), p=weights)\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / (distance_matrix_2[u][v] + 1e-10))))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / (distance_matrix_2[new_solution[c]][new_solution[i]] + 1e-10)))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    # Calculate crowding distance for Pareto front\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    # Build Pareto front\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThis algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThis algorithm employs adaptive multi-objective selection with probabilistic dominance checks to choose promising solutions from an archive, then applies dynamic segment swaps and cost-sensitive edge insertions to generate improved neighbors while maintaining feasibility. It prioritizes solutions with better objective values but occasionally selects non-dominated ones with a small probability, and uses lognormal-distributed segment sizes for adaptive exploration. The local search combines segment swaps (if they improve at least one objective) with edge insertions weighted by combined distance costs to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1]) or \\\n           (current[1][0] <= best[1][0] and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.2:  # Small chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=0.5, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    # Cost-sensitive edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive Pareto selection with weighted crowding distance to prioritize diverse solutions, then applies a hybrid local search that dynamically rotates segments, cost-sensitively prioritizes edges, and conditionally reverses segments when improving at least one objective, ensuring feasibility through strict validation. The approach balances exploration via random segment operations and exploitation via cost-aware prioritization, with dynamic segment sizes and operation probabilities adjusted based on solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThis heuristic combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic operations weighted by edge costs in both objectives, and conditionally reverses segments only when they improve at least one objective, while ensuring feasibility through strict checks. The algorithm balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design for the bi-objective TSP:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 103,
        "algorithm": "This algorithm combines adaptive Pareto selection with weighted crowding distance to prioritize diverse, non-dominated solutions, then applies a hybrid local search that dynamically rotates segments, cost-sensitively prioritizes edges, and conditionally reverses segments when improving at least one objective, while ensuring feasibility through strict checks. The algorithm balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities, with edge selection weighted by combined multi-objective distances and segment reversal triggered probabilistically.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -0.9110619859580767,
            0.3026983141899109
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the archive using weighted random selection based on normalized objectives, then applies adaptive segment-based perturbation, multi-phase edge reversal, and optional node insertion to generate a new neighbor solution while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and dynamically adjusts perturbation intensity based on solution quality, using probabilistic segment sizes and deterministic reversal phases. The method combines segment-based modifications with edge reversal and selective node insertion to explore the solution space effectively.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives with different weighting scheme\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment-based perturbation with probabilistic segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=n/5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Multi-phase edge reversal with deterministic range adjustment\n    reversal_phases = [max(2, min(n // 4, int(n / (i+1)))) for i in range(3)]\n    for phase in reversal_phases:\n        c = np.random.randint(0, n - phase + 1)\n        d = c + phase - 1\n        new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node insertion with quality-based probability\n    if np.random.rand() < 0.4 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        insert_node = np.random.choice(new_solution)\n        new_solution = np.delete(new_solution, np.where(new_solution == insert_node)[0][0])\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, insert_node)\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 104,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives (simplified)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / weights.sum()\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Simplified segment-based perturbation (fixed size)\n    segment_size = max(2, min(n // 3, 4))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Simplified edge reversal (fixed phases)\n    reversal_phases = [2, 3, 4]\n    for phase in reversal_phases:\n        if phase < n:\n            c = np.random.randint(0, n - phase + 1)\n            new_solution[c:c+phase] = new_solution[c:c+phase][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.8778337152805835,
            0.48280221223831177
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives (simplified)\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / weights.sum()\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Simplified segment-based perturbation (fixed size)\n    segment_size = max(2, min(n // 3, 4))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Simplified edge reversal (fixed phases)\n    reversal_phases = [2, 3, 4]\n    for phase in reversal_phases:\n        if phase < n:\n            c = np.random.randint(0, n - phase + 1)\n            new_solution[c:c+phase] = new_solution[c:c+phase][::-1]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThis algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm implements a multi-phase approach for the bi-objective TSP, first selecting promising solutions via Pareto-dominance and hypervolume-based weighting, then applying a hybrid local search combining dynamic segment swapping (randomly exchanging variable-length segments) and adaptive edge flipping (probabilistically reversing edges based on combined distance improvements). It prioritizes exploration through exponential segment length selection and exploitation through weighted edge flipping, while maintaining feasibility through valid TSP tour operations. The selection process favors non-dominated solutions, and the local search dynamically balances segment lengths and edge improvements to navigate the trade-off between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Non-dominated sorting and hypervolume-based selection\n    fronts = []\n    dominated_counts = [0] * len(archive)\n    domination_sets = [[] for _ in range(len(archive))]\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            if (archive[i][1][0] <= archive[j][1][0] and archive[i][1][1] <= archive[j][1][1] and\n                (archive[i][1][0] < archive[j][1][0] or archive[i][1][1] < archive[j][1][1])):\n                domination_sets[i].append(j)\n            elif (archive[j][1][0] <= archive[i][1][0] and archive[j][1][1] <= archive[i][1][1] and\n                  (archive[j][1][0] < archive[i][1][0] or archive[j][1][1] < archive[i][1][1])):\n                dominated_counts[i] += 1\n\n        if dominated_counts[i] == 0:\n            fronts.append([i])\n\n    current_front = 0\n    while len(fronts) <= current_front and fronts[current_front]:\n        next_front = []\n        for i in fronts[current_front]:\n            for j in domination_sets[i]:\n                dominated_counts[j] -= 1\n                if dominated_counts[j] == 0:\n                    next_front.append(j)\n        fronts.append(next_front)\n        current_front += 1\n\n    # Select from the first front with probability proportional to hypervolume contribution\n    if fronts[0]:\n        selected_idx = np.random.choice(fronts[0])\n    else:\n        selected_idx = np.random.choice(len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swapping\n    segment_length = max(2, min(n // 2, int(np.random.exponential(scale=2.0))))\n    a = np.random.randint(0, n - segment_length + 1)\n    b = a + segment_length - 1\n\n    # Find a non-adjacent segment to swap with\n    candidates = [i for i in range(n) if i not in range(a, b+1) and i + segment_length - 1 < n]\n    if candidates:\n        c = np.random.choice(candidates)\n        d = c + segment_length - 1\n\n        # Swap segments\n        temp = new_solution[a:b+1].copy()\n        new_solution[a:b+1] = new_solution[c:d+1]\n        new_solution[c:d+1] = temp\n\n    # Adaptive edge flipping\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_improvements = []\n\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        u_prev = new_solution[(i-1)%n]\n        v_next = new_solution[(i+2)%n]\n\n        original_cost = combined_distances[u_prev][u] + combined_distances[u][v] + combined_distances[v][v_next]\n        flipped_cost = combined_distances[u_prev][v] + combined_distances[v][u] + combined_distances[u][v_next]\n\n        edge_improvements.append(original_cost - flipped_cost)\n\n    edge_improvements = np.array(edge_improvements)\n    positive_improvements = edge_improvements > 0\n    if np.any(positive_improvements):\n        selected_edges = np.where(positive_improvements)[0]\n        flip_probabilities = edge_improvements[selected_edges] / np.sum(edge_improvements[selected_edges])\n        selected_edge = np.random.choice(selected_edges, p=flip_probabilities)\n\n        # Flip the selected edge\n        new_solution[selected_edge], new_solution[(selected_edge+1)%n] = new_solution[(selected_edge+1)%n], new_solution[selected_edge]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the bi-objective TSP:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 105,
        "algorithm": "This algorithm combines adaptive Pareto selection with a hybrid local search approach. It first selects promising solutions from the archive using a weighted Pareto tournament that prioritizes high hypervolume contribution, then applies a novel Multi-Objective Segment Inversion (MOSE) operator followed by cost-sensitive edge reinsertions, dynamically balancing exploration and exploitation while maintaining feasibility. The method emphasizes edges with high combined distance products in both objective spaces and adapts segment sizes probabilistically to navigate the Pareto front efficiently.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with hypervolume weighting\n    fronts = []\n    dominated_counts = [0] * len(archive)\n    domination_sets = [[] for _ in range(len(archive))]\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            if (archive[i][1][0] <= archive[j][1][0] and archive[i][1][1] <= archive[j][1][1] and\n                (archive[i][1][0] < archive[j][1][0] or archive[i][1][1] < archive[j][1][1])):\n                domination_sets[i].append(j)\n            elif (archive[j][1][0] <= archive[i][1][0] and archive[j][1][1] <= archive[i][1][1] and\n                  (archive[j][1][0] < archive[i][1][0] or archive[j][1][1] < archive[i][1][1])):\n                dominated_counts[i] += 1\n\n        if dominated_counts[i] == 0:\n            fronts.append([i])\n\n    current_front = 0\n    while len(fronts) <= current_front and fronts[current_front]:\n        next_front = []\n        for i in fronts[current_front]:\n            for j in domination_sets[i]:\n                dominated_counts[j] -= 1\n                if dominated_counts[j] == 0:\n                    next_front.append(j)\n        fronts.append(next_front)\n        current_front += 1\n\n    # Select with probability proportional to hypervolume contribution\n    if fronts[0]:\n        # Calculate hypervolume contributions (simplified approximation)\n        hypervolumes = []\n        for i in fronts[0]:\n            contrib = 1.0 / (1 + archive[i][1][0] + archive[i][1][1])\n            hypervolumes.append(contrib)\n        hypervolumes = np.array(hypervolumes)\n        hypervolumes = hypervolumes / np.sum(hypervolumes)\n        selected_idx = np.random.choice(fronts[0], p=hypervolumes)\n    else:\n        selected_idx = np.random.choice(len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Multi-objective segment inversion (MOSE)\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    original_cost1 = (distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] +\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]])\n    original_cost2 = (distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] +\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]])\n\n    inverted_segment = new_solution[a:b+1][::-1]\n    new_cost1 = (distance_matrix_1[inverted_segment[0]][new_solution[(a-1)%n]] +\n                 distance_matrix_1[inverted_segment[-1]][new_solution[(b+1)%n]])\n    new_cost2 = (distance_matrix_2[inverted_segment[0]][new_solution[(a-1)%n]] +\n                 distance_matrix_2[inverted_segment[-1]][new_solution[(b+1)%n]])\n\n    if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n        new_solution[a:b+1] = inverted_segment\n\n    # Cost-sensitive edge reinsertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_scores = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_scores.append(combined_distances[u][v])\n\n    edge_scores = np.array(edge_scores)\n    edge_scores = edge_scores / np.sum(edge_scores)\n    selected_edge = np.random.choice(n, p=edge_scores)\n\n    # Remove the selected edge and reinsert it elsewhere\n    removed_node = new_solution[selected_edge]\n    new_solution = np.delete(new_solution, selected_edge)\n\n    # Find best insertion position\n    best_pos = 0\n    best_improvement = 0\n    for i in range(n-1):\n        original_cost = (combined_distances[new_solution[i]][new_solution[(i+1)%(n-1)]] +\n                        combined_distances[new_solution[(i-1)%(n-1)]][new_solution[i]])\n        new_cost = (combined_distances[new_solution[(i-1)%(n-1)]][removed_node] +\n                    combined_distances[removed_node][new_solution[i]] +\n                    combined_distances[new_solution[i]][new_solution[(i+1)%(n-1)]])\n\n        improvement = original_cost - new_cost\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n\n    new_solution = np.insert(new_solution, best_pos, removed_node)\n\n    return new_solution\n\n",
        "score": [
            -0.7893582521116683,
            0.7391265034675598
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with hypervolume weighting\n    fronts = []\n    dominated_counts = [0] * len(archive)\n    domination_sets = [[] for _ in range(len(archive))]\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            if (archive[i][1][0] <= archive[j][1][0] and archive[i][1][1] <= archive[j][1][1] and\n                (archive[i][1][0] < archive[j][1][0] or archive[i][1][1] < archive[j][1][1])):\n                domination_sets[i].append(j)\n            elif (archive[j][1][0] <= archive[i][1][0] and archive[j][1][1] <= archive[i][1][1] and\n                  (archive[j][1][0] < archive[i][1][0] or archive[j][1][1] < archive[i][1][1])):\n                dominated_counts[i] += 1\n\n        if dominated_counts[i] == 0:\n            fronts.append([i])\n\n    current_front = 0\n    while len(fronts) <= current_front and fronts[current_front]:\n        next_front = []\n        for i in fronts[current_front]:\n            for j in domination_sets[i]:\n                dominated_counts[j] -= 1\n                if dominated_counts[j] == 0:\n                    next_front.append(j)\n        fronts.append(next_front)\n        current_front += 1\n\n    # Select with probability proportional to hypervolume contribution\n    if fronts[0]:\n        # Calculate hypervolume contributions (simplified approximation)\n        hypervolumes = []\n        for i in fronts[0]:\n            contrib = 1.0 / (1 + archive[i][1][0] + archive[i][1][1])\n            hypervolumes.append(contrib)\n        hypervolumes = np.array(hypervolumes)\n        hypervolumes = hypervolumes / np.sum(hypervolumes)\n        selected_idx = np.random.choice(fronts[0], p=hypervolumes)\n    else:\n        selected_idx = np.random.choice(len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Multi-objective segment inversion (MOSE)\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    original_cost1 = (distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] +\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]])\n    original_cost2 = (distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] +\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]])\n\n    inverted_segment = new_solution[a:b+1][::-1]\n    new_cost1 = (distance_matrix_1[inverted_segment[0]][new_solution[(a-1)%n]] +\n                 distance_matrix_1[inverted_segment[-1]][new_solution[(b+1)%n]])\n    new_cost2 = (distance_matrix_2[inverted_segment[0]][new_solution[(a-1)%n]] +\n                 distance_matrix_2[inverted_segment[-1]][new_solution[(b+1)%n]])\n\n    if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n        new_solution[a:b+1] = inverted_segment\n\n    # Cost-sensitive edge reinsertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_scores = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_scores.append(combined_distances[u][v])\n\n    edge_scores = np.array(edge_scores)\n    edge_scores = edge_scores / np.sum(edge_scores)\n    selected_edge = np.random.choice(n, p=edge_scores)\n\n    # Remove the selected edge and reinsert it elsewhere\n    removed_node = new_solution[selected_edge]\n    new_solution = np.delete(new_solution, selected_edge)\n\n    # Find best insertion position\n    best_pos = 0\n    best_improvement = 0\n    for i in range(n-1):\n        original_cost = (combined_distances[new_solution[i]][new_solution[(i+1)%(n-1)]] +\n                        combined_distances[new_solution[(i-1)%(n-1)]][new_solution[i]])\n        new_cost = (combined_distances[new_solution[(i-1)%(n-1)]][removed_node] +\n                    combined_distances[removed_node][new_solution[i]] +\n                    combined_distances[new_solution[i]][new_solution[(i+1)%(n-1)]])\n\n        improvement = original_cost - new_cost\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n\n    new_solution = np.insert(new_solution, best_pos, removed_node)\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm implements a multi-phase approach for the bi-objective TSP, first selecting promising solutions via Pareto-dominance and hypervolume-based weighting, then applying a hybrid local search combining dynamic segment swapping (randomly exchanging variable-length segments) and adaptive edge flipping (probabilistically reversing edges based on combined distance improvements). It prioritizes exploration through exponential segment length selection and exploitation through weighted edge flipping, while maintaining feasibility through valid TSP tour operations. The selection process favors non-dominated solutions, and the local search dynamically balances segment lengths and edge improvements to navigate the trade-off between objectives.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Non-dominated sorting and hypervolume-based selection\n    fronts = []\n    dominated_counts = [0] * len(archive)\n    domination_sets = [[] for _ in range(len(archive))]\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            if (archive[i][1][0] <= archive[j][1][0] and archive[i][1][1] <= archive[j][1][1] and\n                (archive[i][1][0] < archive[j][1][0] or archive[i][1][1] < archive[j][1][1])):\n                domination_sets[i].append(j)\n            elif (archive[j][1][0] <= archive[i][1][0] and archive[j][1][1] <= archive[i][1][1] and\n                  (archive[j][1][0] < archive[i][1][0] or archive[j][1][1] < archive[i][1][1])):\n                dominated_counts[i] += 1\n\n        if dominated_counts[i] == 0:\n            fronts.append([i])\n\n    current_front = 0\n    while len(fronts) <= current_front and fronts[current_front]:\n        next_front = []\n        for i in fronts[current_front]:\n            for j in domination_sets[i]:\n                dominated_counts[j] -= 1\n                if dominated_counts[j] == 0:\n                    next_front.append(j)\n        fronts.append(next_front)\n        current_front += 1\n\n    # Select from the first front with probability proportional to hypervolume contribution\n    if fronts[0]:\n        selected_idx = np.random.choice(fronts[0])\n    else:\n        selected_idx = np.random.choice(len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swapping\n    segment_length = max(2, min(n // 2, int(np.random.exponential(scale=2.0))))\n    a = np.random.randint(0, n - segment_length + 1)\n    b = a + segment_length - 1\n\n    # Find a non-adjacent segment to swap with\n    candidates = [i for i in range(n) if i not in range(a, b+1) and i + segment_length - 1 < n]\n    if candidates:\n        c = np.random.choice(candidates)\n        d = c + segment_length - 1\n\n        # Swap segments\n        temp = new_solution[a:b+1].copy()\n        new_solution[a:b+1] = new_solution[c:d+1]\n        new_solution[c:d+1] = temp\n\n    # Adaptive edge flipping\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_improvements = []\n\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        u_prev = new_solution[(i-1)%n]\n        v_next = new_solution[(i+2)%n]\n\n        original_cost = combined_distances[u_prev][u] + combined_distances[u][v] + combined_distances[v][v_next]\n        flipped_cost = combined_distances[u_prev][v] + combined_distances[v][u] + combined_distances[u][v_next]\n\n        edge_improvements.append(original_cost - flipped_cost)\n\n    edge_improvements = np.array(edge_improvements)\n    positive_improvements = edge_improvements > 0\n    if np.any(positive_improvements):\n        selected_edges = np.where(positive_improvements)[0]\n        flip_probabilities = edge_improvements[selected_edges] / np.sum(edge_improvements[selected_edges])\n        selected_edge = np.random.choice(selected_edges, p=flip_probabilities)\n\n        # Flip the selected edge\n        new_solution[selected_edge], new_solution[(selected_edge+1)%n] = new_solution[(selected_edge+1)%n], new_solution[selected_edge]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 106,
        "algorithm": "The algorithm implements a multi-phase selection process that combines Pareto-dominance with an adaptive segment insertion operator, followed by a hybrid local search combining probabilistic segment reversal and weighted edge insertion, while dynamically adjusting segment lengths based on solution quality and maintaining feasibility through TSP tour constraints. It prioritizes solutions from the first Pareto front with higher probability, uses combined objective values to guide segment operations, and applies probabilistic local search operators to explore the solution space while ensuring feasibility. The critical design ideas are the Pareto-based selection, adaptive segment operations, and weighted edge insertion, which collectively drive the search toward high-quality solutions across both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance based selection with adaptive weighting\n    fronts = []\n    dominated_counts = [0] * len(archive)\n    domination_sets = [[] for _ in range(len(archive))]\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            if (archive[i][1][0] <= archive[j][1][0] and archive[i][1][1] <= archive[j][1][1] and\n                (archive[i][1][0] < archive[j][1][0] or archive[i][1][1] < archive[j][1][1])):\n                domination_sets[i].append(j)\n            elif (archive[j][1][0] <= archive[i][1][0] and archive[j][1][1] <= archive[i][1][1] and\n                  (archive[j][1][0] < archive[i][1][0] or archive[j][1][1] < archive[i][1][1])):\n                dominated_counts[i] += 1\n\n        if dominated_counts[i] == 0:\n            fronts.append([i])\n\n    current_front = 0\n    while len(fronts) <= current_front and fronts[current_front]:\n        next_front = []\n        for i in fronts[current_front]:\n            for j in domination_sets[i]:\n                dominated_counts[j] -= 1\n                if dominated_counts[j] == 0:\n                    next_front.append(j)\n        fronts.append(next_front)\n        current_front += 1\n\n    # Select with probability based on combined objective value and dominance\n    if fronts[0]:\n        weights = np.array([1/(archive[i][1][0] + archive[i][1][1] + 1e-6) for i in fronts[0]])\n        weights = weights / np.sum(weights)\n        selected_idx = np.random.choice(fronts[0], p=weights)\n    else:\n        selected_idx = np.random.choice(len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment insertion\n    segment_length = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_length + 1)\n    segment = new_solution[a:a+segment_length]\n\n    # Find insertion point with maximum combined distance improvement\n    max_improvement = -np.inf\n    best_pos = -1\n    combined_distances = distance_matrix_1 + distance_matrix_2\n\n    for i in range(n - segment_length + 1):\n        if i == a:  # Skip original position\n            continue\n        # Calculate improvement for inserting segment at position i\n        prev_node = new_solution[(i-1)%n]\n        next_node = new_solution[i%n]\n\n        original_cost = combined_distances[prev_node][new_solution[i%n]] + combined_distances[new_solution[(i+segment_length-1)%n]][next_node]\n        new_cost = combined_distances[prev_node][segment[0]] + combined_distances[segment[-1]][next_node]\n\n        improvement = original_cost - new_cost\n\n        if improvement > max_improvement:\n            max_improvement = improvement\n            best_pos = i\n\n    if best_pos != -1 and max_improvement > 0:\n        # Remove original segment\n        new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_length:]])\n        # Insert at new position\n        new_solution = np.concatenate([new_solution[:best_pos], segment, new_solution[best_pos:]])\n\n    # Probabilistic segment reversal\n    if np.random.random() < 0.3:  # 30% chance to reverse a segment\n        segment_length = max(2, min(n // 4, int(np.random.exponential(scale=1.0))))\n        a = np.random.randint(0, n - segment_length + 1)\n        new_solution[a:a+segment_length] = new_solution[a:a+segment_length][::-1]\n\n    # Weighted edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = np.zeros(n)\n\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        u_prev = new_solution[(i-1)%n]\n        v_next = new_solution[(i+2)%n]\n\n        original_cost = combined_distances[u_prev][u] + combined_distances[u][v] + combined_distances[v][v_next]\n        flipped_cost = combined_distances[u_prev][v] + combined_distances[v][u] + combined_distances[u][v_next]\n\n        edge_weights[i] = max(0, original_cost - flipped_cost)\n\n    if np.sum(edge_weights) > 0:\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n\n        # Insert the selected edge in reverse\n        new_solution[selected_edge], new_solution[(selected_edge+1)%n] = new_solution[(selected_edge+1)%n], new_solution[selected_edge]\n\n    return new_solution\n\n",
        "score": [
            -0.8064550898540235,
            0.7705090045928955
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-dominance based selection with adaptive weighting\n    fronts = []\n    dominated_counts = [0] * len(archive)\n    domination_sets = [[] for _ in range(len(archive))]\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            if (archive[i][1][0] <= archive[j][1][0] and archive[i][1][1] <= archive[j][1][1] and\n                (archive[i][1][0] < archive[j][1][0] or archive[i][1][1] < archive[j][1][1])):\n                domination_sets[i].append(j)\n            elif (archive[j][1][0] <= archive[i][1][0] and archive[j][1][1] <= archive[i][1][1] and\n                  (archive[j][1][0] < archive[i][1][0] or archive[j][1][1] < archive[i][1][1])):\n                dominated_counts[i] += 1\n\n        if dominated_counts[i] == 0:\n            fronts.append([i])\n\n    current_front = 0\n    while len(fronts) <= current_front and fronts[current_front]:\n        next_front = []\n        for i in fronts[current_front]:\n            for j in domination_sets[i]:\n                dominated_counts[j] -= 1\n                if dominated_counts[j] == 0:\n                    next_front.append(j)\n        fronts.append(next_front)\n        current_front += 1\n\n    # Select with probability based on combined objective value and dominance\n    if fronts[0]:\n        weights = np.array([1/(archive[i][1][0] + archive[i][1][1] + 1e-6) for i in fronts[0]])\n        weights = weights / np.sum(weights)\n        selected_idx = np.random.choice(fronts[0], p=weights)\n    else:\n        selected_idx = np.random.choice(len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment insertion\n    segment_length = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_length + 1)\n    segment = new_solution[a:a+segment_length]\n\n    # Find insertion point with maximum combined distance improvement\n    max_improvement = -np.inf\n    best_pos = -1\n    combined_distances = distance_matrix_1 + distance_matrix_2\n\n    for i in range(n - segment_length + 1):\n        if i == a:  # Skip original position\n            continue\n        # Calculate improvement for inserting segment at position i\n        prev_node = new_solution[(i-1)%n]\n        next_node = new_solution[i%n]\n\n        original_cost = combined_distances[prev_node][new_solution[i%n]] + combined_distances[new_solution[(i+segment_length-1)%n]][next_node]\n        new_cost = combined_distances[prev_node][segment[0]] + combined_distances[segment[-1]][next_node]\n\n        improvement = original_cost - new_cost\n\n        if improvement > max_improvement:\n            max_improvement = improvement\n            best_pos = i\n\n    if best_pos != -1 and max_improvement > 0:\n        # Remove original segment\n        new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_length:]])\n        # Insert at new position\n        new_solution = np.concatenate([new_solution[:best_pos], segment, new_solution[best_pos:]])\n\n    # Probabilistic segment reversal\n    if np.random.random() < 0.3:  # 30% chance to reverse a segment\n        segment_length = max(2, min(n // 4, int(np.random.exponential(scale=1.0))))\n        a = np.random.randint(0, n - segment_length + 1)\n        new_solution[a:a+segment_length] = new_solution[a:a+segment_length][::-1]\n\n    # Weighted edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = np.zeros(n)\n\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        u_prev = new_solution[(i-1)%n]\n        v_next = new_solution[(i+2)%n]\n\n        original_cost = combined_distances[u_prev][u] + combined_distances[u][v] + combined_distances[v][v_next]\n        flipped_cost = combined_distances[u_prev][v] + combined_distances[v][u] + combined_distances[u][v_next]\n\n        edge_weights[i] = max(0, original_cost - flipped_cost)\n\n    if np.sum(edge_weights) > 0:\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n\n        # Insert the selected edge in reverse\n        new_solution[selected_edge], new_solution[(selected_edge+1)%n] = new_solution[(selected_edge+1)%n], new_solution[selected_edge]\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm implements a multi-phase approach for the bi-objective TSP, first selecting promising solutions via Pareto-dominance and hypervolume-based weighting, then applying a hybrid local search combining dynamic segment swapping (randomly exchanging variable-length segments) and adaptive edge flipping (probabilistically reversing edges based on combined distance improvements). It prioritizes exploration through exponential segment length selection and exploitation through weighted edge flipping, while maintaining feasibility through valid TSP tour operations. The selection process favors non-dominated solutions, and the local search dynamically balances segment lengths and edge improvements to navigate the trade-off between objectives.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Non-dominated sorting and hypervolume-based selection\n    fronts = []\n    dominated_counts = [0] * len(archive)\n    domination_sets = [[] for _ in range(len(archive))]\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            if (archive[i][1][0] <= archive[j][1][0] and archive[i][1][1] <= archive[j][1][1] and\n                (archive[i][1][0] < archive[j][1][0] or archive[i][1][1] < archive[j][1][1])):\n                domination_sets[i].append(j)\n            elif (archive[j][1][0] <= archive[i][1][0] and archive[j][1][1] <= archive[i][1][1] and\n                  (archive[j][1][0] < archive[i][1][0] or archive[j][1][1] < archive[i][1][1])):\n                dominated_counts[i] += 1\n\n        if dominated_counts[i] == 0:\n            fronts.append([i])\n\n    current_front = 0\n    while len(fronts) <= current_front and fronts[current_front]:\n        next_front = []\n        for i in fronts[current_front]:\n            for j in domination_sets[i]:\n                dominated_counts[j] -= 1\n                if dominated_counts[j] == 0:\n                    next_front.append(j)\n        fronts.append(next_front)\n        current_front += 1\n\n    # Select from the first front with probability proportional to hypervolume contribution\n    if fronts[0]:\n        selected_idx = np.random.choice(fronts[0])\n    else:\n        selected_idx = np.random.choice(len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swapping\n    segment_length = max(2, min(n // 2, int(np.random.exponential(scale=2.0))))\n    a = np.random.randint(0, n - segment_length + 1)\n    b = a + segment_length - 1\n\n    # Find a non-adjacent segment to swap with\n    candidates = [i for i in range(n) if i not in range(a, b+1) and i + segment_length - 1 < n]\n    if candidates:\n        c = np.random.choice(candidates)\n        d = c + segment_length - 1\n\n        # Swap segments\n        temp = new_solution[a:b+1].copy()\n        new_solution[a:b+1] = new_solution[c:d+1]\n        new_solution[c:d+1] = temp\n\n    # Adaptive edge flipping\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_improvements = []\n\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        u_prev = new_solution[(i-1)%n]\n        v_next = new_solution[(i+2)%n]\n\n        original_cost = combined_distances[u_prev][u] + combined_distances[u][v] + combined_distances[v][v_next]\n        flipped_cost = combined_distances[u_prev][v] + combined_distances[v][u] + combined_distances[u][v_next]\n\n        edge_improvements.append(original_cost - flipped_cost)\n\n    edge_improvements = np.array(edge_improvements)\n    positive_improvements = edge_improvements > 0\n    if np.any(positive_improvements):\n        selected_edges = np.where(positive_improvements)[0]\n        flip_probabilities = edge_improvements[selected_edges] / np.sum(edge_improvements[selected_edges])\n        selected_edge = np.random.choice(selected_edges, p=flip_probabilities)\n\n        # Flip the selected edge\n        new_solution[selected_edge], new_solution[(selected_edge+1)%n] = new_solution[(selected_edge+1)%n], new_solution[selected_edge]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 107,
        "algorithm": "The algorithm implements a multi-phase approach that first identifies Pareto-optimal solutions (first front) and probabilistically selects one based on normalized objective sums, then applies adaptive segment relocation with geometrically distributed segment lengths followed by probabilistic edge reversal weighted by normalized improvements in combined distance matrices to generate a neighbor solution while ensuring feasibility. The selection prioritizes solutions from the Pareto front, and the local search balances exploration (random segment lengths) with exploitation (weighted edge flips).",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Non-dominated sorting\n    fronts = []\n    dominated_counts = [0] * len(archive)\n    domination_sets = [[] for _ in range(len(archive))]\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            if (archive[i][1][0] <= archive[j][1][0] and archive[i][1][1] <= archive[j][1][1] and\n                (archive[i][1][0] < archive[j][1][0] or archive[i][1][1] < archive[j][1][1])):\n                domination_sets[i].append(j)\n            elif (archive[j][1][0] <= archive[i][1][0] and archive[j][1][1] <= archive[i][1][1] and\n                  (archive[j][1][0] < archive[i][1][0] or archive[j][1][1] < archive[i][1][1])):\n                dominated_counts[i] += 1\n\n        if dominated_counts[i] == 0:\n            fronts.append([i])\n\n    current_front = 0\n    while len(fronts) <= current_front and fronts[current_front]:\n        next_front = []\n        for i in fronts[current_front]:\n            for j in domination_sets[i]:\n                dominated_counts[j] -= 1\n                if dominated_counts[j] == 0:\n                    next_front.append(j)\n        fronts.append(next_front)\n        current_front += 1\n\n    # Select from the first front with probability proportional to normalized objective sum\n    if fronts[0]:\n        objectives = np.array([archive[i][1] for i in fronts[0]])\n        weights = 1 / (np.sum(objectives, axis=1) + 1e-6)  # Avoid division by zero\n        weights = weights / np.sum(weights)\n        selected_idx = np.random.choice(fronts[0], p=weights)\n    else:\n        selected_idx = np.random.choice(len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment relocation with geometric distribution\n    segment_length = max(2, min(n // 3, int(np.random.geometric(p=0.3))))\n    a = np.random.randint(0, n - segment_length + 1)\n    b = a + segment_length - 1\n\n    # Find a non-adjacent position to insert the segment\n    candidates = [i for i in range(n) if i not in range(a, b+1) and i + segment_length - 1 < n]\n    if candidates:\n        c = np.random.choice(candidates)\n        segment = new_solution[a:b+1].copy()\n\n        # Remove the segment\n        new_solution = np.concatenate([new_solution[:a], new_solution[b+1:]])\n        # Insert the segment at new position\n        new_solution = np.concatenate([new_solution[:c], segment, new_solution[c:]])\n\n    # Probabilistic edge reversal weighted by normalized improvements\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_improvements = []\n\n    for i in range(n-1):\n        u = new_solution[i]\n        v = new_solution[i+1]\n        u_prev = new_solution[i-1]\n        v_next = new_solution[(i+2)%n]\n\n        original_cost = combined_distances[u_prev][u] + combined_distances[u][v] + combined_distances[v][v_next]\n        flipped_cost = combined_distances[u_prev][v] + combined_distances[v][u] + combined_distances[u][v_next]\n\n        edge_improvements.append(original_cost - flipped_cost)\n\n    edge_improvements = np.array(edge_improvements)\n    positive_improvements = edge_improvements > 0\n    if np.any(positive_improvements):\n        selected_edges = np.where(positive_improvements)[0]\n        flip_weights = edge_improvements[selected_edges] / np.sum(edge_improvements[selected_edges])\n        selected_edge = np.random.choice(selected_edges, p=flip_weights)\n\n        # Reverse the selected edge\n        new_solution[selected_edge], new_solution[selected_edge+1] = new_solution[selected_edge+1], new_solution[selected_edge]\n\n    return new_solution\n\n",
        "score": [
            -0.8662019815611784,
            0.7086807489395142
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Non-dominated sorting\n    fronts = []\n    dominated_counts = [0] * len(archive)\n    domination_sets = [[] for _ in range(len(archive))]\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            if (archive[i][1][0] <= archive[j][1][0] and archive[i][1][1] <= archive[j][1][1] and\n                (archive[i][1][0] < archive[j][1][0] or archive[i][1][1] < archive[j][1][1])):\n                domination_sets[i].append(j)\n            elif (archive[j][1][0] <= archive[i][1][0] and archive[j][1][1] <= archive[i][1][1] and\n                  (archive[j][1][0] < archive[i][1][0] or archive[j][1][1] < archive[i][1][1])):\n                dominated_counts[i] += 1\n\n        if dominated_counts[i] == 0:\n            fronts.append([i])\n\n    current_front = 0\n    while len(fronts) <= current_front and fronts[current_front]:\n        next_front = []\n        for i in fronts[current_front]:\n            for j in domination_sets[i]:\n                dominated_counts[j] -= 1\n                if dominated_counts[j] == 0:\n                    next_front.append(j)\n        fronts.append(next_front)\n        current_front += 1\n\n    # Select from the first front with probability proportional to normalized objective sum\n    if fronts[0]:\n        objectives = np.array([archive[i][1] for i in fronts[0]])\n        weights = 1 / (np.sum(objectives, axis=1) + 1e-6)  # Avoid division by zero\n        weights = weights / np.sum(weights)\n        selected_idx = np.random.choice(fronts[0], p=weights)\n    else:\n        selected_idx = np.random.choice(len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment relocation with geometric distribution\n    segment_length = max(2, min(n // 3, int(np.random.geometric(p=0.3))))\n    a = np.random.randint(0, n - segment_length + 1)\n    b = a + segment_length - 1\n\n    # Find a non-adjacent position to insert the segment\n    candidates = [i for i in range(n) if i not in range(a, b+1) and i + segment_length - 1 < n]\n    if candidates:\n        c = np.random.choice(candidates)\n        segment = new_solution[a:b+1].copy()\n\n        # Remove the segment\n        new_solution = np.concatenate([new_solution[:a], new_solution[b+1:]])\n        # Insert the segment at new position\n        new_solution = np.concatenate([new_solution[:c], segment, new_solution[c:]])\n\n    # Probabilistic edge reversal weighted by normalized improvements\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_improvements = []\n\n    for i in range(n-1):\n        u = new_solution[i]\n        v = new_solution[i+1]\n        u_prev = new_solution[i-1]\n        v_next = new_solution[(i+2)%n]\n\n        original_cost = combined_distances[u_prev][u] + combined_distances[u][v] + combined_distances[v][v_next]\n        flipped_cost = combined_distances[u_prev][v] + combined_distances[v][u] + combined_distances[u][v_next]\n\n        edge_improvements.append(original_cost - flipped_cost)\n\n    edge_improvements = np.array(edge_improvements)\n    positive_improvements = edge_improvements > 0\n    if np.any(positive_improvements):\n        selected_edges = np.where(positive_improvements)[0]\n        flip_weights = edge_improvements[selected_edges] / np.sum(edge_improvements[selected_edges])\n        selected_edge = np.random.choice(selected_edges, p=flip_weights)\n\n        # Reverse the selected edge\n        new_solution[selected_edge], new_solution[selected_edge+1] = new_solution[selected_edge+1], new_solution[selected_edge]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm implements a multi-phase approach for the bi-objective TSP, first selecting promising solutions via Pareto-dominance and hypervolume-based weighting, then applying a hybrid local search combining dynamic segment swapping (randomly exchanging variable-length segments) and adaptive edge flipping (probabilistically reversing edges based on combined distance improvements). It prioritizes exploration through exponential segment length selection and exploitation through weighted edge flipping, while maintaining feasibility through valid TSP tour operations. The selection process favors non-dominated solutions, and the local search dynamically balances segment lengths and edge improvements to navigate the trade-off between objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Non-dominated sorting and hypervolume-based selection\n    fronts = []\n    dominated_counts = [0] * len(archive)\n    domination_sets = [[] for _ in range(len(archive))]\n\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            if (archive[i][1][0] <= archive[j][1][0] and archive[i][1][1] <= archive[j][1][1] and\n                (archive[i][1][0] < archive[j][1][0] or archive[i][1][1] < archive[j][1][1])):\n                domination_sets[i].append(j)\n            elif (archive[j][1][0] <= archive[i][1][0] and archive[j][1][1] <= archive[i][1][1] and\n                  (archive[j][1][0] < archive[i][1][0] or archive[j][1][1] < archive[i][1][1])):\n                dominated_counts[i] += 1\n\n        if dominated_counts[i] == 0:\n            fronts.append([i])\n\n    current_front = 0\n    while len(fronts) <= current_front and fronts[current_front]:\n        next_front = []\n        for i in fronts[current_front]:\n            for j in domination_sets[i]:\n                dominated_counts[j] -= 1\n                if dominated_counts[j] == 0:\n                    next_front.append(j)\n        fronts.append(next_front)\n        current_front += 1\n\n    # Select from the first front with probability proportional to hypervolume contribution\n    if fronts[0]:\n        selected_idx = np.random.choice(fronts[0])\n    else:\n        selected_idx = np.random.choice(len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swapping\n    segment_length = max(2, min(n // 2, int(np.random.exponential(scale=2.0))))\n    a = np.random.randint(0, n - segment_length + 1)\n    b = a + segment_length - 1\n\n    # Find a non-adjacent segment to swap with\n    candidates = [i for i in range(n) if i not in range(a, b+1) and i + segment_length - 1 < n]\n    if candidates:\n        c = np.random.choice(candidates)\n        d = c + segment_length - 1\n\n        # Swap segments\n        temp = new_solution[a:b+1].copy()\n        new_solution[a:b+1] = new_solution[c:d+1]\n        new_solution[c:d+1] = temp\n\n    # Adaptive edge flipping\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_improvements = []\n\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        u_prev = new_solution[(i-1)%n]\n        v_next = new_solution[(i+2)%n]\n\n        original_cost = combined_distances[u_prev][u] + combined_distances[u][v] + combined_distances[v][v_next]\n        flipped_cost = combined_distances[u_prev][v] + combined_distances[v][u] + combined_distances[u][v_next]\n\n        edge_improvements.append(original_cost - flipped_cost)\n\n    edge_improvements = np.array(edge_improvements)\n    positive_improvements = edge_improvements > 0\n    if np.any(positive_improvements):\n        selected_edges = np.where(positive_improvements)[0]\n        flip_probabilities = edge_improvements[selected_edges] / np.sum(edge_improvements[selected_edges])\n        selected_edge = np.random.choice(selected_edges, p=flip_probabilities)\n\n        # Flip the selected edge\n        new_solution[selected_edge], new_solution[(selected_edge+1)%n] = new_solution[(selected_edge+1)%n], new_solution[selected_edge]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the bi-objective TSP:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 108,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted tournament\n    selected_idx = None\n    if len(archive) > 1:\n        # Select 2 random solutions and pick the non-dominated one\n        candidates = np.random.choice(len(archive), size=min(5, len(archive)), replace=False)\n        best_idx = candidates[0]\n        for i in candidates[1:]:\n            if (archive[i][1][0] <= archive[best_idx][1][0] and archive[i][1][1] <= archive[best_idx][1][1] and\n                (archive[i][1][0] < archive[best_idx][1][0] or archive[i][1][1] < archive[best_idx][1][1])):\n                best_idx = i\n        selected_idx = best_idx\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Hybrid segment rotation with variable length\n    segment_length = max(2, min(n // 2, int(np.random.exponential(scale=2.0))))\n    a = np.random.randint(0, n - segment_length + 1)\n    b = a + segment_length - 1\n\n    # Rotate segment by random positions\n    rotation = np.random.randint(1, segment_length)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with conditional reversals\n    combined_weights = np.maximum(distance_matrix_1, distance_matrix_2)  # Normalized weights\n    edge_scores = []\n\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        u_prev = new_solution[(i-1)%n]\n        v_next = new_solution[(i+2)%n]\n\n        original_cost = combined_weights[u_prev][u] + combined_weights[u][v] + combined_weights[v][v_next]\n        flipped_cost = combined_weights[u_prev][v] + combined_weights[v][u] + combined_weights[u][v_next]\n        improvement = original_cost - flipped_cost\n\n        if improvement > 0:\n            # Check if flip improves at least one objective\n            cost1_diff = (distance_matrix_1[u_prev][v] + distance_matrix_1[v][u] + distance_matrix_1[u][v_next]) - \\\n                         (distance_matrix_1[u_prev][u] + distance_matrix_1[u][v] + distance_matrix_1[v][v_next])\n            cost2_diff = (distance_matrix_2[u_prev][v] + distance_matrix_2[v][u] + distance_matrix_2[u][v_next]) - \\\n                         (distance_matrix_2[u_prev][u] + distance_matrix_2[u][v] + distance_matrix_2[v][v_next])\n\n            if cost1_diff < 0 or cost2_diff < 0:\n                edge_scores.append((i, improvement))\n\n    if edge_scores:\n        # Select edge with highest improvement\n        edge_scores.sort(key=lambda x: -x[1])\n        best_edge = edge_scores[0][0]\n        new_solution[best_edge], new_solution[(best_edge+1)%n] = new_solution[(best_edge+1)%n], new_solution[best_edge]\n\n    # Conditional feasibility check\n    if len(np.unique(new_solution)) != n:\n        # Revert to base solution if feasibility is violated\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7960664941102268,
            0.7871317267417908
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted tournament\n    selected_idx = None\n    if len(archive) > 1:\n        # Select 2 random solutions and pick the non-dominated one\n        candidates = np.random.choice(len(archive), size=min(5, len(archive)), replace=False)\n        best_idx = candidates[0]\n        for i in candidates[1:]:\n            if (archive[i][1][0] <= archive[best_idx][1][0] and archive[i][1][1] <= archive[best_idx][1][1] and\n                (archive[i][1][0] < archive[best_idx][1][0] or archive[i][1][1] < archive[best_idx][1][1])):\n                best_idx = i\n        selected_idx = best_idx\n    else:\n        selected_idx = 0\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Hybrid segment rotation with variable length\n    segment_length = max(2, min(n // 2, int(np.random.exponential(scale=2.0))))\n    a = np.random.randint(0, n - segment_length + 1)\n    b = a + segment_length - 1\n\n    # Rotate segment by random positions\n    rotation = np.random.randint(1, segment_length)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with conditional reversals\n    combined_weights = np.maximum(distance_matrix_1, distance_matrix_2)  # Normalized weights\n    edge_scores = []\n\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        u_prev = new_solution[(i-1)%n]\n        v_next = new_solution[(i+2)%n]\n\n        original_cost = combined_weights[u_prev][u] + combined_weights[u][v] + combined_weights[v][v_next]\n        flipped_cost = combined_weights[u_prev][v] + combined_weights[v][u] + combined_weights[u][v_next]\n        improvement = original_cost - flipped_cost\n\n        if improvement > 0:\n            # Check if flip improves at least one objective\n            cost1_diff = (distance_matrix_1[u_prev][v] + distance_matrix_1[v][u] + distance_matrix_1[u][v_next]) - \\\n                         (distance_matrix_1[u_prev][u] + distance_matrix_1[u][v] + distance_matrix_1[v][v_next])\n            cost2_diff = (distance_matrix_2[u_prev][v] + distance_matrix_2[v][u] + distance_matrix_2[u][v_next]) - \\\n                         (distance_matrix_2[u_prev][u] + distance_matrix_2[u][v] + distance_matrix_2[v][v_next])\n\n            if cost1_diff < 0 or cost2_diff < 0:\n                edge_scores.append((i, improvement))\n\n    if edge_scores:\n        # Select edge with highest improvement\n        edge_scores.sort(key=lambda x: -x[1])\n        best_edge = edge_scores[0][0]\n        new_solution[best_edge], new_solution[(best_edge+1)%n] = new_solution[(best_edge+1)%n], new_solution[best_edge]\n\n    # Conditional feasibility check\n    if len(np.unique(new_solution)) != n:\n        # Revert to base solution if feasibility is violated\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    # Calculate crowding distance for Pareto front\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    # Build Pareto front\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThis algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThis algorithm employs adaptive multi-objective selection with probabilistic dominance checks to choose promising solutions from an archive, then applies dynamic segment swaps and cost-sensitive edge insertions to generate improved neighbors while maintaining feasibility. It prioritizes solutions with better objective values but occasionally selects non-dominated ones with a small probability, and uses lognormal-distributed segment sizes for adaptive exploration. The local search combines segment swaps (if they improve at least one objective) with edge insertions weighted by combined distance costs to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1]) or \\\n           (current[1][0] <= best[1][0] and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.2:  # Small chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=0.5, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    # Cost-sensitive edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive Pareto selection with weighted crowding distance to prioritize diverse solutions, then applies a hybrid local search that dynamically rotates segments, cost-sensitively prioritizes edges, and conditionally reverses segments when improving at least one objective, ensuring feasibility through strict validation. The approach balances exploration via random segment operations and exploitation via cost-aware prioritization, with dynamic segment sizes and operation probabilities adjusted based on solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThis heuristic combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic operations weighted by edge costs in both objectives, and conditionally reverses segments only when they improve at least one objective, while ensuring feasibility through strict checks. The algorithm balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design for the bi-objective TSP:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\nThe key innovation is combining *adaptive Pareto selection* with *hybrid segment-rotation* and *cost-sensitive edge prioritization*, while rigorously avoiding static or overly greedy operators. This ensures both exploration and exploitation while maintaining feasibility.\n\n```python\nimport numpy as np\nimport random\n\ndef select_neighbor(archive, objectives):\n    # Step 1: Adaptive Pareto selection\n    nondominated = [i for i in range(len(archive)) if not any(\n        all(objectives[i][k] >= objectives[j][k] for k in range(2)) and\n        any(objectives[i][k] > objectives[j][k] for k in range(2))\n        for j in range(len(archive)) if j != i\n    )]\n\n    # Step 2: Weighted selection (crowding distance)\n    if len(nondominated) > 1:\n        selected_idx = random.choices(\n            nondominated,\n            weights=[sum(objectives[i]) for i in nondominated],\n            k=1\n        )[0]\n    else:\n        selected_idx = random.choice(nondominated)\n\n    tour = archive[selected_idx].copy()\n    n = len(tour)\n\n    # Step 3: Hybrid local search\n    # Segment rotation\n    a, b = sorted(random.sample(range(n), 2))\n    segment = tour[a:b]\n    if random.random() < 0.5:  # Reverse with 50% probability\n        segment = segment[::-1]\n    else:  # Rotate by random offset\n        offset = random.randint(1, len(segment)-1)\n        segment = segment[offset:] + segment[:offset]\n    new_tour = np.concatenate([tour[:a], segment, tour[b:]])\n\n    # Conditional edge reversal\n    for _ in range(2):  # Try 2 random edges\n        i, j = sorted(random.sample(range(n), 2))\n        if (objectives[selected_idx][0] * objectives[selected_idx][1] >\n            (objectives[selected_idx][0] + objectives[selected_idx][1]) / 2):\n            new_tour[i:j] = new_tour[i:j][::-1]  # Reverse if cost-sensitive\n\n    # Feasibility check\n    if len(set(new_tour)) != n:\n        return tour  # Revert if invalid\n    return new_tour\n```\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 109,
        "algorithm": "The algorithm combines adaptive Pareto selection with a hybrid local search that dynamically rotates segments, prioritizes edges based on multi-objective costs, and conditionally reverses segments to improve at least one objective, ensuring feasibility through strict checks. It balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities, prioritizing solutions with better crowding distances on the Pareto front. The key design ideas are the cost-sensitive edge prioritization, conditional segment reversal, and dynamic segment operations, all while maintaining feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search with dynamic segment operations\n    # 1. Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # 2. Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        # Weight edges based on both objectives with adaptive trade-off\n        weight = combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / (distance_matrix_2[u][v] + 1e-6)))\n        edge_weights.append(weight)\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = []\n        for i in candidates:\n            # Evaluate insertion cost for both objectives\n            cost1 = distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_1[new_solution[i]][new_solution[d]]\n            cost2 = distance_matrix_2[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[i]][new_solution[d]]\n            combined_cost = cost1 + cost2\n            candidate_distances.append(combined_cost)\n\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # 3. Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        # Only reverse if it improves at least one objective\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -0.8987597441314347,
            0.3021925687789917
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search with dynamic segment operations\n    # 1. Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # 2. Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        # Weight edges based on both objectives with adaptive trade-off\n        weight = combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / (distance_matrix_2[u][v] + 1e-6)))\n        edge_weights.append(weight)\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = []\n        for i in candidates:\n            # Evaluate insertion cost for both objectives\n            cost1 = distance_matrix_1[new_solution[c]][new_solution[i]] + distance_matrix_1[new_solution[i]][new_solution[d]]\n            cost2 = distance_matrix_2[new_solution[c]][new_solution[i]] + distance_matrix_2[new_solution[i]][new_solution[d]]\n            combined_cost = cost1 + cost2\n            candidate_distances.append(combined_cost)\n\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # 3. Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        # Only reverse if it improves at least one objective\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the archive using weighted random selection based on normalized objectives, then applies adaptive segment-based perturbation, multi-phase edge reversal, and optional node insertion to generate a new neighbor solution while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and dynamically adjusts perturbation intensity based on solution quality, using probabilistic segment sizes and deterministic reversal phases. The method combines segment-based modifications with edge reversal and selective node insertion to explore the solution space effectively.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives with different weighting scheme\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment-based perturbation with probabilistic segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=n/5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Multi-phase edge reversal with deterministic range adjustment\n    reversal_phases = [max(2, min(n // 4, int(n / (i+1)))) for i in range(3)]\n    for phase in reversal_phases:\n        c = np.random.randint(0, n - phase + 1)\n        d = c + phase - 1\n        new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node insertion with quality-based probability\n    if np.random.rand() < 0.4 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        insert_node = np.random.choice(new_solution)\n        new_solution = np.delete(new_solution, np.where(new_solution == insert_node)[0][0])\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, insert_node)\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 110,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Fast weighted selection using precomputed weights\n    objectives = np.array([obj for _, obj in archive])\n    min_obj = np.min(objectives, axis=0)\n    max_obj = np.max(objectives, axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0]\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Simplified segment-based perturbation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=n/5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Optimized multi-phase edge reversal\n    reversal_phases = [max(2, n // 4), max(2, n // 8), max(2, n // 12)]\n    for phase in reversal_phases:\n        c = np.random.randint(0, n - phase + 1)\n        new_solution[c:c+phase] = new_solution[c:c+phase][::-1]\n\n    # Step 4: Conditional node insertion with simplified probability\n    if np.random.rand() < 0.4:\n        insert_node = np.random.choice(new_solution)\n        new_solution = np.delete(new_solution, np.where(new_solution == insert_node)[0][0])\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, insert_node)\n\n    return new_solution\n\n",
        "score": [
            -0.93244582809426,
            0.49210870265960693
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Fast weighted selection using precomputed weights\n    objectives = np.array([obj for _, obj in archive])\n    min_obj = np.min(objectives, axis=0)\n    max_obj = np.max(objectives, axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0]\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Simplified segment-based perturbation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=n/5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Optimized multi-phase edge reversal\n    reversal_phases = [max(2, n // 4), max(2, n // 8), max(2, n // 12)]\n    for phase in reversal_phases:\n        c = np.random.randint(0, n - phase + 1)\n        new_solution[c:c+phase] = new_solution[c:c+phase][::-1]\n\n    # Step 4: Conditional node insertion with simplified probability\n    if np.random.rand() < 0.4:\n        insert_node = np.random.choice(new_solution)\n        new_solution = np.delete(new_solution, np.where(new_solution == insert_node)[0][0])\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, insert_node)\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 5 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects the best solution from the archive based on the sum of its two objectives, then applies a hybrid local search that reverses a randomly selected segment of the tour (edge-swap) to generate a neighbor solution, ensuring feasibility by falling back to a simple swap if the reversal causes duplicates. This approach prioritizes solutions with lower combined costs while using a constrained perturbation to explore the solution space efficiently.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a promising solution based on combined objective values\n    archive_sorted = sorted(archive, key=lambda x: sum(x[1]))\n    selected_solution = archive_sorted[0][0].copy()\n\n    # Hybrid local search: edge-swap with constrained perturbation\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Randomly select a segment to perturb\n    seg_start = np.random.randint(0, n - 2)\n    seg_length = np.random.randint(2, min(5, n - seg_start))\n    seg_end = seg_start + seg_length\n\n    # Reverse the segment (edge-swap)\n    new_solution[seg_start:seg_end] = new_solution[seg_start:seg_end][::-1]\n\n    # Ensure feasibility by checking for duplicates (though reversal should prevent this)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a simple swap if reversal causes issues\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\nNo. 3 algorithm and the corresponding code are:\nThe algorithm selects a random solution from the archive and applies a hybrid local search combining edge swapping (reversing a random segment) and segment insertion (moving a random segment to another position), ensuring feasibility by reverting to edge swapping if duplicates arise. It prioritizes exploration by randomly sampling segments while maintaining tour validity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., non-dominated or with high variance in objectives)\n    selected_idx = random.randint(0, len(archive) - 1)\n    selected_solution = archive[selected_idx][0].copy()\n    n = len(selected_solution)\n\n    # Hybrid local search: combine edge swapping with segment insertion\n    new_solution = selected_solution.copy()\n\n    # Edge swapping (similar to 2-opt but with a twist)\n    if n > 3:\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    # Segment insertion (novel mechanism)\n    if n > 4:\n        k, l = sorted(random.sample(range(n), 2))\n        segment = new_solution[k:l+1]\n        new_solution = np.concatenate([new_solution[:k], new_solution[l+1:], segment])\n\n    # Ensure feasibility (no duplicates and all nodes visited)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to edge swapping if segment insertion causes duplicates\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n\n    return new_solution\n\nNo. 4 algorithm and the corresponding code are:\nThe heuristic selects a random solution from the archive and applies a hybrid local search combining edge insertion and node swapping, prioritizing improvements that reduce the total tour length in both objective spaces while ensuring feasibility. The edge insertion randomly moves a node to a new position, and node swapping further refines the solution by swapping nodes if it improves the combined cost. The algorithm balances exploration (random selection) and exploitation (cost-based swapping) to generate high-quality neighbors.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., not dominated by others)\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and node swapping\n    n = len(new_solution)\n    if n < 4:\n        return new_solution  # Too small to apply operators\n\n    # Step 1: Edge insertion\n    i = np.random.randint(0, n)\n    j = np.random.randint(0, n)\n    while j == i or abs(j - i) == 1:\n        j = np.random.randint(0, n)\n\n    # Remove node at j and reinsert it after i\n    node = new_solution[j]\n    new_solution = np.concatenate([new_solution[:j], new_solution[j+1:]])\n    insert_pos = (i + 1) % len(new_solution)\n    new_solution = np.insert(new_solution, insert_pos, node)\n\n    # Step 2: Node swapping (if beneficial)\n    if np.random.random() < 0.5:  # 50% chance to apply swapping\n        k = np.random.randint(0, len(new_solution))\n        l = np.random.randint(0, len(new_solution))\n        while k == l:\n            l = np.random.randint(0, len(new_solution))\n\n        # Calculate cost before and after swap\n        def calculate_cost(sol, dist_mat):\n            total = 0\n            for idx in range(len(sol)):\n                total += dist_mat[sol[idx-1], sol[idx]]\n            return total\n\n        cost_before = calculate_cost(new_solution, distance_matrix_1) + calculate_cost(new_solution, distance_matrix_2)\n        temp_sol = new_solution.copy()\n        temp_sol[k], temp_sol[l] = temp_sol[l], temp_sol[k]\n        cost_after = calculate_cost(temp_sol, distance_matrix_1) + calculate_cost(temp_sol, distance_matrix_2)\n\n        if cost_after < cost_before:\n            new_solution = temp_sol\n\n    return new_solution\n\nNo. 5 algorithm and the corresponding code are:\nThe algorithm selects a solution from the archive with probability inversely proportional to its normalized objective values, then applies a hybrid local search combining edge swaps (reversing segments) and node relocations (moving single nodes) to generate a neighbor solution while ensuring feasibility. The selection prioritizes solutions with worse objectives (higher weights) to encourage exploration, while the local search balances exploration and exploitation through randomized segment reversals and node insertions.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with probability inversely proportional to its objective values\n    objectives = np.array([obj for (sol, obj) in archive])\n    normalized_objectives = objectives / objectives.sum(axis=0, keepdims=True)\n    weights = 1 / (normalized_objectives.sum(axis=1) + 1e-6)  # Avoid division by zero\n    weights = weights / weights.sum()  # Normalize weights\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Hybrid local search: combine edge swaps and node relocations\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Perform multiple edge swaps\n    for _ in range(2):\n        i, j = np.random.choice(n, 2, replace=False)\n        if i > j:\n            i, j = j, i\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Perform node relocation\n    for _ in range(1):\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        if i != j:\n            node = new_solution[i]\n            new_solution = np.delete(new_solution, i)\n            new_solution = np.insert(new_solution, j, node)\n\n    return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 111,
        "algorithm": "The algorithm selects a promising solution from the archive by balancing objective values and diversity, then applies a hybrid local search combining segment rotation and geometrically optimized node insertion to generate a neighbor while ensuring feasibility. It prioritizes solutions with balanced objectives and high structural variability, and the local search leverages geometric properties to guide perturbations beyond standard edge-based operators. The selection combines objective values and diversity, while the local search uses segment rotation and optimal insertion to explore the solution space effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution based on dynamic combination of objectives and diversity\n    objectives = np.array([obj for (sol, obj) in archive])\n    diversity = np.array([len(set(sol)) / len(sol) for (sol, obj) in archive])\n    weights = (objectives[:, 0] + objectives[:, 1]) * diversity\n    weights = weights / weights.sum()\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Segment rotation (circular shift of a segment)\n    if n > 3:\n        seg_start = np.random.randint(0, n - 2)\n        seg_length = np.random.randint(2, min(5, n - seg_start))\n        seg_end = seg_start + seg_length\n        shift = np.random.randint(1, seg_length)\n        rotated = np.roll(new_solution[seg_start:seg_end], shift)\n        new_solution[seg_start:seg_end] = rotated\n\n    # Node insertion at geometrically optimized position\n    if n > 4:\n        node_idx = np.random.randint(0, n)\n        node = new_solution[node_idx]\n        new_solution = np.delete(new_solution, node_idx)\n\n        # Find optimal insertion position based on geometric distance\n        distances = []\n        for i in range(len(new_solution)):\n            prev_node = new_solution[i-1]\n            next_node = new_solution[i]\n            # Calculate insertion cost based on both objective spaces\n            cost = (distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] -\n                    distance_matrix_1[prev_node, next_node]) + \\\n                   (distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] -\n                    distance_matrix_2[prev_node, next_node])\n            distances.append(cost)\n        optimal_pos = np.argmin(distances)\n        new_solution = np.insert(new_solution, optimal_pos, node)\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if tour is invalid\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.8747578570955706,
            0.6640944480895996
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution based on dynamic combination of objectives and diversity\n    objectives = np.array([obj for (sol, obj) in archive])\n    diversity = np.array([len(set(sol)) / len(sol) for (sol, obj) in archive])\n    weights = (objectives[:, 0] + objectives[:, 1]) * diversity\n    weights = weights / weights.sum()\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Segment rotation (circular shift of a segment)\n    if n > 3:\n        seg_start = np.random.randint(0, n - 2)\n        seg_length = np.random.randint(2, min(5, n - seg_start))\n        seg_end = seg_start + seg_length\n        shift = np.random.randint(1, seg_length)\n        rotated = np.roll(new_solution[seg_start:seg_end], shift)\n        new_solution[seg_start:seg_end] = rotated\n\n    # Node insertion at geometrically optimized position\n    if n > 4:\n        node_idx = np.random.randint(0, n)\n        node = new_solution[node_idx]\n        new_solution = np.delete(new_solution, node_idx)\n\n        # Find optimal insertion position based on geometric distance\n        distances = []\n        for i in range(len(new_solution)):\n            prev_node = new_solution[i-1]\n            next_node = new_solution[i]\n            # Calculate insertion cost based on both objective spaces\n            cost = (distance_matrix_1[prev_node, node] + distance_matrix_1[node, next_node] -\n                    distance_matrix_1[prev_node, next_node]) + \\\n                   (distance_matrix_2[prev_node, node] + distance_matrix_2[node, next_node] -\n                    distance_matrix_2[prev_node, next_node])\n            distances.append(cost)\n        optimal_pos = np.argmin(distances)\n        new_solution = np.insert(new_solution, optimal_pos, node)\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to simple swap if tour is invalid\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "e1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThis algorithm employs adaptive multi-objective selection with probabilistic dominance checks to choose promising solutions from an archive, then applies dynamic segment swaps and cost-sensitive edge insertions to generate improved neighbors while maintaining feasibility. It prioritizes solutions with better objective values but occasionally selects non-dominated ones with a small probability, and uses lognormal-distributed segment sizes for adaptive exploration. The local search combines segment swaps (if they improve at least one objective) with edge insertions weighted by combined distance costs to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1]) or \\\n           (current[1][0] <= best[1][0] and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.2:  # Small chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=0.5, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    # Cost-sensitive edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the bi-objective TSP:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\nThe key innovation is combining *adaptive Pareto selection* with *hybrid segment-rotation* and *cost-sensitive edge prioritization*, while rigorously avoiding static or overly greedy operators. This ensures both exploration and exploitation while maintaining feasibility.\n\n```python\nimport numpy as np\nimport random\n\ndef select_neighbor(archive, objectives):\n    # Step 1: Adaptive Pareto selection\n    nondominated = [i for i in range(len(archive)) if not any(\n        all(objectives[i][k] >= objectives[j][k] for k in range(2)) and\n        any(objectives[i][k] > objectives[j][k] for k in range(2))\n        for j in range(len(archive)) if j != i\n    )]\n\n    # Step 2: Weighted selection (crowding distance)\n    if len(nondominated) > 1:\n        selected_idx = random.choices(\n            nondominated,\n            weights=[sum(objectives[i]) for i in nondominated],\n            k=1\n        )[0]\n    else:\n        selected_idx = random.choice(nondominated)\n\n    tour = archive[selected_idx].copy()\n    n = len(tour)\n\n    # Step 3: Hybrid local search\n    # Segment rotation\n    a, b = sorted(random.sample(range(n), 2))\n    segment = tour[a:b]\n    if random.random() < 0.5:  # Reverse with 50% probability\n        segment = segment[::-1]\n    else:  # Rotate by random offset\n        offset = random.randint(1, len(segment)-1)\n        segment = segment[offset:] + segment[:offset]\n    new_tour = np.concatenate([tour[:a], segment, tour[b:]])\n\n    # Conditional edge reversal\n    for _ in range(2):  # Try 2 random edges\n        i, j = sorted(random.sample(range(n), 2))\n        if (objectives[selected_idx][0] * objectives[selected_idx][1] >\n            (objectives[selected_idx][0] + objectives[selected_idx][1]) / 2):\n            new_tour[i:j] = new_tour[i:j][::-1]  # Reverse if cost-sensitive\n\n    # Feasibility check\n    if len(set(new_tour)) != n:\n        return tour  # Revert if invalid\n    return new_tour\n```\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 112,
        "algorithm": "The algorithm combines adaptive Pareto selection with a novel hybrid local search that prioritizes dynamic segment transposition, objective-aware edge prioritization, and conditional path inversion while maintaining feasibility. It first selects solutions using a weighted Pareto tournament that balances dominance and diversity, then applies multi-phase perturbations: segment transposition with lognormal-sized segments, edge prioritization based on combined objective costs, and conditional path inversion that only reverses segments if they improve at least one objective. The method rigorously enforces feasibility through geometric mean-based cost evaluation and conditional checks, ensuring valid TSP tours.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive weighted Pareto selection\n    tournament_size = min(4, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[0]\n\n    for idx in selected_indices[1:]:\n        current = archive[idx]\n        selected = archive[selected_idx]\n\n        # Weighted Pareto comparison\n        current_score = np.prod(current[1])  # Geometric mean of objectives\n        selected_score = np.prod(selected[1])\n\n        if (current[1][0] < selected[1][0] and current[1][1] <= selected[1][1]) or \\\n           (current[1][0] <= selected[1][0] and current[1][1] < selected[1][1]) or \\\n           (current_score > selected_score and np.random.rand() < 0.3):\n            selected_idx = idx\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment transposition\n    segment_size = max(2, min(n // 5, int(np.random.lognormal(mean=0.0, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Transpose segments\n    segment1 = new_solution[a:b+1]\n    segment2 = new_solution[c:d+1]\n    new_solution[a:b+1] = segment2\n    new_solution[c:d+1] = segment1\n\n    # Objective-aware edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional path inversion\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 6, int(np.random.lognormal(mean=0.0, sigma=0.3))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -0.8183669127428308,
            3.3002602458000183
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive weighted Pareto selection\n    tournament_size = min(4, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[0]\n\n    for idx in selected_indices[1:]:\n        current = archive[idx]\n        selected = archive[selected_idx]\n\n        # Weighted Pareto comparison\n        current_score = np.prod(current[1])  # Geometric mean of objectives\n        selected_score = np.prod(selected[1])\n\n        if (current[1][0] < selected[1][0] and current[1][1] <= selected[1][1]) or \\\n           (current[1][0] <= selected[1][0] and current[1][1] < selected[1][1]) or \\\n           (current_score > selected_score and np.random.rand() < 0.3):\n            selected_idx = idx\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment transposition\n    segment_size = max(2, min(n // 5, int(np.random.lognormal(mean=0.0, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Transpose segments\n    segment1 = new_solution[a:b+1]\n    segment2 = new_solution[c:d+1]\n    new_solution[a:b+1] = segment2\n    new_solution[c:d+1] = segment1\n\n    # Objective-aware edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional path inversion\n    if n > 4 and np.random.rand() < 0.4:\n        segment_size = max(2, min(n // 6, int(np.random.lognormal(mean=0.0, sigma=0.3))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        This algorithm employs adaptive multi-objective selection with probabilistic dominance checks to choose promising solutions from an archive, then applies dynamic segment swaps and cost-sensitive edge insertions to generate improved neighbors while maintaining feasibility. It prioritizes solutions with better objective values but occasionally selects non-dominated ones with a small probability, and uses lognormal-distributed segment sizes for adaptive exploration. The local search combines segment swaps (if they improve at least one objective) with edge insertions weighted by combined distance costs to balance exploration and exploitation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1]) or \\\n           (current[1][0] <= best[1][0] and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.2:  # Small chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=0.5, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    # Cost-sensitive edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 113,
        "algorithm": "The algorithm selects a promising solution from an archive using adaptive Pareto-based selection with dynamic neighborhood exploration, then applies a hybrid local search combining segment-based relocations with probabilistic edge reordering. It prioritizes cost-sensitive segment insertion and edge reversal based on normalized objective dominance and weighted probabilities, ensuring feasible TSP tours. The method balances exploration and exploitation by dynamically adjusting segment sizes and insertion points, while the edge reordering step refines solutions further by probabilistically selecting high-cost edges for improvement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with dynamic neighborhood\n    tournament_size = min(4, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n    max_obj1 = max(s[1][0] for s in archive)\n    max_obj2 = max(s[1][1] for s in archive)\n\n    for idx in selected_indices:\n        current = archive[idx]\n        if selected is None:\n            selected = idx\n            continue\n\n        # Normalized dominance check\n        norm_current = (current[1][0]/max_obj1, current[1][1]/max_obj2)\n        norm_best = (archive[selected][1][0]/max_obj1, archive[selected][1][1]/max_obj2)\n\n        if (norm_current[0] < norm_best[0] and norm_current[1] <= norm_best[1]) or \\\n           (norm_current[0] <= norm_best[0] and norm_current[1] < norm_best[1]):\n            selected = idx\n        elif np.random.rand() < 0.15:  # Higher probability for exploration\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Dynamic segment relocation with geometric progression\n    segment_size = max(2, min(n // 3, int(np.random.geometric(p=0.3))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Find insertion point based on cost sensitivity\n    insertion_costs = []\n    for i in range(n):\n        if i > a and i <= b:\n            continue\n        cost1 = distance_matrix_1[new_solution[a-1]][new_solution[i]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(i+1)%n]]\n        cost2 = distance_matrix_2[new_solution[a-1]][new_solution[i]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(i+1)%n]]\n        insertion_costs.append((cost1 + cost2, i))\n\n    if insertion_costs:\n        insertion_costs.sort()\n        top_candidates = min(3, len(insertion_costs))\n        weights = np.exp(-np.arange(top_candidates) * 0.5)\n        weights /= weights.sum()\n        selected_pos = np.random.choice([c[1] for c in insertion_costs[:top_candidates]], p=weights)\n\n        # Relocate segment\n        segment = new_solution[a:b+1]\n        new_solution = np.concatenate([\n            new_solution[:a],\n            new_solution[b+1:selected_pos],\n            segment,\n            new_solution[selected_pos:]\n        ])\n\n    # Probabilistic edge reordering\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(distance_matrix_1[u][v] + distance_matrix_2[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / edge_weights.sum()\n    selected_edge = np.random.choice(n, p=edge_weights)\n    a, b = selected_edge, (selected_edge + 1) % n\n\n    # Find best candidate for edge reversal\n    candidates = [i for i in range(n) if i not in (a, b)]\n    if candidates:\n        best_improvement = -1\n        best_candidate = None\n\n        for i in candidates:\n            cost1 = distance_matrix_1[new_solution[a]][new_solution[i]] + \\\n                    distance_matrix_1[new_solution[b]][new_solution[(i+1)%n]]\n            cost2 = distance_matrix_2[new_solution[a]][new_solution[i]] + \\\n                    distance_matrix_2[new_solution[b]][new_solution[(i+1)%n]]\n            improvement = (edge_weights[a] + edge_weights[b]) - (cost1 + cost2)\n\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_candidate = i\n\n        if best_candidate is not None:\n            new_solution = np.concatenate([\n                new_solution[:a+1],\n                new_solution[best_candidate:best_candidate+1],\n                new_solution[a+1:best_candidate],\n                new_solution[best_candidate+1:]\n            ])\n\n    return new_solution\n\n",
        "score": [
            -0.6518613501906104,
            0.42987149953842163
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with dynamic neighborhood\n    tournament_size = min(4, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n    max_obj1 = max(s[1][0] for s in archive)\n    max_obj2 = max(s[1][1] for s in archive)\n\n    for idx in selected_indices:\n        current = archive[idx]\n        if selected is None:\n            selected = idx\n            continue\n\n        # Normalized dominance check\n        norm_current = (current[1][0]/max_obj1, current[1][1]/max_obj2)\n        norm_best = (archive[selected][1][0]/max_obj1, archive[selected][1][1]/max_obj2)\n\n        if (norm_current[0] < norm_best[0] and norm_current[1] <= norm_best[1]) or \\\n           (norm_current[0] <= norm_best[0] and norm_current[1] < norm_best[1]):\n            selected = idx\n        elif np.random.rand() < 0.15:  # Higher probability for exploration\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        return new_solution\n\n    # Dynamic segment relocation with geometric progression\n    segment_size = max(2, min(n // 3, int(np.random.geometric(p=0.3))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Find insertion point based on cost sensitivity\n    insertion_costs = []\n    for i in range(n):\n        if i > a and i <= b:\n            continue\n        cost1 = distance_matrix_1[new_solution[a-1]][new_solution[i]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(i+1)%n]]\n        cost2 = distance_matrix_2[new_solution[a-1]][new_solution[i]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(i+1)%n]]\n        insertion_costs.append((cost1 + cost2, i))\n\n    if insertion_costs:\n        insertion_costs.sort()\n        top_candidates = min(3, len(insertion_costs))\n        weights = np.exp(-np.arange(top_candidates) * 0.5)\n        weights /= weights.sum()\n        selected_pos = np.random.choice([c[1] for c in insertion_costs[:top_candidates]], p=weights)\n\n        # Relocate segment\n        segment = new_solution[a:b+1]\n        new_solution = np.concatenate([\n            new_solution[:a],\n            new_solution[b+1:selected_pos],\n            segment,\n            new_solution[selected_pos:]\n        ])\n\n    # Probabilistic edge reordering\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(distance_matrix_1[u][v] + distance_matrix_2[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / edge_weights.sum()\n    selected_edge = np.random.choice(n, p=edge_weights)\n    a, b = selected_edge, (selected_edge + 1) % n\n\n    # Find best candidate for edge reversal\n    candidates = [i for i in range(n) if i not in (a, b)]\n    if candidates:\n        best_improvement = -1\n        best_candidate = None\n\n        for i in candidates:\n            cost1 = distance_matrix_1[new_solution[a]][new_solution[i]] + \\\n                    distance_matrix_1[new_solution[b]][new_solution[(i+1)%n]]\n            cost2 = distance_matrix_2[new_solution[a]][new_solution[i]] + \\\n                    distance_matrix_2[new_solution[b]][new_solution[(i+1)%n]]\n            improvement = (edge_weights[a] + edge_weights[b]) - (cost1 + cost2)\n\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_candidate = i\n\n        if best_candidate is not None:\n            new_solution = np.concatenate([\n                new_solution[:a+1],\n                new_solution[best_candidate:best_candidate+1],\n                new_solution[a+1:best_candidate],\n                new_solution[best_candidate+1:]\n            ])\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        This algorithm employs adaptive multi-objective selection with probabilistic dominance checks to choose promising solutions from an archive, then applies dynamic segment swaps and cost-sensitive edge insertions to generate improved neighbors while maintaining feasibility. It prioritizes solutions with better objective values but occasionally selects non-dominated ones with a small probability, and uses lognormal-distributed segment sizes for adaptive exploration. The local search combines segment swaps (if they improve at least one objective) with edge insertions weighted by combined distance costs to balance exploration and exploitation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1]) or \\\n           (current[1][0] <= best[1][0] and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.2:  # Small chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=0.5, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    # Cost-sensitive edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 114,
        "algorithm": "The algorithm implements an adaptive multi-objective selection strategy with probabilistic dominance checks, followed by dynamic segment inversions and cost-sensitive edge swaps, prioritizing solutions with better objective values while occasionally exploring non-dominated ones, using lognormal-distributed segment sizes for adaptive exploration. It balances exploration and exploitation by weighting objectives differently (0.7 for first objective, 0.3 for second) and accepting segment inversions only if they significantly improve at least one objective.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check with different weights\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1] * 1.1) or \\\n           (current[1][0] <= best[1][0] * 1.1 and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.3:  # Higher chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment inversion with adaptive size\n    segment_size = max(3, min(n // 3, int(np.random.lognormal(mean=0.3, sigma=0.4))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Invert segment if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                     distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                     distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n    if not ((new_cost1 < original_cost1 * 0.95) or (new_cost2 < original_cost2 * 0.95)):\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Cost-sensitive edge swap with different weighting\n    combined_distances = distance_matrix_1 * 0.7 + distance_matrix_2 * 0.3\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    a = selected_edge\n    b = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (a, b)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[a]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[b]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        c = np.random.choice(candidates, p=candidate_weights)\n        new_solution[a], new_solution[c] = new_solution[c], new_solution[a]\n\n    return new_solution\n\n",
        "score": [
            -0.6845631229511407,
            0.5657079219818115
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check with different weights\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1] * 1.1) or \\\n           (current[1][0] <= best[1][0] * 1.1 and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.3:  # Higher chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment inversion with adaptive size\n    segment_size = max(3, min(n // 3, int(np.random.lognormal(mean=0.3, sigma=0.4))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n\n    # Invert segment if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                     distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                     distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n    if not ((new_cost1 < original_cost1 * 0.95) or (new_cost2 < original_cost2 * 0.95)):\n        new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Cost-sensitive edge swap with different weighting\n    combined_distances = distance_matrix_1 * 0.7 + distance_matrix_2 * 0.3\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    a = selected_edge\n    b = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (a, b)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[a]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[b]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        c = np.random.choice(candidates, p=candidate_weights)\n        new_solution[a], new_solution[c] = new_solution[c], new_solution[a]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 5 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThis algorithm employs adaptive multi-objective selection with probabilistic dominance checks to choose promising solutions from an archive, then applies dynamic segment swaps and cost-sensitive edge insertions to generate improved neighbors while maintaining feasibility. It prioritizes solutions with better objective values but occasionally selects non-dominated ones with a small probability, and uses lognormal-distributed segment sizes for adaptive exploration. The local search combines segment swaps (if they improve at least one objective) with edge insertions weighted by combined distance costs to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1]) or \\\n           (current[1][0] <= best[1][0] and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.2:  # Small chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=0.5, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    # Cost-sensitive edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThis algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive solution selection with a hybrid local search strategy that alternates between segment-based reinsertion and edge-based reversal, dynamically adjusting perturbation intensity based on solution quality and problem characteristics while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and applies perturbations with segment sizes and reversal ranges determined by probabilistic distributions, balancing exploration and exploitation. The approach avoids standard 2-opt by using multi-phase perturbations with deterministic adjustments for higher-quality multi-objective optimization.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1.0 / (1.0 + np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Dynamic segment-based reinsertion\n    segment_size = max(2, min(n // 3, int(np.random.normal(loc=n//4, scale=n//6))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Edge-based reversal with dynamic range\n    reversal_range = max(2, min(n // 2, int(np.random.exponential(scale=n//3))))\n    c = np.random.randint(0, n - reversal_range + 1)\n    d = c + reversal_range - 1\n    new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive with a weighted random choice favoring lower-cost solutions, then applies a hybrid local search combining adaptive segment reversal and edge insertion to generate a neighbor solution while ensuring feasibility. It prioritizes edges with high combined distance in both objectives for insertion, balancing exploration and exploitation through adaptive segment sizes and randomness. The selection weights and distance-based edge prioritization are key design choices for driving improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    weights = np.zeros(len(archive))\n    for i, (sol, obj) in enumerate(archive):\n        # Weight based on objective values (lower is better)\n        weights[i] = 1.0 / (1.0 + np.sum(obj))\n\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment size based on solution quality\n    segment_size = max(2, min(n // 2, int(np.random.exponential(scale=2))))\n\n    # Select segment to reverse\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Edge insertion based on distance metrics\n    if n > 3:\n        # Find edges with high combined distance in both objectives\n        edges = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edges.append((i, (i+1)%n, distance_matrix_1[u][v] + distance_matrix_2[u][v]))\n\n        edges.sort(key=lambda x: -x[2])\n        if edges:\n            best_edge = edges[0]\n            c = best_edge[0]\n            d = best_edge[1]\n\n            # Insert a random node between c and d\n            if n > 3:\n                candidates = [i for i in range(n) if i not in (c, d)]\n                if candidates:\n                    e = np.random.choice(candidates)\n                    new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a weighted random selection (prioritizing higher-indexed solutions), then applies a hybrid local search combining segment reversal and edge insertion to generate a neighbor. It ensures feasibility by maintaining a valid TSP tour while exploring diverse modifications. The selection bias and randomness in segment/edge choices drive exploration, while the hybrid operator balances structure and perturbation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with the highest potential for improvement\n    selected_idx = np.random.choice(len(archive), p=np.linspace(0.1, 1.0, len(archive)) / np.sum(np.linspace(0.1, 1.0, len(archive))))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Hybrid local search: edge insertion and segment reversal\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Randomly select a segment to reverse\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[a:b+1] = new_solution[a:b+1][::-1]\n\n    # Randomly select an edge to insert\n    if n > 3:\n        c, d = sorted(np.random.choice(n, 2, replace=False))\n        while c == d or (c == a and d == b):\n            c, d = sorted(np.random.choice(n, 2, replace=False))\n        new_solution = np.concatenate([new_solution[:c], new_solution[d:d+1], new_solution[c:d], new_solution[d+1:]])\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the bi-objective TSP:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\nThe key innovation is combining *adaptive Pareto selection* with *hybrid segment-rotation* and *cost-sensitive edge prioritization*, while rigorously avoiding static or overly greedy operators. This ensures both exploration and exploitation while maintaining feasibility.\n\n```python\nimport numpy as np\nimport random\n\ndef select_neighbor(archive, objectives):\n    # Step 1: Adaptive Pareto selection\n    nondominated = [i for i in range(len(archive)) if not any(\n        all(objectives[i][k] >= objectives[j][k] for k in range(2)) and\n        any(objectives[i][k] > objectives[j][k] for k in range(2))\n        for j in range(len(archive)) if j != i\n    )]\n\n    # Step 2: Weighted selection (crowding distance)\n    if len(nondominated) > 1:\n        selected_idx = random.choices(\n            nondominated,\n            weights=[sum(objectives[i]) for i in nondominated],\n            k=1\n        )[0]\n    else:\n        selected_idx = random.choice(nondominated)\n\n    tour = archive[selected_idx].copy()\n    n = len(tour)\n\n    # Step 3: Hybrid local search\n    # Segment rotation\n    a, b = sorted(random.sample(range(n), 2))\n    segment = tour[a:b]\n    if random.random() < 0.5:  # Reverse with 50% probability\n        segment = segment[::-1]\n    else:  # Rotate by random offset\n        offset = random.randint(1, len(segment)-1)\n        segment = segment[offset:] + segment[:offset]\n    new_tour = np.concatenate([tour[:a], segment, tour[b:]])\n\n    # Conditional edge reversal\n    for _ in range(2):  # Try 2 random edges\n        i, j = sorted(random.sample(range(n), 2))\n        if (objectives[selected_idx][0] * objectives[selected_idx][1] >\n            (objectives[selected_idx][0] + objectives[selected_idx][1]) / 2):\n            new_tour[i:j] = new_tour[i:j][::-1]  # Reverse if cost-sensitive\n\n    # Feasibility check\n    if len(set(new_tour)) != n:\n        return tour  # Revert if invalid\n    return new_tour\n```\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 115,
        "algorithm": "The algorithm combines adaptive Pareto selection with weighted crowding distance to choose high-potential solutions, then applies a hybrid local search that alternates between segment rotations (prioritizing structure preservation) and cost-sensitive edge insertions (focusing on high-combined-distance edges). It ensures feasibility by reverting invalid modifications and only accepts improvements to at least one objective, balancing exploration and exploitation through dynamic segment sizes and probabilistic edge selections.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search with dynamic segment operations\n    operation_type = np.random.choice(['rotation', 'insertion'], p=[0.6, 0.4])\n\n    if operation_type == 'rotation':\n        # Dynamic segment rotation with adaptive size\n        segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n        rotation = np.random.randint(1, segment_size)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n    else:\n        # Cost-sensitive edge insertion\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional improvement check\n    if operation_type == 'rotation':\n        # Check if rotation improved at least one objective\n        original_cost1 = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n        original_cost2 = sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n        new_cost1 = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n        new_cost2 = sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n\n        if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n            new_solution = base_solution.copy()\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -0.9585940866987873,
            0.4710537791252136
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search with dynamic segment operations\n    operation_type = np.random.choice(['rotation', 'insertion'], p=[0.6, 0.4])\n\n    if operation_type == 'rotation':\n        # Dynamic segment rotation with adaptive size\n        segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n        rotation = np.random.randint(1, segment_size)\n        new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n    else:\n        # Cost-sensitive edge insertion\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional improvement check\n    if operation_type == 'rotation':\n        # Check if rotation improved at least one objective\n        original_cost1 = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n        original_cost2 = sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n        new_cost1 = sum(distance_matrix_1[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n        new_cost2 = sum(distance_matrix_2[new_solution[i]][new_solution[(i+1)%n]] for i in range(n))\n\n        if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n            new_solution = base_solution.copy()\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm uses Pareto-based tournament selection to choose a promising solution from the archive, then applies a hybrid local search combining adaptive segment rotation, cost-aware edge insertion, and conditional segment reversal to generate a neighbor solution while balancing exploration and exploitation across both objectives. The method prioritizes edges with higher combined weights for insertion and only reverses segments if it improves at least one objective, ensuring feasibility and quality improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Pareto-based tournament selection\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        # Only reverse if it improves at least one objective\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto-based selection with crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    # Calculate crowding distance for Pareto front\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    # Build Pareto front\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment rotation with variable segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-aware edge insertion with probabilistic selection\n    if n > 3:\n        combined_distances = distance_matrix_1 + distance_matrix_2\n        edge_weights = []\n        for i in range(n):\n            u = new_solution[i]\n            v = new_solution[(i+1)%n]\n            edge_weights.append(combined_distances[u][v])\n\n        edge_weights = np.array(edge_weights)\n        edge_weights = edge_weights / np.sum(edge_weights)\n        selected_edge = np.random.choice(n, p=edge_weights)\n        c = selected_edge\n        d = (selected_edge + 1) % n\n\n        candidates = [i for i in range(n) if i not in (c, d)]\n        if candidates:\n            candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                                 combined_distances[new_solution[i]][new_solution[d]]\n                                 for i in candidates]\n            candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n            e = np.random.choice(candidates, p=candidate_weights)\n            new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThis algorithm combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals to generate high-quality neighbors while maintaining feasibility across both objectives. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic segment operations weighted by edge costs, and conditionally reverses segments only when they improve at least one objective. The approach balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThis algorithm employs adaptive multi-objective selection with probabilistic dominance checks to choose promising solutions from an archive, then applies dynamic segment swaps and cost-sensitive edge insertions to generate improved neighbors while maintaining feasibility. It prioritizes solutions with better objective values but occasionally selects non-dominated ones with a small probability, and uses lognormal-distributed segment sizes for adaptive exploration. The local search combines segment swaps (if they improve at least one objective) with edge insertions weighted by combined distance costs to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive dominance selection with probability-based tournament\n    tournament_size = min(3, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    selected = None\n\n    for idx in selected_indices:\n        if selected is None:\n            selected = idx\n            continue\n        current = archive[idx]\n        best = archive[selected]\n\n        # Probabilistic dominance check\n        if (current[1][0] < best[1][0] and current[1][1] <= best[1][1]) or \\\n           (current[1][0] <= best[1][0] and current[1][1] < best[1][1]):\n            selected = idx\n        elif np.random.rand() < 0.2:  # Small chance to select non-dominated\n            selected = idx\n\n    base_solution = archive[selected][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment swap with adaptive size\n    segment_size = max(2, min(n // 4, int(np.random.lognormal(mean=0.5, sigma=0.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    c = np.random.randint(0, n - segment_size + 1)\n    while abs(a - c) < segment_size:\n        c = np.random.randint(0, n - segment_size + 1)\n    d = c + segment_size - 1\n\n    # Swap segments if it improves at least one objective\n    original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                      distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                      distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                      distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    new_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_1[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_1[new_solution[d]][new_solution[(d+1)%n]]\n    new_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + \\\n                distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]] + \\\n                distance_matrix_2[new_solution[c]][new_solution[(c-1)%n]] + \\\n                distance_matrix_2[new_solution[d]][new_solution[(d+1)%n]]\n\n    if not ((new_cost1 < original_cost1) or (new_cost2 < original_cost2)):\n        new_solution[a:b+1], new_solution[c:d+1] = new_solution[c:d+1], new_solution[a:b+1]\n\n    # Cost-sensitive edge insertion\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive Pareto selection with weighted crowding distance to prioritize diverse solutions, then applies a hybrid local search that dynamically rotates segments, cost-sensitively prioritizes edges, and conditionally reverses segments when improving at least one objective, ensuring feasibility through strict validation. The approach balances exploration via random segment operations and exploitation via cost-aware prioritization, with dynamic segment sizes and operation probabilities adjusted based on solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v])\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]]\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThis heuristic combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic operations weighted by edge costs in both objectives, and conditionally reverses segments only when they improve at least one objective, while ensuring feasibility through strict checks. The algorithm balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design for the bi-objective TSP:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\nThe key innovation is combining *adaptive Pareto selection* with *hybrid segment-rotation* and *cost-sensitive edge prioritization*, while rigorously avoiding static or overly greedy operators. This ensures both exploration and exploitation while maintaining feasibility.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 116,
        "algorithm": "The algorithm combines adaptive Pareto selection with a hybrid local search that prioritizes solutions with better crowding distances on the Pareto front, applies dynamic segment rotations and cost-sensitive edge prioritization weighted by combined objective costs, and conditionally reverses segments only when they improve at least one objective, while ensuring feasibility through strict checks. It dynamically adjusts segment sizes and operation probabilities to balance exploration and exploitation in the bi-objective TSP landscape.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "score": [
            -0.9584577799528351,
            0.30620527267456055
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions from the archive using weighted random selection based on normalized objectives, then applies adaptive segment-based perturbation, multi-phase edge reversal, and optional node insertion to generate a new neighbor solution while ensuring feasibility. It prioritizes solutions with lower combined normalized objectives and dynamically adjusts perturbation intensity based on solution quality, using probabilistic segment sizes and deterministic reversal phases. The method combines segment-based modifications with edge reversal and selective node insertion to explore the solution space effectively.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Weighted selection based on normalized objectives with different weighting scheme\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Step 2: Adaptive segment-based perturbation with probabilistic segment size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=n/5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    segment = new_solution[a:a+segment_size]\n    new_solution = np.concatenate([new_solution[:a], new_solution[a+segment_size:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.concatenate([new_solution[:insert_pos], segment, new_solution[insert_pos:]])\n\n    # Step 3: Multi-phase edge reversal with deterministic range adjustment\n    reversal_phases = [max(2, min(n // 4, int(n / (i+1)))) for i in range(3)]\n    for phase in reversal_phases:\n        c = np.random.randint(0, n - phase + 1)\n        d = c + phase - 1\n        new_solution[c:d+1] = new_solution[c:d+1][::-1]\n\n    # Step 4: Optional node insertion with quality-based probability\n    if np.random.rand() < 0.4 * (1 - np.sum(normalized_obj[selected_idx]) / 2):\n        insert_node = np.random.choice(new_solution)\n        new_solution = np.delete(new_solution, np.where(new_solution == insert_node)[0][0])\n        insert_pos = np.random.randint(0, len(new_solution))\n        new_solution = np.insert(new_solution, insert_pos, insert_node)\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 117,
        "algorithm": "The algorithm selects a promising solution from the archive using weighted random selection based on normalized objective values, then applies a hybrid local search strategy combining segment relocation and edge reversal to generate a neighbor solution. It prioritizes solutions with better objective values and ensures feasibility by working directly with indices and array operations. The method balances exploration and exploitation by leveraging precomputed weights and deterministic segment operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute weights once\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    min_obj = np.min(objectives, axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n\n    # Select parent solution\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0]\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Simplified segment operation\n    segment_size = min(n // 3, n - 2)\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size\n    segment = new_solution[a:b]\n    new_solution = np.concatenate([new_solution[:a], new_solution[b:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.insert(new_solution, insert_pos, segment)\n\n    # Simplified edge reversal\n    reversal_size = max(2, min(n // 4, n - 1))\n    c = np.random.randint(0, n - reversal_size + 1)\n    d = c + reversal_size\n    new_solution[c:d] = new_solution[c:d][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.87659263377846,
            0.4870644211769104
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute weights once\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    min_obj = np.min(objectives, axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n    weights = np.exp(-0.5 * np.sum(normalized_obj, axis=1))\n    weights = weights / np.sum(weights)\n\n    # Select parent solution\n    selected_idx = np.random.choice(len(archive), p=weights)\n    base_solution = archive[selected_idx][0]\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Simplified segment operation\n    segment_size = min(n // 3, n - 2)\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size\n    segment = new_solution[a:b]\n    new_solution = np.concatenate([new_solution[:a], new_solution[b:]])\n    insert_pos = np.random.randint(0, len(new_solution) - segment_size + 1)\n    new_solution = np.insert(new_solution, insert_pos, segment)\n\n    # Simplified edge reversal\n    reversal_size = max(2, min(n // 4, n - 1))\n    c = np.random.randint(0, n - reversal_size + 1)\n    d = c + reversal_size\n    new_solution[c:d] = new_solution[c:d][::-1]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThis heuristic combines adaptive Pareto selection with a hybrid local search that uses dynamic segment rotations, cost-sensitive edge prioritization, and conditional segment reversals. It prioritizes solutions with better crowding distances on the Pareto front, applies probabilistic operations weighted by edge costs in both objectives, and conditionally reverses segments only when they improve at least one objective, while ensuring feasibility through strict checks. The algorithm balances exploration and exploitation by dynamically adjusting segment sizes and operation probabilities.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    tournament_size = min(5, len(archive))\n    selected_indices = np.random.choice(len(archive), size=tournament_size, replace=False)\n    pareto_front = []\n\n    def calculate_crowding_distance(pop):\n        distances = np.zeros(len(pop))\n        for m in range(2):\n            sorted_idx = np.argsort([sol[1][m] for sol in pop])\n            distances[sorted_idx[0]] = distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(pop)-1):\n                distances[sorted_idx[i]] += (pop[sorted_idx[i+1]][1][m] - pop[sorted_idx[i-1]][1][m]) / (max(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]) - min(pop[sorted_idx[-1]][1][m], pop[sorted_idx[0]][1][m]))\n        return distances\n\n    for idx in selected_indices:\n        dominated = False\n        for other_idx in selected_indices:\n            if idx == other_idx:\n                continue\n            if (archive[other_idx][1][0] <= archive[idx][1][0] and archive[other_idx][1][1] <= archive[idx][1][1]) and \\\n               (archive[other_idx][1][0] < archive[idx][1][0] or archive[other_idx][1][1] < archive[idx][1][1]):\n                dominated = True\n                break\n        if not dominated:\n            pareto_front.append(archive[idx])\n\n    if not pareto_front:\n        selected_idx = selected_indices[np.argmin([np.sum(archive[i][1]) for i in selected_indices])]\n    else:\n        crowding_distances = calculate_crowding_distance(pareto_front)\n        selected_idx = np.argmax(crowding_distances)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 3:\n        return new_solution\n\n    # Dynamic segment rotation with adaptive size\n    segment_size = max(2, min(n // 3, int(np.random.exponential(scale=1.5))))\n    a = np.random.randint(0, n - segment_size + 1)\n    b = a + segment_size - 1\n    rotation = np.random.randint(1, segment_size)\n    new_solution[a:b+1] = np.roll(new_solution[a:b+1], rotation)\n\n    # Cost-sensitive edge prioritization with multi-objective weighting\n    combined_distances = distance_matrix_1 + distance_matrix_2\n    edge_weights = []\n    for i in range(n):\n        u = new_solution[i]\n        v = new_solution[(i+1)%n]\n        edge_weights.append(combined_distances[u][v] * (1 + 0.1 * (distance_matrix_1[u][v] / distance_matrix_2[u][v])))\n\n    edge_weights = np.array(edge_weights)\n    edge_weights = edge_weights / np.sum(edge_weights)\n    selected_edge = np.random.choice(n, p=edge_weights)\n    c = selected_edge\n    d = (selected_edge + 1) % n\n\n    candidates = [i for i in range(n) if i not in (c, d)]\n    if candidates:\n        candidate_distances = [combined_distances[new_solution[c]][new_solution[i]] +\n                             combined_distances[new_solution[i]][new_solution[d]] *\n                             (1 + 0.1 * (distance_matrix_1[new_solution[c]][new_solution[i]] / distance_matrix_2[new_solution[c]][new_solution[i]]))\n                             for i in candidates]\n        candidate_weights = np.array(candidate_distances) / np.sum(candidate_distances)\n        e = np.random.choice(candidates, p=candidate_weights)\n        new_solution = np.concatenate([new_solution[:c+1], new_solution[e:e+1], new_solution[c+1:]])\n\n    # Conditional segment reversal with multi-objective improvement check\n    if n > 4 and np.random.rand() < 0.3:\n        segment_size = max(2, min(n // 4, int(np.random.exponential(scale=1.2))))\n        a = np.random.randint(0, n - segment_size + 1)\n        b = a + segment_size - 1\n\n        original_cost1 = distance_matrix_1[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_1[new_solution[b]][new_solution[(b+1)%n]]\n        original_cost2 = distance_matrix_2[new_solution[a]][new_solution[(a-1)%n]] + distance_matrix_2[new_solution[b]][new_solution[(b+1)%n]]\n\n        reversed_segment = new_solution[a:b+1][::-1]\n        new_cost1 = distance_matrix_1[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_1[reversed_segment[-1]][new_solution[(b+1)%n]]\n        new_cost2 = distance_matrix_2[reversed_segment[0]][new_solution[(a-1)%n]] + distance_matrix_2[reversed_segment[-1]][new_solution[(b+1)%n]]\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution[a:b+1] = reversed_segment\n\n    # Feasibility check\n    if len(set(new_solution)) != n:\n        return base_solution\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using Pareto dominance and crowding distance, then applies a hybrid local search combining segment crossover (randomly swapping two segments of the tour) and conditional edge reversal (reversing a segment if it improves at least one objective). It ensures feasibility by validating the tour and falling back to a random swap if duplicates occur, balancing exploration and exploitation dynamically.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and crowding distance to select a promising solution\n    objectives = np.array([obj for _, obj in archive])\n    is_dominated = np.zeros(len(archive), dtype=bool)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                is_dominated[i] = True\n                break\n\n    non_dominated_indices = np.where(~is_dominated)[0]\n    if len(non_dominated_indices) > 0:\n        selected_idx = np.random.choice(non_dominated_indices)\n    else:\n        # Fallback to random selection if no non-dominated solutions\n        selected_idx = np.random.randint(0, len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: segment crossover and conditional edge reversal\n    # Segment crossover\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    c, d = sorted(np.random.choice(n, 2, replace=False))\n    segment1 = new_solution[a:b+1]\n    segment2 = new_solution[c:d+1]\n    new_solution = np.concatenate([new_solution[:a], segment2, new_solution[b+1:c], segment1, new_solution[d+1:]])\n\n    # Conditional edge reversal\n    if n > 3:\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        reversed_segment = np.flip(new_solution[i:j+1])\n        temp_solution = np.concatenate([new_solution[:i], reversed_segment, new_solution[j+1:]])\n\n        # Check if reversal improves at least one objective\n        def calculate_cost(sol, dist_matrix):\n            cost = 0\n            for k in range(len(sol) - 1):\n                cost += dist_matrix[sol[k], sol[k+1]]\n            cost += dist_matrix[sol[-1], sol[0]]\n            return cost\n\n        original_cost1 = calculate_cost(new_solution, distance_matrix_1)\n        original_cost2 = calculate_cost(new_solution, distance_matrix_2)\n        new_cost1 = calculate_cost(temp_solution, distance_matrix_1)\n        new_cost2 = calculate_cost(temp_solution, distance_matrix_2)\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to random swap if duplicates occur\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design for the bi-objective TSP:\n\n- **Keywords**: *Adaptive Pareto selection, hybrid segment-rotation, cost-sensitive edge prioritization, conditional feasibility checks.*\n- **Advice**: Use weighted Pareto tournaments to select solutions, then apply segment rotations (random-length) combined with conditional edge reversals (only if improving at least one objective). Prioritize edges with high normalized distance products in both spaces.\n- **Avoid**: Static 2-opt or fixed-length perturbations; ignore trade-offs between objectives; non-adaptive selection (e.g., uniform random).\n- **Explanation**: This hybrid approach balances exploration (random segment rotations) and exploitation (cost-aware edge prioritization), ensuring diversity via Pareto selection and feasibility via conditional checks. It generalizes better than dominated heuristics by adaptively targeting high-potential regions.\n\nThe key innovation is combining *adaptive Pareto selection* with *hybrid segment-rotation* and *cost-sensitive edge prioritization*, while rigorously avoiding static or overly greedy operators. This ensures both exploration and exploitation while maintaining feasibility.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 118,
        "algorithm": "The algorithm combines adaptive Pareto selection with a novel segment insertion strategy, where it intelligently extracts and reinserts segments from promising solutions while prioritizing cost improvements in both objectives, ensuring feasibility through strict validation and fallback mechanisms. It balances exploration through segment diversity and exploitation through cost-aware insertion, with occasional conditional segment reversals for further optimization. The selection process prioritizes non-dominated solutions, and the local search focuses on improving at least one objective while maintaining tour validity.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    is_dominated = np.zeros(len(archive), dtype=bool)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                is_dominated[i] = True\n                break\n\n    non_dominated_indices = np.where(~is_dominated)[0]\n    if len(non_dominated_indices) > 0:\n        selected_idx = np.random.choice(non_dominated_indices)\n    else:\n        selected_idx = np.argmin(np.sum(objectives, axis=1))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Objective-aware segment insertion\n    def calculate_segment_cost(segment, prev_node, next_node, dist_matrix):\n        cost = dist_matrix[prev_node, segment[0]] + dist_matrix[segment[-1], next_node]\n        for i in range(len(segment) - 1):\n            cost += dist_matrix[segment[i], segment[i+1]]\n        return cost\n\n    def find_best_insertion_point(new_solution, segment, dist_matrix1, dist_matrix2):\n        best_pos = -1\n        best_improvement = 0\n        for i in range(n):\n            temp_solution = np.concatenate([new_solution[:i], segment, new_solution[i:]])\n            if len(np.unique(temp_solution)) != n:\n                continue\n            original_cost1 = dist_matrix1[new_solution[i-1], new_solution[i]] + dist_matrix1[new_solution[-1], new_solution[0]]\n            original_cost2 = dist_matrix2[new_solution[i-1], new_solution[i]] + dist_matrix2[new_solution[-1], new_solution[0]]\n            new_cost1 = calculate_segment_cost(segment, new_solution[i-1], new_solution[i], dist_matrix1)\n            new_cost2 = calculate_segment_cost(segment, new_solution[i-1], new_solution[i], dist_matrix2)\n            improvement1 = original_cost1 - new_cost1\n            improvement2 = original_cost2 - new_cost2\n            if improvement1 > 0 or improvement2 > 0:\n                total_improvement = improvement1 + improvement2\n                if total_improvement > best_improvement:\n                    best_improvement = total_improvement\n                    best_pos = i\n        return best_pos\n\n    # Extract a random segment from the selected solution\n    segment_length = max(2, min(n // 4, int(np.random.exponential(scale=1.5))))\n    start = np.random.randint(0, n - segment_length + 1)\n    segment = new_solution[start:start+segment_length]\n\n    # Find the best insertion point\n    best_pos = find_best_insertion_point(new_solution, segment, distance_matrix_1, distance_matrix_2)\n\n    if best_pos != -1:\n        new_solution = np.concatenate([new_solution[:best_pos], segment, new_solution[best_pos:]])\n        if len(np.unique(new_solution)) != n:\n            new_solution = base_solution\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.2:\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        reversed_segment = np.flip(new_solution[i:j+1])\n        temp_solution = np.concatenate([new_solution[:i], reversed_segment, new_solution[j+1:]])\n\n        if len(np.unique(temp_solution)) == n:\n            original_cost1 = distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]]\n            original_cost2 = distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]\n            new_cost1 = distance_matrix_1[new_solution[i-1], reversed_segment[0]] + distance_matrix_1[reversed_segment[-1], new_solution[(j+1)%n]]\n            new_cost2 = distance_matrix_2[new_solution[i-1], reversed_segment[0]] + distance_matrix_2[reversed_segment[-1], new_solution[(j+1)%n]]\n\n            if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "score": [
            -0.55811630051279,
            2.4834550619125366
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto selection with weighted crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    is_dominated = np.zeros(len(archive), dtype=bool)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                is_dominated[i] = True\n                break\n\n    non_dominated_indices = np.where(~is_dominated)[0]\n    if len(non_dominated_indices) > 0:\n        selected_idx = np.random.choice(non_dominated_indices)\n    else:\n        selected_idx = np.argmin(np.sum(objectives, axis=1))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Objective-aware segment insertion\n    def calculate_segment_cost(segment, prev_node, next_node, dist_matrix):\n        cost = dist_matrix[prev_node, segment[0]] + dist_matrix[segment[-1], next_node]\n        for i in range(len(segment) - 1):\n            cost += dist_matrix[segment[i], segment[i+1]]\n        return cost\n\n    def find_best_insertion_point(new_solution, segment, dist_matrix1, dist_matrix2):\n        best_pos = -1\n        best_improvement = 0\n        for i in range(n):\n            temp_solution = np.concatenate([new_solution[:i], segment, new_solution[i:]])\n            if len(np.unique(temp_solution)) != n:\n                continue\n            original_cost1 = dist_matrix1[new_solution[i-1], new_solution[i]] + dist_matrix1[new_solution[-1], new_solution[0]]\n            original_cost2 = dist_matrix2[new_solution[i-1], new_solution[i]] + dist_matrix2[new_solution[-1], new_solution[0]]\n            new_cost1 = calculate_segment_cost(segment, new_solution[i-1], new_solution[i], dist_matrix1)\n            new_cost2 = calculate_segment_cost(segment, new_solution[i-1], new_solution[i], dist_matrix2)\n            improvement1 = original_cost1 - new_cost1\n            improvement2 = original_cost2 - new_cost2\n            if improvement1 > 0 or improvement2 > 0:\n                total_improvement = improvement1 + improvement2\n                if total_improvement > best_improvement:\n                    best_improvement = total_improvement\n                    best_pos = i\n        return best_pos\n\n    # Extract a random segment from the selected solution\n    segment_length = max(2, min(n // 4, int(np.random.exponential(scale=1.5))))\n    start = np.random.randint(0, n - segment_length + 1)\n    segment = new_solution[start:start+segment_length]\n\n    # Find the best insertion point\n    best_pos = find_best_insertion_point(new_solution, segment, distance_matrix_1, distance_matrix_2)\n\n    if best_pos != -1:\n        new_solution = np.concatenate([new_solution[:best_pos], segment, new_solution[best_pos:]])\n        if len(np.unique(new_solution)) != n:\n            new_solution = base_solution\n\n    # Conditional segment reversal\n    if n > 4 and np.random.rand() < 0.2:\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        reversed_segment = np.flip(new_solution[i:j+1])\n        temp_solution = np.concatenate([new_solution[:i], reversed_segment, new_solution[j+1:]])\n\n        if len(np.unique(temp_solution)) == n:\n            original_cost1 = distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_1[new_solution[j], new_solution[(j+1)%n]]\n            original_cost2 = distance_matrix_2[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[j], new_solution[(j+1)%n]]\n            new_cost1 = distance_matrix_1[new_solution[i-1], reversed_segment[0]] + distance_matrix_1[reversed_segment[-1], new_solution[(j+1)%n]]\n            new_cost2 = distance_matrix_2[new_solution[i-1], reversed_segment[0]] + distance_matrix_2[reversed_segment[-1], new_solution[(j+1)%n]]\n\n            if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n                new_solution = temp_solution\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using Pareto dominance and crowding distance, then applies a hybrid local search combining segment crossover (randomly swapping two segments of the tour) and conditional edge reversal (reversing a segment if it improves at least one objective). It ensures feasibility by validating the tour and falling back to a random swap if duplicates occur, balancing exploration and exploitation dynamically.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and crowding distance to select a promising solution\n    objectives = np.array([obj for _, obj in archive])\n    is_dominated = np.zeros(len(archive), dtype=bool)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                is_dominated[i] = True\n                break\n\n    non_dominated_indices = np.where(~is_dominated)[0]\n    if len(non_dominated_indices) > 0:\n        selected_idx = np.random.choice(non_dominated_indices)\n    else:\n        # Fallback to random selection if no non-dominated solutions\n        selected_idx = np.random.randint(0, len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: segment crossover and conditional edge reversal\n    # Segment crossover\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    c, d = sorted(np.random.choice(n, 2, replace=False))\n    segment1 = new_solution[a:b+1]\n    segment2 = new_solution[c:d+1]\n    new_solution = np.concatenate([new_solution[:a], segment2, new_solution[b+1:c], segment1, new_solution[d+1:]])\n\n    # Conditional edge reversal\n    if n > 3:\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        reversed_segment = np.flip(new_solution[i:j+1])\n        temp_solution = np.concatenate([new_solution[:i], reversed_segment, new_solution[j+1:]])\n\n        # Check if reversal improves at least one objective\n        def calculate_cost(sol, dist_matrix):\n            cost = 0\n            for k in range(len(sol) - 1):\n                cost += dist_matrix[sol[k], sol[k+1]]\n            cost += dist_matrix[sol[-1], sol[0]]\n            return cost\n\n        original_cost1 = calculate_cost(new_solution, distance_matrix_1)\n        original_cost2 = calculate_cost(new_solution, distance_matrix_2)\n        new_cost1 = calculate_cost(temp_solution, distance_matrix_1)\n        new_cost2 = calculate_cost(temp_solution, distance_matrix_2)\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to random swap if duplicates occur\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 119,
        "algorithm": "The algorithm selects a high-potential solution from the archive using an edge importance metric that prioritizes solutions with lower combined costs relative to their initial edge distances. It then applies a hybrid local search combining multi-segment swaps and conditional partial reversals, ensuring feasibility through validation and dominance checks, with a fallback to random segment rotation if needed. The selection and operators are designed to balance exploration of promising regions while maintaining tour validity across both objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate edge importance metric for selection\n    objectives = np.array([obj for _, obj in archive])\n    edge_importance = np.zeros(len(archive))\n\n    for i in range(len(archive)):\n        sol = archive[i][0]\n        cost1 = objectives[i][0]\n        cost2 = objectives[i][1]\n        edge_importance[i] = (cost1 + cost2) / (len(sol) * (distance_matrix_1[sol[0], sol[1]] + distance_matrix_2[sol[0], sol[1]]))\n\n    # Select solution with highest edge importance\n    selected_idx = np.argmax(edge_importance)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Multi-segment swap operator\n    k = np.random.randint(2, min(5, n//2))\n    segments = []\n    for _ in range(k):\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        segments.append((a, b))\n\n    segments.sort()\n    temp_solution = new_solution.copy()\n    for i in range(len(segments)-1, -1, -1):\n        a, b = segments[i]\n        segment = new_solution[a:b+1]\n        temp_solution = np.concatenate([temp_solution[:a], segment, temp_solution[b+1:]])\n\n    # Conditional partial reversal\n    if n > 4:\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        if j - i > 2:\n            # Reverse middle portion only\n            mid_start = i + (j - i) // 3\n            mid_end = j - (j - i) // 3\n            reversed_middle = np.flip(new_solution[mid_start:mid_end+1])\n            temp_solution = np.concatenate([\n                new_solution[:mid_start],\n                reversed_middle,\n                new_solution[mid_end+1:]\n            ])\n\n            # Check local dominance\n            def calculate_cost(sol, dist_matrix):\n                cost = 0\n                for k in range(len(sol) - 1):\n                    cost += dist_matrix[sol[k], sol[k+1]]\n                cost += dist_matrix[sol[-1], sol[0]]\n                return cost\n\n            original_cost1 = calculate_cost(new_solution, distance_matrix_1)\n            original_cost2 = calculate_cost(new_solution, distance_matrix_2)\n            new_cost1 = calculate_cost(temp_solution, distance_matrix_1)\n            new_cost2 = calculate_cost(temp_solution, distance_matrix_2)\n\n            if (new_cost1 < original_cost1 and new_cost2 <= original_cost2 + 1e-6) or \\\n               (new_cost2 < original_cost2 and new_cost1 <= original_cost1 + 1e-6):\n                new_solution = temp_solution\n\n    # Feasibility check\n    if len(np.unique(new_solution)) != n:\n        # Fallback to random segment rotation\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        segment = new_solution[a:b+1]\n        new_solution = np.concatenate([new_solution[b+1:], segment, new_solution[:a]])\n\n    return new_solution\n\n",
        "score": [
            -0.36494428575937987,
            1.2230746150016785
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate edge importance metric for selection\n    objectives = np.array([obj for _, obj in archive])\n    edge_importance = np.zeros(len(archive))\n\n    for i in range(len(archive)):\n        sol = archive[i][0]\n        cost1 = objectives[i][0]\n        cost2 = objectives[i][1]\n        edge_importance[i] = (cost1 + cost2) / (len(sol) * (distance_matrix_1[sol[0], sol[1]] + distance_matrix_2[sol[0], sol[1]]))\n\n    # Select solution with highest edge importance\n    selected_idx = np.argmax(edge_importance)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Multi-segment swap operator\n    k = np.random.randint(2, min(5, n//2))\n    segments = []\n    for _ in range(k):\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        segments.append((a, b))\n\n    segments.sort()\n    temp_solution = new_solution.copy()\n    for i in range(len(segments)-1, -1, -1):\n        a, b = segments[i]\n        segment = new_solution[a:b+1]\n        temp_solution = np.concatenate([temp_solution[:a], segment, temp_solution[b+1:]])\n\n    # Conditional partial reversal\n    if n > 4:\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        if j - i > 2:\n            # Reverse middle portion only\n            mid_start = i + (j - i) // 3\n            mid_end = j - (j - i) // 3\n            reversed_middle = np.flip(new_solution[mid_start:mid_end+1])\n            temp_solution = np.concatenate([\n                new_solution[:mid_start],\n                reversed_middle,\n                new_solution[mid_end+1:]\n            ])\n\n            # Check local dominance\n            def calculate_cost(sol, dist_matrix):\n                cost = 0\n                for k in range(len(sol) - 1):\n                    cost += dist_matrix[sol[k], sol[k+1]]\n                cost += dist_matrix[sol[-1], sol[0]]\n                return cost\n\n            original_cost1 = calculate_cost(new_solution, distance_matrix_1)\n            original_cost2 = calculate_cost(new_solution, distance_matrix_2)\n            new_cost1 = calculate_cost(temp_solution, distance_matrix_1)\n            new_cost2 = calculate_cost(temp_solution, distance_matrix_2)\n\n            if (new_cost1 < original_cost1 and new_cost2 <= original_cost2 + 1e-6) or \\\n               (new_cost2 < original_cost2 and new_cost1 <= original_cost1 + 1e-6):\n                new_solution = temp_solution\n\n    # Feasibility check\n    if len(np.unique(new_solution)) != n:\n        # Fallback to random segment rotation\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        segment = new_solution[a:b+1]\n        new_solution = np.concatenate([new_solution[b+1:], segment, new_solution[:a]])\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using Pareto dominance and crowding distance, then applies a hybrid local search combining segment crossover (randomly swapping two segments of the tour) and conditional edge reversal (reversing a segment if it improves at least one objective). It ensures feasibility by validating the tour and falling back to a random swap if duplicates occur, balancing exploration and exploitation dynamically.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and crowding distance to select a promising solution\n    objectives = np.array([obj for _, obj in archive])\n    is_dominated = np.zeros(len(archive), dtype=bool)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                is_dominated[i] = True\n                break\n\n    non_dominated_indices = np.where(~is_dominated)[0]\n    if len(non_dominated_indices) > 0:\n        selected_idx = np.random.choice(non_dominated_indices)\n    else:\n        # Fallback to random selection if no non-dominated solutions\n        selected_idx = np.random.randint(0, len(archive))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Hybrid local search: segment crossover and conditional edge reversal\n    # Segment crossover\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    c, d = sorted(np.random.choice(n, 2, replace=False))\n    segment1 = new_solution[a:b+1]\n    segment2 = new_solution[c:d+1]\n    new_solution = np.concatenate([new_solution[:a], segment2, new_solution[b+1:c], segment1, new_solution[d+1:]])\n\n    # Conditional edge reversal\n    if n > 3:\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        reversed_segment = np.flip(new_solution[i:j+1])\n        temp_solution = np.concatenate([new_solution[:i], reversed_segment, new_solution[j+1:]])\n\n        # Check if reversal improves at least one objective\n        def calculate_cost(sol, dist_matrix):\n            cost = 0\n            for k in range(len(sol) - 1):\n                cost += dist_matrix[sol[k], sol[k+1]]\n            cost += dist_matrix[sol[-1], sol[0]]\n            return cost\n\n        original_cost1 = calculate_cost(new_solution, distance_matrix_1)\n        original_cost2 = calculate_cost(new_solution, distance_matrix_2)\n        new_cost1 = calculate_cost(temp_solution, distance_matrix_1)\n        new_cost2 = calculate_cost(temp_solution, distance_matrix_2)\n\n        if (new_cost1 < original_cost1) or (new_cost2 < original_cost2):\n            new_solution = temp_solution\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to random swap if duplicates occur\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 120,
        "algorithm": "The algorithm selects a promising solution from the archive based on Pareto dominance (lower dominance count indicates better potential), then applies an adaptive segment inversion heuristic to generate a neighbor. If the inversion doesn't improve both objectives or breaks feasibility, it falls back to a random swap. The segment length is dynamically adjusted (20% of tour length) to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and dominance rank\n    objectives = np.array([obj for _, obj in archive])\n    dominance_count = np.zeros(len(archive), dtype=int)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                dominance_count[i] += 1\n\n    # Select solution with lowest dominance count (most promising)\n    selected_idx = np.argmin(dominance_count)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment inversion heuristic\n    segment_length = max(2, int(np.ceil(n * 0.2)))  # Adaptive segment length\n    start_pos = np.random.randint(0, n - segment_length + 1)\n    end_pos = start_pos + segment_length - 1\n\n    # Invert the segment\n    new_solution[start_pos:end_pos+1] = np.flip(new_solution[start_pos:end_pos+1])\n\n    # Check feasibility and cost improvement\n    def calculate_cost(sol, dist_matrix):\n        cost = 0\n        for k in range(len(sol) - 1):\n            cost += dist_matrix[sol[k], sol[k+1]]\n        cost += dist_matrix[sol[-1], sol[0]]\n        return cost\n\n    original_cost1 = calculate_cost(base_solution, distance_matrix_1)\n    original_cost2 = calculate_cost(base_solution, distance_matrix_2)\n    new_cost1 = calculate_cost(new_solution, distance_matrix_1)\n    new_cost2 = calculate_cost(new_solution, distance_matrix_2)\n\n    # Revert if no improvement and not feasible\n    if (new_cost1 >= original_cost1 and new_cost2 >= original_cost2) or len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n        # Fallback to random swap\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "score": [
            -0.6999378468590731,
            0.7898916602134705
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance and dominance rank\n    objectives = np.array([obj for _, obj in archive])\n    dominance_count = np.zeros(len(archive), dtype=int)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j and (objectives[j, 0] <= objectives[i, 0] and objectives[j, 1] <= objectives[i, 1]) and (objectives[j, 0] < objectives[i, 0] or objectives[j, 1] < objectives[i, 1]):\n                dominance_count[i] += 1\n\n    # Select solution with lowest dominance count (most promising)\n    selected_idx = np.argmin(dominance_count)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 3:\n        return new_solution\n\n    # Adaptive segment inversion heuristic\n    segment_length = max(2, int(np.ceil(n * 0.2)))  # Adaptive segment length\n    start_pos = np.random.randint(0, n - segment_length + 1)\n    end_pos = start_pos + segment_length - 1\n\n    # Invert the segment\n    new_solution[start_pos:end_pos+1] = np.flip(new_solution[start_pos:end_pos+1])\n\n    # Check feasibility and cost improvement\n    def calculate_cost(sol, dist_matrix):\n        cost = 0\n        for k in range(len(sol) - 1):\n            cost += dist_matrix[sol[k], sol[k+1]]\n        cost += dist_matrix[sol[-1], sol[0]]\n        return cost\n\n    original_cost1 = calculate_cost(base_solution, distance_matrix_1)\n    original_cost2 = calculate_cost(base_solution, distance_matrix_2)\n    new_cost1 = calculate_cost(new_solution, distance_matrix_1)\n    new_cost2 = calculate_cost(new_solution, distance_matrix_2)\n\n    # Revert if no improvement and not feasible\n    if (new_cost1 >= original_cost1 and new_cost2 >= original_cost2) or len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n        # Fallback to random swap\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "operation": "m2"
    }
]