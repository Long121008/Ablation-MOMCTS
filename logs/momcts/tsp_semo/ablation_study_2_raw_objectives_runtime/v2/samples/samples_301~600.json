[
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        None\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Pareto-aware selection with adaptive crowding distance\n    non_dominated = []\n    objectives = np.array([obj for _, obj in archive])\n\n    for i, (sol, obj) in enumerate(archive):\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if non_dominated:\n        crowding_dist = np.zeros(len(non_dominated))\n        for m in range(2):\n            sorted_idx = np.argsort([obj[m] for _, obj in non_dominated])\n            crowding_dist[sorted_idx[0]] = np.inf\n            crowding_dist[sorted_idx[-1]] = np.inf\n            for i in range(1, len(non_dominated) - 1):\n                crowding_dist[sorted_idx[i]] += (non_dominated[sorted_idx[i+1]][1][m] - non_dominated[sorted_idx[i-1]][1][m]) / (non_dominated[sorted_idx[-1]][1][m] - non_dominated[sorted_idx[0]][1][m] + 1e-10)\n        selected_idx = np.argmax(crowding_dist)\n        base_solution = non_dominated[selected_idx][0].copy()\n    else:\n        selected_idx = np.argmax([sum(obj) for _, obj in archive])\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Hybrid local search with 4-opt and adaptive edge swaps\n    if n >= 5:\n        # 4-opt move\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n        options = [\n            np.concatenate([new_solution[:a], new_solution[b:c], new_solution[a:b], new_solution[d:], new_solution[c:d]]),\n            np.concatenate([new_solution[:a], new_solution[d:], new_solution[b:c], new_solution[a:b], new_solution[c:d]]),\n            np.concatenate([new_solution[:b], new_solution[a:c], new_solution[b:a], new_solution[d:], new_solution[c:d]]),\n            np.concatenate([new_solution[:b], new_solution[d:], new_solution[a:c], new_solution[b:a], new_solution[c:d]])\n        ]\n\n        # Evaluate options with adaptive weights\n        weight1 = 0.5 + 0.3 * (np.std(objectives[:, 0]) / (np.mean(objectives[:, 0]) + 1e-10))\n        weight2 = 0.5 + 0.3 * (np.std(objectives[:, 1]) / (np.mean(objectives[:, 1]) + 1e-10))\n\n        best_cost = float('inf')\n        best_option = None\n        for option in options:\n            cost = 0\n            for i in range(n):\n                j = (i + 1) % n\n                cost += weight1 * distance_matrix_1[option[i], option[j]] + weight2 * distance_matrix_2[option[i], option[j]]\n            if cost < best_cost:\n                best_cost = cost\n                best_option = option.copy()\n\n        if best_option is not None:\n            new_solution = best_option\n\n        # Adaptive edge swaps\n        if np.random.random() < 0.4:\n            for _ in range(2):\n                i, j = sorted(np.random.choice(n, size=2, replace=False))\n                if i != j and abs(i - j) > 1:\n                    temp = new_solution[i:j+1]\n                    np.random.shuffle(temp)\n                    new_solution[i:j+1] = temp\n\n    # Step 3: Feasibility validation\n    if len(np.unique(new_solution)) != n:\n        # Repair by inserting missing nodes at best positions\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            min_cost = float('inf')\n            for pos in range(n + 1):\n                temp = np.insert(new_solution, pos, node)\n                cost = sum(distance_matrix_1[temp[i], temp[(i+1)%(n+1)]] + distance_matrix_2[temp[i], temp[(i+1)%(n+1)]] for i in range(n+1))\n                if cost < min_cost:\n                    min_cost = cost\n                    best_pos = pos\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 301,
        "algorithm": "This algorithm implements a hybrid local search strategy that first selects a promising solution from the archive using objective-aware weighting, then applies adaptive segment swaps and objective-aware edge improvements to generate a neighbor solution while ensuring feasibility through validation and repair. The approach prioritizes solutions with better normalized objective values and dynamically adjusts segment lengths and edge improvements based on problem size, balancing exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Objective-aware selection with adaptive weighting\n    objectives = np.array([obj for _, obj in archive])\n    obj_range = np.max(objectives, axis=0) - np.min(objectives, axis=0)\n    obj_weights = 1.0 / (obj_range + 1e-10)\n    obj_weights /= np.sum(obj_weights)\n\n    weighted_scores = np.dot(objectives, obj_weights)\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Segment swapping with adaptive length\n    if n >= 4:\n        segment_length = min(3, max(2, int(n * 0.3)))\n        a = np.random.randint(0, n - segment_length)\n        b = np.random.randint(0, n - segment_length)\n\n        if a != b:\n            segment_a = new_solution[a:a+segment_length]\n            segment_b = new_solution[b:b+segment_length]\n\n            new_solution[a:a+segment_length] = segment_b\n            new_solution[b:b+segment_length] = segment_a\n\n    # Step 3: Objective-aware edge improvements\n    improvement_attempts = min(5, n // 2)\n    for _ in range(improvement_attempts):\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n\n        if i != j and abs(i - j) > 1:\n            current_cost = (distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] +\n                           distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] +\n                           distance_matrix_1[new_solution[j], new_solution[(j+1)%n]] +\n                           distance_matrix_2[new_solution[j], new_solution[(j+1)%n]])\n\n            new_cost = (distance_matrix_1[new_solution[i], new_solution[j]] +\n                       distance_matrix_2[new_solution[i], new_solution[j]] +\n                       distance_matrix_1[new_solution[(i+1)%n], new_solution[(j+1)%n]] +\n                       distance_matrix_2[new_solution[(i+1)%n], new_solution[(j+1)%n]])\n\n            if new_cost < current_cost:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 4: Feasibility validation and repair\n    if len(np.unique(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            min_cost = float('inf')\n            for pos in range(n + 1):\n                temp = np.insert(new_solution, pos, node)\n                cost = sum(distance_matrix_1[temp[i], temp[(i+1)%(n+1)]] +\n                          distance_matrix_2[temp[i], temp[(i+1)%(n+1)]] for i in range(n+1))\n                if cost < min_cost:\n                    min_cost = cost\n                    best_pos = pos\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9332748839336859,
            4.1310078501701355
        ],
        "raw_score": [
            10.532208246571752,
            10.688354953771292
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Objective-aware selection with adaptive weighting\n    objectives = np.array([obj for _, obj in archive])\n    obj_range = np.max(objectives, axis=0) - np.min(objectives, axis=0)\n    obj_weights = 1.0 / (obj_range + 1e-10)\n    obj_weights /= np.sum(obj_weights)\n\n    weighted_scores = np.dot(objectives, obj_weights)\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Segment swapping with adaptive length\n    if n >= 4:\n        segment_length = min(3, max(2, int(n * 0.3)))\n        a = np.random.randint(0, n - segment_length)\n        b = np.random.randint(0, n - segment_length)\n\n        if a != b:\n            segment_a = new_solution[a:a+segment_length]\n            segment_b = new_solution[b:b+segment_length]\n\n            new_solution[a:a+segment_length] = segment_b\n            new_solution[b:b+segment_length] = segment_a\n\n    # Step 3: Objective-aware edge improvements\n    improvement_attempts = min(5, n // 2)\n    for _ in range(improvement_attempts):\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n\n        if i != j and abs(i - j) > 1:\n            current_cost = (distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] +\n                           distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] +\n                           distance_matrix_1[new_solution[j], new_solution[(j+1)%n]] +\n                           distance_matrix_2[new_solution[j], new_solution[(j+1)%n]])\n\n            new_cost = (distance_matrix_1[new_solution[i], new_solution[j]] +\n                       distance_matrix_2[new_solution[i], new_solution[j]] +\n                       distance_matrix_1[new_solution[(i+1)%n], new_solution[(j+1)%n]] +\n                       distance_matrix_2[new_solution[(i+1)%n], new_solution[(j+1)%n]])\n\n            if new_cost < current_cost:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 4: Feasibility validation and repair\n    if len(np.unique(new_solution)) != n:\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            min_cost = float('inf')\n            for pos in range(n + 1):\n                temp = np.insert(new_solution, pos, node)\n                cost = sum(distance_matrix_1[temp[i], temp[(i+1)%(n+1)]] +\n                          distance_matrix_2[temp[i], temp[(i+1)%(n+1)]] for i in range(n+1))\n                if cost < min_cost:\n                    min_cost = cost\n                    best_pos = pos\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 3 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Pareto-aware selection with adaptive crowding distance\n    non_dominated = []\n    objectives = np.array([obj for _, obj in archive])\n\n    for i, (sol, obj) in enumerate(archive):\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if non_dominated:\n        crowding_dist = np.zeros(len(non_dominated))\n        for m in range(2):\n            sorted_idx = np.argsort([obj[m] for _, obj in non_dominated])\n            crowding_dist[sorted_idx[0]] = np.inf\n            crowding_dist[sorted_idx[-1]] = np.inf\n            for i in range(1, len(non_dominated) - 1):\n                crowding_dist[sorted_idx[i]] += (non_dominated[sorted_idx[i+1]][1][m] - non_dominated[sorted_idx[i-1]][1][m]) / (non_dominated[sorted_idx[-1]][1][m] - non_dominated[sorted_idx[0]][1][m] + 1e-10)\n        selected_idx = np.argmax(crowding_dist)\n        base_solution = non_dominated[selected_idx][0].copy()\n    else:\n        selected_idx = np.argmax([sum(obj) for _, obj in archive])\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Hybrid local search with 4-opt and adaptive edge swaps\n    if n >= 5:\n        # 4-opt move\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n        options = [\n            np.concatenate([new_solution[:a], new_solution[b:c], new_solution[a:b], new_solution[d:], new_solution[c:d]]),\n            np.concatenate([new_solution[:a], new_solution[d:], new_solution[b:c], new_solution[a:b], new_solution[c:d]]),\n            np.concatenate([new_solution[:b], new_solution[a:c], new_solution[b:a], new_solution[d:], new_solution[c:d]]),\n            np.concatenate([new_solution[:b], new_solution[d:], new_solution[a:c], new_solution[b:a], new_solution[c:d]])\n        ]\n\n        # Evaluate options with adaptive weights\n        weight1 = 0.5 + 0.3 * (np.std(objectives[:, 0]) / (np.mean(objectives[:, 0]) + 1e-10))\n        weight2 = 0.5 + 0.3 * (np.std(objectives[:, 1]) / (np.mean(objectives[:, 1]) + 1e-10))\n\n        best_cost = float('inf')\n        best_option = None\n        for option in options:\n            cost = 0\n            for i in range(n):\n                j = (i + 1) % n\n                cost += weight1 * distance_matrix_1[option[i], option[j]] + weight2 * distance_matrix_2[option[i], option[j]]\n            if cost < best_cost:\n                best_cost = cost\n                best_option = option.copy()\n\n        if best_option is not None:\n            new_solution = best_option\n\n        # Adaptive edge swaps\n        if np.random.random() < 0.4:\n            for _ in range(2):\n                i, j = sorted(np.random.choice(n, size=2, replace=False))\n                if i != j and abs(i - j) > 1:\n                    temp = new_solution[i:j+1]\n                    np.random.shuffle(temp)\n                    new_solution[i:j+1] = temp\n\n    # Step 3: Feasibility validation\n    if len(np.unique(new_solution)) != n:\n        # Repair by inserting missing nodes at best positions\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            min_cost = float('inf')\n            for pos in range(n + 1):\n                temp = np.insert(new_solution, pos, node)\n                cost = sum(distance_matrix_1[temp[i], temp[(i+1)%(n+1)]] + distance_matrix_2[temp[i], temp[(i+1)%(n+1)]] for i in range(n+1))\n                if cost < min_cost:\n                    min_cost = cost\n                    best_pos = pos\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm intelligently selects a non-dominated solution from the archive, applies a 4-opt-inspired edge swap followed by conditional multi-edge insertions to generate a neighbor solution, while ensuring feasibility by validating node uniqueness and dynamically adjusting based on objective improvements. The method prioritizes solutions with better Pareto dominance, uses adaptive local search operators, and validates feasibility through node uniqueness checks.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a non-dominated solution with high potential\n    selected = None\n    for sol, obj in archive:\n        if selected is None or (obj[0] < selected[1][0] and obj[1] < selected[1][1]):\n            selected = (sol, obj)\n    if selected is None:\n        selected = archive[0]\n    base_solution = selected[0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Apply 4-opt edge swap\n    if n >= 4:\n        # Select four distinct indices\n        indices = sorted(np.random.choice(range(n), size=4, replace=False))\n        a, b, c, d = indices\n        # Swap edges (a,b) and (c,d) with (a,c) and (b,d)\n        if b == (a + 1) % n and d == (c + 1) % n:\n            # Create new segments\n            segment1 = new_solution[a:b+1]\n            segment2 = new_solution[c:d+1]\n            # Reconstruct the tour\n            new_solution = np.concatenate([new_solution[:a], segment2, new_solution[b+1:c], segment1, new_solution[d+1:]])\n\n    # Step 2: Conditional multi-edge insertion\n    for _ in range(2):  # Try up to 2 insertions\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        while abs(i - j) <= 1 or (i == 0 and j == n-1) or (j == 0 and i == n-1):\n            j = np.random.randint(0, n)\n        # Calculate cost before and after insertion\n        a, b = new_solution[i], new_solution[(i+1)%n]\n        c, d = new_solution[j], new_solution[(j+1)%n]\n        cost_before = distance_matrix_1[a, b] + distance_matrix_2[a, b]\n        cost_after = distance_matrix_1[a, c] + distance_matrix_1[b, d] + distance_matrix_2[a, c] + distance_matrix_2[b, d]\n        if cost_after < cost_before:\n            # Perform the insertion\n            new_solution = np.concatenate([new_solution[:i+1], new_solution[(i+2)%n:]])\n            new_solution = np.insert(new_solution, (j+1)%(n-1), [a, b])\n\n    # Ensure feasibility\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive (prioritizing non-dominated or high-cost solutions) and applies a hybrid local search combining edge insertion with a novel edge-swapping move, ensuring feasibility by maintaining a valid TSP tour. It evaluates potential improvements by reinserting edges and swaps non-adjacent edges to escape local optima.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., non-dominated solutions)\n    selected = None\n    for sol, obj in archive:\n        if selected is None or (obj[0] > selected[1][0] and obj[1] > selected[1][1]):\n            selected = (sol, obj)\n    if selected is None:\n        selected = archive[0]\n    base_solution = selected[0].copy()\n\n    # Hybrid local search: combine edge insertion with a novel move\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify edges with high potential for improvement\n    # Calculate the improvement if we remove an edge and reinsert it elsewhere\n    improvements = []\n    for i in range(n):\n        a, b = new_solution[i], new_solution[(i+1)%n]\n        # Cost before removal\n        cost_before = distance_matrix_1[a, b] + distance_matrix_2[a, b]\n        # Try inserting between other edges\n        for j in range(n):\n            if j == i or j == (i+1)%n:\n                continue\n            c, d = new_solution[j], new_solution[(j+1)%n]\n            # Cost after insertion\n            cost_after = distance_matrix_1[a, c] + distance_matrix_1[b, d] + distance_matrix_2[a, c] + distance_matrix_2[b, d]\n            improvement = cost_before - cost_after\n            if improvement > 0:\n                improvements.append((improvement, i, j))\n\n    if improvements:\n        # Select the best improvement\n        improvements.sort(reverse=True, key=lambda x: x[0])\n        best_improvement, i, j = improvements[0]\n        # Perform the move\n        a, b = new_solution[i], new_solution[(i+1)%n]\n        # Remove edge (a,b)\n        if i < (i+1)%n:\n            new_solution = np.concatenate([new_solution[:i+1], new_solution[(i+2)%n:]])\n        else:\n            new_solution = np.concatenate([new_solution[:(i+1)%n], new_solution[i+1:]])\n        # Insert between j and (j+1)%n\n        new_solution = np.insert(new_solution, (j+1)%(n-1), [a, b])\n\n    # Step 2: Apply a novel move (swap of two non-adjacent edges)\n    if n >= 4:\n        # Select two non-adjacent edges\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        while abs(i - j) <= 1 or (i == 0 and j == n-1) or (j == 0 and i == n-1):\n            j = np.random.randint(0, n)\n        # Swap the edges\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the ultra-concise, high-value response for the bi-TSP heuristic design:\n\n- **Keywords**: Pareto-dominance, hybrid 4-opt, adaptive edge swaps, crowding distance, dynamic weights, feasibility validation.\n- **Advice**: Select non-dominated solutions via crowding distance, apply 4-opt with 30% edge-swap probability, and dynamically adjust objective weights (70/30) for balanced exploration.\n- **Avoid**: Greedy dominated selection, static 2-opt, or moves that risk duplicate nodes/missing nodes. Use nearest-neighbor repair for infeasible tours.\n- **Explanation**: Hybrid 4-opt with conditional edge swaps explores large neighborhoods, while dynamic weights balance objectives. Feasibility checks ensure valid tours.\n\n**Next Step**: Implement the heuristic with crowding-distance selection and hybrid 4-opt + edge-swap local search.\n\n```python\nimport numpy as np\nfrom scipy.spatial.distance import euclidean\n\ndef select_neighbor(archive, objectives):\n    # Step 1: Identify non-dominated solutions using Pareto dominance\n    non_dominated = []\n    for i, sol in enumerate(archive):\n        is_dominated = False\n        for j, other_sol in enumerate(archive):\n            if i != j and np.all(objectives[j] <= objectives[i]) and np.any(objectives[j] < objectives[i]):\n                is_dominated = True\n                break\n        if not is_dominated:\n            non_dominated.append((sol, objectives[i]))\n\n    # Step 2: Select a solution with highest crowding distance (if multiple)\n    if len(non_dominated) > 1:\n        # Calculate crowding distance (simplified for 2 objectives)\n        crowding = []\n        for sol, obj in non_dominated:\n            distances = []\n            for other_sol, other_obj in non_dominated:\n                if sol is not other_sol:\n                    distances.append(np.linalg.norm(np.array(obj) - np.array(other_obj)))\n            crowding.append(np.mean(distances) if distances else 0)\n        selected_idx = np.argmax(crowding)\n    else:\n        selected_idx = 0\n\n    selected_sol, _ = non_dominated[selected_idx]\n    tour = selected_sol.copy()\n\n    # Step 3: Apply hybrid 4-opt with adaptive edge swaps\n    n = len(tour)\n    for _ in range(10):  # Limit iterations to avoid excessive computation\n        i, j, k, l = np.random.choice(n, 4, replace=False)\n        i, j, k, l = sorted([i, j, k, l])\n\n        # 4-opt move (swap segments)\n        new_tour = np.concatenate([\n            tour[:i+1], tour[j:k+1][::-1], tour[l:], tour[i+1:j][::-1], tour[k+1:l+1][::-1]\n        ])\n\n        # Adaptive edge swap (30% probability)\n        if np.random.rand() < 0.3:\n            swap_i, swap_j = np.random.choice(n, 2, replace=False)\n            new_tour[swap_i], new_tour[swap_j] = new_tour[swap_j], new_tour[swap_i]\n\n        # Step 4: Feasibility check and repair\n        if len(np.unique(new_tour)) == n:  # Valid tour\n            tour = new_tour\n        else:  # Repair using nearest-neighbor insertion\n            missing = set(range(n)) - set(new_tour)\n            for node in missing:\n                nearest = np.argmin([euclidean((x1[node], y1[node]), (x1[neighbor], y1[neighbor])) for neighbor in tour])\n                tour = np.insert(tour, nearest, node)\n\n    return tour\n```\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 302,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Pareto-aware selection with adaptive crowding distance\n    non_dominated = []\n    objectives = np.array([obj for _, obj in archive])\n\n    for i, (sol, obj) in enumerate(archive):\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if non_dominated:\n        crowding_dist = np.zeros(len(non_dominated))\n        for m in range(2):\n            sorted_idx = np.argsort([obj[m] for _, obj in non_dominated])\n            crowding_dist[sorted_idx[0]] = np.inf\n            crowding_dist[sorted_idx[-1]] = np.inf\n            for i in range(1, len(non_dominated) - 1):\n                crowding_dist[sorted_idx[i]] += (non_dominated[sorted_idx[i+1]][1][m] - non_dominated[sorted_idx[i-1]][1][m]) / (non_dominated[sorted_idx[-1]][1][m] - non_dominated[sorted_idx[0]][1][m] + 1e-10)\n        selected_idx = np.argmax(crowding_dist)\n        base_solution = non_dominated[selected_idx][0].copy()\n    else:\n        selected_idx = np.argmax([sum(obj) for _, obj in archive])\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Enhanced hybrid local search with adaptive 4-opt and edge swaps\n    if n >= 5:\n        # Adaptive weights based on objective variance\n        weight1 = 0.5 + 0.3 * (np.std(objectives[:, 0]) / (np.mean(objectives[:, 0]) + 1e-10))\n        weight2 = 0.5 + 0.3 * (np.std(objectives[:, 1]) / (np.mean(objectives[:, 1]) + 1e-10))\n\n        # Multiple 4-opt attempts with different segmentations\n        for _ in range(3):\n            a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n            options = [\n                np.concatenate([new_solution[:a], new_solution[b:c], new_solution[a:b], new_solution[d:], new_solution[c:d]]),\n                np.concatenate([new_solution[:a], new_solution[d:], new_solution[b:c], new_solution[a:b], new_solution[c:d]]),\n                np.concatenate([new_solution[:b], new_solution[a:c], new_solution[b:a], new_solution[d:], new_solution[c:d]]),\n                np.concatenate([new_solution[:b], new_solution[d:], new_solution[a:c], new_solution[b:a], new_solution[c:d]])\n            ]\n\n            best_cost = float('inf')\n            best_option = None\n            for option in options:\n                cost = 0\n                for i in range(n):\n                    j = (i + 1) % n\n                    cost += weight1 * distance_matrix_1[option[i], option[j]] + weight2 * distance_matrix_2[option[i], option[j]]\n                if cost < best_cost:\n                    best_cost = cost\n                    best_option = option.copy()\n\n            if best_option is not None:\n                new_solution = best_option\n\n        # Adaptive edge swaps with probability based on improvement potential\n        for _ in range(2):\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n            if i != j and abs(i - j) > 1:\n                # Calculate cost before swap\n                cost_before = (weight1 * distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] +\n                              weight2 * distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] +\n                              weight1 * distance_matrix_1[new_solution[j], new_solution[(j+1)%n]] +\n                              weight2 * distance_matrix_2[new_solution[j], new_solution[(j+1)%n]])\n\n                # Calculate cost after swap\n                cost_after = (weight1 * distance_matrix_1[new_solution[i], new_solution[j]] +\n                             weight2 * distance_matrix_2[new_solution[i], new_solution[j]] +\n                             weight1 * distance_matrix_1[new_solution[(i+1)%n], new_solution[(j+1)%n]] +\n                             weight2 * distance_matrix_2[new_solution[(i+1)%n], new_solution[(j+1)%n]])\n\n                if cost_after < cost_before:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 3: Feasibility validation and repair\n    if len(np.unique(new_solution)) != n:\n        # Repair by inserting missing nodes at best positions\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            min_cost = float('inf')\n            for pos in range(n + 1):\n                temp = np.insert(new_solution, pos, node)\n                cost = sum(distance_matrix_1[temp[i], temp[(i+1)%(n+1)]] + distance_matrix_2[temp[i], temp[(i+1)%(n+1)]] for i in range(n+1))\n                if cost < min_cost:\n                    min_cost = cost\n                    best_pos = pos\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7244309814322126,
            1.241345226764679
        ],
        "raw_score": [
            8.34206468276664,
            7.859619065944894
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Pareto-aware selection with adaptive crowding distance\n    non_dominated = []\n    objectives = np.array([obj for _, obj in archive])\n\n    for i, (sol, obj) in enumerate(archive):\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if non_dominated:\n        crowding_dist = np.zeros(len(non_dominated))\n        for m in range(2):\n            sorted_idx = np.argsort([obj[m] for _, obj in non_dominated])\n            crowding_dist[sorted_idx[0]] = np.inf\n            crowding_dist[sorted_idx[-1]] = np.inf\n            for i in range(1, len(non_dominated) - 1):\n                crowding_dist[sorted_idx[i]] += (non_dominated[sorted_idx[i+1]][1][m] - non_dominated[sorted_idx[i-1]][1][m]) / (non_dominated[sorted_idx[-1]][1][m] - non_dominated[sorted_idx[0]][1][m] + 1e-10)\n        selected_idx = np.argmax(crowding_dist)\n        base_solution = non_dominated[selected_idx][0].copy()\n    else:\n        selected_idx = np.argmax([sum(obj) for _, obj in archive])\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 2: Enhanced hybrid local search with adaptive 4-opt and edge swaps\n    if n >= 5:\n        # Adaptive weights based on objective variance\n        weight1 = 0.5 + 0.3 * (np.std(objectives[:, 0]) / (np.mean(objectives[:, 0]) + 1e-10))\n        weight2 = 0.5 + 0.3 * (np.std(objectives[:, 1]) / (np.mean(objectives[:, 1]) + 1e-10))\n\n        # Multiple 4-opt attempts with different segmentations\n        for _ in range(3):\n            a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n            options = [\n                np.concatenate([new_solution[:a], new_solution[b:c], new_solution[a:b], new_solution[d:], new_solution[c:d]]),\n                np.concatenate([new_solution[:a], new_solution[d:], new_solution[b:c], new_solution[a:b], new_solution[c:d]]),\n                np.concatenate([new_solution[:b], new_solution[a:c], new_solution[b:a], new_solution[d:], new_solution[c:d]]),\n                np.concatenate([new_solution[:b], new_solution[d:], new_solution[a:c], new_solution[b:a], new_solution[c:d]])\n            ]\n\n            best_cost = float('inf')\n            best_option = None\n            for option in options:\n                cost = 0\n                for i in range(n):\n                    j = (i + 1) % n\n                    cost += weight1 * distance_matrix_1[option[i], option[j]] + weight2 * distance_matrix_2[option[i], option[j]]\n                if cost < best_cost:\n                    best_cost = cost\n                    best_option = option.copy()\n\n            if best_option is not None:\n                new_solution = best_option\n\n        # Adaptive edge swaps with probability based on improvement potential\n        for _ in range(2):\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n            if i != j and abs(i - j) > 1:\n                # Calculate cost before swap\n                cost_before = (weight1 * distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] +\n                              weight2 * distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] +\n                              weight1 * distance_matrix_1[new_solution[j], new_solution[(j+1)%n]] +\n                              weight2 * distance_matrix_2[new_solution[j], new_solution[(j+1)%n]])\n\n                # Calculate cost after swap\n                cost_after = (weight1 * distance_matrix_1[new_solution[i], new_solution[j]] +\n                             weight2 * distance_matrix_2[new_solution[i], new_solution[j]] +\n                             weight1 * distance_matrix_1[new_solution[(i+1)%n], new_solution[(j+1)%n]] +\n                             weight2 * distance_matrix_2[new_solution[(i+1)%n], new_solution[(j+1)%n]])\n\n                if cost_after < cost_before:\n                    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Step 3: Feasibility validation and repair\n    if len(np.unique(new_solution)) != n:\n        # Repair by inserting missing nodes at best positions\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            min_cost = float('inf')\n            for pos in range(n + 1):\n                temp = np.insert(new_solution, pos, node)\n                cost = sum(distance_matrix_1[temp[i], temp[(i+1)%(n+1)]] + distance_matrix_2[temp[i], temp[(i+1)%(n+1)]] for i in range(n+1))\n                if cost < min_cost:\n                    min_cost = cost\n                    best_pos = pos\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive based on a weighted combination of objectives (30% for the first objective, 70% for the second), then applies a hybrid local search combining edge reversal and a novel node reordering strategy to generate a neighbor solution, ensuring feasibility by maintaining a valid TSP tour. The weighted selection prioritizes solutions with better performance in the second objective, while the local search explores new configurations by reversing segments and shuffling sub-sequences.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest weighted objective (0.3*obj1 + 0.7*obj2)\n    selected = max(archive, key=lambda x: 0.3 * x[1][0] + 0.7 * x[1][1])\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: edge reversal with node reordering\n    if n >= 3:\n        # Step 1: Reverse a random segment\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n        # Step 2: Novel node reordering in a sub-sequence\n        sub_start = np.random.randint(0, n - 2)\n        sub_end = np.random.randint(sub_start + 2, min(sub_start + 6, n))\n        sub_seq = new_solution[sub_start:sub_end]\n        np.random.shuffle(sub_seq)\n        new_solution[sub_start:sub_end] = sub_seq\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm combines **adaptive Pareto frontier sampling** (prioritizing solutions with high crowding distance) with a **segmented crossover operator** that dynamically blends segments from diverse archive solutions, using a **hybrid objective weighting scheme** to evaluate segment quality while ensuring feasibility through **multi-stage validation**. It balances exploration and exploitation by probabilistically selecting segments from multiple solutions, with segment sizes and positions determined by both objective-aware metrics and spatial proximity in the coordinate spaces.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto frontier sampling with crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    crowding_dist = np.zeros(len(archive))\n\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding_dist[sorted_idx[0]] = np.inf\n        crowding_dist[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive) - 1):\n            crowding_dist[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m] + 1e-10)\n\n    # Select multiple diverse solutions for segment crossover\n    selected_indices = np.argsort(-crowding_dist)[:min(3, len(archive))]\n    base_solution = archive[selected_indices[0]][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Segmented crossover operator\n    if len(selected_indices) > 1:\n        # Select random segments from diverse solutions\n        segment_length = np.random.randint(2, min(4, n // 2))\n        for idx in selected_indices[1:]:\n            donor = archive[idx][0]\n            start = np.random.randint(0, n - segment_length)\n            segment = donor[start:start+segment_length]\n\n            # Find insertion point in new_solution that maintains spatial proximity\n            best_pos = start\n            min_cost = float('inf')\n            for pos in range(n - segment_length + 1):\n                # Evaluate insertion using hybrid objective weights\n                weight1 = 0.5 + 0.3 * (np.std(objectives[:, 0]) / (np.mean(objectives[:, 0]) + 1e-10))\n                weight2 = 0.5 + 0.3 * (np.std(objectives[:, 1]) / (np.mean(objectives[:, 1]) + 1e-10))\n\n                # Calculate cost before and after insertion\n                cost_before = 0\n                cost_after = 0\n                for i in range(pos - 1, pos + segment_length + 1):\n                    i = i % n\n                    j = (i + 1) % n\n                    cost_before += weight1 * distance_matrix_1[new_solution[i], new_solution[j]] + weight2 * distance_matrix_2[new_solution[i], new_solution[j]]\n\n                temp_solution = np.concatenate([new_solution[:pos], segment, new_solution[pos+segment_length:]])\n                for i in range(pos - 1, pos + segment_length + 1):\n                    i = i % n\n                    j = (i + 1) % n\n                    cost_after += weight1 * distance_matrix_1[temp_solution[i], temp_solution[j]] + weight2 * distance_matrix_2[temp_solution[i], temp_solution[j]]\n\n                if cost_after < min_cost:\n                    min_cost = cost_after\n                    best_pos = pos\n\n            new_solution = np.concatenate([new_solution[:best_pos], segment, new_solution[best_pos+segment_length:]])\n\n    # Multi-stage validation\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        # Repair missing nodes by inserting them at positions that minimize cost\n        missing_nodes = np.setdiff1d(np.arange(n), unique_nodes)\n        for node in missing_nodes:\n            best_pos = 0\n            min_cost = float('inf')\n            for pos in range(n + 1):\n                temp_solution = np.insert(new_solution, pos, node)\n                cost = 0\n                for i in range(n):\n                    j = (i + 1) % (n + 1)\n                    cost += distance_matrix_1[temp_solution[i], temp_solution[j]] + distance_matrix_2[temp_solution[i], temp_solution[j]]\n                if cost < min_cost:\n                    min_cost = cost\n                    best_pos = pos\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    # Final validation\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines Pareto-frontier selection with an objective-aware hybrid local search strategy that alternates between merging segments of variable size and conditional node reinsertions, prioritizing the more dominated objective while ensuring feasibility through nearest-neighbor repair. It dynamically adjusts segment size and operation probabilities based on objective balance (larger segments for balanced objectives, smaller targeted reinsertions when one dominates), using adaptive weights (60/40) to guide segment selection. The method maintains feasibility by always checking for missing nodes and repairing with nearest-neighbor insertion when violations occur.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select non-dominated solutions using crowding distance\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(non_dominated):\n        if i == 0:\n            left = non_dominated[-1][1]\n            right = non_dominated[1][1] if len(non_dominated) > 1 else non_dominated[0][1]\n        elif i == len(non_dominated) - 1:\n            left = non_dominated[i-1][1]\n            right = non_dominated[0][1]\n        else:\n            left = non_dominated[i-1][1]\n            right = non_dominated[i+1][1]\n\n        weight_obj1 = 0.6 if obj[0] < obj[1] else 0.4\n        weight_obj2 = 0.6 if obj[1] < obj[0] else 0.4\n        dist = (abs(obj[0] - left[0]) + abs(obj[0] - right[0])) * weight_obj1 + (abs(obj[1] - left[1]) + abs(obj[1] - right[1])) * weight_obj2\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = non_dominated[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Objective-aware segment fusion\n    if n >= 4:\n        # Determine segment size based on objective balance\n        obj1, obj2 = non_dominated[selected_idx][1]\n        if abs(obj1 - obj2) < 0.1 * max(obj1, obj2):  # Objectives balanced\n            seg_size = np.random.randint(2, min(4, n//2))\n        else:  # One objective dominates\n            seg_size = np.random.randint(1, min(3, n//3))\n\n        # Select segments to merge\n        seg1_start = np.random.randint(0, n - seg_size)\n        seg1_end = seg1_start + seg_size\n        seg2_start = np.random.randint(seg1_end, n - seg_size) if seg1_end + seg_size < n else np.random.randint(0, seg1_start)\n        seg2_end = seg2_start + seg_size\n\n        # Merge segments with conditional reinsertion\n        merged = np.concatenate([new_solution[seg1_start:seg1_end], new_solution[seg2_start:seg2_end]])\n        if np.random.random() < 0.6 if obj1 < obj2 else 0.4:  # Higher probability for more dominated objective\n            np.random.shuffle(merged)\n\n        # Reinsert merged segment\n        insert_pos = np.random.randint(0, n - len(merged))\n        if insert_pos >= seg1_start:\n            insert_pos += len(merged)\n        new_solution = np.concatenate([\n            new_solution[:seg1_start],\n            new_solution[seg1_end:seg2_start],\n            new_solution[seg2_end:insert_pos],\n            merged,\n            new_solution[insert_pos:]\n        ])\n\n    # Conditional node reinsertion\n    if np.random.random() < 0.3:\n        node = np.random.randint(0, n)\n        old_pos = np.where(new_solution == node)[0][0]\n        new_pos = np.random.randint(0, n)\n        if new_pos > old_pos:\n            new_pos -= 1\n        new_solution = np.concatenate([\n            new_solution[:old_pos],\n            new_solution[old_pos+1:new_pos+1],\n            [node],\n            new_solution[new_pos+1:]\n        ])\n\n    # Feasibility check and repair\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            best_cost = float('inf')\n            for i in range(n):\n                if i == 0:\n                    cost = distance_matrix_1[new_solution[-1], node] + distance_matrix_1[node, new_solution[0]]\n                    cost += distance_matrix_2[new_solution[-1], node] + distance_matrix_2[node, new_solution[0]]\n                else:\n                    cost = distance_matrix_1[new_solution[i-1], node] + distance_matrix_1[node, new_solution[i]]\n                    cost += distance_matrix_2[new_solution[i-1], node] + distance_matrix_2[node, new_solution[i]]\n                if cost < best_cost:\n                    best_cost = cost\n                    best_pos = i\n            new_solution = np.concatenate([new_solution[:best_pos], [node], new_solution[best_pos:]])\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm combines crowding-distance selection with a hybrid local search that prioritizes improvement in the more crowded objective dimension (70/30 weighting) while using segment inversion and probabilistic cross-dimensional swaps to explore the solution space, dynamically adjusting weights and ensuring feasibility through nearest-neighbor repair. It balances exploitation (segment manipulation) and exploration (cross-dimensional swaps) while maintaining tour validity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest crowding distance\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Dimensional-aware segment inversion\n    a, b = sorted(np.random.choice(n, size=2, replace=False))\n    segment = new_solution[a:b]\n    inverted_segment = segment[::-1]\n\n    # Reinsert inverted segment at a new position\n    insert_pos = np.random.randint(0, n - len(segment))\n    new_solution = np.concatenate([new_solution[:insert_pos], inverted_segment, new_solution[insert_pos:]])\n    new_solution = np.concatenate([new_solution[:n], new_solution[n-len(segment):]])\n\n    # Dynamic weight adjustment (70/30) for objective prioritization\n    weight_1 = 0.7 if archive[selected_idx][1][0] > archive[selected_idx][1][1] else 0.3\n    weight_2 = 1 - weight_1\n\n    # Probabilistic cross-dimensional node swap\n    if np.random.random() < 0.2:\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        old_cost = weight_1 * distance_matrix_1[new_solution[i-1], new_solution[i]] + weight_2 * distance_matrix_2[new_solution[j-1], new_solution[j]]\n        new_cost = weight_1 * distance_matrix_1[new_solution[i-1], new_solution[j]] + weight_2 * distance_matrix_2[new_solution[j-1], new_solution[i]]\n\n        if new_cost < old_cost:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        for i in range(n):\n            if new_solution[i] in new_solution[:i]:\n                nearest = None\n                min_cost = float('inf')\n                for j in range(n):\n                    if j not in new_solution[:i]:\n                        cost = weight_1 * distance_matrix_1[new_solution[i-1], j] + weight_2 * distance_matrix_2[new_solution[i-1], j]\n                        if cost < min_cost:\n                            min_cost = cost\n                            nearest = j\n                new_solution[i] = nearest\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: - **Keywords**: Pareto-dominance, hybrid 4-opt, adaptive edge swaps, crowding distance, dynamic weights, feasibility validation.\n- **Advice**: Select non-dominated solutions via crowding distance, apply 4-opt with 30% edge-swap probability, and dynamically adjust objective weights (70/30) for balanced exploration.\n- **Avoid**: Greedy dominated selection, static 2-opt, or moves that risk duplicate nodes/missing nodes. Use nearest-neighbor repair for infeasible tours.\n- **Explanation**: Hybrid 4-opt with conditional edge swaps explores large neighborhoods, while dynamic weights balance objectives. Feasibility checks ensure valid tours.\n\n**Next Step**: Implement the heuristic with crowding-distance selection and hybrid 4-opt + edge-swap local search.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 303,
        "algorithm": "The algorithm combines Pareto-dominance selection with a hybrid 4-opt local search, using crowding distance to prioritize solutions and dynamic weights (70/30) to balance objectives, while ensuring feasibility through nearest-neighbor repair. It intelligently selects promising solutions from the archive, applies adaptive edge swaps, and maintains tour validity through a nearest-neighbor repair mechanism.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select non-dominated solutions using crowding distance\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(non_dominated):\n        if i == 0:\n            left = non_dominated[-1][1]\n            right = non_dominated[1][1] if len(non_dominated) > 1 else non_dominated[0][1]\n        elif i == len(non_dominated) - 1:\n            left = non_dominated[i-1][1]\n            right = non_dominated[0][1]\n        else:\n            left = non_dominated[i-1][1]\n            right = non_dominated[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = non_dominated[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Dynamic weight adjustment (70/30) for objective prioritization\n    weight_1 = 0.7 if non_dominated[selected_idx][1][0] > non_dominated[selected_idx][1][1] else 0.3\n    weight_2 = 1 - weight_1\n\n    # Hybrid 4-opt with adaptive edge swaps\n    if n >= 4:\n        # Select 4 distinct positions\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n\n        # Evaluate current and potential new configurations\n        current_cost = (weight_1 * distance_matrix_1[new_solution[a-1], new_solution[a]] +\n                        weight_2 * distance_matrix_2[new_solution[a-1], new_solution[a]] +\n                        weight_1 * distance_matrix_1[new_solution[b-1], new_solution[b]] +\n                        weight_2 * distance_matrix_2[new_solution[b-1], new_solution[b]] +\n                        weight_1 * distance_matrix_1[new_solution[c-1], new_solution[c]] +\n                        weight_2 * distance_matrix_2[new_solution[c-1], new_solution[c]] +\n                        weight_1 * distance_matrix_1[new_solution[d-1], new_solution[d]] +\n                        weight_2 * distance_matrix_2[new_solution[d-1], new_solution[d]])\n\n        # Try all possible 4-opt configurations\n        configs = [\n            (a, b, c, d),\n            (a, c, b, d),\n            (a, b, d, c),\n            (a, c, d, b),\n            (a, d, b, c),\n            (a, d, c, b)\n        ]\n\n        best_config = (a, b, c, d)\n        best_cost = current_cost\n\n        for config in configs:\n            a1, b1, c1, d1 = config\n            new_cost = (weight_1 * distance_matrix_1[new_solution[a1-1], new_solution[b1]] +\n                        weight_2 * distance_matrix_2[new_solution[a1-1], new_solution[b1]] +\n                        weight_1 * distance_matrix_1[new_solution[b1-1], new_solution[c1]] +\n                        weight_2 * distance_matrix_2[new_solution[b1-1], new_solution[c1]] +\n                        weight_1 * distance_matrix_1[new_solution[c1-1], new_solution[d1]] +\n                        weight_2 * distance_matrix_2[new_solution[c1-1], new_solution[d1]] +\n                        weight_1 * distance_matrix_1[new_solution[d1-1], new_solution[a1]] +\n                        weight_2 * distance_matrix_2[new_solution[d1-1], new_solution[a1]])\n\n            if new_cost < best_cost:\n                best_cost = new_cost\n                best_config = config\n\n        # Apply the best configuration\n        a1, b1, c1, d1 = best_config\n        new_solution[a1:b1+1] = new_solution[a1:b1+1][::-1]\n        new_solution[b1:c1+1] = new_solution[b1:c1+1][::-1]\n        new_solution[a1:c1+1] = new_solution[a1:c1+1][::-1]\n\n        # Adaptive edge swaps (30% probability)\n        if np.random.random() < 0.3:\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n            old_cost = (weight_1 * distance_matrix_1[new_solution[i-1], new_solution[i]] +\n                        weight_2 * distance_matrix_2[new_solution[j-1], new_solution[j]])\n            new_cost = (weight_1 * distance_matrix_1[new_solution[i-1], new_solution[j]] +\n                        weight_2 * distance_matrix_2[new_solution[j-1], new_solution[i]])\n\n            if new_cost < old_cost:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Feasibility check and repair\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        for i in range(n):\n            if new_solution[i] in new_solution[:i]:\n                nearest = None\n                min_cost = float('inf')\n                for j in range(n):\n                    if j not in new_solution[:i]:\n                        cost = (weight_1 * distance_matrix_1[new_solution[i-1], j] +\n                                weight_2 * distance_matrix_2[new_solution[i-1], j])\n                        if cost < min_cost:\n                            min_cost = cost\n                            nearest = j\n                new_solution[i] = nearest\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7746596912898706,
            0.7795116305351257
        ],
        "raw_score": [
            7.122416963368217,
            6.848133719299543
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select non-dominated solutions using crowding distance\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(non_dominated):\n        if i == 0:\n            left = non_dominated[-1][1]\n            right = non_dominated[1][1] if len(non_dominated) > 1 else non_dominated[0][1]\n        elif i == len(non_dominated) - 1:\n            left = non_dominated[i-1][1]\n            right = non_dominated[0][1]\n        else:\n            left = non_dominated[i-1][1]\n            right = non_dominated[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = non_dominated[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Dynamic weight adjustment (70/30) for objective prioritization\n    weight_1 = 0.7 if non_dominated[selected_idx][1][0] > non_dominated[selected_idx][1][1] else 0.3\n    weight_2 = 1 - weight_1\n\n    # Hybrid 4-opt with adaptive edge swaps\n    if n >= 4:\n        # Select 4 distinct positions\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n\n        # Evaluate current and potential new configurations\n        current_cost = (weight_1 * distance_matrix_1[new_solution[a-1], new_solution[a]] +\n                        weight_2 * distance_matrix_2[new_solution[a-1], new_solution[a]] +\n                        weight_1 * distance_matrix_1[new_solution[b-1], new_solution[b]] +\n                        weight_2 * distance_matrix_2[new_solution[b-1], new_solution[b]] +\n                        weight_1 * distance_matrix_1[new_solution[c-1], new_solution[c]] +\n                        weight_2 * distance_matrix_2[new_solution[c-1], new_solution[c]] +\n                        weight_1 * distance_matrix_1[new_solution[d-1], new_solution[d]] +\n                        weight_2 * distance_matrix_2[new_solution[d-1], new_solution[d]])\n\n        # Try all possible 4-opt configurations\n        configs = [\n            (a, b, c, d),\n            (a, c, b, d),\n            (a, b, d, c),\n            (a, c, d, b),\n            (a, d, b, c),\n            (a, d, c, b)\n        ]\n\n        best_config = (a, b, c, d)\n        best_cost = current_cost\n\n        for config in configs:\n            a1, b1, c1, d1 = config\n            new_cost = (weight_1 * distance_matrix_1[new_solution[a1-1], new_solution[b1]] +\n                        weight_2 * distance_matrix_2[new_solution[a1-1], new_solution[b1]] +\n                        weight_1 * distance_matrix_1[new_solution[b1-1], new_solution[c1]] +\n                        weight_2 * distance_matrix_2[new_solution[b1-1], new_solution[c1]] +\n                        weight_1 * distance_matrix_1[new_solution[c1-1], new_solution[d1]] +\n                        weight_2 * distance_matrix_2[new_solution[c1-1], new_solution[d1]] +\n                        weight_1 * distance_matrix_1[new_solution[d1-1], new_solution[a1]] +\n                        weight_2 * distance_matrix_2[new_solution[d1-1], new_solution[a1]])\n\n            if new_cost < best_cost:\n                best_cost = new_cost\n                best_config = config\n\n        # Apply the best configuration\n        a1, b1, c1, d1 = best_config\n        new_solution[a1:b1+1] = new_solution[a1:b1+1][::-1]\n        new_solution[b1:c1+1] = new_solution[b1:c1+1][::-1]\n        new_solution[a1:c1+1] = new_solution[a1:c1+1][::-1]\n\n        # Adaptive edge swaps (30% probability)\n        if np.random.random() < 0.3:\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n            old_cost = (weight_1 * distance_matrix_1[new_solution[i-1], new_solution[i]] +\n                        weight_2 * distance_matrix_2[new_solution[j-1], new_solution[j]])\n            new_cost = (weight_1 * distance_matrix_1[new_solution[i-1], new_solution[j]] +\n                        weight_2 * distance_matrix_2[new_solution[j-1], new_solution[i]])\n\n            if new_cost < old_cost:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Feasibility check and repair\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        for i in range(n):\n            if new_solution[i] in new_solution[:i]:\n                nearest = None\n                min_cost = float('inf')\n                for j in range(n):\n                    if j not in new_solution[:i]:\n                        cost = (weight_1 * distance_matrix_1[new_solution[i-1], j] +\n                                weight_2 * distance_matrix_2[new_solution[i-1], j])\n                        if cost < min_cost:\n                            min_cost = cost\n                            nearest = j\n                new_solution[i] = nearest\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm combines Pareto-frontier selection with an objective-aware hybrid local search strategy that alternates between merging segments of variable size and conditional node reinsertions, prioritizing the more dominated objective while ensuring feasibility through nearest-neighbor repair. It dynamically adjusts segment size and operation probabilities based on objective balance (larger segments for balanced objectives, smaller targeted reinsertions when one dominates), using adaptive weights (60/40) to guide segment selection. The method maintains feasibility by always checking for missing nodes and repairing with nearest-neighbor insertion when violations occur.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select non-dominated solutions using crowding distance\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(non_dominated):\n        if i == 0:\n            left = non_dominated[-1][1]\n            right = non_dominated[1][1] if len(non_dominated) > 1 else non_dominated[0][1]\n        elif i == len(non_dominated) - 1:\n            left = non_dominated[i-1][1]\n            right = non_dominated[0][1]\n        else:\n            left = non_dominated[i-1][1]\n            right = non_dominated[i+1][1]\n\n        weight_obj1 = 0.6 if obj[0] < obj[1] else 0.4\n        weight_obj2 = 0.6 if obj[1] < obj[0] else 0.4\n        dist = (abs(obj[0] - left[0]) + abs(obj[0] - right[0])) * weight_obj1 + (abs(obj[1] - left[1]) + abs(obj[1] - right[1])) * weight_obj2\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = non_dominated[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Objective-aware segment fusion\n    if n >= 4:\n        # Determine segment size based on objective balance\n        obj1, obj2 = non_dominated[selected_idx][1]\n        if abs(obj1 - obj2) < 0.1 * max(obj1, obj2):  # Objectives balanced\n            seg_size = np.random.randint(2, min(4, n//2))\n        else:  # One objective dominates\n            seg_size = np.random.randint(1, min(3, n//3))\n\n        # Select segments to merge\n        seg1_start = np.random.randint(0, n - seg_size)\n        seg1_end = seg1_start + seg_size\n        seg2_start = np.random.randint(seg1_end, n - seg_size) if seg1_end + seg_size < n else np.random.randint(0, seg1_start)\n        seg2_end = seg2_start + seg_size\n\n        # Merge segments with conditional reinsertion\n        merged = np.concatenate([new_solution[seg1_start:seg1_end], new_solution[seg2_start:seg2_end]])\n        if np.random.random() < 0.6 if obj1 < obj2 else 0.4:  # Higher probability for more dominated objective\n            np.random.shuffle(merged)\n\n        # Reinsert merged segment\n        insert_pos = np.random.randint(0, n - len(merged))\n        if insert_pos >= seg1_start:\n            insert_pos += len(merged)\n        new_solution = np.concatenate([\n            new_solution[:seg1_start],\n            new_solution[seg1_end:seg2_start],\n            new_solution[seg2_end:insert_pos],\n            merged,\n            new_solution[insert_pos:]\n        ])\n\n    # Conditional node reinsertion\n    if np.random.random() < 0.3:\n        node = np.random.randint(0, n)\n        old_pos = np.where(new_solution == node)[0][0]\n        new_pos = np.random.randint(0, n)\n        if new_pos > old_pos:\n            new_pos -= 1\n        new_solution = np.concatenate([\n            new_solution[:old_pos],\n            new_solution[old_pos+1:new_pos+1],\n            [node],\n            new_solution[new_pos+1:]\n        ])\n\n    # Feasibility check and repair\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            best_cost = float('inf')\n            for i in range(n):\n                if i == 0:\n                    cost = distance_matrix_1[new_solution[-1], node] + distance_matrix_1[node, new_solution[0]]\n                    cost += distance_matrix_2[new_solution[-1], node] + distance_matrix_2[node, new_solution[0]]\n                else:\n                    cost = distance_matrix_1[new_solution[i-1], node] + distance_matrix_1[node, new_solution[i]]\n                    cost += distance_matrix_2[new_solution[i-1], node] + distance_matrix_2[node, new_solution[i]]\n                if cost < best_cost:\n                    best_cost = cost\n                    best_pos = i\n            new_solution = np.concatenate([new_solution[:best_pos], [node], new_solution[best_pos:]])\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using crowding distance, applies adaptive segment inversion with dynamic objective weights, and conditionally performs edge swaps (40% probability) to generate neighbors while ensuring feasibility through nearest-neighbor repair. It prioritizes solutions with high crowding distance, dynamically adjusts segment sizes and objective weights, and balances exploration/exploitation while maintaining tour validity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest crowding distance\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment inversion with dynamic weights\n    seg_size = min(4, max(2, int(np.random.normal(3, 1))))\n    seg_start = np.random.randint(0, n - seg_size)\n    segment = new_solution[seg_start:seg_start+seg_size]\n    inverted_segment = segment[::-1]\n\n    # Evaluate original and inverted segments\n    original_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%seg_size]] for i in range(seg_size))\n    inverted_cost1 = sum(distance_matrix_1[inverted_segment[i], inverted_segment[(i+1)%seg_size]] for i in range(seg_size))\n    original_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%seg_size]] for i in range(seg_size))\n    inverted_cost2 = sum(distance_matrix_2[inverted_segment[i], inverted_segment[(i+1)%seg_size]] for i in range(seg_size))\n\n    # Dynamic weights based on crowding distance\n    obj_weights = [0.5, 0.5]\n    if crowding_distances[selected_idx] > np.mean(crowding_distances):\n        obj_weights = [0.7, 0.3] if np.random.random() < 0.5 else [0.3, 0.7]\n\n    original_total = obj_weights[0] * original_cost1 + obj_weights[1] * original_cost2\n    inverted_total = obj_weights[0] * inverted_cost1 + obj_weights[1] * inverted_cost2\n\n    if inverted_total < original_total:\n        new_solution[seg_start:seg_start+seg_size] = inverted_segment\n\n    # Conditional edge swap (40% probability)\n    if np.random.random() < 0.4:\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        while abs(i - j) <= 1:\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n\n        # Swap edges\n        temp = new_solution[i]\n        new_solution[i] = new_solution[j]\n        new_solution[j] = temp\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        visited = set()\n        repaired = []\n        current = new_solution[0]\n        repaired.append(current)\n        visited.add(current)\n\n        for _ in range(n - 1):\n            candidates = [node for node in new_solution if node not in visited]\n            if not candidates:\n                break\n            nearest = min(candidates, key=lambda x: distance_matrix_1[current, x] + distance_matrix_2[current, x])\n            repaired.append(nearest)\n            visited.add(nearest)\n            current = nearest\n\n        if len(repaired) == n:\n            new_solution = np.array(repaired)\n        else:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Pareto-dominance, hybrid 4-opt, adaptive edge swaps, crowding distance, dynamic weights, feasibility validation.\n- **Advice**: Select non-dominated solutions via crowding distance, apply 4-opt with 30% edge-swap probability, and dynamically adjust objective weights (70/30) for balanced exploration.\n- **Avoid**: Greedy dominated selection, static 2-opt, or moves that risk duplicate nodes/missing nodes. Use nearest-neighbor repair for infeasible tours.\n- **Explanation**: Hybrid 4-opt with conditional edge swaps explores large neighborhoods, while dynamic weights balance objectives. Feasibility checks ensure valid tours.\n\n**Next Step**: Implement the heuristic with crowding-distance selection and hybrid 4-opt + edge-swap local search.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 304,
        "algorithm": "The algorithm combines Pareto-dominance filtering with a hybrid local search that alternates between dynamic segment relocations (prioritized for balanced objectives) and adaptive edge crossings (used when one objective dominates), while ensuring feasibility through nearest-neighbor repair. It intelligently selects segments of variable size (2-5 nodes) for relocation, evaluates improvements using weighted objective costs, and conditionally applies edge crossings (30% probability) to explore larger neighborhoods. The method dynamically adjusts operation probabilities (80% relocation vs. 20% crossing) based on objective balance, with higher priority given to solutions with high crowding distance in the non-dominated archive.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select non-dominated solutions using crowding distance\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(non_dominated):\n        if i == 0:\n            left = non_dominated[-1][1]\n            right = non_dominated[1][1] if len(non_dominated) > 1 else non_dominated[0][1]\n        elif i == len(non_dominated) - 1:\n            left = non_dominated[i-1][1]\n            right = non_dominated[0][1]\n        else:\n            left = non_dominated[i-1][1]\n            right = non_dominated[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = non_dominated[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Dynamic segment relocation\n    seg_size = np.random.randint(2, min(5, n//2))\n    seg_start = np.random.randint(0, n - seg_size)\n    segment = new_solution[seg_start:seg_start+seg_size]\n\n    # Evaluate original and relocated segments\n    original_cost1 = distance_matrix_1[new_solution[seg_start-1], new_solution[seg_start]] + distance_matrix_1[new_solution[seg_start+seg_size-1], new_solution[seg_start+seg_size]]\n    original_cost2 = distance_matrix_2[new_solution[seg_start-1], new_solution[seg_start]] + distance_matrix_2[new_solution[seg_start+seg_size-1], new_solution[seg_start+seg_size]]\n\n    best_pos = seg_start\n    best_cost = original_cost1 + original_cost2\n\n    for pos in range(n - seg_size + 1):\n        if pos == seg_start:\n            continue\n        if pos > seg_start:\n            prev = new_solution[pos-1]\n            next_node = new_solution[pos]\n        else:\n            prev = new_solution[pos-1] if pos > 0 else new_solution[-1]\n            next_node = new_solution[pos+seg_size]\n\n        cost1 = distance_matrix_1[prev, segment[0]] + distance_matrix_1[segment[-1], next_node]\n        cost2 = distance_matrix_2[prev, segment[0]] + distance_matrix_2[segment[-1], next_node]\n        total_cost = cost1 + cost2\n\n        if total_cost < best_cost:\n            best_cost = total_cost\n            best_pos = pos\n\n    if best_pos != seg_start:\n        new_solution = np.concatenate([\n            new_solution[:seg_start],\n            new_solution[seg_start+seg_size:best_pos],\n            segment,\n            new_solution[best_pos:]\n        ])\n\n    # Conditional edge crossing (30% probability)\n    if np.random.random() < 0.3:\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        while abs(i - j) <= 1:\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n\n        # Perform edge crossing\n        temp = new_solution[i]\n        new_solution[i] = new_solution[j]\n        new_solution[j] = temp\n\n    # Feasibility check and repair\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        visited = set()\n        repaired = []\n        current = new_solution[0]\n        repaired.append(current)\n        visited.add(current)\n\n        for _ in range(n - 1):\n            candidates = [node for node in new_solution if node not in visited]\n            if not candidates:\n                break\n            nearest = min(candidates, key=lambda x: distance_matrix_1[current, x] + distance_matrix_2[current, x])\n            repaired.append(nearest)\n            visited.add(nearest)\n            current = nearest\n\n        if len(repaired) == n:\n            new_solution = np.array(repaired)\n        else:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9950222293568398,
            0.39545363187789917
        ],
        "raw_score": [
            9.782762386823473,
            9.369078992877537
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select non-dominated solutions using crowding distance\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(non_dominated):\n        if i == 0:\n            left = non_dominated[-1][1]\n            right = non_dominated[1][1] if len(non_dominated) > 1 else non_dominated[0][1]\n        elif i == len(non_dominated) - 1:\n            left = non_dominated[i-1][1]\n            right = non_dominated[0][1]\n        else:\n            left = non_dominated[i-1][1]\n            right = non_dominated[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = non_dominated[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Dynamic segment relocation\n    seg_size = np.random.randint(2, min(5, n//2))\n    seg_start = np.random.randint(0, n - seg_size)\n    segment = new_solution[seg_start:seg_start+seg_size]\n\n    # Evaluate original and relocated segments\n    original_cost1 = distance_matrix_1[new_solution[seg_start-1], new_solution[seg_start]] + distance_matrix_1[new_solution[seg_start+seg_size-1], new_solution[seg_start+seg_size]]\n    original_cost2 = distance_matrix_2[new_solution[seg_start-1], new_solution[seg_start]] + distance_matrix_2[new_solution[seg_start+seg_size-1], new_solution[seg_start+seg_size]]\n\n    best_pos = seg_start\n    best_cost = original_cost1 + original_cost2\n\n    for pos in range(n - seg_size + 1):\n        if pos == seg_start:\n            continue\n        if pos > seg_start:\n            prev = new_solution[pos-1]\n            next_node = new_solution[pos]\n        else:\n            prev = new_solution[pos-1] if pos > 0 else new_solution[-1]\n            next_node = new_solution[pos+seg_size]\n\n        cost1 = distance_matrix_1[prev, segment[0]] + distance_matrix_1[segment[-1], next_node]\n        cost2 = distance_matrix_2[prev, segment[0]] + distance_matrix_2[segment[-1], next_node]\n        total_cost = cost1 + cost2\n\n        if total_cost < best_cost:\n            best_cost = total_cost\n            best_pos = pos\n\n    if best_pos != seg_start:\n        new_solution = np.concatenate([\n            new_solution[:seg_start],\n            new_solution[seg_start+seg_size:best_pos],\n            segment,\n            new_solution[best_pos:]\n        ])\n\n    # Conditional edge crossing (30% probability)\n    if np.random.random() < 0.3:\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        while abs(i - j) <= 1:\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n\n        # Perform edge crossing\n        temp = new_solution[i]\n        new_solution[i] = new_solution[j]\n        new_solution[j] = temp\n\n    # Feasibility check and repair\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        visited = set()\n        repaired = []\n        current = new_solution[0]\n        repaired.append(current)\n        visited.add(current)\n\n        for _ in range(n - 1):\n            candidates = [node for node in new_solution if node not in visited]\n            if not candidates:\n                break\n            nearest = min(candidates, key=lambda x: distance_matrix_1[current, x] + distance_matrix_2[current, x])\n            repaired.append(nearest)\n            visited.add(nearest)\n            current = nearest\n\n        if len(repaired) == n:\n            new_solution = np.array(repaired)\n        else:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using a hybrid objective-diversity score (60% objective, 40% diversity), then applies a multi-segment relocation strategy that considers both objective spaces, with probabilistic segment inversion and adaptive segment merging to explore the solution space effectively. It prioritizes balanced exploration of both objectives (50% weight each) and uses segment-based operations to avoid standard 2-opt limitations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection mechanism combining objective values and solution diversity\n    objective_scores = np.array([(obj[0] + obj[1]) / (np.sum(distance_matrix_1) + np.sum(distance_matrix_2) + 1e-10)\n                                for _, obj in archive])\n    diversity_scores = np.array([np.sum(np.abs(np.diff(sol))) / len(sol) for sol, _ in archive])\n    combined_scores = 0.6 * objective_scores + 0.4 * diversity_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(base_solution)\n\n    # Multi-segment relocation strategy\n    if n >= 6:\n        segment_lengths = np.random.choice([2, 3], size=2)\n        start_positions = sorted(np.random.choice(n, size=2, replace=False))\n        segments = [new_solution[start_positions[i]:start_positions[i]+segment_lengths[i]] for i in range(2)]\n\n        # Evaluate insertion points considering both objectives\n        best_positions = []\n        for seg_idx, segment in enumerate(segments):\n            best_pos = -1\n            best_cost = float('inf')\n            for pos in range(n - len(segment) + 1):\n                if any(pos <= start_positions[i] < pos + len(segment) for i in range(2)):\n                    continue\n\n                temp_sol = new_solution.copy()\n                temp_sol = np.concatenate([\n                    temp_sol[:pos],\n                    segment,\n                    np.delete(temp_sol, [start_positions[seg_idx] + i for i in range(len(segment))])\n                ])\n\n                cost1 = sum(distance_matrix_1[temp_sol[i], temp_sol[(i+1)%n]] for i in range(n))\n                cost2 = sum(distance_matrix_2[temp_sol[i], temp_sol[(i+1)%n]] for i in range(n))\n                weighted_cost = 0.5 * cost1 + 0.5 * cost2\n\n                if weighted_cost < best_cost:\n                    best_cost = weighted_cost\n                    best_pos = pos\n            best_positions.append(best_pos if best_pos != -1 else np.random.randint(0, n - len(segment) + 1))\n\n        # Apply the best found insertions\n        for seg_idx, segment in enumerate(segments):\n            pos = best_positions[seg_idx]\n            new_solution = np.concatenate([\n                new_solution[:pos],\n                segment,\n                np.delete(new_solution, [start_positions[seg_idx] + i for i in range(len(segment))])\n            ])\n\n    # Adaptive segment merging with probabilistic inversion\n    if n >= 4 and np.random.random() < 0.4:\n        merge_points = sorted(np.random.choice(n, size=2, replace=False))\n        a, b = merge_points\n        segment1 = new_solution[:a]\n        segment2 = new_solution[a:b]\n        segment3 = new_solution[b:]\n\n        # Evaluate merging options\n        options = [\n            np.concatenate([segment1, segment2, segment3]),  # Original\n            np.concatenate([segment1, segment3, segment2]),  # Swap middle segments\n            np.concatenate([segment2, segment1, segment3]),  # Rotate\n            np.concatenate([segment3, segment1, segment2])   # Reverse rotate\n        ]\n\n        # Evaluate each option\n        best_option = options[0]\n        best_cost = float('inf')\n        for option in options:\n            cost1 = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n))\n            cost2 = sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            total_cost = 0.5 * cost1 + 0.5 * cost2\n\n            if total_cost < best_cost:\n                best_cost = total_cost\n                best_option = option\n\n        new_solution = best_option\n\n    # Final probabilistic inversion for diversity\n    if np.random.random() < 0.3:\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        new_solution[a:b] = new_solution[a:b][::-1]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive using crowding distance, applies adaptive segment inversion with dynamic objective weights, and conditionally performs edge swaps (40% probability) to generate neighbors while ensuring feasibility through nearest-neighbor repair. It prioritizes solutions with high crowding distance, dynamically adjusts segment sizes and objective weights, and balances exploration/exploitation while maintaining tour validity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest crowding distance\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment inversion with dynamic weights\n    seg_size = min(4, max(2, int(np.random.normal(3, 1))))\n    seg_start = np.random.randint(0, n - seg_size)\n    segment = new_solution[seg_start:seg_start+seg_size]\n    inverted_segment = segment[::-1]\n\n    # Evaluate original and inverted segments\n    original_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%seg_size]] for i in range(seg_size))\n    inverted_cost1 = sum(distance_matrix_1[inverted_segment[i], inverted_segment[(i+1)%seg_size]] for i in range(seg_size))\n    original_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%seg_size]] for i in range(seg_size))\n    inverted_cost2 = sum(distance_matrix_2[inverted_segment[i], inverted_segment[(i+1)%seg_size]] for i in range(seg_size))\n\n    # Dynamic weights based on crowding distance\n    obj_weights = [0.5, 0.5]\n    if crowding_distances[selected_idx] > np.mean(crowding_distances):\n        obj_weights = [0.7, 0.3] if np.random.random() < 0.5 else [0.3, 0.7]\n\n    original_total = obj_weights[0] * original_cost1 + obj_weights[1] * original_cost2\n    inverted_total = obj_weights[0] * inverted_cost1 + obj_weights[1] * inverted_cost2\n\n    if inverted_total < original_total:\n        new_solution[seg_start:seg_start+seg_size] = inverted_segment\n\n    # Conditional edge swap (40% probability)\n    if np.random.random() < 0.4:\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        while abs(i - j) <= 1:\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n\n        # Swap edges\n        temp = new_solution[i]\n        new_solution[i] = new_solution[j]\n        new_solution[j] = temp\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        visited = set()\n        repaired = []\n        current = new_solution[0]\n        repaired.append(current)\n        visited.add(current)\n\n        for _ in range(n - 1):\n            candidates = [node for node in new_solution if node not in visited]\n            if not candidates:\n                break\n            nearest = min(candidates, key=lambda x: distance_matrix_1[current, x] + distance_matrix_2[current, x])\n            repaired.append(nearest)\n            visited.add(nearest)\n            current = nearest\n\n        if len(repaired) == n:\n            new_solution = np.array(repaired)\n        else:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Pareto-dominance, hybrid 4-opt, adaptive edge swaps, crowding distance, dynamic weights, feasibility validation.\n- **Advice**: Select non-dominated solutions via crowding distance, apply 4-opt with 30% edge-swap probability, and dynamically adjust objective weights (70/30) for balanced exploration.\n- **Avoid**: Greedy dominated selection, static 2-opt, or moves that risk duplicate nodes/missing nodes. Use nearest-neighbor repair for infeasible tours.\n- **Explanation**: Hybrid 4-opt with conditional edge swaps explores large neighborhoods, while dynamic weights balance objectives. Feasibility checks ensure valid tours.\n\n**Next Step**: Implement the heuristic with crowding-distance selection and hybrid 4-opt + edge-swap local search.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 305,
        "algorithm": "The algorithm combines crowding-distance selection of non-dominated solutions with a hybrid 4-opt local search that adaptively balances exploration of different objectives (70/30 weight split) and includes edge swaps (30% probability), while ensuring feasibility through nearest-neighbor repair. It prioritizes large-scale neighborhood exploration and dynamically adjusts objective weights to escape local optima, avoiding static 2-opt and dominated selection strategies.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest crowding distance (non-dominated)\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid 4-opt with adaptive edge swaps (30% probability)\n    if n >= 4:\n        # Select 4 distinct positions\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n        segment1 = new_solution[:a]\n        segment2 = new_solution[a:b]\n        segment3 = new_solution[b:c]\n        segment4 = new_solution[c:d]\n        segment5 = new_solution[d:]\n\n        # Generate 3 possible 4-opt moves\n        options = [\n            np.concatenate([segment1, segment2, segment3, segment4, segment5]),  # Original\n            np.concatenate([segment1, segment3, segment2, segment4, segment5]),  # Swap segments 2 and 3\n            np.concatenate([segment1, segment2, segment4, segment3, segment5])    # Swap segments 3 and 4\n        ]\n\n        # Evaluate each option with dynamic weights\n        obj_weights = [0.7, 0.3] if np.random.random() < 0.5 else [0.3, 0.7]\n        best_option = options[0]\n        best_cost = float('inf')\n\n        for option in options:\n            cost1 = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n))\n            cost2 = sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            total_cost = obj_weights[0] * cost1 + obj_weights[1] * cost2\n\n            if total_cost < best_cost:\n                best_cost = total_cost\n                best_option = option\n\n        new_solution = best_option\n\n        # Adaptive edge swap (30% probability)\n        if np.random.random() < 0.3:\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n            while abs(i - j) <= 1:\n                i, j = sorted(np.random.choice(n, size=2, replace=False))\n\n            # Swap edges\n            temp = new_solution[i]\n            new_solution[i] = new_solution[j]\n            new_solution[j] = temp\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        visited = set()\n        repaired = []\n        current = new_solution[0]\n        repaired.append(current)\n        visited.add(current)\n\n        for _ in range(n - 1):\n            candidates = [node for node in new_solution if node not in visited]\n            if not candidates:\n                break\n            nearest = min(candidates, key=lambda x: distance_matrix_1[current, x] + distance_matrix_2[current, x])\n            repaired.append(nearest)\n            visited.add(nearest)\n            current = nearest\n\n        if len(repaired) == n:\n            new_solution = np.array(repaired)\n        else:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7895037838286239,
            0.9990876317024231
        ],
        "raw_score": [
            7.84869063723878,
            7.61575380989972
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest crowding distance (non-dominated)\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid 4-opt with adaptive edge swaps (30% probability)\n    if n >= 4:\n        # Select 4 distinct positions\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n        segment1 = new_solution[:a]\n        segment2 = new_solution[a:b]\n        segment3 = new_solution[b:c]\n        segment4 = new_solution[c:d]\n        segment5 = new_solution[d:]\n\n        # Generate 3 possible 4-opt moves\n        options = [\n            np.concatenate([segment1, segment2, segment3, segment4, segment5]),  # Original\n            np.concatenate([segment1, segment3, segment2, segment4, segment5]),  # Swap segments 2 and 3\n            np.concatenate([segment1, segment2, segment4, segment3, segment5])    # Swap segments 3 and 4\n        ]\n\n        # Evaluate each option with dynamic weights\n        obj_weights = [0.7, 0.3] if np.random.random() < 0.5 else [0.3, 0.7]\n        best_option = options[0]\n        best_cost = float('inf')\n\n        for option in options:\n            cost1 = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n))\n            cost2 = sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            total_cost = obj_weights[0] * cost1 + obj_weights[1] * cost2\n\n            if total_cost < best_cost:\n                best_cost = total_cost\n                best_option = option\n\n        new_solution = best_option\n\n        # Adaptive edge swap (30% probability)\n        if np.random.random() < 0.3:\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n            while abs(i - j) <= 1:\n                i, j = sorted(np.random.choice(n, size=2, replace=False))\n\n            # Swap edges\n            temp = new_solution[i]\n            new_solution[i] = new_solution[j]\n            new_solution[j] = temp\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        visited = set()\n        repaired = []\n        current = new_solution[0]\n        repaired.append(current)\n        visited.add(current)\n\n        for _ in range(n - 1):\n            candidates = [node for node in new_solution if node not in visited]\n            if not candidates:\n                break\n            nearest = min(candidates, key=lambda x: distance_matrix_1[current, x] + distance_matrix_2[current, x])\n            repaired.append(nearest)\n            visited.add(nearest)\n            current = nearest\n\n        if len(repaired) == n:\n            new_solution = np.array(repaired)\n        else:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using crowding distance, applies adaptive segment inversion with dynamic objective weights, and conditionally performs edge swaps (40% probability) to generate neighbors while ensuring feasibility through nearest-neighbor repair. It prioritizes solutions with high crowding distance, dynamically adjusts segment sizes and objective weights, and balances exploration/exploitation while maintaining tour validity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest crowding distance\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment inversion with dynamic weights\n    seg_size = min(4, max(2, int(np.random.normal(3, 1))))\n    seg_start = np.random.randint(0, n - seg_size)\n    segment = new_solution[seg_start:seg_start+seg_size]\n    inverted_segment = segment[::-1]\n\n    # Evaluate original and inverted segments\n    original_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%seg_size]] for i in range(seg_size))\n    inverted_cost1 = sum(distance_matrix_1[inverted_segment[i], inverted_segment[(i+1)%seg_size]] for i in range(seg_size))\n    original_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%seg_size]] for i in range(seg_size))\n    inverted_cost2 = sum(distance_matrix_2[inverted_segment[i], inverted_segment[(i+1)%seg_size]] for i in range(seg_size))\n\n    # Dynamic weights based on crowding distance\n    obj_weights = [0.5, 0.5]\n    if crowding_distances[selected_idx] > np.mean(crowding_distances):\n        obj_weights = [0.7, 0.3] if np.random.random() < 0.5 else [0.3, 0.7]\n\n    original_total = obj_weights[0] * original_cost1 + obj_weights[1] * original_cost2\n    inverted_total = obj_weights[0] * inverted_cost1 + obj_weights[1] * inverted_cost2\n\n    if inverted_total < original_total:\n        new_solution[seg_start:seg_start+seg_size] = inverted_segment\n\n    # Conditional edge swap (40% probability)\n    if np.random.random() < 0.4:\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        while abs(i - j) <= 1:\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n\n        # Swap edges\n        temp = new_solution[i]\n        new_solution[i] = new_solution[j]\n        new_solution[j] = temp\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        visited = set()\n        repaired = []\n        current = new_solution[0]\n        repaired.append(current)\n        visited.add(current)\n\n        for _ in range(n - 1):\n            candidates = [node for node in new_solution if node not in visited]\n            if not candidates:\n                break\n            nearest = min(candidates, key=lambda x: distance_matrix_1[current, x] + distance_matrix_2[current, x])\n            repaired.append(nearest)\n            visited.add(nearest)\n            current = nearest\n\n        if len(repaired) == n:\n            new_solution = np.array(repaired)\n        else:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 306,
        "algorithm": "The algorithm selects a promising solution from an archive using a hybrid of dominance rank and crowding distance, then applies a novel multi-segment inversion operator with adaptive objective weighting, followed by conditional guided edge insertion, ensuring feasibility through nearest-neighbor repair. It dynamically adjusts segment sizes based on solution quality and balances exploration/exploitation through probabilistic segment selection and guided edge operations. The method prioritizes solutions with better combined dominance and crowding scores, with higher weights given to crowding distance (40%) than dominance (60%) in selection.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection using dominance rank and crowding distance\n    dominance_scores = []\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        # Dominance rank (simplified)\n        dominated_count = sum(1 for (_, other_obj) in archive if (other_obj[0] < obj[0] and other_obj[1] < obj[1]) or (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]))\n        non_dominated_count = sum(1 for (_, other_obj) in archive if (obj[0] < other_obj[0] and obj[1] < other_obj[1]) or (obj[0] <= other_obj[0] and obj[1] < other_obj[1]) or (obj[0] < other_obj[0] and obj[1] <= other_obj[1]))\n\n        # Crowding distance\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n\n        dominance_scores.append(dominated_count - non_dominated_count)\n        crowding_distances.append(dist)\n\n    # Normalize scores\n    norm_dominance = (np.array(dominance_scores) - np.min(dominance_scores)) / (np.max(dominance_scores) - np.min(dominance_scores) + 1e-10)\n    norm_crowding = (np.array(crowding_distances) - np.min(crowding_distances)) / (np.max(crowding_distances) - np.min(crowding_distances) + 1e-10)\n\n    # Combined score\n    combined_scores = 0.6 * norm_dominance + 0.4 * norm_crowding\n    selected_idx = np.argmax(combined_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Novel multi-segment inversion with adaptive weights\n    num_segments = min(3, max(1, int(np.random.normal(2, 0.5))))\n    segment_sizes = np.random.choice([2, 3, 4], size=num_segments, p=[0.3, 0.5, 0.2])\n\n    # Calculate solution quality\n    sol_quality = 1 - (combined_scores[selected_idx] - np.min(combined_scores)) / (np.max(combined_scores) - np.min(combined_scores) + 1e-10)\n    segment_sizes = [int(s * (0.7 + 0.3 * sol_quality)) for s in segment_sizes]\n\n    # Apply multi-segment inversion\n    for seg_size in segment_sizes:\n        seg_size = min(seg_size, n - 1)\n        seg_start = np.random.randint(0, n - seg_size)\n        segment = new_solution[seg_start:seg_start+seg_size]\n        inverted_segment = segment[::-1]\n\n        # Evaluate original and inverted segments\n        original_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%seg_size]] for i in range(seg_size))\n        inverted_cost1 = sum(distance_matrix_1[inverted_segment[i], inverted_segment[(i+1)%seg_size]] for i in range(seg_size))\n        original_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%seg_size]] for i in range(seg_size))\n        inverted_cost2 = sum(distance_matrix_2[inverted_segment[i], inverted_segment[(i+1)%seg_size]] for i in range(seg_size))\n\n        # Adaptive weights based on solution quality\n        obj_weights = [0.5, 0.5] if sol_quality < 0.5 else [0.7, 0.3] if np.random.random() < 0.5 else [0.3, 0.7]\n\n        original_total = obj_weights[0] * original_cost1 + obj_weights[1] * original_cost2\n        inverted_total = obj_weights[0] * inverted_cost1 + obj_weights[1] * inverted_cost2\n\n        if inverted_total < original_total:\n            new_solution[seg_start:seg_start+seg_size] = inverted_segment\n\n    # Conditional guided edge insertion (30% probability)\n    if np.random.random() < 0.3:\n        # Select a node to insert\n        insert_node = np.random.choice(new_solution)\n        insert_pos = np.where(new_solution == insert_node)[0][0]\n\n        # Find best insertion position based on both objectives\n        best_pos = insert_pos\n        best_cost = float('inf')\n\n        for pos in range(n):\n            if pos == insert_pos:\n                continue\n\n            # Calculate cost of inserting at this position\n            prev_node = new_solution[pos-1] if pos > 0 else new_solution[-1]\n            next_node = new_solution[pos]\n\n            cost1 = distance_matrix_1[prev_node, insert_node] + distance_matrix_1[insert_node, next_node] - distance_matrix_1[prev_node, next_node]\n            cost2 = distance_matrix_2[prev_node, insert_node] + distance_matrix_2[insert_node, next_node] - distance_matrix_2[prev_node, next_node]\n\n            total_cost = obj_weights[0] * cost1 + obj_weights[1] * cost2\n\n            if total_cost < best_cost:\n                best_cost = total_cost\n                best_pos = pos\n\n        # Perform insertion\n        if best_pos != insert_pos:\n            new_solution = np.concatenate([\n                new_solution[:best_pos],\n                np.array([insert_node]),\n                new_solution[best_pos:insert_pos] if insert_pos > best_pos else new_solution[insert_pos+1:best_pos],\n                new_solution[insert_pos+1:] if insert_pos > best_pos else new_solution[best_pos:]\n            ])\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        visited = set()\n        repaired = []\n        current = new_solution[0]\n        repaired.append(current)\n        visited.add(current)\n\n        for _ in range(n - 1):\n            candidates = [node for node in new_solution if node not in visited]\n            if not candidates:\n                break\n            nearest = min(candidates, key=lambda x: distance_matrix_1[current, x] + distance_matrix_2[current, x])\n            repaired.append(nearest)\n            visited.add(nearest)\n            current = nearest\n\n        if len(repaired) == n:\n            new_solution = np.array(repaired)\n        else:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9424527162576635,
            8.984869956970215
        ],
        "raw_score": [
            10.518712800477388,
            10.634912926890957
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection using dominance rank and crowding distance\n    dominance_scores = []\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        # Dominance rank (simplified)\n        dominated_count = sum(1 for (_, other_obj) in archive if (other_obj[0] < obj[0] and other_obj[1] < obj[1]) or (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]))\n        non_dominated_count = sum(1 for (_, other_obj) in archive if (obj[0] < other_obj[0] and obj[1] < other_obj[1]) or (obj[0] <= other_obj[0] and obj[1] < other_obj[1]) or (obj[0] < other_obj[0] and obj[1] <= other_obj[1]))\n\n        # Crowding distance\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n\n        dominance_scores.append(dominated_count - non_dominated_count)\n        crowding_distances.append(dist)\n\n    # Normalize scores\n    norm_dominance = (np.array(dominance_scores) - np.min(dominance_scores)) / (np.max(dominance_scores) - np.min(dominance_scores) + 1e-10)\n    norm_crowding = (np.array(crowding_distances) - np.min(crowding_distances)) / (np.max(crowding_distances) - np.min(crowding_distances) + 1e-10)\n\n    # Combined score\n    combined_scores = 0.6 * norm_dominance + 0.4 * norm_crowding\n    selected_idx = np.argmax(combined_scores)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Novel multi-segment inversion with adaptive weights\n    num_segments = min(3, max(1, int(np.random.normal(2, 0.5))))\n    segment_sizes = np.random.choice([2, 3, 4], size=num_segments, p=[0.3, 0.5, 0.2])\n\n    # Calculate solution quality\n    sol_quality = 1 - (combined_scores[selected_idx] - np.min(combined_scores)) / (np.max(combined_scores) - np.min(combined_scores) + 1e-10)\n    segment_sizes = [int(s * (0.7 + 0.3 * sol_quality)) for s in segment_sizes]\n\n    # Apply multi-segment inversion\n    for seg_size in segment_sizes:\n        seg_size = min(seg_size, n - 1)\n        seg_start = np.random.randint(0, n - seg_size)\n        segment = new_solution[seg_start:seg_start+seg_size]\n        inverted_segment = segment[::-1]\n\n        # Evaluate original and inverted segments\n        original_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%seg_size]] for i in range(seg_size))\n        inverted_cost1 = sum(distance_matrix_1[inverted_segment[i], inverted_segment[(i+1)%seg_size]] for i in range(seg_size))\n        original_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%seg_size]] for i in range(seg_size))\n        inverted_cost2 = sum(distance_matrix_2[inverted_segment[i], inverted_segment[(i+1)%seg_size]] for i in range(seg_size))\n\n        # Adaptive weights based on solution quality\n        obj_weights = [0.5, 0.5] if sol_quality < 0.5 else [0.7, 0.3] if np.random.random() < 0.5 else [0.3, 0.7]\n\n        original_total = obj_weights[0] * original_cost1 + obj_weights[1] * original_cost2\n        inverted_total = obj_weights[0] * inverted_cost1 + obj_weights[1] * inverted_cost2\n\n        if inverted_total < original_total:\n            new_solution[seg_start:seg_start+seg_size] = inverted_segment\n\n    # Conditional guided edge insertion (30% probability)\n    if np.random.random() < 0.3:\n        # Select a node to insert\n        insert_node = np.random.choice(new_solution)\n        insert_pos = np.where(new_solution == insert_node)[0][0]\n\n        # Find best insertion position based on both objectives\n        best_pos = insert_pos\n        best_cost = float('inf')\n\n        for pos in range(n):\n            if pos == insert_pos:\n                continue\n\n            # Calculate cost of inserting at this position\n            prev_node = new_solution[pos-1] if pos > 0 else new_solution[-1]\n            next_node = new_solution[pos]\n\n            cost1 = distance_matrix_1[prev_node, insert_node] + distance_matrix_1[insert_node, next_node] - distance_matrix_1[prev_node, next_node]\n            cost2 = distance_matrix_2[prev_node, insert_node] + distance_matrix_2[insert_node, next_node] - distance_matrix_2[prev_node, next_node]\n\n            total_cost = obj_weights[0] * cost1 + obj_weights[1] * cost2\n\n            if total_cost < best_cost:\n                best_cost = total_cost\n                best_pos = pos\n\n        # Perform insertion\n        if best_pos != insert_pos:\n            new_solution = np.concatenate([\n                new_solution[:best_pos],\n                np.array([insert_node]),\n                new_solution[best_pos:insert_pos] if insert_pos > best_pos else new_solution[insert_pos+1:best_pos],\n                new_solution[insert_pos+1:] if insert_pos > best_pos else new_solution[best_pos:]\n            ])\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        visited = set()\n        repaired = []\n        current = new_solution[0]\n        repaired.append(current)\n        visited.add(current)\n\n        for _ in range(n - 1):\n            candidates = [node for node in new_solution if node not in visited]\n            if not candidates:\n                break\n            nearest = min(candidates, key=lambda x: distance_matrix_1[current, x] + distance_matrix_2[current, x])\n            repaired.append(nearest)\n            visited.add(nearest)\n            current = nearest\n\n        if len(repaired) == n:\n            new_solution = np.array(repaired)\n        else:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects a promising solution from the archive using crowding distance, applies adaptive segment inversion with dynamic objective weights, and conditionally performs edge swaps (40% probability) to generate neighbors while ensuring feasibility through nearest-neighbor repair. It prioritizes solutions with high crowding distance, dynamically adjusts segment sizes and objective weights, and balances exploration/exploitation while maintaining tour validity.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest crowding distance\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment inversion with dynamic weights\n    seg_size = min(4, max(2, int(np.random.normal(3, 1))))\n    seg_start = np.random.randint(0, n - seg_size)\n    segment = new_solution[seg_start:seg_start+seg_size]\n    inverted_segment = segment[::-1]\n\n    # Evaluate original and inverted segments\n    original_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%seg_size]] for i in range(seg_size))\n    inverted_cost1 = sum(distance_matrix_1[inverted_segment[i], inverted_segment[(i+1)%seg_size]] for i in range(seg_size))\n    original_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%seg_size]] for i in range(seg_size))\n    inverted_cost2 = sum(distance_matrix_2[inverted_segment[i], inverted_segment[(i+1)%seg_size]] for i in range(seg_size))\n\n    # Dynamic weights based on crowding distance\n    obj_weights = [0.5, 0.5]\n    if crowding_distances[selected_idx] > np.mean(crowding_distances):\n        obj_weights = [0.7, 0.3] if np.random.random() < 0.5 else [0.3, 0.7]\n\n    original_total = obj_weights[0] * original_cost1 + obj_weights[1] * original_cost2\n    inverted_total = obj_weights[0] * inverted_cost1 + obj_weights[1] * inverted_cost2\n\n    if inverted_total < original_total:\n        new_solution[seg_start:seg_start+seg_size] = inverted_segment\n\n    # Conditional edge swap (40% probability)\n    if np.random.random() < 0.4:\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        while abs(i - j) <= 1:\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n\n        # Swap edges\n        temp = new_solution[i]\n        new_solution[i] = new_solution[j]\n        new_solution[j] = temp\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        visited = set()\n        repaired = []\n        current = new_solution[0]\n        repaired.append(current)\n        visited.add(current)\n\n        for _ in range(n - 1):\n            candidates = [node for node in new_solution if node not in visited]\n            if not candidates:\n                break\n            nearest = min(candidates, key=lambda x: distance_matrix_1[current, x] + distance_matrix_2[current, x])\n            repaired.append(nearest)\n            visited.add(nearest)\n            current = nearest\n\n        if len(repaired) == n:\n            new_solution = np.array(repaired)\n        else:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 307,
        "algorithm": "This algorithm selects a high-quality solution from the archive using dominance rank and crowding distance, then applies a hybrid local search combining adaptive segment relocation and edge swaps, with dynamic objective weighting and nearest-neighbor repair to ensure feasibility. It prioritizes solutions with better dominance and lower crowding, uses variable segment sizes for relocation, and conditionally applies edge swaps based on objective weights, while repairing invalid tours through a nearest-neighbor heuristic.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest dominance rank and lowest crowding distance\n    dominance_ranks = []\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        # Calculate dominance rank\n        rank = sum(1 for (_, other_obj) in archive if (other_obj[0] < obj[0] and other_obj[1] < obj[1]))\n        dominance_ranks.append(rank)\n\n        # Calculate crowding distance\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    # Select solution with lowest rank and lowest crowding distance\n    selected_idx = np.argmin([rank + 0.1 * dist for rank, dist in zip(dominance_ranks, crowding_distances)])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search operator\n    # Segment relocation with adaptive size\n    seg_size = min(5, max(2, int(np.random.normal(4, 1.5))))\n    seg_start = np.random.randint(0, n - seg_size)\n    seg_end = seg_start + seg_size\n    segment = new_solution[seg_start:seg_end]\n\n    # Find optimal insertion point\n    best_pos = seg_start\n    best_cost = float('inf')\n\n    for pos in range(n - seg_size + 1):\n        if pos == seg_start:\n            continue\n\n        # Temporarily move segment\n        temp_solution = np.concatenate([\n            new_solution[:seg_start],\n            new_solution[seg_end:pos],\n            segment,\n            new_solution[pos:]\n        ])\n\n        # Calculate costs\n        cost1 = sum(distance_matrix_1[temp_solution[i], temp_solution[i+1]] for i in range(n-1)) + distance_matrix_1[temp_solution[-1], temp_solution[0]]\n        cost2 = sum(distance_matrix_2[temp_solution[i], temp_solution[i+1]] for i in range(n-1)) + distance_matrix_2[temp_solution[-1], temp_solution[0]]\n\n        # Dynamic weights based on solution diversity\n        obj_weights = [0.6, 0.4] if np.random.random() < 0.6 else [0.4, 0.6]\n        total_cost = obj_weights[0] * cost1 + obj_weights[1] * cost2\n\n        if total_cost < best_cost:\n            best_cost = total_cost\n            best_pos = pos\n\n    # Apply the best relocation\n    if best_pos != seg_start:\n        new_solution = np.concatenate([\n            new_solution[:seg_start],\n            new_solution[seg_end:best_pos],\n            segment,\n            new_solution[best_pos:]\n        ])\n\n    # Adaptive edge swaps (60% probability)\n    if np.random.random() < 0.6:\n        # Select edges based on objective weights\n        obj_weights = [0.7, 0.3] if np.random.random() < 0.5 else [0.3, 0.7]\n\n        # Find edges with high potential for improvement\n        edge_scores = []\n        for i in range(n):\n            j = (i + 1) % n\n            cost1 = distance_matrix_1[new_solution[i], new_solution[j]]\n            cost2 = distance_matrix_2[new_solution[i], new_solution[j]]\n            score = obj_weights[0] * cost1 + obj_weights[1] * cost2\n            edge_scores.append(score)\n\n        # Select top 20% edges to consider for swapping\n        threshold = np.percentile(edge_scores, 80)\n        candidate_edges = [i for i, score in enumerate(edge_scores) if score > threshold]\n\n        if len(candidate_edges) >= 2:\n            i, j = np.random.choice(candidate_edges, size=2, replace=False)\n            # Perform 2-opt swap\n            if i > j:\n                i, j = j, i\n            new_solution[i+1:j+1] = new_solution[i+1:j+1][::-1]\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        visited = set()\n        repaired = []\n        current = new_solution[0]\n        repaired.append(current)\n        visited.add(current)\n\n        for _ in range(n - 1):\n            candidates = [node for node in new_solution if node not in visited]\n            if not candidates:\n                break\n            nearest = min(candidates, key=lambda x: distance_matrix_1[current, x] + distance_matrix_2[current, x])\n            repaired.append(nearest)\n            visited.add(nearest)\n            current = nearest\n\n        if len(repaired) == n:\n            new_solution = np.array(repaired)\n        else:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.6007119461245519,
            1.2634090185165405
        ],
        "raw_score": [
            6.891831146807202,
            7.370455209842935
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest dominance rank and lowest crowding distance\n    dominance_ranks = []\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        # Calculate dominance rank\n        rank = sum(1 for (_, other_obj) in archive if (other_obj[0] < obj[0] and other_obj[1] < obj[1]))\n        dominance_ranks.append(rank)\n\n        # Calculate crowding distance\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    # Select solution with lowest rank and lowest crowding distance\n    selected_idx = np.argmin([rank + 0.1 * dist for rank, dist in zip(dominance_ranks, crowding_distances)])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search operator\n    # Segment relocation with adaptive size\n    seg_size = min(5, max(2, int(np.random.normal(4, 1.5))))\n    seg_start = np.random.randint(0, n - seg_size)\n    seg_end = seg_start + seg_size\n    segment = new_solution[seg_start:seg_end]\n\n    # Find optimal insertion point\n    best_pos = seg_start\n    best_cost = float('inf')\n\n    for pos in range(n - seg_size + 1):\n        if pos == seg_start:\n            continue\n\n        # Temporarily move segment\n        temp_solution = np.concatenate([\n            new_solution[:seg_start],\n            new_solution[seg_end:pos],\n            segment,\n            new_solution[pos:]\n        ])\n\n        # Calculate costs\n        cost1 = sum(distance_matrix_1[temp_solution[i], temp_solution[i+1]] for i in range(n-1)) + distance_matrix_1[temp_solution[-1], temp_solution[0]]\n        cost2 = sum(distance_matrix_2[temp_solution[i], temp_solution[i+1]] for i in range(n-1)) + distance_matrix_2[temp_solution[-1], temp_solution[0]]\n\n        # Dynamic weights based on solution diversity\n        obj_weights = [0.6, 0.4] if np.random.random() < 0.6 else [0.4, 0.6]\n        total_cost = obj_weights[0] * cost1 + obj_weights[1] * cost2\n\n        if total_cost < best_cost:\n            best_cost = total_cost\n            best_pos = pos\n\n    # Apply the best relocation\n    if best_pos != seg_start:\n        new_solution = np.concatenate([\n            new_solution[:seg_start],\n            new_solution[seg_end:best_pos],\n            segment,\n            new_solution[best_pos:]\n        ])\n\n    # Adaptive edge swaps (60% probability)\n    if np.random.random() < 0.6:\n        # Select edges based on objective weights\n        obj_weights = [0.7, 0.3] if np.random.random() < 0.5 else [0.3, 0.7]\n\n        # Find edges with high potential for improvement\n        edge_scores = []\n        for i in range(n):\n            j = (i + 1) % n\n            cost1 = distance_matrix_1[new_solution[i], new_solution[j]]\n            cost2 = distance_matrix_2[new_solution[i], new_solution[j]]\n            score = obj_weights[0] * cost1 + obj_weights[1] * cost2\n            edge_scores.append(score)\n\n        # Select top 20% edges to consider for swapping\n        threshold = np.percentile(edge_scores, 80)\n        candidate_edges = [i for i, score in enumerate(edge_scores) if score > threshold]\n\n        if len(candidate_edges) >= 2:\n            i, j = np.random.choice(candidate_edges, size=2, replace=False)\n            # Perform 2-opt swap\n            if i > j:\n                i, j = j, i\n            new_solution[i+1:j+1] = new_solution[i+1:j+1][::-1]\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        visited = set()\n        repaired = []\n        current = new_solution[0]\n        repaired.append(current)\n        visited.add(current)\n\n        for _ in range(n - 1):\n            candidates = [node for node in new_solution if node not in visited]\n            if not candidates:\n                break\n            nearest = min(candidates, key=lambda x: distance_matrix_1[current, x] + distance_matrix_2[current, x])\n            repaired.append(nearest)\n            visited.add(nearest)\n            current = nearest\n\n        if len(repaired) == n:\n            new_solution = np.array(repaired)\n        else:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 5 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive using crowding distance, applies adaptive segment inversion with dynamic objective weights, and conditionally performs edge swaps (40% probability) to generate neighbors while ensuring feasibility through nearest-neighbor repair. It prioritizes solutions with high crowding distance, dynamically adjusts segment sizes and objective weights, and balances exploration/exploitation while maintaining tour validity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest crowding distance\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive segment inversion with dynamic weights\n    seg_size = min(4, max(2, int(np.random.normal(3, 1))))\n    seg_start = np.random.randint(0, n - seg_size)\n    segment = new_solution[seg_start:seg_start+seg_size]\n    inverted_segment = segment[::-1]\n\n    # Evaluate original and inverted segments\n    original_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%seg_size]] for i in range(seg_size))\n    inverted_cost1 = sum(distance_matrix_1[inverted_segment[i], inverted_segment[(i+1)%seg_size]] for i in range(seg_size))\n    original_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%seg_size]] for i in range(seg_size))\n    inverted_cost2 = sum(distance_matrix_2[inverted_segment[i], inverted_segment[(i+1)%seg_size]] for i in range(seg_size))\n\n    # Dynamic weights based on crowding distance\n    obj_weights = [0.5, 0.5]\n    if crowding_distances[selected_idx] > np.mean(crowding_distances):\n        obj_weights = [0.7, 0.3] if np.random.random() < 0.5 else [0.3, 0.7]\n\n    original_total = obj_weights[0] * original_cost1 + obj_weights[1] * original_cost2\n    inverted_total = obj_weights[0] * inverted_cost1 + obj_weights[1] * inverted_cost2\n\n    if inverted_total < original_total:\n        new_solution[seg_start:seg_start+seg_size] = inverted_segment\n\n    # Conditional edge swap (40% probability)\n    if np.random.random() < 0.4:\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        while abs(i - j) <= 1:\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n\n        # Swap edges\n        temp = new_solution[i]\n        new_solution[i] = new_solution[j]\n        new_solution[j] = temp\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        visited = set()\n        repaired = []\n        current = new_solution[0]\n        repaired.append(current)\n        visited.add(current)\n\n        for _ in range(n - 1):\n            candidates = [node for node in new_solution if node not in visited]\n            if not candidates:\n                break\n            nearest = min(candidates, key=lambda x: distance_matrix_1[current, x] + distance_matrix_2[current, x])\n            repaired.append(nearest)\n            visited.add(nearest)\n            current = nearest\n\n        if len(repaired) == n:\n            new_solution = np.array(repaired)\n        else:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm combines Pareto-aware selection (via crowding distance) with an adaptive 4-opt variant that dynamically adjusts objective weights and incorporates conditional edge swaps (30% probability) to balance exploration and exploitation, while ensuring feasibility through strict validation and fallback to the base solution. It prioritizes solutions with higher crowding distance and uses weighted cost evaluation to guide the 4-opt search, with weights adjusted based on crowding distribution. The algorithm also includes a probabilistic edge swap for further diversification.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest crowding distance\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive 4-opt with dynamic weights\n    a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n\n    # Generate all possible 4-opt configurations\n    options = [\n        np.concatenate([new_solution[:a], new_solution[b:c], new_solution[a:b], new_solution[c:d], new_solution[d:]]),\n        np.concatenate([new_solution[:a], new_solution[c:d], new_solution[b:c], new_solution[a:b], new_solution[d:]]),\n        np.concatenate([new_solution[:a], new_solution[d:], new_solution[c:d], new_solution[b:c], new_solution[a:b]]),\n        np.concatenate([new_solution[:b], new_solution[a:c], new_solution[b:a], new_solution[d:], new_solution[c:d]]),\n        np.concatenate([new_solution[:b], new_solution[c:d], new_solution[a:c], new_solution[b:a], new_solution[d:]]),\n        np.concatenate([new_solution[:b], new_solution[d:], new_solution[a:c], new_solution[b:a], new_solution[c:d]])\n    ]\n\n    # Evaluate options with dynamic weights\n    best_option = None\n    best_cost = float('inf')\n    obj_weights = [0.5, 0.5]  # Initial weights\n\n    # Adjust weights based on crowding distance\n    if crowding_distances[selected_idx] > np.mean(crowding_distances):\n        obj_weights = [0.6, 0.4] if np.random.random() < 0.5 else [0.4, 0.6]\n\n    for option in options:\n        cost1 = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n        total_cost = obj_weights[0] * cost1 + obj_weights[1] * cost2\n\n        if total_cost < best_cost:\n            best_cost = total_cost\n            best_option = option.copy()\n\n    if best_option is not None:\n        new_solution = best_option\n\n    # Conditional edge swap (30% probability)\n    if np.random.random() < 0.3:\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        while abs(i - j) <= 1:\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n\n        # Swap edges\n        temp = new_solution[i]\n        new_solution[i] = new_solution[j]\n        new_solution[j] = temp\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a non-dominated solution from the archive, applies a hybrid 3-opt with adaptive segment reversals and biased edge insertions, and evaluates all possible configurations to generate a neighbor solution while ensuring feasibility. It prioritizes solutions with lower costs in both objectives, uses probabilistic segment reversal (40% chance) and edge insertion (25% chance) for exploration, and ensures validity by reverting to the base solution if uniqueness is violated. The key variables are `a, b, c` (for 3-opt selection) and `i, j` (for segment reversal/insertion), with probabilistic mechanisms balancing exploitation and exploration.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a non-dominated solution with high potential for improvement\n    selected = None\n    for sol, obj in archive:\n        if selected is None or (obj[0] < selected[1][0] and obj[1] < selected[1][1]):\n            selected = (sol, obj)\n    if selected is None:\n        selected = archive[0]\n    base_solution = selected[0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Select three distinct points for 3-opt\n    a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n\n    # Step 2: Generate all possible 3-opt configurations\n    options = [\n        np.concatenate([new_solution[:a], new_solution[b:c], new_solution[a:b], new_solution[c:]]),\n        np.concatenate([new_solution[:a], new_solution[c:], new_solution[b:c], new_solution[a:b]]),\n        np.concatenate([new_solution[:a], new_solution[a:b], new_solution[c:], new_solution[b:c]]),\n        np.concatenate([new_solution[:a], new_solution[c:], new_solution[a:b], new_solution[b:c]])\n    ]\n\n    # Step 3: Evaluate all options and select the best one\n    best_option = None\n    best_cost = float('inf')\n\n    for option in options:\n        total_cost = sum(distance_matrix_1[option[i], option[(i+1)%n]] + distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n        if total_cost < best_cost:\n            best_cost = total_cost\n            best_option = option.copy()\n\n    if best_option is not None:\n        new_solution = best_option\n\n    # Step 4: Adaptive segment reversal\n    if np.random.random() < 0.4:  # 40% chance to reverse a segment\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        while abs(i - j) <= 1:\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n\n    # Step 5: Biased edge insertion for exploration\n    if np.random.random() < 0.25:  # 25% chance to insert a node\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        while i == j:\n            j = np.random.randint(0, n)\n        node = new_solution[i]\n        new_solution = np.concatenate([new_solution[:j], [node], new_solution[j:i], new_solution[i+1:]])\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects a non-dominated solution from the archive and applies a hybrid 4-opt local search with adaptive edge swaps, evaluating all possible 4-opt reconnections to find the best neighbor solution while occasionally applying random edge swaps for exploration. It ensures feasibility by validating uniqueness of nodes and falls back to the original solution if invalid. The method prioritizes improving both objectives simultaneously by combining 4-opt with adaptive swaps.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a non-dominated solution with high potential for improvement\n    selected = None\n    for sol, obj in archive:\n        if selected is None or (obj[0] < selected[1][0] and obj[1] < selected[1][1]):\n            selected = (sol, obj)\n    if selected is None:\n        selected = archive[0]\n    base_solution = selected[0].copy()\n\n    # Hybrid 4-opt with adaptive edge swaps\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Select four distinct edges\n    a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n\n    # Step 2: Generate all possible 4-opt reconnections\n    options = [\n        np.concatenate([new_solution[:a], new_solution[b:c], new_solution[a:b], new_solution[c:d], new_solution[d:]]),\n        np.concatenate([new_solution[:a], new_solution[b:c], new_solution[c:d], new_solution[a:b], new_solution[d:]]),\n        np.concatenate([new_solution[:a], new_solution[c:d], new_solution[b:c], new_solution[a:b], new_solution[d:]]),\n        np.concatenate([new_solution[:a], new_solution[c:d], new_solution[a:b], new_solution[b:c], new_solution[d:]]),\n        np.concatenate([new_solution[:a], new_solution[a:b], new_solution[d:], new_solution[c:d], new_solution[b:c]]),\n        np.concatenate([new_solution[:a], new_solution[a:b], new_solution[d:], new_solution[b:c], new_solution[c:d]]),\n        np.concatenate([new_solution[:a], new_solution[b:c], new_solution[d:], new_solution[a:b], new_solution[c:d]]),\n        np.concatenate([new_solution[:a], new_solution[b:c], new_solution[d:], new_solution[c:d], new_solution[a:b]]),\n        np.concatenate([new_solution[:a], new_solution[c:d], new_solution[d:], new_solution[a:b], new_solution[b:c]]),\n        np.concatenate([new_solution[:a], new_solution[c:d], new_solution[d:], new_solution[b:c], new_solution[a:b]])\n    ]\n\n    # Step 3: Evaluate all options and select the best one\n    best_option = None\n    best_cost = float('inf')\n\n    for option in options:\n        total_cost = 0\n        for i in range(n):\n            j = (i + 1) % n\n            total_cost += distance_matrix_1[option[i], option[j]] + distance_matrix_2[option[i], option[j]]\n\n        if total_cost < best_cost:\n            best_cost = total_cost\n            best_option = option.copy()\n\n    if best_option is not None:\n        new_solution = best_option\n\n    # Step 4: Adaptive edge swap for exploration\n    if np.random.random() < 0.3:  # 30% chance to apply edge swap\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        while abs(i - j) <= 1 or (i == 0 and j == n-1) or (j == 0 and i == n-1):\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive (prioritizing non-dominated or high-cost solutions) and applies a hybrid local search combining edge insertion with a novel edge-swapping move, ensuring feasibility by maintaining a valid TSP tour. It evaluates potential improvements by reinserting edges and swaps non-adjacent edges to escape local optima.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential for improvement (e.g., non-dominated solutions)\n    selected = None\n    for sol, obj in archive:\n        if selected is None or (obj[0] > selected[1][0] and obj[1] > selected[1][1]):\n            selected = (sol, obj)\n    if selected is None:\n        selected = archive[0]\n    base_solution = selected[0].copy()\n\n    # Hybrid local search: combine edge insertion with a novel move\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify edges with high potential for improvement\n    # Calculate the improvement if we remove an edge and reinsert it elsewhere\n    improvements = []\n    for i in range(n):\n        a, b = new_solution[i], new_solution[(i+1)%n]\n        # Cost before removal\n        cost_before = distance_matrix_1[a, b] + distance_matrix_2[a, b]\n        # Try inserting between other edges\n        for j in range(n):\n            if j == i or j == (i+1)%n:\n                continue\n            c, d = new_solution[j], new_solution[(j+1)%n]\n            # Cost after insertion\n            cost_after = distance_matrix_1[a, c] + distance_matrix_1[b, d] + distance_matrix_2[a, c] + distance_matrix_2[b, d]\n            improvement = cost_before - cost_after\n            if improvement > 0:\n                improvements.append((improvement, i, j))\n\n    if improvements:\n        # Select the best improvement\n        improvements.sort(reverse=True, key=lambda x: x[0])\n        best_improvement, i, j = improvements[0]\n        # Perform the move\n        a, b = new_solution[i], new_solution[(i+1)%n]\n        # Remove edge (a,b)\n        if i < (i+1)%n:\n            new_solution = np.concatenate([new_solution[:i+1], new_solution[(i+2)%n:]])\n        else:\n            new_solution = np.concatenate([new_solution[:(i+1)%n], new_solution[i+1:]])\n        # Insert between j and (j+1)%n\n        new_solution = np.insert(new_solution, (j+1)%(n-1), [a, b])\n\n    # Step 2: Apply a novel move (swap of two non-adjacent edges)\n    if n >= 4:\n        # Select two non-adjacent edges\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        while abs(i - j) <= 1 or (i == 0 and j == n-1) or (j == 0 and i == n-1):\n            j = np.random.randint(0, n)\n        # Swap the edges\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            - **Keywords**: Pareto-dominance, hybrid 4-opt, adaptive edge swaps, crowding distance, dynamic weights, feasibility validation.\n- **Advice**: Select non-dominated solutions via crowding distance, apply 4-opt with 30% edge-swap probability, and dynamically adjust objective weights (70/30) for balanced exploration.\n- **Avoid**: Greedy dominated selection, static 2-opt, or moves that risk duplicate nodes/missing nodes. Use nearest-neighbor repair for infeasible tours.\n- **Explanation**: Hybrid 4-opt with conditional edge swaps explores large neighborhoods, while dynamic weights balance objectives. Feasibility checks ensure valid tours.\n\n**Next Step**: Implement the heuristic with crowding-distance selection and hybrid 4-opt + edge-swap local search.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 308,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distances to identify promising solutions\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Dynamic weights based on crowding distance\n    obj_weights = [0.5, 0.5]\n    if crowding_distances[selected_idx] > np.mean(crowding_distances):\n        obj_weights = [0.7, 0.3] if np.random.random() < 0.5 else [0.3, 0.7]\n\n    # Hybrid 4-opt with edge swaps\n    a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n\n    # Generate all possible 4-opt configurations\n    options = [\n        np.concatenate([new_solution[:a], new_solution[b:c], new_solution[a:b], new_solution[c:d], new_solution[d:]]),\n        np.concatenate([new_solution[:a], new_solution[c:d], new_solution[b:c], new_solution[a:b], new_solution[d:]]),\n        np.concatenate([new_solution[:a], new_solution[d:], new_solution[c:d], new_solution[b:c], new_solution[a:b]]),\n        np.concatenate([new_solution[:b], new_solution[a:c], new_solution[b:a], new_solution[d:], new_solution[c:d]]),\n        np.concatenate([new_solution[:b], new_solution[c:d], new_solution[a:c], new_solution[b:a], new_solution[d:]]),\n        np.concatenate([new_solution[:b], new_solution[d:], new_solution[a:c], new_solution[b:a], new_solution[c:d]])\n    ]\n\n    # Evaluate options with dynamic weights\n    best_option = None\n    best_cost = float('inf')\n\n    for option in options:\n        cost1 = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n        total_cost = obj_weights[0] * cost1 + obj_weights[1] * cost2\n\n        if total_cost < best_cost:\n            best_cost = total_cost\n            best_option = option.copy()\n\n    if best_option is not None:\n        new_solution = best_option\n\n    # Conditional edge swap (30% probability)\n    if np.random.random() < 0.3:\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        while abs(i - j) <= 1:\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n\n        # Swap edges\n        temp = new_solution[i]\n        new_solution[i] = new_solution[j]\n        new_solution[j] = temp\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        visited = set()\n        repaired = []\n        current = new_solution[0]\n        repaired.append(current)\n        visited.add(current)\n\n        for _ in range(n - 1):\n            candidates = [node for node in new_solution if node not in visited]\n            if not candidates:\n                break\n            nearest = min(candidates, key=lambda x: distance_matrix_1[current, x] + distance_matrix_2[current, x])\n            repaired.append(nearest)\n            visited.add(nearest)\n            current = nearest\n\n        if len(repaired) == n:\n            new_solution = np.array(repaired)\n        else:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8436089605162986,
            0.6292945146560669
        ],
        "raw_score": [
            6.283895287526921,
            7.367784771897604
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate crowding distances to identify promising solutions\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Dynamic weights based on crowding distance\n    obj_weights = [0.5, 0.5]\n    if crowding_distances[selected_idx] > np.mean(crowding_distances):\n        obj_weights = [0.7, 0.3] if np.random.random() < 0.5 else [0.3, 0.7]\n\n    # Hybrid 4-opt with edge swaps\n    a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n\n    # Generate all possible 4-opt configurations\n    options = [\n        np.concatenate([new_solution[:a], new_solution[b:c], new_solution[a:b], new_solution[c:d], new_solution[d:]]),\n        np.concatenate([new_solution[:a], new_solution[c:d], new_solution[b:c], new_solution[a:b], new_solution[d:]]),\n        np.concatenate([new_solution[:a], new_solution[d:], new_solution[c:d], new_solution[b:c], new_solution[a:b]]),\n        np.concatenate([new_solution[:b], new_solution[a:c], new_solution[b:a], new_solution[d:], new_solution[c:d]]),\n        np.concatenate([new_solution[:b], new_solution[c:d], new_solution[a:c], new_solution[b:a], new_solution[d:]]),\n        np.concatenate([new_solution[:b], new_solution[d:], new_solution[a:c], new_solution[b:a], new_solution[c:d]])\n    ]\n\n    # Evaluate options with dynamic weights\n    best_option = None\n    best_cost = float('inf')\n\n    for option in options:\n        cost1 = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n))\n        cost2 = sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n        total_cost = obj_weights[0] * cost1 + obj_weights[1] * cost2\n\n        if total_cost < best_cost:\n            best_cost = total_cost\n            best_option = option.copy()\n\n    if best_option is not None:\n        new_solution = best_option\n\n    # Conditional edge swap (30% probability)\n    if np.random.random() < 0.3:\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        while abs(i - j) <= 1:\n            i, j = sorted(np.random.choice(n, size=2, replace=False))\n\n        # Swap edges\n        temp = new_solution[i]\n        new_solution[i] = new_solution[j]\n        new_solution[j] = temp\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        visited = set()\n        repaired = []\n        current = new_solution[0]\n        repaired.append(current)\n        visited.add(current)\n\n        for _ in range(n - 1):\n            candidates = [node for node in new_solution if node not in visited]\n            if not candidates:\n                break\n            nearest = min(candidates, key=lambda x: distance_matrix_1[current, x] + distance_matrix_2[current, x])\n            repaired.append(nearest)\n            visited.add(nearest)\n            current = nearest\n\n        if len(repaired) == n:\n            new_solution = np.array(repaired)\n        else:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Bi-objective Travelling Salesman Problem (bi-TSP), where each node has two different 2D coordinates: (x1, y1) and (x2, y2), representing its position in two objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing two objectives simultaneously: the total tour length in each coordinate space. Given an archive of solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of two values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it.  Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited.Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 4 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive based on a weighted combination of objectives (30% for the first objective, 70% for the second), then applies a hybrid local search combining edge reversal and a novel node reordering strategy to generate a neighbor solution, ensuring feasibility by maintaining a valid TSP tour. The weighted selection prioritizes solutions with better performance in the second objective, while the local search explores new configurations by reversing segments and shuffling sub-sequences.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest weighted objective (0.3*obj1 + 0.7*obj2)\n    selected = max(archive, key=lambda x: 0.3 * x[1][0] + 0.7 * x[1][1])\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: edge reversal with node reordering\n    if n >= 3:\n        # Step 1: Reverse a random segment\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n        # Step 2: Novel node reordering in a sub-sequence\n        sub_start = np.random.randint(0, n - 2)\n        sub_end = np.random.randint(sub_start + 2, min(sub_start + 6, n))\n        sub_seq = new_solution[sub_start:sub_end]\n        np.random.shuffle(sub_seq)\n        new_solution[sub_start:sub_end] = sub_seq\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm combines **adaptive Pareto frontier sampling** (prioritizing solutions with high crowding distance) with a **segmented crossover operator** that dynamically blends segments from diverse archive solutions, using a **hybrid objective weighting scheme** to evaluate segment quality while ensuring feasibility through **multi-stage validation**. It balances exploration and exploitation by probabilistically selecting segments from multiple solutions, with segment sizes and positions determined by both objective-aware metrics and spatial proximity in the coordinate spaces.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive Pareto frontier sampling with crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    crowding_dist = np.zeros(len(archive))\n\n    for m in range(2):\n        sorted_idx = np.argsort(objectives[:, m])\n        crowding_dist[sorted_idx[0]] = np.inf\n        crowding_dist[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive) - 1):\n            crowding_dist[sorted_idx[i]] += (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m] + 1e-10)\n\n    # Select multiple diverse solutions for segment crossover\n    selected_indices = np.argsort(-crowding_dist)[:min(3, len(archive))]\n    base_solution = archive[selected_indices[0]][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Segmented crossover operator\n    if len(selected_indices) > 1:\n        # Select random segments from diverse solutions\n        segment_length = np.random.randint(2, min(4, n // 2))\n        for idx in selected_indices[1:]:\n            donor = archive[idx][0]\n            start = np.random.randint(0, n - segment_length)\n            segment = donor[start:start+segment_length]\n\n            # Find insertion point in new_solution that maintains spatial proximity\n            best_pos = start\n            min_cost = float('inf')\n            for pos in range(n - segment_length + 1):\n                # Evaluate insertion using hybrid objective weights\n                weight1 = 0.5 + 0.3 * (np.std(objectives[:, 0]) / (np.mean(objectives[:, 0]) + 1e-10))\n                weight2 = 0.5 + 0.3 * (np.std(objectives[:, 1]) / (np.mean(objectives[:, 1]) + 1e-10))\n\n                # Calculate cost before and after insertion\n                cost_before = 0\n                cost_after = 0\n                for i in range(pos - 1, pos + segment_length + 1):\n                    i = i % n\n                    j = (i + 1) % n\n                    cost_before += weight1 * distance_matrix_1[new_solution[i], new_solution[j]] + weight2 * distance_matrix_2[new_solution[i], new_solution[j]]\n\n                temp_solution = np.concatenate([new_solution[:pos], segment, new_solution[pos+segment_length:]])\n                for i in range(pos - 1, pos + segment_length + 1):\n                    i = i % n\n                    j = (i + 1) % n\n                    cost_after += weight1 * distance_matrix_1[temp_solution[i], temp_solution[j]] + weight2 * distance_matrix_2[temp_solution[i], temp_solution[j]]\n\n                if cost_after < min_cost:\n                    min_cost = cost_after\n                    best_pos = pos\n\n            new_solution = np.concatenate([new_solution[:best_pos], segment, new_solution[best_pos+segment_length:]])\n\n    # Multi-stage validation\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        # Repair missing nodes by inserting them at positions that minimize cost\n        missing_nodes = np.setdiff1d(np.arange(n), unique_nodes)\n        for node in missing_nodes:\n            best_pos = 0\n            min_cost = float('inf')\n            for pos in range(n + 1):\n                temp_solution = np.insert(new_solution, pos, node)\n                cost = 0\n                for i in range(n):\n                    j = (i + 1) % (n + 1)\n                    cost += distance_matrix_1[temp_solution[i], temp_solution[j]] + distance_matrix_2[temp_solution[i], temp_solution[j]]\n                if cost < min_cost:\n                    min_cost = cost\n                    best_pos = pos\n            new_solution = np.insert(new_solution, best_pos, node)\n\n    # Final validation\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines Pareto-frontier selection with an objective-aware hybrid local search strategy that alternates between merging segments of variable size and conditional node reinsertions, prioritizing the more dominated objective while ensuring feasibility through nearest-neighbor repair. It dynamically adjusts segment size and operation probabilities based on objective balance (larger segments for balanced objectives, smaller targeted reinsertions when one dominates), using adaptive weights (60/40) to guide segment selection. The method maintains feasibility by always checking for missing nodes and repairing with nearest-neighbor insertion when violations occur.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select non-dominated solutions using crowding distance\n    non_dominated = []\n    for sol, obj in archive:\n        dominated = False\n        for _, other_obj in archive:\n            if (other_obj[0] <= obj[0] and other_obj[1] < obj[1]) or (other_obj[0] < obj[0] and other_obj[1] <= obj[1]):\n                dominated = True\n                break\n        if not dominated:\n            non_dominated.append((sol, obj))\n\n    if not non_dominated:\n        non_dominated = archive\n\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(non_dominated):\n        if i == 0:\n            left = non_dominated[-1][1]\n            right = non_dominated[1][1] if len(non_dominated) > 1 else non_dominated[0][1]\n        elif i == len(non_dominated) - 1:\n            left = non_dominated[i-1][1]\n            right = non_dominated[0][1]\n        else:\n            left = non_dominated[i-1][1]\n            right = non_dominated[i+1][1]\n\n        weight_obj1 = 0.6 if obj[0] < obj[1] else 0.4\n        weight_obj2 = 0.6 if obj[1] < obj[0] else 0.4\n        dist = (abs(obj[0] - left[0]) + abs(obj[0] - right[0])) * weight_obj1 + (abs(obj[1] - left[1]) + abs(obj[1] - right[1])) * weight_obj2\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = non_dominated[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Objective-aware segment fusion\n    if n >= 4:\n        # Determine segment size based on objective balance\n        obj1, obj2 = non_dominated[selected_idx][1]\n        if abs(obj1 - obj2) < 0.1 * max(obj1, obj2):  # Objectives balanced\n            seg_size = np.random.randint(2, min(4, n//2))\n        else:  # One objective dominates\n            seg_size = np.random.randint(1, min(3, n//3))\n\n        # Select segments to merge\n        seg1_start = np.random.randint(0, n - seg_size)\n        seg1_end = seg1_start + seg_size\n        seg2_start = np.random.randint(seg1_end, n - seg_size) if seg1_end + seg_size < n else np.random.randint(0, seg1_start)\n        seg2_end = seg2_start + seg_size\n\n        # Merge segments with conditional reinsertion\n        merged = np.concatenate([new_solution[seg1_start:seg1_end], new_solution[seg2_start:seg2_end]])\n        if np.random.random() < 0.6 if obj1 < obj2 else 0.4:  # Higher probability for more dominated objective\n            np.random.shuffle(merged)\n\n        # Reinsert merged segment\n        insert_pos = np.random.randint(0, n - len(merged))\n        if insert_pos >= seg1_start:\n            insert_pos += len(merged)\n        new_solution = np.concatenate([\n            new_solution[:seg1_start],\n            new_solution[seg1_end:seg2_start],\n            new_solution[seg2_end:insert_pos],\n            merged,\n            new_solution[insert_pos:]\n        ])\n\n    # Conditional node reinsertion\n    if np.random.random() < 0.3:\n        node = np.random.randint(0, n)\n        old_pos = np.where(new_solution == node)[0][0]\n        new_pos = np.random.randint(0, n)\n        if new_pos > old_pos:\n            new_pos -= 1\n        new_solution = np.concatenate([\n            new_solution[:old_pos],\n            new_solution[old_pos+1:new_pos+1],\n            [node],\n            new_solution[new_pos+1:]\n        ])\n\n    # Feasibility check and repair\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            best_cost = float('inf')\n            for i in range(n):\n                if i == 0:\n                    cost = distance_matrix_1[new_solution[-1], node] + distance_matrix_1[node, new_solution[0]]\n                    cost += distance_matrix_2[new_solution[-1], node] + distance_matrix_2[node, new_solution[0]]\n                else:\n                    cost = distance_matrix_1[new_solution[i-1], node] + distance_matrix_1[node, new_solution[i]]\n                    cost += distance_matrix_2[new_solution[i-1], node] + distance_matrix_2[node, new_solution[i]]\n                if cost < best_cost:\n                    best_cost = cost\n                    best_pos = i\n            new_solution = np.concatenate([new_solution[:best_pos], [node], new_solution[best_pos:]])\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm combines crowding-distance selection with a hybrid local search that prioritizes improvement in the more crowded objective dimension (70/30 weighting) while using segment inversion and probabilistic cross-dimensional swaps to explore the solution space, dynamically adjusting weights and ensuring feasibility through nearest-neighbor repair. It balances exploitation (segment manipulation) and exploration (cross-dimensional swaps) while maintaining tour validity.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest crowding distance\n    crowding_distances = []\n    for i, (sol, obj) in enumerate(archive):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(obj[0] - left[0]) + abs(obj[1] - left[1]) + abs(obj[0] - right[0]) + abs(obj[1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Dimensional-aware segment inversion\n    a, b = sorted(np.random.choice(n, size=2, replace=False))\n    segment = new_solution[a:b]\n    inverted_segment = segment[::-1]\n\n    # Reinsert inverted segment at a new position\n    insert_pos = np.random.randint(0, n - len(segment))\n    new_solution = np.concatenate([new_solution[:insert_pos], inverted_segment, new_solution[insert_pos:]])\n    new_solution = np.concatenate([new_solution[:n], new_solution[n-len(segment):]])\n\n    # Dynamic weight adjustment (70/30) for objective prioritization\n    weight_1 = 0.7 if archive[selected_idx][1][0] > archive[selected_idx][1][1] else 0.3\n    weight_2 = 1 - weight_1\n\n    # Probabilistic cross-dimensional node swap\n    if np.random.random() < 0.2:\n        i, j = sorted(np.random.choice(n, size=2, replace=False))\n        old_cost = weight_1 * distance_matrix_1[new_solution[i-1], new_solution[i]] + weight_2 * distance_matrix_2[new_solution[j-1], new_solution[j]]\n        new_cost = weight_1 * distance_matrix_1[new_solution[i-1], new_solution[j]] + weight_2 * distance_matrix_2[new_solution[j-1], new_solution[i]]\n\n        if new_cost < old_cost:\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure solution remains valid\n    if len(np.unique(new_solution)) != n:\n        # Nearest-neighbor repair\n        for i in range(n):\n            if new_solution[i] in new_solution[:i]:\n                nearest = None\n                min_cost = float('inf')\n                for j in range(n):\n                    if j not in new_solution[:i]:\n                        cost = weight_1 * distance_matrix_1[new_solution[i-1], j] + weight_2 * distance_matrix_2[new_solution[i-1], j]\n                        if cost < min_cost:\n                            min_cost = cost\n                            nearest = j\n                new_solution[i] = nearest\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the ultra-concise, high-value response for the bi-TSP heuristic design:\n\n- **Keywords**: Pareto-dominance, hybrid 4-opt, adaptive edge swaps, crowding distance, dynamic weights, feasibility validation.\n- **Advice**: Select non-dominated solutions via crowding distance, apply 4-opt with 30% edge-swap probability, and dynamically adjust objective weights (70/30) for balanced exploration.\n- **Avoid**: Greedy dominated selection, static 2-opt, or moves that risk duplicate nodes/missing nodes. Use nearest-neighbor repair for infeasible tours.\n- **Explanation**: Hybrid 4-opt with conditional edge swaps explores large neighborhoods, while dynamic weights balance objectives. Feasibility checks ensure valid tours.\n\n**Next Step**: Implement the heuristic with crowding-distance selection and hybrid 4-opt + edge-swap local search.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 309,
        "algorithm": "The algorithm combines adaptive Pareto selection with a hybrid 4-opt local search, prioritizing high-crowding-distance solutions (30% probability) and using 70/30 objective weights to balance tour lengths across two spaces, while ensuring feasibility through nearest-neighbor repair. It dynamically evaluates all 4-opt configurations to find the best improvement while maintaining valid TSP tours.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest crowding distance\n    crowding_distances = []\n    objectives = np.array([obj for _, obj in archive])\n    for i in range(len(archive)):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(archive[i][1][0] - left[0]) + abs(archive[i][1][1] - left[1]) + abs(archive[i][1][0] - right[0]) + abs(archive[i][1][1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid 4-opt with dynamic edge swaps\n    if n >= 4:\n        # Select 4 distinct nodes\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n\n        # Dynamic edge-swap probability (30% for high-crowding nodes)\n        if np.random.random() < 0.3 or crowding_distances[selected_idx] > np.mean(crowding_distances):\n            # Try all possible 4-opt configurations\n            configs = [\n                [a, c, b, d], [a, d, b, c],\n                [b, a, d, c], [b, c, a, d],\n                [b, d, a, c], [c, a, d, b],\n                [c, b, a, d], [c, d, a, b],\n                [d, a, b, c], [d, b, a, c],\n                [d, c, a, b]\n            ]\n\n            best_config = None\n            min_cost = float('inf')\n\n            # Evaluate each configuration\n            for config in configs:\n                temp_solution = new_solution.copy()\n                temp_solution[config] = new_solution[config]\n\n                # Calculate cost with 70/30 weights\n                cost = 0\n                for i in range(n):\n                    j = (i + 1) % n\n                    cost += 0.7 * distance_matrix_1[temp_solution[i], temp_solution[j]] + 0.3 * distance_matrix_2[temp_solution[i], temp_solution[j]]\n\n                if cost < min_cost:\n                    min_cost = cost\n                    best_config = config\n\n            if best_config:\n                new_solution[best_config] = new_solution[best_config]\n\n    # Feasibility check and repair\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        # Nearest-neighbor repair\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            best_cost = float('inf')\n            for i in range(n):\n                if i == 0:\n                    cost = 0.7 * (distance_matrix_1[new_solution[-1], node] + distance_matrix_1[node, new_solution[0]]) + 0.3 * (distance_matrix_2[new_solution[-1], node] + distance_matrix_2[node, new_solution[0]])\n                else:\n                    cost = 0.7 * (distance_matrix_1[new_solution[i-1], node] + distance_matrix_1[node, new_solution[i]]) + 0.3 * (distance_matrix_2[new_solution[i-1], node] + distance_matrix_2[node, new_solution[i]])\n                if cost < best_cost:\n                    best_cost = cost\n                    best_pos = i\n            new_solution = np.concatenate([new_solution[:best_pos], [node], new_solution[best_pos:]])\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8803432677306561,
            3.5400717854499817
        ],
        "raw_score": [
            9.687254984435011,
            11.073244478140232
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest crowding distance\n    crowding_distances = []\n    objectives = np.array([obj for _, obj in archive])\n    for i in range(len(archive)):\n        if i == 0:\n            left = archive[-1][1]\n            right = archive[1][1] if len(archive) > 1 else archive[0][1]\n        elif i == len(archive) - 1:\n            left = archive[i-1][1]\n            right = archive[0][1]\n        else:\n            left = archive[i-1][1]\n            right = archive[i+1][1]\n\n        dist = abs(archive[i][1][0] - left[0]) + abs(archive[i][1][1] - left[1]) + abs(archive[i][1][0] - right[0]) + abs(archive[i][1][1] - right[1])\n        crowding_distances.append(dist)\n\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid 4-opt with dynamic edge swaps\n    if n >= 4:\n        # Select 4 distinct nodes\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n\n        # Dynamic edge-swap probability (30% for high-crowding nodes)\n        if np.random.random() < 0.3 or crowding_distances[selected_idx] > np.mean(crowding_distances):\n            # Try all possible 4-opt configurations\n            configs = [\n                [a, c, b, d], [a, d, b, c],\n                [b, a, d, c], [b, c, a, d],\n                [b, d, a, c], [c, a, d, b],\n                [c, b, a, d], [c, d, a, b],\n                [d, a, b, c], [d, b, a, c],\n                [d, c, a, b]\n            ]\n\n            best_config = None\n            min_cost = float('inf')\n\n            # Evaluate each configuration\n            for config in configs:\n                temp_solution = new_solution.copy()\n                temp_solution[config] = new_solution[config]\n\n                # Calculate cost with 70/30 weights\n                cost = 0\n                for i in range(n):\n                    j = (i + 1) % n\n                    cost += 0.7 * distance_matrix_1[temp_solution[i], temp_solution[j]] + 0.3 * distance_matrix_2[temp_solution[i], temp_solution[j]]\n\n                if cost < min_cost:\n                    min_cost = cost\n                    best_config = config\n\n            if best_config:\n                new_solution[best_config] = new_solution[best_config]\n\n    # Feasibility check and repair\n    unique_nodes = np.unique(new_solution)\n    if len(unique_nodes) != n:\n        # Nearest-neighbor repair\n        missing = set(range(n)) - set(new_solution)\n        for node in missing:\n            best_pos = 0\n            best_cost = float('inf')\n            for i in range(n):\n                if i == 0:\n                    cost = 0.7 * (distance_matrix_1[new_solution[-1], node] + distance_matrix_1[node, new_solution[0]]) + 0.3 * (distance_matrix_2[new_solution[-1], node] + distance_matrix_2[node, new_solution[0]])\n                else:\n                    cost = 0.7 * (distance_matrix_1[new_solution[i-1], node] + distance_matrix_1[node, new_solution[i]]) + 0.3 * (distance_matrix_2[new_solution[i-1], node] + distance_matrix_2[node, new_solution[i]])\n                if cost < best_cost:\n                    best_cost = cost\n                    best_pos = i\n            new_solution = np.concatenate([new_solution[:best_pos], [node], new_solution[best_pos:]])\n\n    return new_solution\n\n",
        "operation": "elitist"
    }
]