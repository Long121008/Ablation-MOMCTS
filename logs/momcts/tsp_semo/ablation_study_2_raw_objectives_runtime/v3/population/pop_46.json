[
    {
        "algorithm": "The heuristic selects a random solution from the archive, applies a hybrid local search combining edge insertion and node relocation to generate a neighbor, and ensures feasibility by reverting to a simple swap if duplicates occur. The selection is random, while the local search prioritizes edge-wise and node-wise modifications for exploration. The design balances simplicity and feasibility, with fallback mechanisms to maintain valid TSP tours.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential (e.g., non-dominated or high diversity)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    n = len(base_solution)\n\n    # Hybrid local search: combine edge insertion and node relocation\n    new_solution = base_solution.copy()\n\n    # Edge insertion (insert a node at a random position)\n    i = random.randint(0, n - 1)\n    j = random.randint(0, n - 1)\n    if i != j:\n        node = new_solution[i]\n        new_solution = np.delete(new_solution, i)\n        new_solution = np.insert(new_solution, j, node)\n\n    # Node relocation (move a node to a new position)\n    i = random.randint(0, n - 1)\n    j = random.randint(0, n - 1)\n    if i != j:\n        node = new_solution[i]\n        new_solution = np.delete(new_solution, i)\n        new_solution = np.insert(new_solution, j, node)\n\n    # Ensure feasibility (no duplicates, all nodes visited)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a simple swap if operations cause duplicates\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution = base_solution.copy()\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9722195366932449,
            0.5455512404441833
        ],
        "raw_score": [
            7.274013559989165,
            6.750318961900975
        ]
    },
    {
        "algorithm": "The algorithm selects a solution with the highest objective variance from the archive, then applies a hybrid local search combining 3-opt and node insertion to generate a neighbor. It prioritizes diversity in objectives and uses a fallback swap if the solution becomes invalid. The key design ideas are selecting high-variance solutions and combining 3-opt with node insertion for exploration, with validation to ensure feasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    selected_solution = max(archive, key=lambda x: abs(x[1][0] - x[1][1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: 3-opt with node insertion\n    i, j, k = sorted(random.sample(range(n), 3))\n\n    # Apply 3-opt by reversing segments\n    new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    new_solution[j:k+1] = new_solution[j:k+1][::-1]\n\n    # Randomly insert a node elsewhere\n    node_to_move = new_solution[random.randint(0, n-1)]\n    insert_pos = random.randint(0, n-2)\n    if insert_pos < n-1:\n        new_solution = np.concatenate([\n            new_solution[:insert_pos],\n            np.array([node_to_move]),\n            new_solution[insert_pos:-1][new_solution[insert_pos:-1] != node_to_move],\n            [new_solution[-1]]\n        ])\n\n    # Validate the solution\n    if len(set(new_solution)) != n or len(new_solution) != n:\n        # Fallback to simple swap if invalid\n        a, b = sorted(random.sample(range(n), 2))\n        new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9315092738042138,
            0.2931731939315796
        ],
        "raw_score": [
            6.562713517573391,
            9.376940086743101
        ]
    },
    {
        "algorithm": "The algorithm selects a solution near the Pareto front using crowding distance, then applies adaptive segment reversal and probabilistic edge insertions to generate neighbors, prioritizing solutions that improve both objectives while falling back to random perturbations if no improvement is found. It ensures feasibility by validating node uniqueness and maintains diversity by occasionally sampling from other solutions in the archive.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def crowding_distance(solutions):\n        distances = []\n        for i in range(len(solutions)):\n            left = solutions[i-1][1] if i > 0 else None\n            right = solutions[i+1][1] if i < len(solutions)-1 else None\n            if left is None or right is None:\n                distances.append(float('inf'))\n            else:\n                dist = abs(right[0] - left[0]) + abs(right[1] - left[1])\n                distances.append(dist)\n        return distances\n\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0], x[1][1]))\n    distances = crowding_distance(sorted_archive)\n    selected_idx = np.argmax(distances)\n    base_solution = sorted_archive[selected_idx][0].copy()\n    base_obj = sorted_archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n    improved = False\n\n    for _ in range(3):\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        if i != j:\n            if i > j:\n                i, j = j, i\n            temp_solution = new_solution.copy()\n            temp_solution[i:j+1] = temp_solution[i:j+1][::-1]\n\n            current_cost1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(n))\n            new_cost1 = sum(distance_matrix_1[temp_solution[k-1], temp_solution[k]] for k in range(n))\n            new_cost2 = sum(distance_matrix_2[temp_solution[k-1], temp_solution[k]] for k in range(n))\n\n            if (new_cost1 < current_cost1 and new_cost2 < current_cost2) or \\\n               (new_cost1 < current_cost1 * 0.95 and new_cost2 < current_cost2 * 0.95):\n                new_solution = temp_solution\n                improved = True\n\n    if len(archive) > 1 and not improved:\n        other_idx = np.random.choice([idx for idx in range(len(archive)) if idx != selected_idx])\n        other_solution = archive[other_idx][0]\n\n        best_node = None\n        best_pos = -1\n        best_improvement = 0\n\n        for k in range(n):\n            node = other_solution[k]\n            if node not in new_solution:\n                for pos in range(n):\n                    temp_solution = np.insert(new_solution, pos, node)\n                    temp_solution = temp_solution[:n]\n\n                    new_cost1 = sum(distance_matrix_1[temp_solution[k-1], temp_solution[k]] for k in range(n))\n                    new_cost2 = sum(distance_matrix_2[temp_solution[k-1], temp_solution[k]] for k in range(n))\n\n                    improvement = (base_obj[0] - new_cost1)/base_obj[0] + (base_obj[1] - new_cost2)/base_obj[1]\n\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_node = node\n                        best_pos = pos\n\n        if best_node is not None:\n            new_solution = np.insert(new_solution, best_pos, best_node)\n            new_solution = new_solution[:n]\n            improved = True\n\n    if not improved:\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        if i != j:\n            if i > j:\n                i, j = j, i\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n        if len(archive) > 1:\n            other_idx = np.random.choice([idx for idx in range(len(archive)) if idx != selected_idx])\n            other_solution = archive[other_idx][0]\n            node = np.random.choice(other_solution)\n            if node not in new_solution:\n                pos = np.random.randint(0, n)\n                new_solution = np.insert(new_solution, pos, node)\n                new_solution = new_solution[:n]\n\n    return new_solution\n\n",
        "metric_score": [
            -1.037720641543422,
            1.3144855499267578
        ],
        "raw_score": [
            4.084941344187676,
            10.466301442220711
        ]
    },
    {
        "algorithm": "The algorithm selects solutions from the archive with higher priority based on their inverse Euclidean distance in the objective space, then applies either a coordinate-aware 3-opt (60% chance) that prioritizes nodes with high geometric discrepancy between objectives or a dynamic segment shuffle (40% chance) with adaptive segment length, falling back to a random 2-opt if duplicates arise, ensuring feasibility through continuous validation. The selection weights favor solutions with better overall performance across both objectives, while the local search operators adapt to the solution's geometric properties to explore diverse neighborhoods effectively.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Weighted selection based on Euclidean distance in objective space\n    objectives = [obj for _, obj in archive]\n    distances = [np.linalg.norm(obj) for obj in objectives]\n    weights = [1 / (dist + 1e-8) for dist in distances]  # Inverse distance weighting\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = random.randint(0, len(archive) - 1)\n    else:\n        selected_idx = random.choices(range(len(archive)), weights=weights, k=1)[0]\n\n    base_solution = archive[selected_idx][0].copy()\n    n = len(base_solution)\n    new_solution = base_solution.copy()\n\n    # Hybrid local search with coordinate-aware node selection\n    if random.random() < 0.6:  # 60% chance for 3-opt with geometric discrepancy\n        # Calculate geometric discrepancy between coordinates\n        discrepancies = []\n        for node in base_solution:\n            x1, y1, x2, y2 = instance[node]\n            v1 = np.array([x1, y1])\n            v2 = np.array([x2, y2])\n            discrepancy = np.linalg.norm(v1 - v2)\n            discrepancies.append(discrepancy)\n\n        if sum(discrepancies) > 0:\n            node_weights = discrepancies\n        else:\n            node_weights = [1] * n\n\n        selected_nodes = random.choices(range(n), weights=node_weights, k=3)\n        i, j, k = sorted(selected_nodes)\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n        new_solution[j:k+1] = new_solution[j:k+1][::-1]\n\n    else:  # 40% chance for dynamic segment shuffle\n        segment_length = random.randint(3, min(8, n//3))\n        a = random.randint(0, n - segment_length)\n        b = a + segment_length\n        segment = new_solution[a:b]\n        random.shuffle(segment)\n        new_solution[a:b] = segment\n\n    # Feasibility check and fallback to random 2-opt\n    if len(np.unique(new_solution)) != n:\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution = base_solution.copy()\n        # Perform 2-opt\n        if i < j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
        "metric_score": [
            -1.0117520614385667,
            0.8328625559806824
        ],
        "raw_score": [
            6.884514329057092,
            6.867396868766875
        ]
    },
    {
        "algorithm": "This algorithm combines adaptive Pareto dominance-based selection (prioritizing solutions with high Pareto front contribution) with a novel multi-objective segment inversion operator that dynamically balances exploration and exploitation by applying objective-weighted segment inversions, falling back to random swaps when feasibility is violated. It selects solutions with 70% probability based on Pareto dominance and 30% randomly, then applies segment inversions while reverting if no improvement is detected, ensuring feasibility through a fallback swap mechanism. The operator weights improvements by the relative costs of each objective, making it particularly effective for bi-objective optimization in TSP.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate Pareto dominance count for each solution\n    def pareto_dominance(solutions):\n        dominance = [0] * len(solutions)\n        for i, (sol_i, obj_i) in enumerate(solutions):\n            for j, (sol_j, obj_j) in enumerate(solutions):\n                if i != j and (obj_i[0] < obj_j[0] and obj_i[1] < obj_j[1]):\n                    dominance[i] += 1\n        return dominance\n\n    # Select solution with highest Pareto dominance (70% chance) or random (30% chance)\n    if np.random.random() < 0.7:\n        dominance = pareto_dominance(archive)\n        selected = archive[np.argmax(dominance)]\n    else:\n        selected = random.choice(archive)\n\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Calculate current objective weights\n    weight1 = selected[1][0] / (selected[1][0] + selected[1][1] + 1e-6)\n    weight2 = selected[1][1] / (selected[1][0] + selected[1][1] + 1e-6)\n\n    # Multi-objective segment inversion\n    if n > 2:\n        # Select a segment to invert\n        start = np.random.randint(0, n-1)\n        end = np.random.randint(start+1, n)\n\n        # Calculate improvement potential\n        original_cost1 = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(start, end+1))\n        original_cost2 = sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(start, end+1))\n\n        # Invert the segment\n        inverted_segment = new_solution[start:end+1][::-1]\n        new_solution[start:end+1] = inverted_segment\n\n        # Calculate new cost\n        new_cost1 = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(start, end+1))\n        new_cost2 = sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(start, end+1))\n\n        # Revert if no improvement\n        if (weight1 * new_cost1 + weight2 * new_cost2) >= (weight1 * original_cost1 + weight2 * original_cost2):\n            new_solution[start:end+1] = inverted_segment[::-1]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a random swap\n        i, j = sorted(np.random.choice(range(n), size=2, replace=False))\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9711126442467652,
            0.6652889847755432
        ],
        "raw_score": [
            7.143172504086787,
            6.136703950363287
        ]
    },
    {
        "algorithm": "The algorithm selects the solution with the highest combined normalized objective value from the archive, then applies a hybrid local search combining segment reversal and node relocation, followed by edge swaps and validation to ensure feasibility, with a fallback to random swaps if needed. It prioritizes solutions with better overall performance (sum of normalized objectives) and uses randomized operations to explore the solution space while maintaining tour validity. The key variables are the segment indices for reversal, the node and insertion position for relocation, and the edge swap candidates, with strict validation to prevent infeasibility.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    max_obj = max(archive, key=lambda x: (x[1][0] + x[1][1]) / (sum(x[1]) + 1e-6))\n    selected_solution = max_obj[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: segment reversal with node relocation\n    i, j = sorted(random.sample(range(n), 2))\n    new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Relocate a node to a position that maintains feasibility\n    node_to_move = new_solution[random.randint(0, n-1)]\n    insert_pos = random.randint(0, n-2)\n    if insert_pos < n-1:\n        new_solution = np.concatenate([\n            new_solution[:insert_pos],\n            np.array([node_to_move]),\n            new_solution[insert_pos:-1][new_solution[insert_pos:-1] != node_to_move],\n            [new_solution[-1]]\n        ])\n\n    # Edge swap validation\n    for _ in range(2):\n        a, b = sorted(random.sample(range(n), 2))\n        if a != b and a != n-1 and b != n-1:\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n            if len(set(new_solution)) == n:\n                break\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Final validation\n    if len(set(new_solution)) != n or len(new_solution) != n:\n        a, b = sorted(random.sample(range(n), 2))\n        new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.7496000485100427,
            0.3808279037475586
        ],
        "raw_score": [
            9.372289478749114,
            9.653513168638309
        ]
    },
    {
        "algorithm": "The algorithm intelligently selects a solution from the archive with high potential for improvement, then applies a hybrid local search combining edge exchange and segment inversion to explore diverse neighborhoods while ensuring feasibility. The selection prioritizes randomness for exploration, while the hybrid search balances edge-wise and segment-wise modifications to escape local optima. The feasibility check ensures valid TSP tours by reverting to simpler operations if needed.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high potential (e.g., non-dominated or high diversity)\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution = archive[selected_idx][0].copy()\n    n = len(base_solution)\n\n    # Hybrid local search: combine edge exchange and segment inversion\n    new_solution = base_solution.copy()\n\n    # Edge exchange (swap two random edges)\n    i, j = sorted(random.sample(range(n), 2))\n    new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Segment inversion (reverse a random segment)\n    a, b = sorted(random.sample(range(n), 2))\n    new_solution[a:b] = new_solution[a:b][::-1]\n\n    # Ensure feasibility (no duplicates, all nodes visited)\n    if len(np.unique(new_solution)) != n:\n        # Fallback to a simple swap if inversion causes duplicates\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution = base_solution.copy()\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.8790760004126856,
            0.47520631551742554
        ],
        "raw_score": [
            7.31569362287178,
            7.144871037754502
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using dominance rank and crowding distance, then applies a hybrid local search combining segment reversals and probabilistic edge insertions, prioritizing objective-weighted improvements while ensuring feasibility through validation checks. It uses weighted objective thresholds to accept moves and includes fallback mechanisms to maintain diversity, always returning a valid TSP tour.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def dominance_rank(solutions):\n        ranks = []\n        for i in range(len(solutions)):\n            is_dominated = False\n            for j in range(len(solutions)):\n                if i == j:\n                    continue\n                if solutions[j][1][0] <= solutions[i][1][0] and solutions[j][1][1] <= solutions[i][1][1] and (solutions[j][1][0] < solutions[i][1][0] or solutions[j][1][1] < solutions[i][1][1]):\n                    is_dominated = True\n                    break\n            ranks.append(1 if is_dominated else 0)\n        return ranks\n\n    def crowding_distance(solutions):\n        distances = []\n        objectives = np.array([obj for _, obj in solutions])\n        for m in range(2):\n            sorted_idx = np.argsort(objectives[:, m])\n            dist = np.zeros(len(solutions))\n            dist[sorted_idx[0]] = dist[sorted_idx[-1]] = float('inf')\n            for i in range(1, len(solutions)-1):\n                dist[sorted_idx[i]] = (objectives[sorted_idx[i+1], m] - objectives[sorted_idx[i-1], m]) / (objectives[sorted_idx[-1], m] - objectives[sorted_idx[0], m] + 1e-6)\n            if m == 0:\n                distances = dist\n            else:\n                distances += dist\n        return distances\n\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0], x[1][1]))\n    ranks = dominance_rank(sorted_archive)\n    distances = crowding_distance(sorted_archive)\n\n    weights = [1 / (rank + 1) * dist for rank, dist in zip(ranks, distances)]\n    selected_idx = np.argmax(weights)\n    base_solution = sorted_archive[selected_idx][0].copy()\n    base_obj = sorted_archive[selected_idx][1]\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n    improved = False\n\n    obj1, obj2 = base_obj\n    weight1 = obj1 / (obj1 + obj2 + 1e-6)\n    weight2 = obj2 / (obj1 + obj2 + 1e-6)\n\n    for _ in range(5):\n        if np.random.random() < 0.7:\n            i, j = sorted(np.random.choice(range(n), size=2, replace=False))\n            temp_solution = new_solution.copy()\n            temp_solution[i:j+1] = temp_solution[i:j+1][::-1]\n\n            current_cost1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(n))\n            new_cost1 = sum(distance_matrix_1[temp_solution[k-1], temp_solution[k]] for k in range(n))\n            new_cost2 = sum(distance_matrix_2[temp_solution[k-1], temp_solution[k]] for k in range(n))\n\n            if (weight1 * new_cost1 + weight2 * new_cost2) < (weight1 * current_cost1 + weight2 * current_cost2) * 0.95:\n                new_solution = temp_solution\n                improved = True\n        else:\n            if len(archive) > 1:\n                other_idx = np.random.choice([idx for idx in range(len(archive)) if idx != selected_idx])\n                other_solution = archive[other_idx][0]\n                node = np.random.choice(other_solution)\n                if node not in new_solution:\n                    pos = np.random.randint(0, n)\n                    temp_solution = np.insert(new_solution, pos, node)\n                    temp_solution = temp_solution[:n]\n\n                    new_cost1 = sum(distance_matrix_1[temp_solution[k-1], temp_solution[k]] for k in range(n))\n                    new_cost2 = sum(distance_matrix_2[temp_solution[k-1], temp_solution[k]] for k in range(n))\n\n                    if (weight1 * new_cost1 + weight2 * new_cost2) < (weight1 * base_obj[0] + weight2 * base_obj[1]) * 0.95:\n                        new_solution = temp_solution\n                        improved = True\n\n    if not improved and len(archive) > 1:\n        other_idx = np.random.choice([idx for idx in range(len(archive)) if idx != selected_idx])\n        other_solution = archive[other_idx][0]\n\n        for _ in range(3):\n            i = np.random.randint(0, n)\n            j = np.random.randint(0, n)\n            if i != j:\n                if i > j:\n                    i, j = j, i\n                temp_solution = new_solution.copy()\n                temp_solution[i:j+1] = temp_solution[i:j+1][::-1]\n\n                new_cost1 = sum(distance_matrix_1[temp_solution[k-1], temp_solution[k]] for k in range(n))\n                new_cost2 = sum(distance_matrix_2[temp_solution[k-1], temp_solution[k]] for k in range(n))\n\n                if (weight1 * new_cost1 + weight2 * new_cost2) < (weight1 * base_obj[0] + weight2 * base_obj[1]) * 0.98:\n                    new_solution = temp_solution\n                    improved = True\n                    break\n\n    if not improved:\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        if i != j:\n            if i > j:\n                i, j = j, i\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    if len(np.unique(new_solution)) != n:\n        for _ in range(5):\n            i, j = sorted(np.random.choice(range(n), size=2, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if len(np.unique(new_solution)) == n:\n                break\n        else:\n            np.random.shuffle(new_solution)\n\n    return new_solution\n\n",
        "metric_score": [
            -1.0147105251223683,
            4.994230687618256
        ],
        "raw_score": [
            4.214385526182349,
            9.671220943235054
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using crowding distance to identify solutions on the Pareto front, then applies a hybrid local search combining adaptive segment reversal and probabilistic edge insertion to generate improved neighbors while ensuring feasibility. It prioritizes solutions with higher crowding distance and uses a probabilistic acceptance criterion to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    def crowding_distance(solutions):\n        distances = []\n        for i in range(len(solutions)):\n            left = solutions[i-1][1] if i > 0 else None\n            right = solutions[i+1][1] if i < len(solutions)-1 else None\n            if left is None or right is None:\n                distances.append(float('inf'))\n            else:\n                dist = abs(right[0] - left[0]) + abs(right[1] - left[1])\n                distances.append(dist)\n        return distances\n\n    # Select solution with highest crowding distance (Pareto front candidate)\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0], x[1][1]))\n    distances = crowding_distance(sorted_archive)\n    selected_idx = np.argmax(distances)\n    base_solution = sorted_archive[selected_idx][0].copy()\n    n = len(base_solution)\n\n    new_solution = base_solution.copy()\n    improved = False\n\n    # Adaptive segment reversal with probabilistic acceptance\n    for _ in range(3):\n        i = np.random.randint(0, n)\n        j = np.random.randint(0, n)\n        if i != j:\n            if i > j:\n                i, j = j, i\n            temp_solution = new_solution.copy()\n            temp_solution[i:j+1] = temp_solution[i:j+1][::-1]\n\n            current_cost1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(n))\n            current_cost2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(n))\n            new_cost1 = sum(distance_matrix_1[temp_solution[k-1], temp_solution[k]] for k in range(n))\n            new_cost2 = sum(distance_matrix_2[temp_solution[k-1], temp_solution[k]] for k in range(n))\n\n            if (new_cost1 < current_cost1 and new_cost2 < current_cost2) or \\\n               (new_cost1 < current_cost1 * 0.95 and new_cost2 < current_cost2 * 0.95):\n                new_solution = temp_solution\n                improved = True\n\n    # Probabilistic edge insertion from other solutions\n    if len(archive) > 1 and not improved and random.random() < 0.5:\n        other_idx = np.random.choice([idx for idx in range(len(archive)) if idx != selected_idx])\n        other_solution = archive[other_idx][0]\n\n        best_node = None\n        best_pos = -1\n        best_improvement = 0\n\n        for k in range(n):\n            node = other_solution[k]\n            if node not in new_solution:\n                for pos in range(n):\n                    temp_solution = np.insert(new_solution, pos, node)\n                    temp_solution = temp_solution[:n]\n\n                    new_cost1 = sum(distance_matrix_1[temp_solution[k-1], temp_solution[k]] for k in range(n))\n                    new_cost2 = sum(distance_matrix_2[temp_solution[k-1], temp_solution[k]] for k in range(n))\n\n                    improvement = (current_cost1 - new_cost1)/current_cost1 + (current_cost2 - new_cost2)/current_cost2\n\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_node = node\n                        best_pos = pos\n\n        if best_node is not None:\n            new_solution = np.insert(new_solution, best_pos, best_node)\n            new_solution = new_solution[:n]\n            improved = True\n\n    # Fallback to random perturbation if no improvement\n    if not improved:\n        if random.random() < 0.7:\n            i = np.random.randint(0, n)\n            j = np.random.randint(0, n)\n            if i != j:\n                if i > j:\n                    i, j = j, i\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n        else:\n            a, b = sorted(random.sample(range(n), 2))\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9752570731503626,
            1.0885544419288635
        ],
        "raw_score": [
            4.161838114047093,
            10.521109995840689
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest crowding distance (Pareto front candidate)\n    sorted_archive = sorted(archive, key=lambda x: (x[1][0], x[1][1]))\n    distances = []\n    for i in range(len(sorted_archive)):\n        left = sorted_archive[i-1][1] if i > 0 else None\n        right = sorted_archive[i+1][1] if i < len(sorted_archive)-1 else None\n        if left is None or right is None:\n            distances.append(float('inf'))\n        else:\n            dist = abs(right[0] - left[0]) + abs(right[1] - left[1])\n            distances.append(dist)\n    selected_idx = np.argmax(distances)\n    base_solution = sorted_archive[selected_idx][0].copy()\n    n = len(base_solution)\n\n    new_solution = base_solution.copy()\n    improved = False\n\n    # Dynamic segment inversion with adaptive length\n    segment_length = min(3, n // 4)  # Adaptive segment length\n    for _ in range(3):\n        start = np.random.randint(0, n - segment_length)\n        end = start + segment_length\n        temp_solution = new_solution.copy()\n        temp_solution[start:end] = temp_solution[start:end][::-1]\n\n        current_cost1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(n))\n        current_cost2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(n))\n        new_cost1 = sum(distance_matrix_1[temp_solution[k-1], temp_solution[k]] for k in range(n))\n        new_cost2 = sum(distance_matrix_2[temp_solution[k-1], temp_solution[k]] for k in range(n))\n\n        if (new_cost1 < current_cost1 and new_cost2 < current_cost2) or \\\n           (new_cost1 < current_cost1 * 0.95 and new_cost2 < current_cost2 * 0.95):\n            new_solution = temp_solution\n            improved = True\n\n    # Guided node insertion using combined distance matrices\n    if not improved and len(archive) > 1 and random.random() < 0.6:\n        other_idx = np.random.choice([idx for idx in range(len(archive)) if idx != selected_idx])\n        other_solution = archive[other_idx][0]\n\n        combined_matrix = distance_matrix_1 + distance_matrix_2\n        best_node = None\n        best_pos = -1\n        best_improvement = 0\n\n        for k in range(n):\n            node = other_solution[k]\n            if node not in new_solution:\n                for pos in range(n):\n                    temp_solution = np.insert(new_solution, pos, node)\n                    temp_solution = temp_solution[:n]\n\n                    new_cost1 = sum(distance_matrix_1[temp_solution[k-1], temp_solution[k]] for k in range(n))\n                    new_cost2 = sum(distance_matrix_2[temp_solution[k-1], temp_solution[k]] for k in range(n))\n\n                    improvement = (current_cost1 - new_cost1)/current_cost1 + (current_cost2 - new_cost2)/current_cost2\n\n                    if improvement > best_improvement:\n                        best_improvement = improvement\n                        best_node = node\n                        best_pos = pos\n\n        if best_node is not None:\n            new_solution = np.insert(new_solution, best_pos, best_node)\n            new_solution = new_solution[:n]\n            improved = True\n\n    # Fallback to random perturbation with feasibility check\n    if not improved:\n        if random.random() < 0.5:\n            i, j = sorted(np.random.choice(n, 2, replace=False))\n            new_solution[i:j] = new_solution[i:j][::-1]\n        else:\n            a, b = sorted(random.sample(range(n), 2))\n            new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Ensure feasibility\n    assert len(new_solution) == len(base_solution)\n    assert len(np.unique(new_solution)) == len(base_solution)\n\n    return new_solution\n\n",
        "metric_score": [
            -0.9956633752011468,
            1.1808897256851196
        ],
        "raw_score": [
            4.429324937539713,
            10.690254055394236
        ]
    }
]