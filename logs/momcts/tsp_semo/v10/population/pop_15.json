[
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    def combined_score(obj):\n        return 0.5 * obj[0] + 0.5 * obj[1]  # Equal weights for both objectives\n    selected_solution = min(archive, key=lambda x: combined_score(x[1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify the worst node in terms of both objectives\n    node_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        node_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                         distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_node = np.argmax(node_scores)\n\n    # Step 2: Remove the worst node and reinsert it in a position that improves both objectives\n    removed_node = new_solution[worst_node]\n    new_solution = np.delete(new_solution, worst_node)\n\n    best_pos = 0\n    best_improvement = -float('inf')\n\n    for i in range(n-1):\n        # Try inserting the removed node between i and i+1\n        temp_solution = np.insert(new_solution, i, removed_node)\n        # Calculate the change in both objectives\n        prev = temp_solution[i-1]\n        curr = temp_solution[i]\n        next_ = temp_solution[(i+1)%(n-1)]\n\n        delta1 = (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]) - \\\n                 (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n        delta2 = (distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]) - \\\n                 (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n        improvement = -delta1 - delta2  # Negative because we want to minimize\n\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n\n    new_solution = np.insert(new_solution, best_pos, removed_node)\n\n    # Step 3: Apply a 3-opt move with a 60% probability to explore different configurations\n    if np.random.rand() < 0.6:\n        a, b, c = sorted(np.random.choice(n, 3, replace=False))\n        # Try different 3-opt configurations\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b][::-1], new_solution[b:c], new_solution[c:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c][::-1], new_solution[a:b], new_solution[c:]]),\n            np.concatenate([new_solution[:a], new_solution[a:b], new_solution[b:c][::-1], new_solution[c:]])\n        ]\n        # Evaluate all options and select the best one\n        best_option = new_solution\n        best_score = combined_score((sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)),\n                                    sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))))\n        for option in options:\n            score1 = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n))\n            score2 = sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            current_score = combined_score((score1, score2))\n            if current_score < best_score:\n                best_score = current_score\n                best_option = option\n        new_solution = best_option\n\n    return new_solution\n\n",
        "score": [
            5.885829592179676,
            5.710212425737046
        ]
    },
    {
        "algorithm": "The algorithm selects the best solution from the archive based on a weighted combined objective score (60% first objective, 40% second), then applies a hybrid local search combining probabilistic 3-opt moves (80% chance), biased edge insertion (60% chance), and adaptive 2-opt segment reversal (50% chance), ensuring feasibility at each step. The method prioritizes the first objective while balancing improvements in both spaces, with each operator targeting different aspects of tour optimization.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    def combined_score(obj):\n        return 0.6 * obj[0] + 0.4 * obj[1]\n\n    def is_feasible(tour):\n        return len(np.unique(tour)) == len(tour) and len(tour) == len(instance)\n\n    selected_solution = min(archive, key=lambda x: combined_score(x[1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Probabilistic 3-opt move with biased selection\n    if np.random.rand() < 0.8:\n        a, b, c = np.random.choice(n, size=3, replace=False)\n        a, b, c = sorted([a, b, c])\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b+1][::-1], new_solution[b+1:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c+1], new_solution[a:b], new_solution[c+1:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c+1][::-1], new_solution[a:b], new_solution[c+1:]])\n        ]\n        best_option = new_solution\n        best_score = combined_score((sum(distance_matrix_1[best_option[i], best_option[(i+1)%n]] for i in range(n)),\n                                    sum(distance_matrix_2[best_option[i], best_option[(i+1)%n]] for i in range(n))))\n        for option in options:\n            if is_feasible(option):\n                score1 = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n))\n                score2 = sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n                current_score = combined_score((score1, score2))\n                if current_score < best_score:\n                    best_score = current_score\n                    best_option = option\n        new_solution = best_option\n\n    # Step 2: Biased edge insertion for improvement\n    if np.random.rand() < 0.6:\n        worst_edge = np.argmax([distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)])\n        removed_node = new_solution[worst_edge]\n        temp_solution = np.delete(new_solution, worst_edge)\n        best_pos = 0\n        best_improvement = 0\n\n        for i in range(len(temp_solution)):\n            candidate = np.insert(temp_solution, i, removed_node)\n            if is_feasible(candidate):\n                delta1 = (distance_matrix_1[candidate[i-1], candidate[i]] + distance_matrix_1[candidate[i], candidate[(i+1)%n]] -\n                         (distance_matrix_1[temp_solution[i-1], temp_solution[i]] + distance_matrix_1[temp_solution[i], temp_solution[(i+1)%len(temp_solution)]]))\n                delta2 = (distance_matrix_2[candidate[i-1], candidate[i]] + distance_matrix_2[candidate[i], candidate[(i+1)%n]] -\n                         (distance_matrix_2[temp_solution[i-1], temp_solution[i]] + distance_matrix_2[temp_solution[i], temp_solution[(i+1)%len(temp_solution)]]))\n                improvement = -delta1 - delta2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_pos = i\n        new_solution = np.insert(temp_solution, best_pos, removed_node)\n\n    # Step 3: Adaptive 2-opt segment reversal\n    if np.random.rand() < 0.5:\n        a, b = sorted(np.random.choice(n, size=2, replace=False))\n        candidate = np.concatenate([new_solution[:a], new_solution[a:b+1][::-1], new_solution[b+1:]])\n        if is_feasible(candidate):\n            delta1 = (sum(distance_matrix_1[candidate[i], candidate[(i+1)%n]] for i in range(n)) -\n                     sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)))\n            delta2 = (sum(distance_matrix_2[candidate[i], candidate[(i+1)%n]] for i in range(n)) -\n                     sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n)))\n            if delta1 + delta2 < 0:\n                new_solution = candidate\n\n    return new_solution\n\n",
        "score": [
            5.399567917958221,
            6.241680779401998
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive by normalizing objectives and choosing the one with the lowest combined score, then applies a hybrid local search strategy: it first removes the worst segment (highest combined distance in both objectives) and reinserts it optimally, followed by adaptive 4-opt moves (70% probability) and biased edge swaps (50% probability) to further improve the solution while ensuring feasibility. The method prioritizes segments and edges with high combined distances for improvement, using probabilistic exploration of different neighborhood structures.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = np.sum(normalized, axis=1)\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify and remove the worst segment (highest total distance in both objectives)\n    segment_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        segment_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                            distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_segment = np.argmax(segment_scores)\n    removed = new_solution[worst_segment]\n    new_solution = np.delete(new_solution, worst_segment)\n\n    # Step 2: Reinsert the removed segment in the best position\n    best_pos = 0\n    best_improvement = 0\n    for i in range(n-1):\n        temp_solution = np.insert(new_solution, i, removed)\n        prev = temp_solution[i-1]\n        curr = temp_solution[i]\n        next_ = temp_solution[(i+1)%(n-1)]\n        delta1 = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] - \\\n                 (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n        delta2 = distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_] - \\\n                 (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n        improvement = -delta1 - delta2\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n    new_solution = np.insert(new_solution, best_pos, removed)\n\n    # Step 3: Apply adaptive 4-opt move (70% probability)\n    if np.random.rand() < 0.7:\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b][::-1], new_solution[b:c], new_solution[c:d][::-1], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[c:d], new_solution[b:c], new_solution[a:b], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c][::-1], new_solution[a:b], new_solution[c:d], new_solution[d:]])\n        ]\n        best_option = new_solution\n        best_score = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                     sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n        for option in options:\n            score = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n)) + \\\n                    sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            if score < best_score:\n                best_score = score\n                best_option = option\n        new_solution = best_option\n\n    # Step 4: Perform biased edge swap (50% probability)\n    if np.random.rand() < 0.5:\n        edge_scores = np.zeros(n)\n        for i in range(n):\n            prev = new_solution[i-1]\n            curr = new_solution[i]\n            edge_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_2[prev, curr]\n        worst_edge = np.argmax(edge_scores)\n        best_swap = worst_edge\n        best_improvement = 0\n        for i in range(n):\n            if i != worst_edge and abs(i - worst_edge) > 1:\n                prev_worst = new_solution[(worst_edge-1)%n]\n                next_worst = new_solution[(worst_edge+1)%n]\n                prev_i = new_solution[(i-1)%n]\n                next_i = new_solution[(i+1)%n]\n                old_cost1 = distance_matrix_1[prev_worst, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[i]] + distance_matrix_1[new_solution[i], next_i]\n                new_cost1 = distance_matrix_1[prev_worst, new_solution[i]] + distance_matrix_1[new_solution[i], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_i]\n                old_cost2 = distance_matrix_2[prev_worst, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[i]] + distance_matrix_2[new_solution[i], next_i]\n                new_cost2 = distance_matrix_2[prev_worst, new_solution[i]] + distance_matrix_2[new_solution[i], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_i]\n                improvement = (old_cost1 + old_cost2) - (new_cost1 + new_cost2)\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_swap = i\n        if best_swap != worst_edge:\n            new_solution[worst_edge], new_solution[best_swap] = new_solution[best_swap], new_solution[worst_edge]\n\n    return new_solution\n\n",
        "score": [
            6.5962745856836165,
            5.54039310583721
        ]
    },
    {
        "algorithm": "The algorithm selects a promising solution from the archive using a normalized objective score, then applies a hybrid local search combining worst-segment removal, adaptive 4-opt moves (70% probability), and biased edge swaps (50% probability), prioritizing segments and edges with higher combined distances in both objective spaces while maintaining feasibility through structured perturbations. The method balances exploration and exploitation by adaptively selecting local search operators and evaluating improvements across multiple objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = np.sum(normalized, axis=1)\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify and remove the worst segment (highest combined distance)\n    segment_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        segment_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                            distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_segment = np.argmax(segment_scores)\n    removed_node = new_solution[worst_segment]\n    new_solution = np.delete(new_solution, worst_segment)\n\n    # Step 2: Reinsert the removed node in the best position\n    best_pos = 0\n    best_improvement = -float('inf')\n    for i in range(n-1):\n        temp_solution = np.insert(new_solution, i, removed_node)\n        prev = temp_solution[i-1]\n        curr = temp_solution[i]\n        next_ = temp_solution[(i+1)%(n-1)]\n        delta1 = (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]) - \\\n                (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n        delta2 = (distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]) - \\\n                (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n        improvement = -delta1 - delta2\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n    new_solution = np.insert(new_solution, best_pos, removed_node)\n\n    # Step 3: Apply adaptive 4-opt move (70% probability)\n    if np.random.rand() < 0.7:\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b][::-1], new_solution[b:c], new_solution[c:d][::-1], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[c:d], new_solution[b:c], new_solution[a:b], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c][::-1], new_solution[a:b], new_solution[c:d], new_solution[d:]])\n        ]\n        best_option = new_solution\n        best_score = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                     sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n        for option in options:\n            score = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n)) + \\\n                    sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            if score < best_score:\n                best_score = score\n                best_option = option\n        new_solution = best_option\n\n    # Step 4: Perform biased edge swap (50% probability)\n    if np.random.rand() < 0.5:\n        edge_scores = np.zeros(n)\n        for i in range(n):\n            prev = new_solution[i-1]\n            curr = new_solution[i]\n            edge_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_2[prev, curr]\n        worst_edge = np.argmax(edge_scores)\n        best_swap = worst_edge\n        best_improvement = 0\n        for i in range(n):\n            if i != worst_edge and abs(i - worst_edge) > 1:\n                prev_worst = new_solution[(worst_edge-1)%n]\n                next_worst = new_solution[(worst_edge+1)%n]\n                prev_i = new_solution[(i-1)%n]\n                next_i = new_solution[(i+1)%n]\n                old_cost1 = distance_matrix_1[prev_worst, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[i]] + distance_matrix_1[new_solution[i], next_i]\n                new_cost1 = distance_matrix_1[prev_worst, new_solution[i]] + distance_matrix_1[new_solution[i], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_i]\n                old_cost2 = distance_matrix_2[prev_worst, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[i]] + distance_matrix_2[new_solution[i], next_i]\n                new_cost2 = distance_matrix_2[prev_worst, new_solution[i]] + distance_matrix_2[new_solution[i], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_i]\n                improvement = (old_cost1 + old_cost2) - (new_cost1 + new_cost2)\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_swap = i\n        if best_swap != worst_edge:\n            new_solution[worst_edge], new_solution[best_swap] = new_solution[best_swap], new_solution[worst_edge]\n\n    return new_solution\n\n",
        "score": [
            5.7301280137273505,
            5.9960207296721775
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive (based on normalized objective scores) and applies a hybrid local search combining segment removal/reinsertion, adaptive 4-opt moves (70% probability), and biased edge swaps (50% probability), prioritizing segments and edges with higher combined distances in both objective spaces. It ensures feasibility by maintaining a valid TSP tour throughout all operations. The method balances exploration (via randomness in 4-opt and edge swaps) with exploitation (targeting high-cost segments/edges) to improve both objectives simultaneously.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of two float values (cost in each space).\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = np.sum(normalized, axis=1)\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify and remove the worst segment (highest combined distance)\n    segment_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        segment_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                            distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_segment = np.argmax(segment_scores)\n    removed_node = new_solution[worst_segment]\n    new_solution = np.delete(new_solution, worst_segment)\n\n    # Step 2: Reinsert the removed node in the best position\n    best_pos = 0\n    best_improvement = -float('inf')\n    for i in range(n-1):\n        temp_solution = np.insert(new_solution, i, removed_node)\n        prev = temp_solution[i-1]\n        curr = temp_solution[i]\n        next_ = temp_solution[(i+1)%(n-1)]\n        delta1 = (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]) - \\\n                (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n        delta2 = (distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]) - \\\n                (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n        improvement = -delta1 - delta2\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n    new_solution = np.insert(new_solution, best_pos, removed_node)\n\n    # Step 3: Apply adaptive 4-opt move (70% probability)\n    if np.random.rand() < 0.7:\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b][::-1], new_solution[b:c], new_solution[c:d][::-1], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[c:d], new_solution[b:c], new_solution[a:b], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c][::-1], new_solution[a:b], new_solution[c:d], new_solution[d:]])\n        ]\n        best_option = new_solution\n        best_score = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                     sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n        for option in options:\n            score = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n)) + \\\n                    sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            if score < best_score:\n                best_score = score\n                best_option = option\n        new_solution = best_option\n\n    # Step 4: Perform biased edge swap (50% probability)\n    if np.random.rand() < 0.5:\n        edge_scores = np.zeros(n)\n        for i in range(n):\n            prev = new_solution[i-1]\n            curr = new_solution[i]\n            edge_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_2[prev, curr]\n        worst_edge = np.argmax(edge_scores)\n        best_swap = worst_edge\n        best_improvement = 0\n        for i in range(n):\n            if i != worst_edge and abs(i - worst_edge) > 1:\n                prev_worst = new_solution[(worst_edge-1)%n]\n                next_worst = new_solution[(worst_edge+1)%n]\n                prev_i = new_solution[(i-1)%n]\n                next_i = new_solution[(i+1)%n]\n                old_cost1 = distance_matrix_1[prev_worst, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[i]] + distance_matrix_1[new_solution[i], next_i]\n                new_cost1 = distance_matrix_1[prev_worst, new_solution[i]] + distance_matrix_1[new_solution[i], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_i]\n                old_cost2 = distance_matrix_2[prev_worst, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[i]] + distance_matrix_2[new_solution[i], next_i]\n                new_cost2 = distance_matrix_2[prev_worst, new_solution[i]] + distance_matrix_2[new_solution[i], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_i]\n                improvement = (old_cost1 + old_cost2) - (new_cost1 + new_cost2)\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_swap = i\n        if best_swap != worst_edge:\n            new_solution[worst_edge], new_solution[best_swap] = new_solution[best_swap], new_solution[worst_edge]\n\n    return new_solution\n\n",
        "score": [
            6.376746310326254,
            5.561677280256628
        ]
    },
    {
        "algorithm": "The algorithm selects a solution from the archive using normalized objective scores, then applies a hybrid local search combining worst-segment removal, adaptive 4-opt moves (prioritizing segments with high combined distances), and biased edge insertion (focusing on long edges) to generate improved neighbors while maintaining feasibility. The method intelligently balances exploration and exploitation by probabilistically applying these operations to escape local optima while maintaining solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = np.sum(normalized, axis=1)\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify and remove the worst segment (highest combined distance)\n    segment_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        segment_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                            distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_segment = np.argmax(segment_scores)\n    removed_node = new_solution[worst_segment]\n    new_solution = np.delete(new_solution, worst_segment)\n\n    # Step 2: Reinsert the removed node in the best position\n    best_pos = 0\n    best_improvement = -float('inf')\n    for i in range(n-1):\n        temp_solution = np.insert(new_solution, i, removed_node)\n        prev = temp_solution[i-1]\n        curr = temp_solution[i]\n        next_ = temp_solution[(i+1)%(n-1)]\n        delta1 = (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]) - \\\n                (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n        delta2 = (distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]) - \\\n                (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n        improvement = -delta1 - delta2\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n    new_solution = np.insert(new_solution, best_pos, removed_node)\n\n    # Step 3: Apply adaptive 4-opt move (70% probability)\n    if np.random.rand() < 0.7:\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b][::-1], new_solution[b:c], new_solution[c:d][::-1], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[c:d], new_solution[b:c], new_solution[a:b], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c][::-1], new_solution[a:b], new_solution[c:d], new_solution[d:]])\n        ]\n        best_option = new_solution\n        best_score = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                     sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n        for option in options:\n            score = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n)) + \\\n                    sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            if score < best_score:\n                best_score = score\n                best_option = option\n        new_solution = best_option\n\n    # Step 4: Perform biased edge insertion (60% probability)\n    if np.random.rand() < 0.6:\n        worst_edge = np.argmax([distance_matrix_1[new_solution[i-1], new_solution[i]] + distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)])\n        removed_node = new_solution[worst_edge]\n        temp_solution = np.delete(new_solution, worst_edge)\n        best_pos = 0\n        best_improvement = -float('inf')\n\n        for i in range(len(temp_solution)):\n            candidate = np.insert(temp_solution, i, removed_node)\n            delta1 = (distance_matrix_1[candidate[i-1], candidate[i]] + distance_matrix_1[candidate[i], candidate[(i+1)%len(candidate)]]) - \\\n                    (distance_matrix_1[temp_solution[i-1], temp_solution[i]] + distance_matrix_1[temp_solution[i], temp_solution[(i+1)%len(temp_solution)]])\n            delta2 = (distance_matrix_2[candidate[i-1], candidate[i]] + distance_matrix_2[candidate[i], candidate[(i+1)%len(candidate)]]) - \\\n                    (distance_matrix_2[temp_solution[i-1], temp_solution[i]] + distance_matrix_2[temp_solution[i], temp_solution[(i+1)%len(temp_solution)]])\n            improvement = -delta1 - delta2\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_pos = i\n        new_solution = np.insert(temp_solution, best_pos, removed_node)\n\n    return new_solution\n\n",
        "score": [
            5.894141691004092,
            5.716769718585903
        ]
    },
    {
        "algorithm": "The algorithm first selects the most promising solution from the archive by combining both objectives with weights (0.6 for the first objective and 0.4 for the second), then applies a hybrid local search strategy: it removes the worst segment (highest combined distance) and reinserts it in a better position, followed by an adaptive 4-opt move with a 70% probability to explore different tour configurations, and finally performs a biased edge swap (50% probability) to improve both objectives by swapping the worst edge with a better candidate. The algorithm ensures feasibility by maintaining valid TSP tours throughout.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    def combined_score(obj):\n        return 0.6 * obj[0] + 0.4 * obj[1]  # Adjust weights based on preference\n    selected_solution = min(archive, key=lambda x: combined_score(x[1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify the worst segment (highest total distance in both objectives)\n    segment_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        segment_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                            distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_segment = np.argmax(segment_scores)\n\n    # Step 2: Remove the worst segment and reinsert it in a better position\n    removed = new_solution[worst_segment]\n    new_solution = np.delete(new_solution, worst_segment)\n    best_pos = 0\n    best_improvement = 0\n\n    for i in range(n-1):\n        # Try inserting the removed node between i and i+1\n        temp_solution = np.insert(new_solution, i, removed)\n        # Calculate the change in both objectives\n        prev = temp_solution[i-1]\n        curr = temp_solution[i]\n        next_ = temp_solution[(i+1)%(n-1)]\n        delta1 = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] - \\\n                 (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n        delta2 = distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_] - \\\n                 (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n        improvement = -delta1 - delta2  # Negative because we want to minimize\n\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n\n    new_solution = np.insert(new_solution, best_pos, removed)\n\n    # Step 3: Apply adaptive 4-opt to further refine the solution\n    if np.random.rand() < 0.7:  # Higher probability to explore\n        a, b, c, d = np.random.choice(n, size=4, replace=False)\n        a, b, c, d = sorted([a, b, c, d])\n        # Try different 4-opt configurations\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b][::-1], new_solution[b:c], new_solution[c:d][::-1], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[c:d], new_solution[b:c], new_solution[a:b], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c][::-1], new_solution[a:b], new_solution[c:d], new_solution[d:]])\n        ]\n        # Evaluate all options and select the best one\n        best_option = new_solution\n        best_score = combined_score((sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)),\n                                    sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))))\n        for option in options:\n            score1 = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n))\n            score2 = sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            current_score = combined_score((score1, score2))\n            if current_score < best_score:\n                best_score = current_score\n                best_option = option\n        new_solution = best_option\n\n    # Step 4: Perform a biased edge swap to improve both objectives\n    if np.random.rand() < 0.5:\n        # Find the worst edge (highest sum of distances in both objectives)\n        edge_scores = np.zeros(n)\n        for i in range(n):\n            prev = new_solution[i-1]\n            curr = new_solution[i]\n            edge_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_2[prev, curr]\n        worst_edge = np.argmax(edge_scores)\n\n        # Find the best swap partner that improves both objectives\n        best_swap = worst_edge\n        best_improvement = 0\n\n        for i in range(n):\n            if i != worst_edge and abs(i - worst_edge) > 1:  # Ensure non-adjacent nodes\n                # Calculate the change in both objectives for this swap\n                prev_worst = new_solution[(worst_edge-1)%n]\n                next_worst = new_solution[(worst_edge+1)%n]\n                prev_i = new_solution[(i-1)%n]\n                next_i = new_solution[(i+1)%n]\n\n                old_cost1 = distance_matrix_1[prev_worst, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[i]] + distance_matrix_1[new_solution[i], next_i]\n                new_cost1 = distance_matrix_1[prev_worst, new_solution[i]] + distance_matrix_1[new_solution[i], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_i]\n                delta1 = new_cost1 - old_cost1\n\n                old_cost2 = distance_matrix_2[prev_worst, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[i]] + distance_matrix_2[new_solution[i], next_i]\n                new_cost2 = distance_matrix_2[prev_worst, new_solution[i]] + distance_matrix_2[new_solution[i], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_i]\n                delta2 = new_cost2 - old_cost2\n\n                improvement = -delta1 - delta2\n\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_swap = i\n\n        if best_swap != worst_edge:\n            new_solution[worst_edge], new_solution[best_swap] = new_solution[best_swap], new_solution[worst_edge]\n\n    return new_solution\n\n",
        "score": [
            5.691282738966747,
            6.858667235229451
        ]
    },
    {
        "algorithm": "The algorithm combines objective-aware selection with a hybrid local search that prioritizes high-impact segments (weighted by combined objective costs) for biased edge reinsertion, followed by probabilistic segment reversal to explore the solution space while maintaining feasibility through validation checks. It balances exploration and exploitation through adaptive probabilities, dynamically adjusting segment reversal based on archive size, and ensures tour validity by reverting to the base solution if infeasibility occurs.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Objective-aware selection with normalized multi-objective criterion\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = 0.6 * normalized[:, 0] + 0.4 * normalized[:, 1]  # Weighted combination\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Decompose tour into critical segments based on combined objective impact\n    segment_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        segment_scores[i] = (distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]) * 0.6 + \\\n                           (distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]) * 0.4\n\n    # Step 2: Biased edge reinsertion strategy\n    for _ in range(2):  # Perform multiple reinsertions\n        # Select worst segment with probability proportional to its score\n        probs = segment_scores / segment_scores.sum()\n        worst_segment = np.random.choice(n, p=probs)\n        node = new_solution[worst_segment]\n\n        # Remove the node and find best reinsertion position\n        temp_solution = np.delete(new_solution, worst_segment)\n        best_pos = -1\n        best_improvement = -float('inf')\n\n        for i in range(n-1):\n            # Try inserting between i and i+1\n            prev = temp_solution[i-1]\n            curr = temp_solution[i]\n            next_ = temp_solution[(i+1)%(n-1)]\n\n            delta1 = (distance_matrix_1[prev, node] + distance_matrix_1[node, curr] - distance_matrix_1[prev, curr]) * 0.6\n            delta2 = (distance_matrix_2[prev, node] + distance_matrix_2[node, curr] - distance_matrix_2[prev, curr]) * 0.4\n            improvement = -(delta1 + delta2)\n\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_pos = i\n\n            # Try inserting between i+1 and next\n            delta1 = (distance_matrix_1[curr, node] + distance_matrix_1[node, next_] - distance_matrix_1[curr, next_]) * 0.6\n            delta2 = (distance_matrix_2[curr, node] + distance_matrix_2[node, next_] - distance_matrix_2[curr, next_]) * 0.4\n            improvement = -(delta1 + delta2)\n\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_pos = i+1\n\n        if best_pos != -1:\n            new_solution = np.insert(temp_solution, best_pos, node)\n\n    # Step 3: Adaptive segment reversal with decreasing probability\n    reversal_prob = 0.3 * (1 - len(archive) / (len(archive) + 10))  # Decrease as archive grows\n    if np.random.rand() < reversal_prob:\n        a, b = sorted(np.random.choice(n, 2, replace=False))\n        segment_length = min(b - a, n - (b - a))\n        if segment_length > 2:  # Only reverse meaningful segments\n            new_solution[a:b] = new_solution[a:b][::-1]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            5.686062100225063,
            6.979893744484661
        ]
    },
    {
        "algorithm": "The algorithm selects the most balanced solution from the archive (by normalizing objectives and choosing the one with the lowest sum of normalized scores), then applies a hybrid local search combining worst-segment removal and reinsertion, adaptive 4-opt moves (with 70% probability), and objective-aware edge swaps (with 50% probability). It prioritizes improving both objectives simultaneously while ensuring feasibility through careful segment removal and reinsertion.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = np.sum(normalized, axis=1)\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Step 1: Identify and remove the worst segment\n    segment_scores = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        segment_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                            distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_segment = np.argmax(segment_scores)\n    removed = new_solution[worst_segment]\n    new_solution = np.delete(new_solution, worst_segment)\n\n    # Step 2: Reinsert the removed segment in the best position\n    best_pos = 0\n    best_improvement = 0\n    for i in range(n-1):\n        temp_solution = np.insert(new_solution, i, removed)\n        prev = temp_solution[i-1]\n        curr = temp_solution[i]\n        next_ = temp_solution[(i+1)%(n-1)]\n        delta1 = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] - \\\n                (distance_matrix_1[prev, new_solution[i-1]] + distance_matrix_1[new_solution[i-1], new_solution[i]])\n        delta2 = distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_] - \\\n                (distance_matrix_2[prev, new_solution[i-1]] + distance_matrix_2[new_solution[i-1], new_solution[i]])\n        improvement = -delta1 - delta2\n        if improvement > best_improvement:\n            best_improvement = improvement\n            best_pos = i\n    new_solution = np.insert(new_solution, best_pos, removed)\n\n    # Step 3: Apply adaptive 4-opt with probability\n    if np.random.rand() < 0.7:\n        a, b, c, d = np.random.choice(n, size=4, replace=False)\n        a, b, c, d = sorted([a, b, c, d])\n        options = [\n            np.concatenate([new_solution[:a], new_solution[a:b][::-1], new_solution[b:c], new_solution[c:d][::-1], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[c:d], new_solution[b:c], new_solution[a:b], new_solution[d:]]),\n            np.concatenate([new_solution[:a], new_solution[b:c][::-1], new_solution[a:b], new_solution[c:d], new_solution[d:]])\n        ]\n        best_option = new_solution\n        best_score = sum(distance_matrix_1[new_solution[i], new_solution[(i+1)%n]] for i in range(n)) + \\\n                     sum(distance_matrix_2[new_solution[i], new_solution[(i+1)%n]] for i in range(n))\n        for option in options:\n            score = sum(distance_matrix_1[option[i], option[(i+1)%n]] for i in range(n)) + \\\n                   sum(distance_matrix_2[option[i], option[(i+1)%n]] for i in range(n))\n            if score < best_score:\n                best_score = score\n                best_option = option\n        new_solution = best_option\n\n    # Step 4: Perform objective-aware edge swap\n    if np.random.rand() < 0.5:\n        edge_scores = np.zeros(n)\n        for i in range(n):\n            prev = new_solution[i-1]\n            curr = new_solution[i]\n            edge_scores[i] = distance_matrix_1[prev, curr] + distance_matrix_2[prev, curr]\n        worst_edge = np.argmax(edge_scores)\n        best_swap = worst_edge\n        best_improvement = 0\n        for i in range(n):\n            if i != worst_edge and abs(i - worst_edge) > 1:\n                prev_worst = new_solution[(worst_edge-1)%n]\n                next_worst = new_solution[(worst_edge+1)%n]\n                prev_i = new_solution[(i-1)%n]\n                next_i = new_solution[(i+1)%n]\n                old_cost1 = distance_matrix_1[prev_worst, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[i]] + distance_matrix_1[new_solution[i], next_i]\n                new_cost1 = distance_matrix_1[prev_worst, new_solution[i]] + distance_matrix_1[new_solution[i], next_worst] + \\\n                            distance_matrix_1[prev_i, new_solution[worst_edge]] + distance_matrix_1[new_solution[worst_edge], next_i]\n                delta1 = new_cost1 - old_cost1\n                old_cost2 = distance_matrix_2[prev_worst, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[i]] + distance_matrix_2[new_solution[i], next_i]\n                new_cost2 = distance_matrix_2[prev_worst, new_solution[i]] + distance_matrix_2[new_solution[i], next_worst] + \\\n                            distance_matrix_2[prev_i, new_solution[worst_edge]] + distance_matrix_2[new_solution[worst_edge], next_i]\n                delta2 = new_cost2 - old_cost2\n                improvement = -delta1 - delta2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_swap = i\n        if best_swap != worst_edge:\n            new_solution[worst_edge], new_solution[best_swap] = new_solution[best_swap], new_solution[worst_edge]\n\n    return new_solution\n\n",
        "score": [
            5.864198351670412,
            6.953682451557423
        ]
    },
    {
        "algorithm": "The algorithm selects the most promising solution from the archive by normalizing and summing the objective values, then applies a hybrid local search combining 3-opt with an objective-aware swap prioritizing nodes with high combined distances in both objective spaces. It systematically evaluates potential swaps to improve both objectives simultaneously, ensuring feasibility through structured node selection and cost calculations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray) -> np.ndarray:\n    objectives = np.array([obj for _, obj in archive])\n    normalized = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-8)\n    scores = np.sum(normalized, axis=1)\n    selected_idx = np.argmin(scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: 3-opt with structured objective-aware selection\n    a, b, c = sorted(np.random.choice(n, 3, replace=False))\n    new_solution[b:c+1] = np.flip(new_solution[b:c+1])\n\n    # Objective-aware worst-node targeting\n    total_distances = np.zeros(n)\n    for i in range(n):\n        prev = new_solution[i-1]\n        curr = new_solution[i]\n        next_ = new_solution[(i+1)%n]\n        total_distances[i] = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_] + \\\n                             distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n    worst_node = np.argmax(total_distances)\n\n    # Find the best swap candidate (node that improves both objectives)\n    best_swap = worst_node\n    for i in range(n):\n        if i != worst_node:\n            prev = new_solution[(worst_node-1)%n]\n            curr = new_solution[worst_node]\n            next_ = new_solution[(worst_node+1)%n]\n            new_prev = new_solution[(i-1)%n]\n            new_curr = new_solution[i]\n            new_next = new_solution[(i+1)%n]\n\n            old_cost1 = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_]\n            new_cost1 = distance_matrix_1[prev, new_curr] + distance_matrix_1[new_curr, next_] + \\\n                        distance_matrix_1[new_prev, curr] + distance_matrix_1[curr, new_next]\n            delta1 = new_cost1 - old_cost1\n\n            old_cost2 = distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_]\n            new_cost2 = distance_matrix_2[prev, new_curr] + distance_matrix_2[new_curr, next_] + \\\n                        distance_matrix_2[new_prev, curr] + distance_matrix_2[curr, new_next]\n            delta2 = new_cost2 - old_cost2\n\n            if delta1 < 0 and delta2 < 0:\n                best_swap = i\n                break\n\n    if best_swap != worst_node:\n        new_solution[worst_node], new_solution[best_swap] = new_solution[best_swap], new_solution[worst_node]\n\n    return new_solution\n\n",
        "score": [
            6.166820109168404,
            5.767610019830773
        ]
    }
]