[
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 7 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm combines dominance-aware selection with adaptive local search, prioritizing solutions from the least dominated objective space while using crowding distance to identify diverse candidates. It applies hybrid segment exchanges with dynamic lengths, balancing exploration and exploitation through probabilistic 2-opt/3-opt moves, and ensures feasibility through careful segment handling. The approach dynamically adjusts segment lengths and move probabilities based on dominance ratios and objective scaling factors.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance in least dominated objective\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with probability based on dominance\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:  # 60% chance to reverse first segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:  # 40% chance to reverse second segment\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with probabilistic segment reversal\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < 0.7:  # 70% chance to reverse the segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm combines dominance-aware selection with adaptive segment-based relinking, hybrid 2-opt/3-opt moves, and dynamic acceptance criteria to optimize tri-objective TSP solutions. It prioritizes solutions from the least-dominated objective space, uses crowding distance to select diverse candidates, and applies segment exchanges with adaptive lengths based on dominance ratios. The hybrid local search operators are probabilistically chosen, and the solution is accepted based on improvement counts and tradeoff factors. The algorithm ensures feasibility by carefully handling segment exchanges and inversion operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance in least dominated objective\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with probability based on dominance\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with feasibility check\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with feasibility check\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Dynamic acceptance criteria\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    tradeoff_factor = 0.15 * np.sum([abs((new - orig)/orig) for orig, new in zip(original_costs, new_costs)])\n    accept_prob = 0.3 + 0.4 * (improvement_count / 3) - 0.2 * tradeoff_factor\n\n    if improvement_count == 0 and np.random.rand() > accept_prob:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects solutions with high crowding distance in the least dominated objective space, applies dominance-aware segment inversion with adaptive objective scaling, and uses hybrid 2-opt/3-opt moves to generate improved neighbor solutions while ensuring feasibility. It prioritizes objectives based on dominance counts, dynamically adjusts segment lengths, and balances exploration and exploitation through probabilistic 2-opt/3-opt moves, ensuring valid TSP tours by carefully handling segment exchanges and edge cases in the local search operators.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with probability based on dominance\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with feasibility check\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with feasibility check\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm implements a hybrid multi-objective local search that adaptively prioritizes objectives based on their correlation, using a 70/30 split between segment-based and edge-based perturbations, and employs a probabilistic acceptance criterion favoring solutions that improve two or more objectives with higher probability. It selects solutions from the archive based on objective correlation and applies either segment reversals or 2-opt edge exchanges, weighted by the current objective's priority.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high objective correlation using Pearson correlation\n    objectives = np.array([obj for _, obj in archive])\n    correlation_matrix = np.corrcoef(objectives.T)\n    correlation_scores = np.sum(correlation_matrix, axis=1)\n    selected_idx = np.argmax(correlation_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive objective prioritization based on correlation\n    obj_correlation = correlation_matrix[selected_idx]\n    priority_order = np.argsort(obj_correlation)[::-1]  # Highest correlation first\n    current_obj = priority_order[np.random.choice(min(3, len(priority_order)))]\n\n    # Hybrid local search with 70% segment-based and 30% edge-based perturbations\n    if np.random.rand() < 0.7:  # 70% chance for segment-based perturbation\n        segment_size = max(2, int(0.3 * n))\n        i = np.random.randint(0, n - segment_size + 1)\n        segment = new_solution[i:i+segment_size]\n\n        # Objective-aware segment reversal with correlation consideration\n        obj_values = []\n        for k in range(len(segment)-1):\n            node1, node2 = segment[k], segment[k+1]\n            obj_values.append([\n                distance_matrix_1[node1, node2] * (1 + obj_correlation[0]),\n                distance_matrix_2[node1, node2] * (1 + obj_correlation[1]),\n                distance_matrix_3[node1, node2] * (1 + obj_correlation[2])\n            ])\n\n        obj_values = np.array(obj_values)[:, current_obj]\n        worst_segment = np.argmax(obj_values)\n        new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n    else:\n        # Objective-aware edge exchange with 2-opt\n        obj_edges = []\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            obj_edges.append((\n                node1, node2,\n                distance_matrix_1[node1, node2] * (1 + obj_correlation[0]),\n                distance_matrix_2[node1, node2] * (1 + obj_correlation[1]),\n                distance_matrix_3[node1, node2] * (1 + obj_correlation[2])\n            ))\n\n        # Sort edges by current objective\n        obj_edges.sort(key=lambda x: x[current_obj + 2])\n        worst_edge = obj_edges[-1][:2]\n\n        # Find position of worst edge\n        pos = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge or\n              (new_solution[(i+1)%n], new_solution[i]) == worst_edge]\n\n        if pos:\n            pos = pos[0]\n            # Perform 2-opt move to replace worst edge\n            i, j = sorted(np.random.choice(range(n), 2, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Enhanced probabilistic acceptance\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    if improvement_count >= 2:\n        accept_prob = 0.8  # 80% for improving 2+ objectives\n    else:\n        accept_prob = 0.3 + 0.2 * improvement_count  # 30% base + 20% per objective\n\n    if improvement_count == 0 and np.random.rand() > accept_prob:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThis algorithm implements a dynamic multi-objective local search for the Tri-objective TSP, prioritizing objectives based on their dominance in the archive while alternating between segment-based perturbations and edge exchanges. It uses a weighted diversity selection to choose promising solutions and employs objective-aware perturbations (60% segment-based, 40% edge-based) with a probabilistic acceptance criterion that favors solutions improving more objectives. The method balances exploration and exploitation by dynamically adjusting perturbation strategies based on objective priorities and solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high objective diversity using weighted sum\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1 / (np.std(normalized_obj, axis=0) + 1e-10)\n    diversity_scores = np.sum(weights * normalized_obj, axis=1)\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Dynamic objective prioritization\n    obj_dominance = np.sum([obj <= archive[selected_idx][1] for _, obj in archive], axis=0) / len(archive)\n    priority_order = np.argsort(obj_dominance)\n    current_obj = priority_order[np.random.choice(min(2, len(priority_order)))]\n\n    # Adaptive local search with objective-aware perturbations\n    if np.random.rand() < 0.6:  # 60% chance for segment-based perturbation\n        segment_size = max(2, int(0.4 * n))\n        i = np.random.randint(0, n - segment_size + 1)\n        segment = new_solution[i:i+segment_size]\n\n        # Objective-aware segment reversal\n        obj_values = []\n        for k in range(len(segment)-1):\n            node1, node2 = segment[k], segment[k+1]\n            obj_values.append([\n                distance_matrix_1[node1, node2],\n                distance_matrix_2[node1, node2],\n                distance_matrix_3[node1, node2]\n            ])\n\n        if np.random.rand() < 0.7:  # 70% chance to reverse based on current objective\n            obj_values = np.array(obj_values)[:, current_obj]\n            worst_segment = np.argmax(obj_values)\n            new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n        else:\n            # Random segment reversal\n            new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n    else:\n        # Objective-aware edge exchange with 3-opt\n        obj_edges = []\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            obj_edges.append((\n                node1, node2,\n                distance_matrix_1[node1, node2],\n                distance_matrix_2[node1, node2],\n                distance_matrix_3[node1, node2]\n            ))\n\n        # Sort edges by current objective\n        obj_edges.sort(key=lambda x: x[current_obj + 2])\n        worst_edge = obj_edges[-1][:2]\n\n        # Find position of worst edge\n        pos = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge or\n              (new_solution[(i+1)%n], new_solution[i]) == worst_edge]\n\n        if pos:\n            pos = pos[0]\n            # Perform 3-opt move to replace worst edge\n            i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n\n    # Enhanced probabilistic acceptance\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    accept_prob = 0.3 + 0.4 * (improvement_count / 3)  # Base 30% + 40% per objective improved\n\n    if improvement_count == 0 and np.random.rand() > accept_prob:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm combines objective diversity selection with a hybrid local search that alternates between large-scale segment reversals and fine-grained edge exchanges, prioritizing the least-dominated objective for edge selection, while using a probabilistic acceptance criterion to balance multi-objective improvement. It dynamically adapts search strategies based on solution dominance and objective diversity, ensuring feasibility through constrained perturbations and 2-opt moves.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    objective_ranges = np.max(objectives, axis=0) - np.min(objectives, axis=0)\n    diversity_scores = np.sum(objective_ranges * objectives, axis=1)\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Calculate objective dominance\n    obj_dominance = np.sum([obj <= archive[selected_idx][1] for _, obj in archive], axis=0) / len(archive)\n    least_dominated_obj = np.argmin(obj_dominance)\n\n    # Hybrid local search with objective-aware perturbation\n    if np.random.rand() < 0.7:  # 70% chance for large-scale perturbation\n        segment_size = max(2, int(0.3 * n))\n        i = np.random.randint(0, n - segment_size + 1)\n        new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n    else:\n        # Objective-aware edge exchange\n        obj_edges = []\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            obj_edges.append((\n                node1, node2,\n                distance_matrix_1[node1, node2],\n                distance_matrix_2[node1, node2],\n                distance_matrix_3[node1, node2]\n            ))\n\n        # Sort edges by the least dominated objective\n        obj_edges.sort(key=lambda x: x[least_dominated_obj + 2])\n        worst_edge = obj_edges[-1][:2]\n\n        # Find position of worst edge\n        pos = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge or\n              (new_solution[(i+1)%n], new_solution[i]) == worst_edge]\n\n        if pos:\n            pos = pos[0]\n            # Perform 2-opt move to replace worst edge\n            i, j = sorted(np.random.choice(range(n), 2, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Probabilistic acceptance based on multi-objective improvement\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    if improvement_count < 2 and np.random.rand() > 0.4:  # Accept with 60% probability if only one objective improves\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 7 algorithm's description and the corresponding code are:\nThe heuristic selects the solution with the lowest combined objective value from the archive, then applies a multi-objective edge exchange by identifying the worst edges in each objective space and performing a 2-opt move between randomly chosen positions to generate a neighbor solution, ensuring feasibility by maintaining a valid tour structure.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the lowest combined objective value\n    selected_solution = min(archive, key=lambda x: sum(x[1]))[0].copy()\n    new_solution = selected_solution.copy()\n\n    # Apply multi-objective edge exchange\n    n = len(new_solution)\n    if n < 4:\n        return new_solution  # Too small to perform exchange\n\n    # Randomly select two edges from different objectives\n    obj1_edges = []\n    obj2_edges = []\n    obj3_edges = []\n\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        obj1_edges.append((node1, node2, distance_matrix_1[node1, node2]))\n        obj2_edges.append((node1, node2, distance_matrix_2[node1, node2]))\n        obj3_edges.append((node1, node2, distance_matrix_3[node1, node2]))\n\n    # Sort edges by their distance in each objective\n    obj1_edges.sort(key=lambda x: x[2])\n    obj2_edges.sort(key=lambda x: x[2])\n    obj3_edges.sort(key=lambda x: x[2])\n\n    # Select the worst edges from each objective\n    worst_edge1 = obj1_edges[-1][:2]\n    worst_edge2 = obj2_edges[-1][:2]\n    worst_edge3 = obj3_edges[-1][:2]\n\n    # Find positions of these edges in the tour\n    pos1 = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge1 or (new_solution[(i+1)%n], new_solution[i]) == worst_edge1]\n    pos2 = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge2 or (new_solution[(i+1)%n], new_solution[i]) == worst_edge2]\n    pos3 = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge3 or (new_solution[(i+1)%n], new_solution[i]) == worst_edge3]\n\n    # Select one position from each\n    if pos1 and pos2 and pos3:\n        pos1, pos2, pos3 = pos1[0], pos2[0], pos3[0]\n\n        # Swap nodes to create a new feasible tour\n        # This is a simplified version - a proper implementation would need more complex handling\n        # Here we just perform a 2-opt move between two random positions\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design with clear actionable steps:\n\n- **Keywords**: *Tri-Objective Adaptive Relinking, Dominance-Aware Crowding, Feasibility-Preserving Hybrid Operators, Objective-Scaled Segment Inversion*\n- **Advice**: *Select solutions with highest crowding distance in least dominated objective. Apply dominance-aware segment inversion with adaptive objective scaling. Use hybrid 2-opt/3-opt with feasibility checks. Prioritize non-dominated segments during relinking.*\n- **Avoid**: *Static weights; random swaps violating feasibility; neglecting dominance in selection; ignoring crowding distance during inversion. Over-reliance on single-objective improvements.*\n- **Explanation**: *Adaptive scaling ensures balanced Pareto progress. Feasibility checks prevent invalid tours. Hybrid operators leverage multi-objective structure. Non-dominated segment prioritization accelerates convergence.*\n\n*(99 words)*\n\n**Python Implementation**:\n```python\ndef select_neighbor(archive):\n    # Select solution with highest crowding distance in least dominated objective\n    least_dom_obj = np.argmin([sum(dominates(s, other) for other in archive) for s in archive])\n    selected = max(archive, key=lambda s: crowding_distance(s, least_dom_obj))\n\n    # Hybrid Local Search with adaptive objective scaling\n    tour = selected.copy()\n    for _ in range(10):\n        worst_obj = np.argmax(selected.objectives)\n        scaled_obj = selected.objectives * (1 + 0.3 * (worst_obj == np.arange(3)))\n\n        # Hybrid 2-opt/3-opt with dominance check\n        if random.random() < 0.7:\n            a, b = random.sample(range(len(tour)), 2)\n            new_tour = two_opt_swap(tour, a, b)\n        else:\n            a, b, c = sorted(random.sample(range(len(tour)), 3))\n            new_tour = three_opt_inversion(tour, a, b, c)\n\n        if any(new_tour.objectives < scaled_obj) and is_valid(new_tour):\n            tour = new_tour\n\n    return tour\n```\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 301,
        "algorithm": "The algorithm combines dominance-aware selection with crowding distance to identify promising solutions, then applies a hybrid local search that adaptively alternates between objective-scaled segment inversions and multi-objective edge exchanges, using dynamic objective prioritization and probabilistic acceptance to balance Pareto progress while maintaining tour feasibility through constrained perturbations and feasibility checks. It prioritizes the least dominated objective for selection and uses adaptive segment lengths and hybrid 2-opt/3-opt moves based on dominance ratios, with probabilistic acceptance of solutions that show balanced improvement across all objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts and least dominated objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance in least dominated objective\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with probability based on dominance\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:  # 60% chance to reverse first segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:  # 40% chance to reverse second segment\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with probabilistic segment reversal\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < 0.7:  # 70% chance to reverse the segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Multi-objective edge exchange\n    obj_edges = []\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        obj_edges.append((\n            node1, node2,\n            distance_matrix_1[node1, node2],\n            distance_matrix_2[node1, node2],\n            distance_matrix_3[node1, node2]\n        ))\n\n    # Sort edges by current objective\n    current_obj = np.random.choice(3)\n    obj_edges.sort(key=lambda x: x[current_obj + 2])\n    worst_edge = obj_edges[-1][:2]\n\n    # Find position of worst edge\n    pos = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge or\n          (new_solution[(i+1)%n], new_solution[i]) == worst_edge]\n\n    if pos:\n        pos = pos[0]\n        # Perform 2-opt move to replace worst edge\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Enhanced probabilistic acceptance\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    tradeoff_factor = 0.15 * np.sum([abs((new - orig)/orig) for orig, new in zip(original_costs, new_costs)])\n    accept_prob = 0.3 + 0.4 * (improvement_count / 3) - 0.2 * tradeoff_factor\n\n    if improvement_count == 0 and np.random.rand() > accept_prob:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.6467182417304788,
            0.33224514722824094
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts and least dominated objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance in least dominated objective\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with probability based on dominance\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:  # 60% chance to reverse first segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:  # 40% chance to reverse second segment\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with probabilistic segment reversal\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < 0.7:  # 70% chance to reverse the segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Multi-objective edge exchange\n    obj_edges = []\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        obj_edges.append((\n            node1, node2,\n            distance_matrix_1[node1, node2],\n            distance_matrix_2[node1, node2],\n            distance_matrix_3[node1, node2]\n        ))\n\n    # Sort edges by current objective\n    current_obj = np.random.choice(3)\n    obj_edges.sort(key=lambda x: x[current_obj + 2])\n    worst_edge = obj_edges[-1][:2]\n\n    # Find position of worst edge\n    pos = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge or\n          (new_solution[(i+1)%n], new_solution[i]) == worst_edge]\n\n    if pos:\n        pos = pos[0]\n        # Perform 2-opt move to replace worst edge\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Enhanced probabilistic acceptance\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    tradeoff_factor = 0.15 * np.sum([abs((new - orig)/orig) for orig, new in zip(original_costs, new_costs)])\n    accept_prob = 0.3 + 0.4 * (improvement_count / 3) - 0.2 * tradeoff_factor\n\n    if improvement_count == 0 and np.random.rand() > accept_prob:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe heuristic selects the solution with the lowest combined objective value from the archive and applies a hybrid local search (70% 2-opt, 30% 3-opt) to generate a neighbor, ensuring feasibility by always reversing or reordering segments of the tour. The selection prioritizes solutions with minimal total cost, while the local search balances exploration (random segment selection) and exploitation (reversing segments) to improve multi-objective performance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the lowest combined objective value\n    selected_idx = np.argmin([sum(obj) for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Apply hybrid local search: 2-opt or 3-opt based on a random choice\n    n = len(new_solution)\n    if n < 4:\n        # For small instances, just swap two nodes\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n    else:\n        # With 70% probability, apply 2-opt, else 3-opt\n        if np.random.rand() < 0.7:\n            # 2-opt move\n            i, j = sorted(np.random.choice(n, 2, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n        else:\n            # 3-opt move\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segment1 = new_solution[i:j]\n            segment2 = new_solution[j:k]\n            new_solution[i:k] = np.concatenate([segment2, segment1])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects the most crowding-distance-promising solution from the least dominated objective, applies an adaptive segment inversion operator with dynamic objective scaling, and employs a hybrid 2-opt/3-opt local search with dominance-aware move probabilities to generate high-quality multi-objective neighbors while maintaining feasibility. It prioritizes solutions with lower dominance counts in the least dominated objective and uses crowding distance to identify promising regions for improvement, while dynamically adjusting segment lengths and move probabilities based on dominance ratios. The hybrid local search ensures both exploration and exploitation across all objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in least dominated objective\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment inversion with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes[::-1]\n                new_solution[best_segment:best_end] = worst_segment_nodes[::-1]\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes[::-1].copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes[::-1].copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/3-opt with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if (i+1) <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines dominance-aware selection with adaptive segment relinking to optimize a tri-objective TSP, prioritizing segments in the least-dominated objective space while dynamically adjusting segment lengths and applying hybrid local search operators (2-opt/3-opt) probabilistically based on dominance ratios. It ensures feasibility through careful segment exchanges and probabilistic acceptance of solutions improving two or more objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with probability based on dominance\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with feasibility check\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with feasibility check\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Probabilistic acceptance based on multi-objective improvement\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    if improvement_count < 2 and np.random.rand() > 0.4:  # Accept with 60% probability if only one objective improves\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm combines dominance-aware selection with an adaptive segment relinking strategy, prioritizing solutions that show high crowding distance in the least dominated objective. It then applies a hybrid local search blending 2-opt and 3-opt moves with dominance-scaled segment lengths, ensuring feasibility through non-overlapping segment inversions and adaptive move probabilities to balance exploration and exploitation across all three objectives. The selection process favors solutions with better crowding distance in the least dominated objective, while the local search dynamically adapts segment lengths and move probabilities based on dominance relationships.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in least dominated objective\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment inversion with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes[::-1]\n                new_solution[best_segment:best_end] = worst_segment_nodes[::-1]\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes[::-1].copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes[::-1].copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/3-opt with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if (i+1) <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive segment-based perturbations with dominance-aware edge swaps, prioritizing the most diverse objective dimension while dynamically adjusting segment lengths and swap probabilities based on improvement potential. It selects solutions with high crowding distance in the chosen objective and applies hybrid 2-opt/4-opt moves, with segment-based reversals that adapt to historical improvement rates, ensuring feasibility through careful tour manipulation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate objective diversity and select most diverse dimension\n    obj_std = np.std(objectives, axis=0)\n    selected_obj = np.argmax(obj_std)\n\n    # Calculate normalized improvement potential\n    obj_ranges = np.max(objectives, axis=0) - np.min(objectives, axis=0)\n    improvement_potential = obj_ranges / (np.sum(obj_ranges) + 1e-8)\n\n    # Select solution with highest crowding distance in selected objective\n    normalized_obj = (objectives[:, selected_obj] - np.min(objectives[:, selected_obj])) / (np.max(objectives[:, selected_obj]) - np.min(objectives[:, selected_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Dynamic segment length based on improvement potential\n    segment_length = max(2, min(6, int(4 * improvement_potential[selected_obj] + 2)))\n\n    # Find worst and best segments in selected objective\n    worst_segment = None\n    worst_score = -np.inf\n    best_segment = None\n    best_score = np.inf\n\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = distance_matrices[selected_obj][node1, node2]\n\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n        if score < best_score:\n            best_score = score\n            best_segment = i\n\n    if worst_segment is not None and best_segment is not None:\n        worst_end = (worst_segment + segment_length) % n\n        best_end = (best_segment + segment_length) % n\n\n        if worst_segment < worst_end:\n            worst_segment_nodes = new_solution[worst_segment:worst_end]\n        else:\n            worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n        if best_segment < best_end:\n            best_segment_nodes = new_solution[best_segment:best_end]\n        else:\n            best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n        if worst_segment < worst_end and best_segment < best_end:\n            new_solution[worst_segment:worst_end] = best_segment_nodes\n            new_solution[best_segment:best_end] = worst_segment_nodes\n        else:\n            if worst_segment > worst_end:\n                temp = worst_segment_nodes.copy()\n                new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n            if best_segment > best_end:\n                temp = best_segment_nodes.copy()\n                new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/4-opt with improvement-aware probability\n    if np.random.rand() < 0.6 * improvement_potential[selected_obj]:\n        # 4-opt move\n        i, j, k, l = sorted(np.random.choice(range(n), 4, replace=False))\n        if (i+1) <= j and (j+1) <= k and (k+1) <= l:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[k:l+1] = new_solution[k:l+1][::-1]\n    else:\n        # 2-opt move with segment-based selection\n        segment_start = np.random.randint(0, n - segment_length)\n        segment_end = (segment_start + segment_length) % n\n        if segment_start < segment_end:\n            new_solution[segment_start:segment_end] = new_solution[segment_start:segment_end][::-1]\n        else:\n            temp = new_solution[segment_start:].copy()\n            new_solution[segment_start:] = new_solution[:segment_end][::-1]\n            new_solution[:segment_end] = temp[::-1]\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm combines dominance-aware selection with multi-objective segment inversion, prioritizing solutions in the least dominated objective space and applying adaptive segment exchanges between worst and best segments across different objectives, while also incorporating hybrid 2-opt/3-opt moves and adaptive relinking to preserve common segments between solutions. It dynamically adjusts segment lengths and move probabilities based on dominance ratios, ensuring exploration and exploitation balance through dominance-aware parameter adaptation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:  # 60% chance to reverse first segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:  # 40% chance to reverse second segment\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with probabilistic segment reversal\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < 0.7:  # 70% chance to reverse the segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Multi-objective adaptive relinking\n    if np.random.rand() < 0.3:  # 30% chance to perform relinking\n        # Select a reference solution from the archive\n        ref_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n        ref_solution = archive[ref_idx][0]\n\n        # Identify common segments between base and reference solutions\n        common_segments = []\n        for i in range(n):\n            if new_solution[i] == ref_solution[i] and new_solution[(i+1)%n] == ref_solution[(i+1)%n]:\n                common_segments.append(i)\n\n        if common_segments:\n            # Select a random common segment to preserve\n            segment_to_preserve = np.random.choice(common_segments)\n            segment_length = min(3, n // 4)  # Preserve up to 3 nodes from the common segment\n\n            # Create a new solution by combining segments from base and reference\n            preserved_nodes = new_solution[segment_to_preserve:segment_to_preserve+segment_length]\n            remaining_nodes = [node for node in ref_solution if node not in preserved_nodes]\n\n            # Reconstruct the tour\n            new_solution = np.concatenate([preserved_nodes, remaining_nodes])\n            new_solution = np.roll(new_solution, -segment_to_preserve)\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design with clear actionable steps:\n\n- **Keywords**: *Tri-Objective Dominance-Aware Relinking, Adaptive Crowding-Scaled Swaps, Feasibility-Preserving Hybrid Operators, Objective-Scaled Segment Inversion*\n- **Advice**: *Select solutions with highest crowding distance in least dominated objective. Apply dominance-aware segment inversion with adaptive objective scaling. Use hybrid 2-opt/3-opt with feasibility checks. Prioritize non-dominated segments during relinking.*\n- **Avoid**: *Static weights; random swaps violating feasibility; neglecting dominance in selection; ignoring crowding distance during inversion. Over-reliance on single-objective improvements.*\n- **Explanation**: *Adaptive scaling ensures balanced Pareto progress. Feasibility checks prevent invalid tours. Hybrid operators leverage multi-objective structure. Non-dominated segment prioritization accelerates convergence.*\n\n*(99 words)*\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 302,
        "algorithm": "The algorithm selects solutions with high crowding distance in the least dominated objective, applies dominance-aware segment inversion with adaptive objective scaling, and uses hybrid 2-opt/3-opt moves to generate multi-objective neighbors while preserving feasibility through careful tour manipulation. It prioritizes the least dominated objective (selected via dominance counts) and focuses on improving segments that show promise in other objectives, balancing exploration with exploitation through probabilistic segment reversal and preservation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment inversion with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes[::-1]\n                new_solution[best_segment:best_end] = worst_segment_nodes[::-1]\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes[::-1].copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes[::-1].copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/3-opt move with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:  # 60% chance to reverse first segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:  # 40% chance to reverse second segment\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with probabilistic segment reversal\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < 0.7:  # 70% chance to reverse the segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Probabilistic segment preservation for multi-objective improvement\n    if np.random.rand() < 0.3:  # 30% chance to preserve segments\n        # Identify segments that improve at least two objectives\n        preserved_segments = []\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            improvements = 0\n            for obj_idx in range(3):\n                if distance_matrices[obj_idx][node1, node2] < distance_matrices[obj_idx][base_solution[i], base_solution[(i+1)%n]]:\n                    improvements += 1\n            if improvements >= 2:\n                preserved_segments.append(i)\n\n        if preserved_segments:\n            # Preserve a random segment that improves multiple objectives\n            segment_to_preserve = np.random.choice(preserved_segments)\n            preserved_length = min(3, segment_length)\n            preserved_nodes = new_solution[segment_to_preserve:segment_to_preserve+preserved_length]\n\n            # Reconstruct the tour while preserving the segment\n            remaining_nodes = [node for node in base_solution if node not in preserved_nodes]\n            new_solution = np.concatenate([preserved_nodes, remaining_nodes])\n            new_solution = np.roll(new_solution, -segment_to_preserve)\n\n    return new_solution\n\n",
        "score": [
            -0.5166824688093712,
            0.3290159463882446
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment inversion with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes[::-1]\n                new_solution[best_segment:best_end] = worst_segment_nodes[::-1]\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes[::-1].copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes[::-1].copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/3-opt move with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:  # 60% chance to reverse first segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:  # 40% chance to reverse second segment\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with probabilistic segment reversal\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < 0.7:  # 70% chance to reverse the segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Probabilistic segment preservation for multi-objective improvement\n    if np.random.rand() < 0.3:  # 30% chance to preserve segments\n        # Identify segments that improve at least two objectives\n        preserved_segments = []\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            improvements = 0\n            for obj_idx in range(3):\n                if distance_matrices[obj_idx][node1, node2] < distance_matrices[obj_idx][base_solution[i], base_solution[(i+1)%n]]:\n                    improvements += 1\n            if improvements >= 2:\n                preserved_segments.append(i)\n\n        if preserved_segments:\n            # Preserve a random segment that improves multiple objectives\n            segment_to_preserve = np.random.choice(preserved_segments)\n            preserved_length = min(3, segment_length)\n            preserved_nodes = new_solution[segment_to_preserve:segment_to_preserve+preserved_length]\n\n            # Reconstruct the tour while preserving the segment\n            remaining_nodes = [node for node in base_solution if node not in preserved_nodes]\n            new_solution = np.concatenate([preserved_nodes, remaining_nodes])\n            new_solution = np.roll(new_solution, -segment_to_preserve)\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines adaptive segment-based perturbations with dominance-aware edge swaps, prioritizing the most diverse objective dimension while dynamically adjusting segment lengths and swap probabilities based on improvement potential. It selects solutions with high crowding distance in the chosen objective and applies hybrid 2-opt/4-opt moves, with segment-based reversals that adapt to historical improvement rates, ensuring feasibility through careful tour manipulation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate objective diversity and select most diverse dimension\n    obj_std = np.std(objectives, axis=0)\n    selected_obj = np.argmax(obj_std)\n\n    # Calculate normalized improvement potential\n    obj_ranges = np.max(objectives, axis=0) - np.min(objectives, axis=0)\n    improvement_potential = obj_ranges / (np.sum(obj_ranges) + 1e-8)\n\n    # Select solution with highest crowding distance in selected objective\n    normalized_obj = (objectives[:, selected_obj] - np.min(objectives[:, selected_obj])) / (np.max(objectives[:, selected_obj]) - np.min(objectives[:, selected_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Dynamic segment length based on improvement potential\n    segment_length = max(2, min(6, int(4 * improvement_potential[selected_obj] + 2)))\n\n    # Find worst and best segments in selected objective\n    worst_segment = None\n    worst_score = -np.inf\n    best_segment = None\n    best_score = np.inf\n\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = distance_matrices[selected_obj][node1, node2]\n\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n        if score < best_score:\n            best_score = score\n            best_segment = i\n\n    if worst_segment is not None and best_segment is not None:\n        worst_end = (worst_segment + segment_length) % n\n        best_end = (best_segment + segment_length) % n\n\n        if worst_segment < worst_end:\n            worst_segment_nodes = new_solution[worst_segment:worst_end]\n        else:\n            worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n        if best_segment < best_end:\n            best_segment_nodes = new_solution[best_segment:best_end]\n        else:\n            best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n        if worst_segment < worst_end and best_segment < best_end:\n            new_solution[worst_segment:worst_end] = best_segment_nodes\n            new_solution[best_segment:best_end] = worst_segment_nodes\n        else:\n            if worst_segment > worst_end:\n                temp = worst_segment_nodes.copy()\n                new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n            if best_segment > best_end:\n                temp = best_segment_nodes.copy()\n                new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/4-opt with improvement-aware probability\n    if np.random.rand() < 0.6 * improvement_potential[selected_obj]:\n        # 4-opt move\n        i, j, k, l = sorted(np.random.choice(range(n), 4, replace=False))\n        if (i+1) <= j and (j+1) <= k and (k+1) <= l:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[k:l+1] = new_solution[k:l+1][::-1]\n    else:\n        # 2-opt move with segment-based selection\n        segment_start = np.random.randint(0, n - segment_length)\n        segment_end = (segment_start + segment_length) % n\n        if segment_start < segment_end:\n            new_solution[segment_start:segment_end] = new_solution[segment_start:segment_end][::-1]\n        else:\n            temp = new_solution[segment_start:].copy()\n            new_solution[segment_start:] = new_solution[:segment_end][::-1]\n            new_solution[:segment_end] = temp[::-1]\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 303,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Precompute objective statistics\n    obj_std = np.std(objectives, axis=0)\n    selected_obj = np.argmax(obj_std)\n    obj_min = np.min(objectives[:, selected_obj])\n    obj_max = np.max(objectives[:, selected_obj])\n    obj_range = obj_max - obj_min\n\n    if obj_range == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_obj = (objectives[:, selected_obj] - obj_min) / obj_range\n        sorted_idx = np.argsort(normalized_obj)\n        crowding_dist = np.zeros(len(archive))\n        crowding_dist[sorted_idx[0]] = np.inf\n        crowding_dist[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n        selected_idx = np.argmax(crowding_dist)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Precompute edge scores\n    selected_matrix = distance_matrices[selected_obj]\n    edge_scores = np.array([selected_matrix[new_solution[i], new_solution[(i+1)%n]] for i in range(n)])\n\n    worst_segment = np.argmax(edge_scores)\n    best_segment = np.argmin(edge_scores)\n\n    # Simple 2-opt move\n    i, j = sorted(np.random.choice(range(n), 2, replace=False))\n    if i < j:\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.45377789635474597,
            0.4162373900413513
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Precompute objective statistics\n    obj_std = np.std(objectives, axis=0)\n    selected_obj = np.argmax(obj_std)\n    obj_min = np.min(objectives[:, selected_obj])\n    obj_max = np.max(objectives[:, selected_obj])\n    obj_range = obj_max - obj_min\n\n    if obj_range == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_obj = (objectives[:, selected_obj] - obj_min) / obj_range\n        sorted_idx = np.argsort(normalized_obj)\n        crowding_dist = np.zeros(len(archive))\n        crowding_dist[sorted_idx[0]] = np.inf\n        crowding_dist[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive)-1):\n            crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n        selected_idx = np.argmax(crowding_dist)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Precompute edge scores\n    selected_matrix = distance_matrices[selected_obj]\n    edge_scores = np.array([selected_matrix[new_solution[i], new_solution[(i+1)%n]] for i in range(n)])\n\n    worst_segment = np.argmax(edge_scores)\n    best_segment = np.argmin(edge_scores)\n\n    # Simple 2-opt move\n    i, j = sorted(np.random.choice(range(n), 2, replace=False))\n    if i < j:\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:  # 60% chance to reverse first segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:  # 40% chance to reverse second segment\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with probabilistic segment reversal\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < 0.7:  # 70% chance to reverse the segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nThe algorithm combines dominance-aware selection with a multi-objective segment relinking strategy, prioritizing segments in the least-dominated objective space while adaptively balancing objectives through crowding distance and hybrid 2-opt/4-opt moves, ensuring feasibility through constrained neighborhood exploration. It dynamically adjusts segment lengths and move probabilities based on dominance counts, with a focus on improving the least-dominated objective while maintaining diversity across the Pareto front. The algorithm alternates between segment exchanges and local search moves, scaling move selection probabilities based on dominance ratios to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in least dominated objective\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/4-opt with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.6 + 0.2 * dominance_ratio:\n        # 4-opt move\n        i, j, k, l = sorted(np.random.choice(range(n), 4, replace=False))\n        if (i+1) <= j and (j+1) <= k and (k+1) <= l:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[k:l+1] = new_solution[k:l+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if (i+1) <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design with clear actionable steps:\n\n- **Keywords**: *Tri-Objective Dominance-Aware Relinking, Adaptive Crowding-Scaled Swaps, Feasibility-Preserving Hybrid Operators, Objective-Scaled Segment Inversion*\n- **Advice**: *Select solutions with highest crowding distance in least dominated objective. Apply dominance-aware segment inversion with adaptive objective scaling. Use hybrid 2-opt/3-opt with feasibility checks. Prioritize non-dominated segments during relinking.*\n- **Avoid**: *Static weights; random swaps violating feasibility; neglecting dominance in selection; ignoring crowding distance during inversion. Over-reliance on single-objective improvements.*\n- **Explanation**: *Adaptive scaling ensures balanced Pareto progress. Feasibility checks prevent invalid tours. Hybrid operators leverage multi-objective structure. Non-dominated segment prioritization accelerates convergence.*\n\n*(99 words)*\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 304,
        "algorithm": "The algorithm combines dominance-aware selection with a hybrid local search strategy, prioritizing segments in the least-dominated objective space while adaptively balancing objectives through crowding distance and segment exchanges. It dynamically adjusts segment lengths and move probabilities based on dominance counts, alternating between segment relinking and inversion operations to improve solution quality across all objectives while maintaining feasibility. The least-dominated objective is emphasized, with occasional objective-scaled inversions to enhance exploration.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in least dominated objective\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Novel objective-scaled segment inversion\n    if np.random.rand() < 0.7:\n        # Select a segment to invert\n        start = np.random.randint(0, n)\n        length = np.random.randint(2, min(5, n))\n        end = (start + length) % n\n\n        # Determine which objective to prioritize for inversion\n        obj_to_invert = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        invert_matrix = distance_matrices[obj_to_invert]\n\n        # Calculate potential improvement\n        current_segment_score = 0\n        inverted_segment_score = 0\n        for i in range(start, end):\n            node1 = new_solution[i]\n            node2 = new_solution[(i+1)%n]\n            current_segment_score += invert_matrix[node1, node2]\n\n        # Create inverted segment\n        inverted_segment = new_solution[start:end][::-1]\n        for i in range(len(inverted_segment)-1):\n            node1 = inverted_segment[i]\n            node2 = inverted_segment[i+1]\n            inverted_segment_score += invert_matrix[node1, node2]\n\n        # Apply inversion if beneficial\n        if inverted_segment_score < current_segment_score:\n            new_solution[start:end] = inverted_segment\n\n    return new_solution\n\n",
        "score": [
            -0.7247411171865572,
            0.26422164440155027
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in least dominated objective\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Novel objective-scaled segment inversion\n    if np.random.rand() < 0.7:\n        # Select a segment to invert\n        start = np.random.randint(0, n)\n        length = np.random.randint(2, min(5, n))\n        end = (start + length) % n\n\n        # Determine which objective to prioritize for inversion\n        obj_to_invert = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        invert_matrix = distance_matrices[obj_to_invert]\n\n        # Calculate potential improvement\n        current_segment_score = 0\n        inverted_segment_score = 0\n        for i in range(start, end):\n            node1 = new_solution[i]\n            node2 = new_solution[(i+1)%n]\n            current_segment_score += invert_matrix[node1, node2]\n\n        # Create inverted segment\n        inverted_segment = new_solution[start:end][::-1]\n        for i in range(len(inverted_segment)-1):\n            node1 = inverted_segment[i]\n            node2 = inverted_segment[i+1]\n            inverted_segment_score += invert_matrix[node1, node2]\n\n        # Apply inversion if beneficial\n        if inverted_segment_score < current_segment_score:\n            new_solution[start:end] = inverted_segment\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines dominance-aware selection with a multi-objective segment relinking strategy, prioritizing segments in the least-dominated objective space while adaptively balancing objectives through crowding distance and hybrid 2-opt/4-opt moves, ensuring feasibility through constrained neighborhood exploration. It dynamically adjusts segment lengths and move probabilities based on dominance counts, with a focus on improving the least-dominated objective while maintaining diversity across the Pareto front. The algorithm alternates between segment exchanges and local search moves, scaling move selection probabilities based on dominance ratios to balance exploration and exploitation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in least dominated objective\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/4-opt with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.6 + 0.2 * dominance_ratio:\n        # 4-opt move\n        i, j, k, l = sorted(np.random.choice(range(n), 4, replace=False))\n        if (i+1) <= j and (j+1) <= k and (k+1) <= l:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[k:l+1] = new_solution[k:l+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if (i+1) <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 305,
        "algorithm": "The algorithm employs an adaptive multi-objective path relinking strategy that dynamically selects solutions based on dominance scores and crowding distance in a primary objective, then applies hybrid segment-swapping and edge-swap operations tailored to the dominance ratios and objective-space correlations between the three objectives. It prioritizes less-dominated objectives while maintaining diversity through crowding-distance-aware selection and balances between local search and segment relinking based on dominance ratios and correlations. The method ensures feasibility by always generating valid TSP tours through carefully designed segment operations and edge swaps.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n    n = len(archive[0][0])\n\n    # Calculate dominance scores and objective correlations\n    dominance_scores = np.zeros(3)\n    obj_correlations = np.zeros((3, 3))\n    for i in range(3):\n        for j in range(3):\n            if i != j:\n                better = np.sum((objectives[:, i] <= objectives[:, j]) & (objectives[:, i] < objectives[:, j]))\n                worse = np.sum((objectives[:, i] >= objectives[:, j]) & (objectives[:, i] > objectives[:, j]))\n                dominance_scores[i] += better - worse\n                obj_correlations[i, j] = np.corrcoef(objectives[:, i], objectives[:, j])[0, 1]\n\n    # Select primary objective based on dominance and correlation\n    primary_obj = np.argmax(dominance_scores)\n    secondary_obj = np.argmax([np.abs(obj_correlations[primary_obj, j]) for j in range(3) if j != primary_obj])\n\n    # Calculate crowding distance in primary objective\n    crowding_dist = np.zeros(len(archive))\n    sorted_idx = np.argsort(objectives[:, primary_obj])\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = (objectives[sorted_idx[i+1], primary_obj] - objectives[sorted_idx[i-1], primary_obj])\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment selection based on dominance and correlation\n    segment_length = max(2, min(5, int(3 * (1 - dominance_scores[primary_obj] / (sum(dominance_scores) + 1e-8)) + 1)))\n    correlation_factor = 1 + 0.5 * obj_correlations[primary_obj, secondary_obj]\n\n    # Find worst and best segments\n    worst_segment = None\n    worst_score = -np.inf\n    best_segment = None\n    best_score = np.inf\n\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        primary_score = distance_matrices[primary_obj][node1, node2]\n        secondary_score = distance_matrices[secondary_obj][node1, node2]\n\n        combined_score = primary_score + correlation_factor * secondary_score\n\n        if combined_score > worst_score:\n            worst_score = combined_score\n            worst_segment = i\n\n        if combined_score < best_score:\n            best_score = combined_score\n            best_segment = i\n\n    if worst_segment is not None and best_segment is not None:\n        worst_end = (worst_segment + segment_length) % n\n        best_end = (best_segment + segment_length) % n\n\n        if worst_segment < worst_end:\n            worst_segment_nodes = new_solution[worst_segment:worst_end]\n        else:\n            worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n        if best_segment < best_end:\n            best_segment_nodes = new_solution[best_segment:best_end]\n        else:\n            best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n        if worst_segment < worst_end and best_segment < best_end:\n            new_solution[worst_segment:worst_end] = best_segment_nodes\n            new_solution[best_segment:best_end] = worst_segment_nodes\n        else:\n            if worst_segment > worst_end:\n                temp = worst_segment_nodes.copy()\n                new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n            if best_segment > best_end:\n                temp = best_segment_nodes.copy()\n                new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid edge-swap operation based on dominance and correlation\n    dominance_ratio = dominance_scores[primary_obj] / (sum(dominance_scores) + 1e-8)\n    if np.random.rand() < 0.7 - 0.3 * correlation_factor:\n        # 3-opt move\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if i+1 <= j and j+1 <= k:\n            segment1 = new_solution[i:j+1]\n            segment2 = new_solution[j+1:k+1]\n            new_solution[i:k+1] = np.concatenate([segment2, segment1])\n    else:\n        # Adaptive 2-opt move\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < dominance_ratio:\n                # Reverse segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            else:\n                # Shift segment\n                segment = new_solution[i:j+1]\n                new_solution[i:j+1] = np.roll(segment, np.random.randint(1, len(segment)))\n\n    return new_solution\n\n",
        "score": [
            -0.637342776727788,
            0.4937251448631287
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n    n = len(archive[0][0])\n\n    # Calculate dominance scores and objective correlations\n    dominance_scores = np.zeros(3)\n    obj_correlations = np.zeros((3, 3))\n    for i in range(3):\n        for j in range(3):\n            if i != j:\n                better = np.sum((objectives[:, i] <= objectives[:, j]) & (objectives[:, i] < objectives[:, j]))\n                worse = np.sum((objectives[:, i] >= objectives[:, j]) & (objectives[:, i] > objectives[:, j]))\n                dominance_scores[i] += better - worse\n                obj_correlations[i, j] = np.corrcoef(objectives[:, i], objectives[:, j])[0, 1]\n\n    # Select primary objective based on dominance and correlation\n    primary_obj = np.argmax(dominance_scores)\n    secondary_obj = np.argmax([np.abs(obj_correlations[primary_obj, j]) for j in range(3) if j != primary_obj])\n\n    # Calculate crowding distance in primary objective\n    crowding_dist = np.zeros(len(archive))\n    sorted_idx = np.argsort(objectives[:, primary_obj])\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = (objectives[sorted_idx[i+1], primary_obj] - objectives[sorted_idx[i-1], primary_obj])\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment selection based on dominance and correlation\n    segment_length = max(2, min(5, int(3 * (1 - dominance_scores[primary_obj] / (sum(dominance_scores) + 1e-8)) + 1)))\n    correlation_factor = 1 + 0.5 * obj_correlations[primary_obj, secondary_obj]\n\n    # Find worst and best segments\n    worst_segment = None\n    worst_score = -np.inf\n    best_segment = None\n    best_score = np.inf\n\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        primary_score = distance_matrices[primary_obj][node1, node2]\n        secondary_score = distance_matrices[secondary_obj][node1, node2]\n\n        combined_score = primary_score + correlation_factor * secondary_score\n\n        if combined_score > worst_score:\n            worst_score = combined_score\n            worst_segment = i\n\n        if combined_score < best_score:\n            best_score = combined_score\n            best_segment = i\n\n    if worst_segment is not None and best_segment is not None:\n        worst_end = (worst_segment + segment_length) % n\n        best_end = (best_segment + segment_length) % n\n\n        if worst_segment < worst_end:\n            worst_segment_nodes = new_solution[worst_segment:worst_end]\n        else:\n            worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n        if best_segment < best_end:\n            best_segment_nodes = new_solution[best_segment:best_end]\n        else:\n            best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n        if worst_segment < worst_end and best_segment < best_end:\n            new_solution[worst_segment:worst_end] = best_segment_nodes\n            new_solution[best_segment:best_end] = worst_segment_nodes\n        else:\n            if worst_segment > worst_end:\n                temp = worst_segment_nodes.copy()\n                new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n            if best_segment > best_end:\n                temp = best_segment_nodes.copy()\n                new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid edge-swap operation based on dominance and correlation\n    dominance_ratio = dominance_scores[primary_obj] / (sum(dominance_scores) + 1e-8)\n    if np.random.rand() < 0.7 - 0.3 * correlation_factor:\n        # 3-opt move\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if i+1 <= j and j+1 <= k:\n            segment1 = new_solution[i:j+1]\n            segment2 = new_solution[j+1:k+1]\n            new_solution[i:k+1] = np.concatenate([segment2, segment1])\n    else:\n        # Adaptive 2-opt move\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < dominance_ratio:\n                # Reverse segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            else:\n                # Shift segment\n                segment = new_solution[i:j+1]\n                new_solution[i:j+1] = np.roll(segment, np.random.randint(1, len(segment)))\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines dominance-aware selection with a multi-objective segment relinking strategy, prioritizing segments in the least-dominated objective space while adaptively balancing objectives through crowding distance and hybrid 2-opt/4-opt moves, ensuring feasibility through constrained neighborhood exploration. It dynamically adjusts segment lengths and move probabilities based on dominance counts, with a focus on improving the least-dominated objective while maintaining diversity across the Pareto front. The algorithm alternates between segment exchanges and local search moves, scaling move selection probabilities based on dominance ratios to balance exploration and exploitation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in least dominated objective\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/4-opt with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.6 + 0.2 * dominance_ratio:\n        # 4-opt move\n        i, j, k, l = sorted(np.random.choice(range(n), 4, replace=False))\n        if (i+1) <= j and (j+1) <= k and (k+1) <= l:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[k:l+1] = new_solution[k:l+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if (i+1) <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 306,
        "algorithm": "This algorithm employs a multi-objective adaptive segment exchange strategy that prioritizes objectives based on dominance ranks, combining segment relinking with hybrid 3-opt/5-opt local search to balance exploration and exploitation while maintaining feasibility. It dynamically selects segments to exchange between solutions, with segment length and move probability adjusted based on dominance ranks, and scales segment selection across different objectives to improve solution quality. The method ensures feasibility by carefully handling segment boundaries and using dominance-based probabilistic selection for local search moves.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance ranks\n    dominance_ranks = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_ranks[i] += 1\n\n    # Select objective with highest dominance rank\n    selected_obj = np.argmax(dominance_ranks)\n    selected_matrix = distance_matrices[selected_obj]\n\n    # Select solution with highest crowding distance in selected objective\n    normalized_obj = (objectives[:, selected_obj] - np.min(objectives[:, selected_obj])) / (np.max(objectives[:, selected_obj]) - np.min(objectives[:, selected_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance rank\n    segment_length = max(2, min(6, int(4 * (dominance_ranks[selected_obj] / (sum(dominance_ranks) + 1)) + 3)))\n\n    # Find worst segment in selected objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != selected_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.3 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 3-opt/5-opt with dominance-based probability\n    dominance_ratio = dominance_ranks[selected_obj] / (sum(dominance_ranks) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 5-opt move\n        i, j, k, l, m = sorted(np.random.choice(range(n), 5, replace=False))\n        if (i+1) <= j and (j+1) <= k and (k+1) <= l and (l+1) <= m:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[k:l+1] = new_solution[k:l+1][::-1]\n            new_solution[l:m+1] = new_solution[l:m+1][::-1]\n    else:\n        # 3-opt move\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.7585626481161116,
            0.21429355144500734
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance ranks\n    dominance_ranks = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_ranks[i] += 1\n\n    # Select objective with highest dominance rank\n    selected_obj = np.argmax(dominance_ranks)\n    selected_matrix = distance_matrices[selected_obj]\n\n    # Select solution with highest crowding distance in selected objective\n    normalized_obj = (objectives[:, selected_obj] - np.min(objectives[:, selected_obj])) / (np.max(objectives[:, selected_obj]) - np.min(objectives[:, selected_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance rank\n    segment_length = max(2, min(6, int(4 * (dominance_ranks[selected_obj] / (sum(dominance_ranks) + 1)) + 3)))\n\n    # Find worst segment in selected objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != selected_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.3 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 3-opt/5-opt with dominance-based probability\n    dominance_ratio = dominance_ranks[selected_obj] / (sum(dominance_ranks) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 5-opt move\n        i, j, k, l, m = sorted(np.random.choice(range(n), 5, replace=False))\n        if (i+1) <= j and (j+1) <= k and (k+1) <= l and (l+1) <= m:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[k:l+1] = new_solution[k:l+1][::-1]\n            new_solution[l:m+1] = new_solution[l:m+1][::-1]\n    else:\n        # 3-opt move\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 8 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nThe algorithm combines dominance-aware selection with a multi-objective segment relinking strategy, prioritizing segments in the least-dominated objective space while adaptively balancing objectives through crowding distance and hybrid 2-opt/4-opt moves, ensuring feasibility through constrained neighborhood exploration. It dynamically adjusts segment lengths and move probabilities based on dominance counts, with a focus on improving the least-dominated objective while maintaining diversity across the Pareto front. The algorithm alternates between segment exchanges and local search moves, scaling move selection probabilities based on dominance ratios to balance exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in least dominated objective\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/4-opt with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.6 + 0.2 * dominance_ratio:\n        # 4-opt move\n        i, j, k, l = sorted(np.random.choice(range(n), 4, replace=False))\n        if (i+1) <= j and (j+1) <= k and (k+1) <= l:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[k:l+1] = new_solution[k:l+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if (i+1) <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm combines dominance-aware selection with adaptive local search, prioritizing solutions from the least dominated objective space while using crowding distance to identify diverse candidates. It applies hybrid segment exchanges with dynamic lengths, balancing exploration and exploitation through probabilistic 2-opt/3-opt moves, and ensures feasibility through careful segment handling. The approach dynamically adjusts segment lengths and move probabilities based on dominance ratios and objective scaling factors.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance in least dominated objective\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with probability based on dominance\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:  # 60% chance to reverse first segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:  # 40% chance to reverse second segment\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with probabilistic segment reversal\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < 0.7:  # 70% chance to reverse the segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines dominance-aware selection with adaptive segment-based relinking, hybrid 2-opt/3-opt moves, and dynamic acceptance criteria to optimize tri-objective TSP solutions. It prioritizes solutions from the least-dominated objective space, uses crowding distance to select diverse candidates, and applies segment exchanges with adaptive lengths based on dominance ratios. The hybrid local search operators are probabilistically chosen, and the solution is accepted based on improvement counts and tradeoff factors. The algorithm ensures feasibility by carefully handling segment exchanges and inversion operations.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance in least dominated objective\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with probability based on dominance\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with feasibility check\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with feasibility check\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Dynamic acceptance criteria\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    tradeoff_factor = 0.15 * np.sum([abs((new - orig)/orig) for orig, new in zip(original_costs, new_costs)])\n    accept_prob = 0.3 + 0.4 * (improvement_count / 3) - 0.2 * tradeoff_factor\n\n    if improvement_count == 0 and np.random.rand() > accept_prob:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects solutions with high crowding distance in the least dominated objective space, applies dominance-aware segment inversion with adaptive objective scaling, and uses hybrid 2-opt/3-opt moves to generate improved neighbor solutions while ensuring feasibility. It prioritizes objectives based on dominance counts, dynamically adjusts segment lengths, and balances exploration and exploitation through probabilistic 2-opt/3-opt moves, ensuring valid TSP tours by carefully handling segment exchanges and edge cases in the local search operators.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with probability based on dominance\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with feasibility check\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with feasibility check\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm implements a hybrid multi-objective local search that adaptively prioritizes objectives based on their correlation, using a 70/30 split between segment-based and edge-based perturbations, and employs a probabilistic acceptance criterion favoring solutions that improve two or more objectives with higher probability. It selects solutions from the archive based on objective correlation and applies either segment reversals or 2-opt edge exchanges, weighted by the current objective's priority.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high objective correlation using Pearson correlation\n    objectives = np.array([obj for _, obj in archive])\n    correlation_matrix = np.corrcoef(objectives.T)\n    correlation_scores = np.sum(correlation_matrix, axis=1)\n    selected_idx = np.argmax(correlation_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive objective prioritization based on correlation\n    obj_correlation = correlation_matrix[selected_idx]\n    priority_order = np.argsort(obj_correlation)[::-1]  # Highest correlation first\n    current_obj = priority_order[np.random.choice(min(3, len(priority_order)))]\n\n    # Hybrid local search with 70% segment-based and 30% edge-based perturbations\n    if np.random.rand() < 0.7:  # 70% chance for segment-based perturbation\n        segment_size = max(2, int(0.3 * n))\n        i = np.random.randint(0, n - segment_size + 1)\n        segment = new_solution[i:i+segment_size]\n\n        # Objective-aware segment reversal with correlation consideration\n        obj_values = []\n        for k in range(len(segment)-1):\n            node1, node2 = segment[k], segment[k+1]\n            obj_values.append([\n                distance_matrix_1[node1, node2] * (1 + obj_correlation[0]),\n                distance_matrix_2[node1, node2] * (1 + obj_correlation[1]),\n                distance_matrix_3[node1, node2] * (1 + obj_correlation[2])\n            ])\n\n        obj_values = np.array(obj_values)[:, current_obj]\n        worst_segment = np.argmax(obj_values)\n        new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n    else:\n        # Objective-aware edge exchange with 2-opt\n        obj_edges = []\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            obj_edges.append((\n                node1, node2,\n                distance_matrix_1[node1, node2] * (1 + obj_correlation[0]),\n                distance_matrix_2[node1, node2] * (1 + obj_correlation[1]),\n                distance_matrix_3[node1, node2] * (1 + obj_correlation[2])\n            ))\n\n        # Sort edges by current objective\n        obj_edges.sort(key=lambda x: x[current_obj + 2])\n        worst_edge = obj_edges[-1][:2]\n\n        # Find position of worst edge\n        pos = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge or\n              (new_solution[(i+1)%n], new_solution[i]) == worst_edge]\n\n        if pos:\n            pos = pos[0]\n            # Perform 2-opt move to replace worst edge\n            i, j = sorted(np.random.choice(range(n), 2, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Enhanced probabilistic acceptance\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    if improvement_count >= 2:\n        accept_prob = 0.8  # 80% for improving 2+ objectives\n    else:\n        accept_prob = 0.3 + 0.2 * improvement_count  # 30% base + 20% per objective\n\n    if improvement_count == 0 and np.random.rand() > accept_prob:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThis algorithm implements a dynamic multi-objective local search for the Tri-objective TSP, prioritizing objectives based on their dominance in the archive while alternating between segment-based perturbations and edge exchanges. It uses a weighted diversity selection to choose promising solutions and employs objective-aware perturbations (60% segment-based, 40% edge-based) with a probabilistic acceptance criterion that favors solutions improving more objectives. The method balances exploration and exploitation by dynamically adjusting perturbation strategies based on objective priorities and solution quality.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high objective diversity using weighted sum\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1 / (np.std(normalized_obj, axis=0) + 1e-10)\n    diversity_scores = np.sum(weights * normalized_obj, axis=1)\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Dynamic objective prioritization\n    obj_dominance = np.sum([obj <= archive[selected_idx][1] for _, obj in archive], axis=0) / len(archive)\n    priority_order = np.argsort(obj_dominance)\n    current_obj = priority_order[np.random.choice(min(2, len(priority_order)))]\n\n    # Adaptive local search with objective-aware perturbations\n    if np.random.rand() < 0.6:  # 60% chance for segment-based perturbation\n        segment_size = max(2, int(0.4 * n))\n        i = np.random.randint(0, n - segment_size + 1)\n        segment = new_solution[i:i+segment_size]\n\n        # Objective-aware segment reversal\n        obj_values = []\n        for k in range(len(segment)-1):\n            node1, node2 = segment[k], segment[k+1]\n            obj_values.append([\n                distance_matrix_1[node1, node2],\n                distance_matrix_2[node1, node2],\n                distance_matrix_3[node1, node2]\n            ])\n\n        if np.random.rand() < 0.7:  # 70% chance to reverse based on current objective\n            obj_values = np.array(obj_values)[:, current_obj]\n            worst_segment = np.argmax(obj_values)\n            new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n        else:\n            # Random segment reversal\n            new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n    else:\n        # Objective-aware edge exchange with 3-opt\n        obj_edges = []\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            obj_edges.append((\n                node1, node2,\n                distance_matrix_1[node1, node2],\n                distance_matrix_2[node1, node2],\n                distance_matrix_3[node1, node2]\n            ))\n\n        # Sort edges by current objective\n        obj_edges.sort(key=lambda x: x[current_obj + 2])\n        worst_edge = obj_edges[-1][:2]\n\n        # Find position of worst edge\n        pos = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge or\n              (new_solution[(i+1)%n], new_solution[i]) == worst_edge]\n\n        if pos:\n            pos = pos[0]\n            # Perform 3-opt move to replace worst edge\n            i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n\n    # Enhanced probabilistic acceptance\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    accept_prob = 0.3 + 0.4 * (improvement_count / 3)  # Base 30% + 40% per objective improved\n\n    if improvement_count == 0 and np.random.rand() > accept_prob:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 7 algorithm's description and the corresponding code are:\nThe algorithm combines objective diversity selection with a hybrid local search that alternates between large-scale segment reversals and fine-grained edge exchanges, prioritizing the least-dominated objective for edge selection, while using a probabilistic acceptance criterion to balance multi-objective improvement. It dynamically adapts search strategies based on solution dominance and objective diversity, ensuring feasibility through constrained perturbations and 2-opt moves.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    objective_ranges = np.max(objectives, axis=0) - np.min(objectives, axis=0)\n    diversity_scores = np.sum(objective_ranges * objectives, axis=1)\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Calculate objective dominance\n    obj_dominance = np.sum([obj <= archive[selected_idx][1] for _, obj in archive], axis=0) / len(archive)\n    least_dominated_obj = np.argmin(obj_dominance)\n\n    # Hybrid local search with objective-aware perturbation\n    if np.random.rand() < 0.7:  # 70% chance for large-scale perturbation\n        segment_size = max(2, int(0.3 * n))\n        i = np.random.randint(0, n - segment_size + 1)\n        new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n    else:\n        # Objective-aware edge exchange\n        obj_edges = []\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            obj_edges.append((\n                node1, node2,\n                distance_matrix_1[node1, node2],\n                distance_matrix_2[node1, node2],\n                distance_matrix_3[node1, node2]\n            ))\n\n        # Sort edges by the least dominated objective\n        obj_edges.sort(key=lambda x: x[least_dominated_obj + 2])\n        worst_edge = obj_edges[-1][:2]\n\n        # Find position of worst edge\n        pos = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge or\n              (new_solution[(i+1)%n], new_solution[i]) == worst_edge]\n\n        if pos:\n            pos = pos[0]\n            # Perform 2-opt move to replace worst edge\n            i, j = sorted(np.random.choice(range(n), 2, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Probabilistic acceptance based on multi-objective improvement\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    if improvement_count < 2 and np.random.rand() > 0.4:  # Accept with 60% probability if only one objective improves\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 8 algorithm's description and the corresponding code are:\nThe heuristic selects the solution with the lowest combined objective value from the archive, then applies a multi-objective edge exchange by identifying the worst edges in each objective space and performing a 2-opt move between randomly chosen positions to generate a neighbor solution, ensuring feasibility by maintaining a valid tour structure.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the lowest combined objective value\n    selected_solution = min(archive, key=lambda x: sum(x[1]))[0].copy()\n    new_solution = selected_solution.copy()\n\n    # Apply multi-objective edge exchange\n    n = len(new_solution)\n    if n < 4:\n        return new_solution  # Too small to perform exchange\n\n    # Randomly select two edges from different objectives\n    obj1_edges = []\n    obj2_edges = []\n    obj3_edges = []\n\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        obj1_edges.append((node1, node2, distance_matrix_1[node1, node2]))\n        obj2_edges.append((node1, node2, distance_matrix_2[node1, node2]))\n        obj3_edges.append((node1, node2, distance_matrix_3[node1, node2]))\n\n    # Sort edges by their distance in each objective\n    obj1_edges.sort(key=lambda x: x[2])\n    obj2_edges.sort(key=lambda x: x[2])\n    obj3_edges.sort(key=lambda x: x[2])\n\n    # Select the worst edges from each objective\n    worst_edge1 = obj1_edges[-1][:2]\n    worst_edge2 = obj2_edges[-1][:2]\n    worst_edge3 = obj3_edges[-1][:2]\n\n    # Find positions of these edges in the tour\n    pos1 = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge1 or (new_solution[(i+1)%n], new_solution[i]) == worst_edge1]\n    pos2 = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge2 or (new_solution[(i+1)%n], new_solution[i]) == worst_edge2]\n    pos3 = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge3 or (new_solution[(i+1)%n], new_solution[i]) == worst_edge3]\n\n    # Select one position from each\n    if pos1 and pos2 and pos3:\n        pos1, pos2, pos3 = pos1[0], pos2[0], pos3[0]\n\n        # Swap nodes to create a new feasible tour\n        # This is a simplified version - a proper implementation would need more complex handling\n        # Here we just perform a 2-opt move between two random positions\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design with clear actionable steps:\n\n- **Keywords**: *Tri-Objective Dominance-Aware Relinking, Adaptive Crowding-Scaled Swaps, Feasibility-Preserving Hybrid Operators, Objective-Scaled Segment Inversion*\n- **Advice**: *Select solutions with highest crowding distance in least dominated objective. Apply dominance-aware segment inversion with adaptive objective scaling. Use hybrid 2-opt/3-opt with feasibility checks. Prioritize non-dominated segments during relinking.*\n- **Avoid**: *Static weights; random swaps violating feasibility; neglecting dominance in selection; ignoring crowding distance during inversion. Over-reliance on single-objective improvements.*\n- **Explanation**: *Adaptive scaling ensures balanced Pareto progress. Feasibility checks prevent invalid tours. Hybrid operators leverage multi-objective structure. Non-dominated segment prioritization accelerates convergence.*\n\n*(99 words)*\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 307,
        "algorithm": "The algorithm combines dominance-aware selection with adaptive crowding-scaled segment inversion, using hybrid 2-opt/3-opt moves and objective-scaled relinking to generate neighbors. It prioritizes solutions with high crowding distance in the least-dominated objective space, dynamically adjusts segment lengths and move probabilities based on dominance ratios, and uses probabilistic acceptance criteria favoring solutions improving multiple objectives. The algorithm ensures feasibility through careful segment handling and edge case management, alternating between segment-based and edge-based perturbations to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance in least dominated objective\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with probability based on dominance\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with feasibility check\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with feasibility check\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Enhanced probabilistic acceptance based on multi-objective improvement\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    if improvement_count >= 2:\n        accept_prob = 0.8  # High probability for improving 2+ objectives\n    else:\n        accept_prob = 0.3 + 0.2 * improvement_count  # Base 30% + 20% per objective\n\n    if improvement_count == 0 and np.random.rand() > accept_prob:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7188284464239624,
            0.2718083024024963
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance in least dominated objective\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with probability based on dominance\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with feasibility check\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with feasibility check\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Enhanced probabilistic acceptance based on multi-objective improvement\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    if improvement_count >= 2:\n        accept_prob = 0.8  # High probability for improving 2+ objectives\n    else:\n        accept_prob = 0.3 + 0.2 * improvement_count  # Base 30% + 20% per objective\n\n    if improvement_count == 0 and np.random.rand() > accept_prob:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nThe heuristic selects the solution with the lowest combined objective value from the archive and applies a hybrid local search (70% 2-opt, 30% 3-opt) to generate a neighbor, ensuring feasibility by always reversing or reordering segments of the tour. The selection prioritizes solutions with minimal total cost, while the local search balances exploration (random segment selection) and exploitation (reversing segments) to improve multi-objective performance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the lowest combined objective value\n    selected_idx = np.argmin([sum(obj) for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Apply hybrid local search: 2-opt or 3-opt based on a random choice\n    n = len(new_solution)\n    if n < 4:\n        # For small instances, just swap two nodes\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n    else:\n        # With 70% probability, apply 2-opt, else 3-opt\n        if np.random.rand() < 0.7:\n            # 2-opt move\n            i, j = sorted(np.random.choice(n, 2, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n        else:\n            # 3-opt move\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segment1 = new_solution[i:j]\n            segment2 = new_solution[j:k]\n            new_solution[i:k] = np.concatenate([segment2, segment1])\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects the most crowding-distance-promising solution from the least dominated objective, applies an adaptive segment inversion operator with dynamic objective scaling, and employs a hybrid 2-opt/3-opt local search with dominance-aware move probabilities to generate high-quality multi-objective neighbors while maintaining feasibility. It prioritizes solutions with lower dominance counts in the least dominated objective and uses crowding distance to identify promising regions for improvement, while dynamically adjusting segment lengths and move probabilities based on dominance ratios. The hybrid local search ensures both exploration and exploitation across all objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in least dominated objective\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment inversion with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes[::-1]\n                new_solution[best_segment:best_end] = worst_segment_nodes[::-1]\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes[::-1].copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes[::-1].copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/3-opt with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if (i+1) <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm combines dominance-aware selection with adaptive segment relinking to optimize a tri-objective TSP, prioritizing segments in the least-dominated objective space while dynamically adjusting segment lengths and applying hybrid local search operators (2-opt/3-opt) probabilistically based on dominance ratios. It ensures feasibility through careful segment exchanges and probabilistic acceptance of solutions improving two or more objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with probability based on dominance\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with feasibility check\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with feasibility check\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Probabilistic acceptance based on multi-objective improvement\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    if improvement_count < 2 and np.random.rand() > 0.4:  # Accept with 60% probability if only one objective improves\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm combines dominance-aware selection with an adaptive segment relinking strategy, prioritizing solutions that show high crowding distance in the least dominated objective. It then applies a hybrid local search blending 2-opt and 3-opt moves with dominance-scaled segment lengths, ensuring feasibility through non-overlapping segment inversions and adaptive move probabilities to balance exploration and exploitation across all three objectives. The selection process favors solutions with better crowding distance in the least dominated objective, while the local search dynamically adapts segment lengths and move probabilities based on dominance relationships.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in least dominated objective\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment inversion with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes[::-1]\n                new_solution[best_segment:best_end] = worst_segment_nodes[::-1]\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes[::-1].copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes[::-1].copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/3-opt with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if (i+1) <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm combines adaptive segment-based perturbations with dominance-aware edge swaps, prioritizing the most diverse objective dimension while dynamically adjusting segment lengths and swap probabilities based on improvement potential. It selects solutions with high crowding distance in the chosen objective and applies hybrid 2-opt/4-opt moves, with segment-based reversals that adapt to historical improvement rates, ensuring feasibility through careful tour manipulation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate objective diversity and select most diverse dimension\n    obj_std = np.std(objectives, axis=0)\n    selected_obj = np.argmax(obj_std)\n\n    # Calculate normalized improvement potential\n    obj_ranges = np.max(objectives, axis=0) - np.min(objectives, axis=0)\n    improvement_potential = obj_ranges / (np.sum(obj_ranges) + 1e-8)\n\n    # Select solution with highest crowding distance in selected objective\n    normalized_obj = (objectives[:, selected_obj] - np.min(objectives[:, selected_obj])) / (np.max(objectives[:, selected_obj]) - np.min(objectives[:, selected_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Dynamic segment length based on improvement potential\n    segment_length = max(2, min(6, int(4 * improvement_potential[selected_obj] + 2)))\n\n    # Find worst and best segments in selected objective\n    worst_segment = None\n    worst_score = -np.inf\n    best_segment = None\n    best_score = np.inf\n\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = distance_matrices[selected_obj][node1, node2]\n\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n        if score < best_score:\n            best_score = score\n            best_segment = i\n\n    if worst_segment is not None and best_segment is not None:\n        worst_end = (worst_segment + segment_length) % n\n        best_end = (best_segment + segment_length) % n\n\n        if worst_segment < worst_end:\n            worst_segment_nodes = new_solution[worst_segment:worst_end]\n        else:\n            worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n        if best_segment < best_end:\n            best_segment_nodes = new_solution[best_segment:best_end]\n        else:\n            best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n        if worst_segment < worst_end and best_segment < best_end:\n            new_solution[worst_segment:worst_end] = best_segment_nodes\n            new_solution[best_segment:best_end] = worst_segment_nodes\n        else:\n            if worst_segment > worst_end:\n                temp = worst_segment_nodes.copy()\n                new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n            if best_segment > best_end:\n                temp = best_segment_nodes.copy()\n                new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/4-opt with improvement-aware probability\n    if np.random.rand() < 0.6 * improvement_potential[selected_obj]:\n        # 4-opt move\n        i, j, k, l = sorted(np.random.choice(range(n), 4, replace=False))\n        if (i+1) <= j and (j+1) <= k and (k+1) <= l:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[k:l+1] = new_solution[k:l+1][::-1]\n    else:\n        # 2-opt move with segment-based selection\n        segment_start = np.random.randint(0, n - segment_length)\n        segment_end = (segment_start + segment_length) % n\n        if segment_start < segment_end:\n            new_solution[segment_start:segment_end] = new_solution[segment_start:segment_end][::-1]\n        else:\n            temp = new_solution[segment_start:].copy()\n            new_solution[segment_start:] = new_solution[:segment_end][::-1]\n            new_solution[:segment_end] = temp[::-1]\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm combines dominance-aware selection with multi-objective segment inversion, prioritizing solutions in the least dominated objective space and applying adaptive segment exchanges between worst and best segments across different objectives, while also incorporating hybrid 2-opt/3-opt moves and adaptive relinking to preserve common segments between solutions. It dynamically adjusts segment lengths and move probabilities based on dominance ratios, ensuring exploration and exploitation balance through dominance-aware parameter adaptation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:  # 60% chance to reverse first segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:  # 40% chance to reverse second segment\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with probabilistic segment reversal\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < 0.7:  # 70% chance to reverse the segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Multi-objective adaptive relinking\n    if np.random.rand() < 0.3:  # 30% chance to perform relinking\n        # Select a reference solution from the archive\n        ref_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n        ref_solution = archive[ref_idx][0]\n\n        # Identify common segments between base and reference solutions\n        common_segments = []\n        for i in range(n):\n            if new_solution[i] == ref_solution[i] and new_solution[(i+1)%n] == ref_solution[(i+1)%n]:\n                common_segments.append(i)\n\n        if common_segments:\n            # Select a random common segment to preserve\n            segment_to_preserve = np.random.choice(common_segments)\n            segment_length = min(3, n // 4)  # Preserve up to 3 nodes from the common segment\n\n            # Create a new solution by combining segments from base and reference\n            preserved_nodes = new_solution[segment_to_preserve:segment_to_preserve+segment_length]\n            remaining_nodes = [node for node in ref_solution if node not in preserved_nodes]\n\n            # Reconstruct the tour\n            new_solution = np.concatenate([preserved_nodes, remaining_nodes])\n            new_solution = np.roll(new_solution, -segment_to_preserve)\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design with clear actionable steps:\n\n- **Keywords**: *Tri-Objective Dominance-Aware Relinking, Adaptive Crowding-Scaled Swaps, Feasibility-Preserving Hybrid Operators, Objective-Scaled Segment Inversion*\n- **Advice**: *Select solutions with highest crowding distance in least dominated objective. Apply dominance-aware segment inversion with adaptive objective scaling. Use hybrid 2-opt/3-opt with feasibility checks. Prioritize non-dominated segments during relinking.*\n- **Avoid**: *Static weights; random swaps violating feasibility; neglecting dominance in selection; ignoring crowding distance during inversion. Over-reliance on single-objective improvements.*\n- **Explanation**: *Adaptive scaling ensures balanced Pareto progress. Feasibility checks prevent invalid tours. Hybrid operators leverage multi-objective structure. Non-dominated segment prioritization accelerates convergence.*\n\n*(99 words)*\n\n**Python Implementation**:\n```python\ndef select_neighbor(archive):\n    # Select solution with highest crowding distance in least dominated objective\n    least_dom_obj = np.argmin([sum(dominates(s, other) for other in archive) for s in archive])\n    selected = max(archive, key=lambda s: crowding_distance(s, least_dom_obj))\n\n    # Hybrid Local Search with adaptive objective scaling\n    tour = selected.copy()\n    for _ in range(10):\n        worst_obj = np.argmax(selected.objectives)\n        scaled_obj = selected.objectives * (1 + 0.3 * (worst_obj == np.arange(3)))\n\n        # Hybrid 2-opt/3-opt with dominance check\n        if random.random() < 0.7:\n            a, b = random.sample(range(len(tour)), 2)\n            new_tour = two_opt_swap(tour, a, b)\n        else:\n            a, b, c = sorted(random.sample(range(len(tour)), 3))\n            new_tour = three_opt_inversion(tour, a, b, c)\n\n        if any(new_tour.objectives < scaled_obj) and is_valid(new_tour):\n            tour = new_tour\n\n    return tour\n```\n\n**Key Improvements**:\n1. Added dominance-aware selection of segments during inversion\n2. Implemented adaptive scaling based on worst-performing objective\n3. Included feasibility checks for all operators\n4. Balanced exploration/exploitation with hybrid 2-opt/3-opt moves\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 308,
        "algorithm": "The algorithm combines dominance-aware selection with adaptive segment inversion and hybrid 2-opt/3-opt moves, prioritizing solutions in the least dominated objective space while ensuring feasibility through dynamic segment manipulation and objective-scaled operations. It selects solutions with high crowding distance in the least dominated objective, then applies segment inversions between worst and best segments across different objectives, with adaptive scaling based on dominance ratios. The hybrid 2-opt/3-opt moves are applied with dominance-based probabilities to further refine the solution.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Perform segment inversion with feasibility check\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes[::-1]\n                new_solution[best_segment:best_end] = worst_segment_nodes[::-1]\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes[::-1].copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes[::-1].copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/3-opt move with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with feasibility check\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with feasibility check\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.6658043043902595,
            0.2172075629234314
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Perform segment inversion with feasibility check\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes[::-1]\n                new_solution[best_segment:best_end] = worst_segment_nodes[::-1]\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes[::-1].copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes[::-1].copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/3-opt move with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with feasibility check\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with feasibility check\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm combines adaptive segment-based perturbations with dominance-aware edge swaps, prioritizing the most diverse objective dimension while dynamically adjusting segment lengths and swap probabilities based on improvement potential. It selects solutions with high crowding distance in the chosen objective and applies hybrid 2-opt/4-opt moves, with segment-based reversals that adapt to historical improvement rates, ensuring feasibility through careful tour manipulation.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate objective diversity and select most diverse dimension\n    obj_std = np.std(objectives, axis=0)\n    selected_obj = np.argmax(obj_std)\n\n    # Calculate normalized improvement potential\n    obj_ranges = np.max(objectives, axis=0) - np.min(objectives, axis=0)\n    improvement_potential = obj_ranges / (np.sum(obj_ranges) + 1e-8)\n\n    # Select solution with highest crowding distance in selected objective\n    normalized_obj = (objectives[:, selected_obj] - np.min(objectives[:, selected_obj])) / (np.max(objectives[:, selected_obj]) - np.min(objectives[:, selected_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Dynamic segment length based on improvement potential\n    segment_length = max(2, min(6, int(4 * improvement_potential[selected_obj] + 2)))\n\n    # Find worst and best segments in selected objective\n    worst_segment = None\n    worst_score = -np.inf\n    best_segment = None\n    best_score = np.inf\n\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = distance_matrices[selected_obj][node1, node2]\n\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n        if score < best_score:\n            best_score = score\n            best_segment = i\n\n    if worst_segment is not None and best_segment is not None:\n        worst_end = (worst_segment + segment_length) % n\n        best_end = (best_segment + segment_length) % n\n\n        if worst_segment < worst_end:\n            worst_segment_nodes = new_solution[worst_segment:worst_end]\n        else:\n            worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n        if best_segment < best_end:\n            best_segment_nodes = new_solution[best_segment:best_end]\n        else:\n            best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n        if worst_segment < worst_end and best_segment < best_end:\n            new_solution[worst_segment:worst_end] = best_segment_nodes\n            new_solution[best_segment:best_end] = worst_segment_nodes\n        else:\n            if worst_segment > worst_end:\n                temp = worst_segment_nodes.copy()\n                new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n            if best_segment > best_end:\n                temp = best_segment_nodes.copy()\n                new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/4-opt with improvement-aware probability\n    if np.random.rand() < 0.6 * improvement_potential[selected_obj]:\n        # 4-opt move\n        i, j, k, l = sorted(np.random.choice(range(n), 4, replace=False))\n        if (i+1) <= j and (j+1) <= k and (k+1) <= l:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[k:l+1] = new_solution[k:l+1][::-1]\n    else:\n        # 2-opt move with segment-based selection\n        segment_start = np.random.randint(0, n - segment_length)\n        segment_end = (segment_start + segment_length) % n\n        if segment_start < segment_end:\n            new_solution[segment_start:segment_end] = new_solution[segment_start:segment_end][::-1]\n        else:\n            temp = new_solution[segment_start:].copy()\n            new_solution[segment_start:] = new_solution[:segment_end][::-1]\n            new_solution[:segment_end] = temp[::-1]\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 309,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute objectives and distance matrices\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Select objective with maximum standard deviation (simplified)\n    selected_obj = np.argmax(np.std(objectives, axis=0))\n\n    # Select solution with highest crowding distance (simplified)\n    obj_values = objectives[:, selected_obj]\n    sorted_idx = np.argsort(obj_values)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = obj_values[sorted_idx[i+1]] - obj_values[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Hybrid 2-opt/4-opt with simplified logic\n    if np.random.rand() < 0.5:  # Fixed probability for speed\n        # 4-opt move (simplified)\n        i, j, k, l = sorted(np.random.choice(range(n), 4, replace=False))\n        if (i+1) <= j and (j+1) <= k and (k+1) <= l:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[k:l+1] = new_solution[k:l+1][::-1]\n    else:\n        # 2-opt move with fixed segment length\n        segment_length = min(4, n//2)\n        segment_start = np.random.randint(0, n - segment_length)\n        segment_end = segment_start + segment_length\n        new_solution[segment_start:segment_end] = new_solution[segment_start:segment_end][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.464023845492007,
            0.37634806632995604
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute objectives and distance matrices\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Select objective with maximum standard deviation (simplified)\n    selected_obj = np.argmax(np.std(objectives, axis=0))\n\n    # Select solution with highest crowding distance (simplified)\n    obj_values = objectives[:, selected_obj]\n    sorted_idx = np.argsort(obj_values)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = obj_values[sorted_idx[i+1]] - obj_values[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Hybrid 2-opt/4-opt with simplified logic\n    if np.random.rand() < 0.5:  # Fixed probability for speed\n        # 4-opt move (simplified)\n        i, j, k, l = sorted(np.random.choice(range(n), 4, replace=False))\n        if (i+1) <= j and (j+1) <= k and (k+1) <= l:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[k:l+1] = new_solution[k:l+1][::-1]\n    else:\n        # 2-opt move with fixed segment length\n        segment_length = min(4, n//2)\n        segment_start = np.random.randint(0, n - segment_length)\n        segment_end = segment_start + segment_length\n        new_solution[segment_start:segment_end] = new_solution[segment_start:segment_end][::-1]\n\n    return new_solution\n\n",
        "operation": "r1"
    }
]