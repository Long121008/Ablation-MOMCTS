[
    {
        "algorithm": "The heuristic selects the solution with the lowest combined objective value from the archive and applies a hybrid local search (70% 2-opt, 30% 3-opt) to generate a neighbor, ensuring feasibility by always reversing or reordering segments of the tour. The selection prioritizes solutions with minimal total cost, while the local search balances exploration (random segment selection) and exploitation (reversing segments) to improve multi-objective performance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the lowest combined objective value\n    selected_idx = np.argmin([sum(obj) for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Apply hybrid local search: 2-opt or 3-opt based on a random choice\n    n = len(new_solution)\n    if n < 4:\n        # For small instances, just swap two nodes\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n    else:\n        # With 70% probability, apply 2-opt, else 3-opt\n        if np.random.rand() < 0.7:\n            # 2-opt move\n            i, j = sorted(np.random.choice(n, 2, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n        else:\n            # 3-opt move\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segment1 = new_solution[i:j]\n            segment2 = new_solution[j:k]\n            new_solution[i:k] = np.concatenate([segment2, segment1])\n\n    return new_solution\n\n",
        "score": [
            -0.8028366341020267,
            0.34138243198394774
        ]
    },
    {
        "algorithm": "The algorithm dynamically identifies the least dominated objective and selects a high-crowding-distance solution from the archive, then applies an objective-biased segment swap to exchange segments between the worst-performing path and another objective's path, ensuring feasibility through careful boundary handling. It prioritizes underperforming objectives while maintaining tour validity through segment swaps of variable length (2-4 nodes). The method balances exploration and exploitation by focusing on both dominance and diversity in the archive.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance for each objective\n    objectives = np.array([obj for _, obj in archive])\n    dominance = np.sum(objectives <= objectives, axis=0) / len(archive)\n\n    # Select the least dominated objective\n    least_dominated_obj = np.argmin(dominance)\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance in this objective\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2]\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Perform segment swap\n            segment_length = np.random.randint(2, min(5, n//3))\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            # Extract segments\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Swap segments\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                # Handle wrap-around cases\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                # Perform the swap\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    return new_solution\n\n",
        "score": [
            -0.5911691427935126,
            0.250174880027771
        ]
    },
    {
        "algorithm": "The algorithm selects solutions from the archive based on objective diversity, then applies adaptive local search with dynamic perturbation intensity (ranging from small swaps to large segment reversals) based on the solution's dominance, while ensuring feasibility through probabilistic acceptance that prioritizes multi-objective improvement. It balances exploration and exploitation by varying perturbation intensity and accepting solutions probabilistically when improvements are marginal.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high objective diversity (not just minimal sum)\n    objectives = np.array([obj for _, obj in archive])\n    objective_ranges = np.max(objectives, axis=0) - np.min(objectives, axis=0)\n    diversity_scores = np.sum(objective_ranges * objectives, axis=1)\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        # For small instances, swap two nodes\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n    else:\n        # Dynamic perturbation intensity based on objective dominance\n        obj_dominance = np.sum([obj <= archive[selected_idx][1] for _, obj in archive], axis=0) / len(archive)\n        perturbation_intensity = 1 - np.mean(obj_dominance)  # Higher when less dominated\n\n        # Multi-objective local search with varying intensity\n        if np.random.rand() < perturbation_intensity:\n            # Large-scale perturbation: reverse a large segment\n            segment_size = max(2, int(perturbation_intensity * n))\n            i = np.random.randint(0, n - segment_size + 1)\n            new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n        else:\n            # Small-scale perturbation: swap or reverse small segments\n            if np.random.rand() < 0.5:\n                # Small swap\n                i, j = np.random.choice(n, 2, replace=False)\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            else:\n                # Small reverse\n                i, j = sorted(np.random.choice(n, 2, replace=False))\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n        # Probabilistic acceptance based on multi-objective improvement\n        original_costs = [\n            sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n            sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n            sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n        ]\n        new_costs = [\n            sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n            sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n            sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n        ]\n\n        improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n        if improvement_count < 2 and np.random.rand() > 0.3:  # Accept with 30% probability if only one objective improves\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.73888223731041,
            0.4111027121543884
        ]
    },
    {
        "algorithm": "This algorithm implements a dynamic multi-objective local search for the Tri-objective TSP, prioritizing objectives based on their dominance in the archive while alternating between segment-based perturbations and edge exchanges. It uses a weighted diversity selection to choose promising solutions and employs objective-aware perturbations (60% segment-based, 40% edge-based) with a probabilistic acceptance criterion that favors solutions improving more objectives. The method balances exploration and exploitation by dynamically adjusting perturbation strategies based on objective priorities and solution quality.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high objective diversity using weighted sum\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    weights = 1 / (np.std(normalized_obj, axis=0) + 1e-10)\n    diversity_scores = np.sum(weights * normalized_obj, axis=1)\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Dynamic objective prioritization\n    obj_dominance = np.sum([obj <= archive[selected_idx][1] for _, obj in archive], axis=0) / len(archive)\n    priority_order = np.argsort(obj_dominance)\n    current_obj = priority_order[np.random.choice(min(2, len(priority_order)))]\n\n    # Adaptive local search with objective-aware perturbations\n    if np.random.rand() < 0.6:  # 60% chance for segment-based perturbation\n        segment_size = max(2, int(0.4 * n))\n        i = np.random.randint(0, n - segment_size + 1)\n        segment = new_solution[i:i+segment_size]\n\n        # Objective-aware segment reversal\n        obj_values = []\n        for k in range(len(segment)-1):\n            node1, node2 = segment[k], segment[k+1]\n            obj_values.append([\n                distance_matrix_1[node1, node2],\n                distance_matrix_2[node1, node2],\n                distance_matrix_3[node1, node2]\n            ])\n\n        if np.random.rand() < 0.7:  # 70% chance to reverse based on current objective\n            obj_values = np.array(obj_values)[:, current_obj]\n            worst_segment = np.argmax(obj_values)\n            new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n        else:\n            # Random segment reversal\n            new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n    else:\n        # Objective-aware edge exchange with 3-opt\n        obj_edges = []\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            obj_edges.append((\n                node1, node2,\n                distance_matrix_1[node1, node2],\n                distance_matrix_2[node1, node2],\n                distance_matrix_3[node1, node2]\n            ))\n\n        # Sort edges by current objective\n        obj_edges.sort(key=lambda x: x[current_obj + 2])\n        worst_edge = obj_edges[-1][:2]\n\n        # Find position of worst edge\n        pos = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge or\n              (new_solution[(i+1)%n], new_solution[i]) == worst_edge]\n\n        if pos:\n            pos = pos[0]\n            # Perform 3-opt move to replace worst edge\n            i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n\n    # Enhanced probabilistic acceptance\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    accept_prob = 0.3 + 0.4 * (improvement_count / 3)  # Base 30% + 40% per objective improved\n\n    if improvement_count == 0 and np.random.rand() > accept_prob:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7560779850487018,
            0.4668965101242065
        ]
    },
    {
        "algorithm": "The algorithm selects the most under-optimized solution from the archive (based on objective ratios) and applies a hybrid local search (60% 3-opt, 40% 4-opt) to generate a neighbor, prioritizing exploration in the least optimized objective space. It intelligently adapts the search strategy to the problem size and ensures feasibility by maintaining valid TSP tours. The selection criteria and adaptive local search are key design choices for balancing exploration and exploitation across multiple objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate average objective costs across all solutions\n    avg_obj1 = np.mean([obj[0] for _, obj in archive])\n    avg_obj2 = np.mean([obj[1] for _, obj in archive])\n    avg_obj3 = np.mean([obj[2] for _, obj in archive])\n\n    # Find the solution with the lowest objective in the least optimized space\n    min_ratios = []\n    for sol, obj in archive:\n        ratio1 = obj[0] / avg_obj1 if avg_obj1 > 0 else 0\n        ratio2 = obj[1] / avg_obj2 if avg_obj2 > 0 else 0\n        ratio3 = obj[2] / avg_obj3 if avg_obj3 > 0 else 0\n        min_ratios.append(min(ratio1, ratio2, ratio3))\n\n    selected_idx = np.argmin(min_ratios)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 5:\n        # For small instances, swap two nodes\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n    else:\n        # With 60% probability, apply 3-opt, else 4-opt\n        if np.random.rand() < 0.6:\n            # 3-opt move\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segment1 = new_solution[i:j]\n            segment2 = new_solution[j:k]\n            new_solution[i:k] = np.concatenate([segment2, segment1])\n        else:\n            # 4-opt move (select 4 distinct indices and reorder segments)\n            a, b, c, d = sorted(np.random.choice(n, 4, replace=False))\n            segment1 = new_solution[a:b]\n            segment2 = new_solution[b:c]\n            segment3 = new_solution[c:d]\n            # Reorder segments in a different configuration\n            new_solution[a:d] = np.concatenate([segment2, segment1, segment3])\n\n    return new_solution\n\n",
        "score": [
            -0.43905360579104036,
            0.3563701272010803
        ]
    },
    {
        "algorithm": "The algorithm combines objective diversity selection with a hybrid local search that alternates between large-scale segment reversals and fine-grained edge exchanges, prioritizing the least-dominated objective for edge selection, while using a probabilistic acceptance criterion to balance multi-objective improvement. It dynamically adapts search strategies based on solution dominance and objective diversity, ensuring feasibility through constrained perturbations and 2-opt moves.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    objective_ranges = np.max(objectives, axis=0) - np.min(objectives, axis=0)\n    diversity_scores = np.sum(objective_ranges * objectives, axis=1)\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Calculate objective dominance\n    obj_dominance = np.sum([obj <= archive[selected_idx][1] for _, obj in archive], axis=0) / len(archive)\n    least_dominated_obj = np.argmin(obj_dominance)\n\n    # Hybrid local search with objective-aware perturbation\n    if np.random.rand() < 0.7:  # 70% chance for large-scale perturbation\n        segment_size = max(2, int(0.3 * n))\n        i = np.random.randint(0, n - segment_size + 1)\n        new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n    else:\n        # Objective-aware edge exchange\n        obj_edges = []\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            obj_edges.append((\n                node1, node2,\n                distance_matrix_1[node1, node2],\n                distance_matrix_2[node1, node2],\n                distance_matrix_3[node1, node2]\n            ))\n\n        # Sort edges by the least dominated objective\n        obj_edges.sort(key=lambda x: x[least_dominated_obj + 2])\n        worst_edge = obj_edges[-1][:2]\n\n        # Find position of worst edge\n        pos = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge or\n              (new_solution[(i+1)%n], new_solution[i]) == worst_edge]\n\n        if pos:\n            pos = pos[0]\n            # Perform 2-opt move to replace worst edge\n            i, j = sorted(np.random.choice(range(n), 2, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Probabilistic acceptance based on multi-objective improvement\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    if improvement_count < 2 and np.random.rand() > 0.4:  # Accept with 60% probability if only one objective improves\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7220877380002139,
            0.42280006408691406
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high objective diversity and low dominance\n    objectives = np.array([obj for _, obj in archive])\n    objective_ranges = np.max(objectives, axis=0) - np.min(objectives, axis=0)\n    diversity_scores = np.sum(objective_ranges * objectives, axis=1)\n    dominance_scores = np.sum([np.sum(obj <= archive[i][1]) for i, obj in enumerate(objectives)], axis=0)\n    combined_scores = diversity_scores - 0.5 * dominance_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Calculate objective improvement status\n    improvement_status = np.zeros(3)\n    for i in range(n):\n        node1, node2 = base_solution[i], base_solution[(i+1)%n]\n        for k in range(3):\n            if k == 0:\n                improvement_status[k] += distance_matrix_1[node1, node2]\n            elif k == 1:\n                improvement_status[k] += distance_matrix_2[node1, node2]\n            else:\n                improvement_status[k] += distance_matrix_3[node1, node2]\n\n    # Identify least improved objective\n    least_improved_obj = np.argmin(improvement_status)\n\n    # Adaptive multi-phase perturbation\n    perturbation_type = np.random.choice(['segment', 'edge', 'insertion'], p=[0.4, 0.3, 0.3])\n\n    if perturbation_type == 'segment':\n        # Objective-aware segment reversal\n        segment_size = max(2, int(0.3 * n))\n        i = np.random.randint(0, n - segment_size + 1)\n        new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n    elif perturbation_type == 'edge':\n        # Edge exchange prioritizing least improved objective\n        obj_edges = []\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            obj_edges.append((\n                node1, node2,\n                distance_matrix_1[node1, node2],\n                distance_matrix_2[node1, node2],\n                distance_matrix_3[node1, node2]\n            ))\n\n        # Sort edges by least improved objective with adaptive weight\n        obj_edges.sort(key=lambda x: x[least_improved_obj + 2])\n        worst_edge = obj_edges[-1][:2]\n\n        # Find position of worst edge\n        pos = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge or\n              (new_solution[(i+1)%n], new_solution[i]) == worst_edge]\n\n        if pos:\n            pos = pos[0]\n            # Perform 2-opt move\n            i, j = sorted(np.random.choice(range(n), 2, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:\n        # Node insertion prioritizing least improved objective\n        i, j = np.random.choice(range(n), 2, replace=False)\n        node = new_solution[i]\n        new_solution = np.concatenate([new_solution[:i], new_solution[i+1:j+1], [node], new_solution[j+1:]])\n\n    # Enhanced probabilistic acceptance based on Pareto front improvement\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    # Count Pareto improvements\n    pareto_improvements = 0\n    for i in range(len(archive)):\n        if all(new < orig for new, orig in zip(new_costs, archive[i][1])):\n            pareto_improvements += 1\n\n    accept_prob = min(0.9, 0.3 + 0.4 * (pareto_improvements / len(archive)))\n\n    if np.random.rand() > accept_prob:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7341246895979942,
            1.0625690579414369
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high objective diversity and low dominance\n    objectives = np.array([obj for _, obj in archive])\n    objective_ranges = np.max(objectives, axis=0) - np.min(objectives, axis=0)\n    diversity_scores = np.sum(objective_ranges * objectives, axis=1)\n    dominance_scores = np.sum([np.sum(obj <= archive[i][1]) for i, obj in enumerate(objectives)], axis=0)\n    combined_scores = diversity_scores - 0.5 * dominance_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Calculate objective dominance and identify least dominated objective\n    obj_dominance = np.sum([obj <= archive[selected_idx][1] for _, obj in archive], axis=0) / len(archive)\n    least_dominated_obj = np.argmin(obj_dominance)\n\n    # Novel hybrid local search with objective-aware perturbation and adaptive strategy selection\n    if np.random.rand() < 0.6:  # 60% chance for large-scale perturbation\n        segment_size = max(2, int(0.25 * n))\n        i = np.random.randint(0, n - segment_size + 1)\n        new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n    else:\n        # Objective-aware edge exchange with adaptive selection\n        obj_edges = []\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            obj_edges.append((\n                node1, node2,\n                distance_matrix_1[node1, node2],\n                distance_matrix_2[node1, node2],\n                distance_matrix_3[node1, node2]\n            ))\n\n        # Sort edges by the least dominated objective with adaptive weight\n        alpha = 0.3  # Weight for adaptive selection\n        obj_edges.sort(key=lambda x: x[least_dominated_obj + 2] * (1 - alpha) + alpha * np.mean(x[2:]))\n        worst_edge = obj_edges[-1][:2]\n\n        # Find position of worst edge\n        pos = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == worst_edge or\n              (new_solution[(i+1)%n], new_solution[i]) == worst_edge]\n\n        if pos:\n            pos = pos[0]\n            # Perform adaptive 2-opt move with higher probability of node insertion\n            i, j = sorted(np.random.choice(range(n), 2, replace=False))\n            if np.random.rand() < 0.5:  # 50% chance for standard 2-opt\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            else:  # 50% chance for node insertion\n                node = new_solution[i]\n                new_solution = np.concatenate([new_solution[:i], new_solution[i+1:j+1], [node], new_solution[j+1:]])\n\n    # Enhanced probabilistic acceptance based on multi-objective improvement\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    if improvement_count < 2 and np.random.rand() > 0.2:  # Accept with 80% probability if only one objective improves\n        new_solution = base_solution.copy()\n\n    # Additional local improvement: perform a small segment reversal if no improvement\n    if improvement_count == 0 and np.random.rand() < 0.3:\n        segment_size = 2\n        i = np.random.randint(0, n - segment_size + 1)\n        new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.7339226919804782,
            0.9980083703994751
        ]
    },
    {
        "algorithm": "The algorithm combines objective diversity selection with a hybrid local search, prioritizing the least-dominated objective for edge selection while dynamically alternating between large-scale segment reversals and fine-grained segment exchanges. It ensures feasibility through constrained perturbations and uses a probabilistic acceptance criterion to balance multi-objective improvement, with a 60% chance of large-scale perturbations and a 50% chance of accepting solutions that improve only one objective.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with high objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    objective_ranges = np.max(objectives, axis=0) - np.min(objectives, axis=0)\n    diversity_scores = np.sum(objective_ranges * objectives, axis=1)\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Calculate objective dominance\n    obj_dominance = np.sum([obj <= archive[selected_idx][1] for _, obj in archive], axis=0) / len(archive)\n    least_dominated_obj = np.argmin(obj_dominance)\n\n    # Hybrid local search with objective-aware perturbation\n    if np.random.rand() < 0.6:  # 60% chance for large-scale perturbation\n        segment_size = max(2, int(0.3 * n))\n        i = np.random.randint(0, n - segment_size + 1)\n        new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n    else:\n        # Objective-aware segment exchange\n        obj_segments = []\n        for i in range(n - 2):\n            segment = new_solution[i:i+3]\n            cost1 = sum(distance_matrix_1[segment[j], segment[(j+1)%3]] for j in range(3))\n            cost2 = sum(distance_matrix_2[segment[j], segment[(j+1)%3]] for j in range(3))\n            cost3 = sum(distance_matrix_3[segment[j], segment[(j+1)%3]] for j in range(3))\n            obj_segments.append((i, cost1, cost2, cost3))\n\n        # Sort segments by the least dominated objective\n        obj_segments.sort(key=lambda x: x[least_dominated_obj + 1])\n        worst_segment = obj_segments[-1][0]\n\n        # Exchange worst segment with another segment\n        j = np.random.randint(0, n - 2)\n        new_solution[worst_segment:worst_segment+3], new_solution[j:j+3] = new_solution[j:j+3].copy(), new_solution[worst_segment:worst_segment+3].copy()\n\n    # Probabilistic acceptance based on multi-objective improvement\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    if improvement_count < 2 and np.random.rand() > 0.5:  # Accept with 50% probability if only one objective improves\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7111803834567021,
            0.4264137506484985
        ]
    },
    {
        "algorithm": "The algorithm combines clustering with objective-aware local search, prioritizing under-represented objectives by selecting worst edges in the least-dominated objective space and applying targeted perturbations (edge swaps or segment reversals), while using dynamic acceptance thresholds to balance exploration and exploitation. It alternates between fine-grained (edge-based) and large-scale (segment-based) perturbations based on cluster-specific objective priorities.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Cluster solutions based on objective similarity\n    objectives = np.array([obj for _, obj in archive])\n    n_clusters = min(3, len(archive))\n    if n_clusters < 2:\n        base_solution = archive[0][0].copy()\n    else:\n        from sklearn.cluster import KMeans\n        kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(objectives)\n        cluster_labels = kmeans.labels_\n        cluster_sizes = np.bincount(cluster_labels)\n\n        # Select cluster with most diverse solutions\n        selected_cluster = np.argmax(cluster_sizes)\n        cluster_indices = np.where(cluster_labels == selected_cluster)[0]\n        selected_idx = np.random.choice(cluster_indices)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Calculate cluster-specific objective priorities\n    cluster_objectives = objectives[cluster_labels == selected_cluster]\n    obj_dominance = np.sum([obj <= archive[selected_idx][1] for _, obj in archive], axis=0) / len(archive)\n    least_dominated_obj = np.argmin(obj_dominance)\n\n    # Objective-aware edge selection\n    obj_edges = []\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        obj_edges.append((\n            i, node1, node2,\n            distance_matrix_1[node1, node2],\n            distance_matrix_2[node1, node2],\n            distance_matrix_3[node1, node2]\n        ))\n\n    # Sort edges by least dominated objective\n    obj_edges.sort(key=lambda x: x[least_dominated_obj + 3])\n    worst_edge_idx = obj_edges[-1][0]\n\n    # Perform cluster-specific perturbation\n    if np.random.rand() < 0.7:  # 70% chance for edge-based perturbation\n        # Exchange worst edge with a better edge\n        better_edges = obj_edges[:int(0.3 * len(obj_edges))]\n        if better_edges:\n            selected_edge = better_edges[np.random.randint(0, len(better_edges))]\n            pos = [i for i in range(n) if (new_solution[i], new_solution[(i+1)%n]) == (selected_edge[1], selected_edge[2]) or\n                  (new_solution[(i+1)%n], new_solution[i]) == (selected_edge[1], selected_edge[2])]\n            if pos:\n                pos = pos[0]\n                new_solution[worst_edge_idx], new_solution[(worst_edge_idx+1)%n] = new_solution[pos], new_solution[(pos+1)%n]\n    else:\n        # Segment-based perturbation\n        segment_size = max(2, int(0.25 * n))\n        i = np.random.randint(0, n - segment_size + 1)\n        new_solution[i:i+segment_size] = new_solution[i:i+segment_size][::-1]\n\n    # Dynamic probabilistic acceptance\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    accept_threshold = 0.4 + 0.2 * (improvement_count / 3)  # Base 40% + 20% per objective improved\n\n    if improvement_count == 0 and np.random.rand() > accept_threshold:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7209448408120471,
            1.5830826878547668
        ]
    }
]