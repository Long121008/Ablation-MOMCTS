[
    {
        "algorithm": "The heuristic selects the solution with the lowest combined objective value from the archive and applies a hybrid local search (70% 2-opt, 30% 3-opt) to generate a neighbor, ensuring feasibility by always reversing or reordering segments of the tour. The selection prioritizes solutions with minimal total cost, while the local search balances exploration (random segment selection) and exploitation (reversing segments) to improve multi-objective performance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the lowest combined objective value\n    selected_idx = np.argmin([sum(obj) for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Apply hybrid local search: 2-opt or 3-opt based on a random choice\n    n = len(new_solution)\n    if n < 4:\n        # For small instances, just swap two nodes\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n    else:\n        # With 70% probability, apply 2-opt, else 3-opt\n        if np.random.rand() < 0.7:\n            # 2-opt move\n            i, j = sorted(np.random.choice(n, 2, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n        else:\n            # 3-opt move\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segment1 = new_solution[i:j]\n            segment2 = new_solution[j:k]\n            new_solution[i:k] = np.concatenate([segment2, segment1])\n\n    return new_solution\n\n",
        "score": [
            -0.8028366341020267,
            0.34138243198394774
        ]
    },
    {
        "algorithm": "The algorithm selects the most crowding-distance-promising solution from the least dominated objective, applies an adaptive segment inversion operator with dynamic objective scaling, and employs a hybrid 2-opt/3-opt local search with dominance-aware move probabilities to generate high-quality multi-objective neighbors while maintaining feasibility. It prioritizes solutions with lower dominance counts in the least dominated objective and uses crowding distance to identify promising regions for improvement, while dynamically adjusting segment lengths and move probabilities based on dominance ratios. The hybrid local search ensures both exploration and exploitation across all objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in least dominated objective\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment inversion with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes[::-1]\n                new_solution[best_segment:best_end] = worst_segment_nodes[::-1]\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes[::-1].copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes[::-1].copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/3-opt with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if (i+1) <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.7669217121502199,
            0.22827595472335815
        ]
    },
    {
        "algorithm": "The algorithm combines dominance-aware selection with adaptive segment relinking to optimize a tri-objective TSP, prioritizing segments in the least-dominated objective space while dynamically adjusting segment lengths and applying hybrid local search operators (2-opt/3-opt) probabilistically based on dominance ratios. It ensures feasibility through careful segment exchanges and probabilistic acceptance of solutions improving two or more objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with probability based on dominance\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with feasibility check\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with feasibility check\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Probabilistic acceptance based on multi-objective improvement\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    if improvement_count < 2 and np.random.rand() > 0.4:  # Accept with 60% probability if only one objective improves\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.8202739799376605,
            0.34582159519195554
        ]
    },
    {
        "algorithm": "The algorithm combines dominance-aware selection with an adaptive segment relinking strategy, prioritizing solutions that show high crowding distance in the least dominated objective. It then applies a hybrid local search blending 2-opt and 3-opt moves with dominance-scaled segment lengths, ensuring feasibility through non-overlapping segment inversions and adaptive move probabilities to balance exploration and exploitation across all three objectives. The selection process favors solutions with better crowding distance in the least dominated objective, while the local search dynamically adapts segment lengths and move probabilities based on dominance relationships.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in least dominated objective\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment inversion with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes[::-1]\n                new_solution[best_segment:best_end] = worst_segment_nodes[::-1]\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes[::-1].copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes[::-1].copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/3-opt with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if (i+1) <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.770002016699428,
            0.24700621366500855
        ]
    },
    {
        "algorithm": "The algorithm combines adaptive segment-based perturbations with dominance-aware edge swaps, prioritizing the most diverse objective dimension while dynamically adjusting segment lengths and swap probabilities based on improvement potential. It selects solutions with high crowding distance in the chosen objective and applies hybrid 2-opt/4-opt moves, with segment-based reversals that adapt to historical improvement rates, ensuring feasibility through careful tour manipulation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate objective diversity and select most diverse dimension\n    obj_std = np.std(objectives, axis=0)\n    selected_obj = np.argmax(obj_std)\n\n    # Calculate normalized improvement potential\n    obj_ranges = np.max(objectives, axis=0) - np.min(objectives, axis=0)\n    improvement_potential = obj_ranges / (np.sum(obj_ranges) + 1e-8)\n\n    # Select solution with highest crowding distance in selected objective\n    normalized_obj = (objectives[:, selected_obj] - np.min(objectives[:, selected_obj])) / (np.max(objectives[:, selected_obj]) - np.min(objectives[:, selected_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Dynamic segment length based on improvement potential\n    segment_length = max(2, min(6, int(4 * improvement_potential[selected_obj] + 2)))\n\n    # Find worst and best segments in selected objective\n    worst_segment = None\n    worst_score = -np.inf\n    best_segment = None\n    best_score = np.inf\n\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = distance_matrices[selected_obj][node1, node2]\n\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n        if score < best_score:\n            best_score = score\n            best_segment = i\n\n    if worst_segment is not None and best_segment is not None:\n        worst_end = (worst_segment + segment_length) % n\n        best_end = (best_segment + segment_length) % n\n\n        if worst_segment < worst_end:\n            worst_segment_nodes = new_solution[worst_segment:worst_end]\n        else:\n            worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n        if best_segment < best_end:\n            best_segment_nodes = new_solution[best_segment:best_end]\n        else:\n            best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n        if worst_segment < worst_end and best_segment < best_end:\n            new_solution[worst_segment:worst_end] = best_segment_nodes\n            new_solution[best_segment:best_end] = worst_segment_nodes\n        else:\n            if worst_segment > worst_end:\n                temp = worst_segment_nodes.copy()\n                new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n            if best_segment > best_end:\n                temp = best_segment_nodes.copy()\n                new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/4-opt with improvement-aware probability\n    if np.random.rand() < 0.6 * improvement_potential[selected_obj]:\n        # 4-opt move\n        i, j, k, l = sorted(np.random.choice(range(n), 4, replace=False))\n        if (i+1) <= j and (j+1) <= k and (k+1) <= l:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[k:l+1] = new_solution[k:l+1][::-1]\n    else:\n        # 2-opt move with segment-based selection\n        segment_start = np.random.randint(0, n - segment_length)\n        segment_end = (segment_start + segment_length) % n\n        if segment_start < segment_end:\n            new_solution[segment_start:segment_end] = new_solution[segment_start:segment_end][::-1]\n        else:\n            temp = new_solution[segment_start:].copy()\n            new_solution[segment_start:] = new_solution[:segment_end][::-1]\n            new_solution[:segment_end] = temp[::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.7111661794644676,
            0.18285337686538697
        ]
    },
    {
        "algorithm": "The algorithm combines dominance-aware selection with multi-objective segment inversion, prioritizing solutions in the least dominated objective space and applying adaptive segment exchanges between worst and best segments across different objectives, while also incorporating hybrid 2-opt/3-opt moves and adaptive relinking to preserve common segments between solutions. It dynamically adjusts segment lengths and move probabilities based on dominance ratios, ensuring exploration and exploitation balance through dominance-aware parameter adaptation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:  # 60% chance to reverse first segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:  # 40% chance to reverse second segment\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with probabilistic segment reversal\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < 0.7:  # 70% chance to reverse the segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Multi-objective adaptive relinking\n    if np.random.rand() < 0.3:  # 30% chance to perform relinking\n        # Select a reference solution from the archive\n        ref_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n        ref_solution = archive[ref_idx][0]\n\n        # Identify common segments between base and reference solutions\n        common_segments = []\n        for i in range(n):\n            if new_solution[i] == ref_solution[i] and new_solution[(i+1)%n] == ref_solution[(i+1)%n]:\n                common_segments.append(i)\n\n        if common_segments:\n            # Select a random common segment to preserve\n            segment_to_preserve = np.random.choice(common_segments)\n            segment_length = min(3, n // 4)  # Preserve up to 3 nodes from the common segment\n\n            # Create a new solution by combining segments from base and reference\n            preserved_nodes = new_solution[segment_to_preserve:segment_to_preserve+segment_length]\n            remaining_nodes = [node for node in ref_solution if node not in preserved_nodes]\n\n            # Reconstruct the tour\n            new_solution = np.concatenate([preserved_nodes, remaining_nodes])\n            new_solution = np.roll(new_solution, -segment_to_preserve)\n\n    return new_solution\n\n",
        "score": [
            -0.7553913688134337,
            0.20449998378753662
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance ranks for each objective\n    dominance_ranks = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_ranks[i] += 1\n\n    # Select objective with lowest dominance rank (most improved)\n    target_obj = np.argmin(dominance_ranks)\n    selected_matrix = distance_matrices[target_obj]\n\n    # Calculate normalized objective values\n    normalized_obj = (objectives[:, target_obj] - np.min(objectives[:, target_obj])) / (np.max(objectives[:, target_obj]) - np.min(objectives[:, target_obj]) + 1e-8)\n\n    # Select solution with highest normalized objective value (most potential for improvement)\n    selected_idx = np.argmax(normalized_obj)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Dynamic segment length based on dominance rank\n    segment_length = max(2, min(5, int(3 * (1 - dominance_ranks[target_obj]/2) + 2)))\n\n    # Find worst segment in target objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with dynamic scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != target_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate dynamic scaling factor based on objective range\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.3 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Swap segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment swap with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Adaptive 3-opt move with dominance-based probability\n    dominance_prob = 0.5 + 0.3 * (1 - dominance_ranks[target_obj]/2)\n    if np.random.rand() < dominance_prob:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n\n    # Objective-aware node insertion\n    if np.random.rand() < 0.25:\n        # Select a node to move\n        node_to_move = np.random.choice(new_solution)\n        node_idx = np.where(new_solution == node_to_move)[0][0]\n\n        # Find best insertion point in target objective\n        best_insert_pos = -1\n        best_insert_cost = np.inf\n        for i in range(n):\n            if i != node_idx and i != (node_idx - 1) % n:\n                # Calculate cost of inserting node_to_move between i and i+1\n                cost = selected_matrix[new_solution[i], node_to_move] + selected_matrix[node_to_move, new_solution[(i+1)%n]] - selected_matrix[new_solution[i], new_solution[(i+1)%n]]\n                if cost < best_insert_cost:\n                    best_insert_cost = cost\n                    best_insert_pos = i\n\n        if best_insert_pos != -1:\n            # Perform insertion\n            new_solution = np.delete(new_solution, node_idx)\n            if best_insert_pos > node_idx:\n                best_insert_pos -= 1\n            new_solution = np.insert(new_solution, best_insert_pos, node_to_move)\n\n    return new_solution\n\n",
        "score": [
            -0.63648776185076,
            0.18939058780670165
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:  # 60% chance to reverse first segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:  # 40% chance to reverse second segment\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with probabilistic segment reversal\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < 0.7:  # 70% chance to reverse the segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Multi-objective adaptive relinking\n    if np.random.rand() < 0.3:  # 30% chance to perform relinking\n        # Select a reference solution from the archive\n        ref_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n        ref_solution = archive[ref_idx][0]\n\n        # Identify common segments between base and reference solutions\n        common_segments = []\n        for i in range(n):\n            if new_solution[i] == ref_solution[i] and new_solution[(i+1)%n] == ref_solution[(i+1)%n]:\n                common_segments.append(i)\n\n        if common_segments:\n            # Select a random common segment to preserve\n            segment_to_preserve = np.random.choice(common_segments)\n            segment_length = min(3, n // 4)  # Preserve up to 3 nodes from the common segment\n\n            # Create a new solution by combining segments from base and reference\n            preserved_nodes = new_solution[segment_to_preserve:segment_to_preserve+segment_length]\n            remaining_nodes = [node for node in ref_solution if node not in preserved_nodes]\n\n            # Reconstruct the tour\n            new_solution = np.concatenate([preserved_nodes, remaining_nodes])\n            new_solution = np.roll(new_solution, -segment_to_preserve)\n\n    return new_solution\n\n",
        "score": [
            -0.7033462343065521,
            0.19583982229232788
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:  # 60% chance to reverse first segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:  # 40% chance to reverse second segment\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with probabilistic segment reversal\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < 0.7:  # 70% chance to reverse the segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.7431294180373934,
            0.21708015203475953
        ]
    },
    {
        "algorithm": "The algorithm combines dominance-aware selection with adaptive segment relinking, prioritizing solutions with high crowding distance in the least dominated objective while applying hybrid 2-opt/3-opt moves with objective-scaled segment inversion and feasibility-preserving tour reconstruction. It intelligently selects solutions based on dominance counts and crowding distance, then performs localized improvements using segment swaps and adaptive relinking to preserve common segments between solutions. The approach balances exploration and exploitation across multiple objectives through dominance-based probability and adaptive scaling of search operations.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n    n = len(archive[0][0])\n\n    # Calculate dominance counts\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in least dominated objective\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment inversion with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes[::-1]\n                new_solution[best_segment:best_end] = worst_segment_nodes[::-1]\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes[::-1].copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes[::-1].copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/3-opt with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if (i+1) <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Multi-objective adaptive relinking\n    if np.random.rand() < 0.3:\n        ref_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n        ref_solution = archive[ref_idx][0]\n\n        common_segments = []\n        for i in range(n):\n            if new_solution[i] == ref_solution[i] and new_solution[(i+1)%n] == ref_solution[(i+1)%n]:\n                common_segments.append(i)\n\n        if common_segments:\n            segment_to_preserve = np.random.choice(common_segments)\n            segment_length = min(3, n // 4)\n\n            preserved_nodes = new_solution[segment_to_preserve:segment_to_preserve+segment_length]\n            remaining_nodes = [node for node in ref_solution if node not in preserved_nodes]\n\n            new_solution = np.concatenate([preserved_nodes, remaining_nodes])\n            new_solution = np.roll(new_solution, -segment_to_preserve)\n\n    return new_solution\n\n",
        "score": [
            -0.6339903184228066,
            0.21210198402404784
        ]
    }
]