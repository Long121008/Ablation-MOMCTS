[
    {
        "algorithm": "The heuristic selects the solution with the lowest combined objective value from the archive and applies a hybrid local search (70% 2-opt, 30% 3-opt) to generate a neighbor, ensuring feasibility by always reversing or reordering segments of the tour. The selection prioritizes solutions with minimal total cost, while the local search balances exploration (random segment selection) and exploitation (reversing segments) to improve multi-objective performance.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the lowest combined objective value\n    selected_idx = np.argmin([sum(obj) for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Apply hybrid local search: 2-opt or 3-opt based on a random choice\n    n = len(new_solution)\n    if n < 4:\n        # For small instances, just swap two nodes\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n    else:\n        # With 70% probability, apply 2-opt, else 3-opt\n        if np.random.rand() < 0.7:\n            # 2-opt move\n            i, j = sorted(np.random.choice(n, 2, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n        else:\n            # 3-opt move\n            i, j, k = sorted(np.random.choice(n, 3, replace=False))\n            segment1 = new_solution[i:j]\n            segment2 = new_solution[j:k]\n            new_solution[i:k] = np.concatenate([segment2, segment1])\n\n    return new_solution\n\n",
        "score": [
            -0.8028366341020267,
            0.34138243198394774
        ]
    },
    {
        "algorithm": "The algorithm dynamically identifies the least dominated objective, selects a high-crowding-distance solution from the archive, and applies an adaptive segment inversion operator that swaps variable-length segments (2-5 nodes) between worst-performing edges in the least dominated objective and best-performing edges in another randomly chosen objective, ensuring feasibility through careful boundary handling. The operator prioritizes underperforming objectives while balancing exploration and exploitation by adaptively adjusting segment lengths based on dominance and diversity in the archive.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate dominance for each objective\n    objectives = np.array([obj for _, obj in archive])\n    dominance = np.sum(objectives <= objectives, axis=0) / len(archive)\n\n    # Select the least dominated objective\n    least_dominated_obj = np.argmin(dominance)\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance in this objective\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2]\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Perform segment inversion\n            segment_length = np.random.randint(2, min(6, n//2))\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            # Extract segments\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Invert segments\n            worst_segment_nodes = worst_segment_nodes[::-1]\n            best_segment_nodes = best_segment_nodes[::-1]\n\n            # Swap inverted segments\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                # Handle wrap-around cases\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                # Perform the swap\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    return new_solution\n\n",
        "score": [
            -0.7057904658048765,
            0.19627649784088136
        ]
    },
    {
        "algorithm": "The algorithm prioritizes the most diverse objective (highest standard deviation in objectives) and selects a high-crowding-distance solution from the archive, then applies an adaptive segment relinking operator that swaps segments between worst-performing edges in the most diverse objective and best-performing edges in another objective, using dynamic segment lengths based on objective diversity. The selection is based on crowding distance in the most diverse objective's space, while the relinking adapts segment sizes proportionally to diversity ratios.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate diversity for each objective\n    diversity = np.std(objectives, axis=0)\n    most_diverse_obj = np.argmax(diversity)\n    selected_matrix = distance_matrices[most_diverse_obj]\n\n    # Calculate crowding distance in the most diverse objective's space\n    normalized_obj = (objectives[:, most_diverse_obj] - np.min(objectives[:, most_diverse_obj])) / (np.max(objectives[:, most_diverse_obj]) - np.min(objectives[:, most_diverse_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Find worst segment in the most diverse objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != most_diverse_obj])\n        other_matrix = distance_matrices[other_obj]\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2]\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Dynamic segment length based on objective diversity\n            segment_length = min(3, max(2, int(np.ceil(np.sqrt(n) * (diversity[most_diverse_obj] / np.sum(diversity))))))\n\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            # Extract segments\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Relink segments\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    return new_solution\n\n",
        "score": [
            -0.7111454534642736,
            0.21573500633239745
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:  # 60% chance to reverse first segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:  # 40% chance to reverse second segment\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with probabilistic segment reversal\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < 0.7:  # 70% chance to reverse the segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Multi-objective adaptive relinking\n    if np.random.rand() < 0.3:  # 30% chance to perform relinking\n        # Select a reference solution from the archive\n        ref_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n        ref_solution = archive[ref_idx][0]\n\n        # Identify common segments between base and reference solutions\n        common_segments = []\n        for i in range(n):\n            if new_solution[i] == ref_solution[i] and new_solution[(i+1)%n] == ref_solution[(i+1)%n]:\n                common_segments.append(i)\n\n        if common_segments:\n            # Select a random common segment to preserve\n            segment_to_preserve = np.random.choice(common_segments)\n            segment_length = min(3, n // 4)  # Preserve up to 3 nodes from the common segment\n\n            # Create a new solution by combining segments from base and reference\n            preserved_nodes = new_solution[segment_to_preserve:segment_to_preserve+segment_length]\n            remaining_nodes = [node for node in ref_solution if node not in preserved_nodes]\n\n            # Reconstruct the tour\n            new_solution = np.concatenate([preserved_nodes, remaining_nodes])\n            new_solution = np.roll(new_solution, -segment_to_preserve)\n\n    return new_solution\n\n",
        "score": [
            -0.7033462343065521,
            0.19583982229232788
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:  # 60% chance to reverse first segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:  # 40% chance to reverse second segment\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with probabilistic segment reversal\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < 0.7:  # 70% chance to reverse the segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.7431294180373934,
            0.21708015203475953
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance ranks for each objective\n    dominance_ranks = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_ranks[i] += 1\n\n    # Select objective with lowest dominance rank (most improved)\n    target_obj = np.argmin(dominance_ranks)\n    selected_matrix = distance_matrices[target_obj]\n\n    # Calculate normalized objective values\n    normalized_obj = (objectives[:, target_obj] - np.min(objectives[:, target_obj])) / (np.max(objectives[:, target_obj]) - np.min(objectives[:, target_obj]) + 1e-8)\n\n    # Select solution with highest normalized objective value (most potential for improvement)\n    selected_idx = np.argmax(normalized_obj)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Dynamic segment length based on dominance rank\n    segment_length = max(2, min(5, int(3 * (1 - dominance_ranks[target_obj]/2) + 2)))\n\n    # Find worst segment in target objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with dynamic scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != target_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate dynamic scaling factor based on objective range\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.3 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Swap segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment swap with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Adaptive 3-opt move with dominance-based probability\n    dominance_prob = 0.5 + 0.3 * (1 - dominance_ranks[target_obj]/2)\n    if np.random.rand() < dominance_prob:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n\n    # Objective-aware node insertion\n    if np.random.rand() < 0.25:\n        # Select a node to move\n        node_to_move = np.random.choice(new_solution)\n        node_idx = np.where(new_solution == node_to_move)[0][0]\n\n        # Find best insertion point in target objective\n        best_insert_pos = -1\n        best_insert_cost = np.inf\n        for i in range(n):\n            if i != node_idx and i != (node_idx - 1) % n:\n                # Calculate cost of inserting node_to_move between i and i+1\n                cost = selected_matrix[new_solution[i], node_to_move] + selected_matrix[node_to_move, new_solution[(i+1)%n]] - selected_matrix[new_solution[i], new_solution[(i+1)%n]]\n                if cost < best_insert_cost:\n                    best_insert_cost = cost\n                    best_insert_pos = i\n\n        if best_insert_pos != -1:\n            # Perform insertion\n            new_solution = np.delete(new_solution, node_idx)\n            if best_insert_pos > node_idx:\n                best_insert_pos -= 1\n            new_solution = np.insert(new_solution, best_insert_pos, node_to_move)\n\n    return new_solution\n\n",
        "score": [
            -0.63648776185076,
            0.18939058780670165
        ]
    },
    {
        "algorithm": "The algorithm selects the most crowding-distance-promising solution from the least dominated objective, applies an adaptive segment inversion operator with dynamic objective scaling, and employs a hybrid 2-opt/3-opt local search with dominance-aware move probabilities to generate high-quality multi-objective neighbors while maintaining feasibility. It prioritizes solutions with lower dominance counts in the least dominated objective and uses crowding distance to identify promising regions for improvement, while dynamically adjusting segment lengths and move probabilities based on dominance ratios. The hybrid local search ensures both exploration and exploitation across all objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in least dominated objective\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment inversion with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes[::-1]\n                new_solution[best_segment:best_end] = worst_segment_nodes[::-1]\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes[::-1].copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes[::-1].copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n    # Hybrid 2-opt/3-opt with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if (i+1) <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.7669217121502199,
            0.22827595472335815
        ]
    },
    {
        "algorithm": "The algorithm combines dominance-aware selection with adaptive segment relinking to optimize a tri-objective TSP, prioritizing segments in the least-dominated objective space while dynamically adjusting segment lengths and applying hybrid local search operators (2-opt/3-opt) probabilistically based on dominance ratios. It ensures feasibility through careful segment exchanges and probabilistic acceptance of solutions improving two or more objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with probability based on dominance\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with feasibility check\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with feasibility check\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Probabilistic acceptance based on multi-objective improvement\n    original_costs = [\n        sum(distance_matrix_1[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[base_solution[k], base_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[base_solution[k], base_solution[(k+1)%n]] for k in range(n))\n    ]\n    new_costs = [\n        sum(distance_matrix_1[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_2[new_solution[k], new_solution[(k+1)%n]] for k in range(n)),\n        sum(distance_matrix_3[new_solution[k], new_solution[(k+1)%n]] for k in range(n))\n    ]\n\n    improvement_count = sum(1 for orig, new in zip(original_costs, new_costs) if new < orig)\n    if improvement_count < 2 and np.random.rand() > 0.4:  # Accept with 60% probability if only one objective improves\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.8202739799376605,
            0.34582159519195554
        ]
    },
    {
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate dominance counts for each objective\n    dominance_counts = np.zeros(3)\n    for i in range(3):\n        for j in range(3):\n            if j != i:\n                if np.all(objectives[:, i] <= objectives[:, j]):\n                    dominance_counts[i] += 1\n\n    least_dominated_obj = np.argmin(dominance_counts)\n    selected_matrix = distance_matrices[least_dominated_obj]\n\n    # Calculate crowding distance in the least dominated objective's space\n    normalized_obj = (objectives[:, least_dominated_obj] - np.min(objectives[:, least_dominated_obj])) / (np.max(objectives[:, least_dominated_obj]) - np.min(objectives[:, least_dominated_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Adaptive segment length based on dominance\n    segment_length = max(2, min(5, int(3 * (dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)) + 2)))\n\n    # Find worst segment in the least dominated objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective with adaptive scaling\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_dominated_obj])\n        other_matrix = distance_matrices[other_obj]\n\n        # Calculate objective scaling factor\n        obj_range = np.max(objectives[:, other_obj]) - np.min(objectives[:, other_obj])\n        scaling_factor = 1.0 + 0.2 * (obj_range / (np.max(objectives) - np.min(objectives) + 1e-8))\n\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2] * scaling_factor\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Exchange segments with dynamic length\n            worst_end = (worst_segment + segment_length) % n\n            best_end = (best_segment + segment_length) % n\n\n            if worst_segment < worst_end:\n                worst_segment_nodes = new_solution[worst_segment:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_segment:], new_solution[:worst_end]])\n\n            if best_segment < best_end:\n                best_segment_nodes = new_solution[best_segment:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_segment:], new_solution[:best_end]])\n\n            # Perform segment exchange with feasibility check\n            if worst_segment < worst_end and best_segment < best_end:\n                new_solution[worst_segment:worst_end] = best_segment_nodes\n                new_solution[best_segment:best_end] = worst_segment_nodes\n            else:\n                if worst_segment > worst_end:\n                    temp = worst_segment_nodes.copy()\n                    new_solution[worst_segment:] = temp[:len(new_solution[worst_segment:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_segment:]):]\n\n                if best_segment > best_end:\n                    temp = best_segment_nodes.copy()\n                    new_solution[best_segment:] = temp[:len(new_solution[best_segment:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_segment:]):]\n\n                if worst_segment < worst_end:\n                    new_solution[worst_segment:worst_end] = best_segment_nodes\n                if best_segment < best_end:\n                    new_solution[best_segment:best_end] = worst_segment_nodes\n\n    # Hybrid 2-opt/3-opt move with dominance-based probability\n    dominance_ratio = dominance_counts[least_dominated_obj] / (sum(dominance_counts) + 1)\n    if np.random.rand() < 0.5 + 0.3 * dominance_ratio:\n        # 3-opt move with probabilistic segment reversal\n        i, j, k = sorted(np.random.choice(range(n), 3, replace=False))\n        if (i+1) <= j and (j+1) <= k:\n            if np.random.rand() < 0.6:  # 60% chance to reverse first segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            if np.random.rand() < 0.4:  # 40% chance to reverse second segment\n                new_solution[j:k+1] = new_solution[j:k+1][::-1]\n    else:\n        # 2-opt move with probabilistic segment reversal\n        i, j = sorted(np.random.choice(range(n), 2, replace=False))\n        if i+1 <= j:\n            if np.random.rand() < 0.7:  # 70% chance to reverse the segment\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Multi-objective adaptive relinking\n    if np.random.rand() < 0.3:  # 30% chance to perform relinking\n        # Select a reference solution from the archive\n        ref_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n        ref_solution = archive[ref_idx][0]\n\n        # Identify common segments between base and reference solutions\n        common_segments = []\n        for i in range(n):\n            if new_solution[i] == ref_solution[i] and new_solution[(i+1)%n] == ref_solution[(i+1)%n]:\n                common_segments.append(i)\n\n        if common_segments:\n            # Select a random common segment to preserve\n            segment_to_preserve = np.random.choice(common_segments)\n            segment_length = min(3, n // 4)  # Preserve up to 3 nodes from the common segment\n\n            # Create a new solution by combining segments from base and reference\n            preserved_nodes = new_solution[segment_to_preserve:segment_to_preserve+segment_length]\n            remaining_nodes = [node for node in ref_solution if node not in preserved_nodes]\n\n            # Reconstruct the tour\n            new_solution = np.concatenate([preserved_nodes, remaining_nodes])\n            new_solution = np.roll(new_solution, -segment_to_preserve)\n\n    return new_solution\n\n",
        "score": [
            -0.7067493472241306,
            0.2112190842628479
        ]
    },
    {
        "algorithm": "The algorithm prioritizes the least diverse objective (lowest standard deviation) to focus on stable regions, selects a solution with high crowding distance in that objective's space, then applies a dynamic 2-opt* operator that exchanges segments between worst-performing edges in the least diverse objective and best-performing edges in another objective, with segment lengths adaptively determined by the ratio of objective diversity.\n\nKey variables: The least diverse objective is identified by computing standard deviations of all objectives, and the solution with the highest crowding distance in that objective's space is selected. The 2-opt* operator dynamically adjusts segment lengths based on diversity ratios, ensuring feasible TSP tours while optimizing across multiple objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for _, obj in archive])\n    distance_matrices = [distance_matrix_1, distance_matrix_2, distance_matrix_3]\n\n    # Calculate diversity for each objective\n    diversity = np.std(objectives, axis=0)\n    least_diverse_obj = np.argmin(diversity)\n    selected_matrix = distance_matrices[least_diverse_obj]\n\n    # Calculate crowding distance in the least diverse objective's space\n    normalized_obj = (objectives[:, least_diverse_obj] - np.min(objectives[:, least_diverse_obj])) / (np.max(objectives[:, least_diverse_obj]) - np.min(objectives[:, least_diverse_obj]) + 1e-8)\n    sorted_idx = np.argsort(normalized_obj)\n    crowding_dist = np.zeros(len(archive))\n    crowding_dist[sorted_idx[0]] = np.inf\n    crowding_dist[sorted_idx[-1]] = np.inf\n    for i in range(1, len(archive)-1):\n        crowding_dist[sorted_idx[i]] = normalized_obj[sorted_idx[i+1]] - normalized_obj[sorted_idx[i-1]]\n\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    n = len(new_solution)\n    if n < 4:\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n    # Find worst segment in the least diverse objective\n    worst_segment = None\n    worst_score = -np.inf\n    for i in range(n):\n        node1, node2 = new_solution[i], new_solution[(i+1)%n]\n        score = selected_matrix[node1, node2]\n        if score > worst_score:\n            worst_score = score\n            worst_segment = i\n\n    if worst_segment is not None:\n        # Find best segment in another objective\n        best_segment = None\n        best_score = np.inf\n        other_obj = np.random.choice([i for i in range(3) if i != least_diverse_obj])\n        other_matrix = distance_matrices[other_obj]\n        for i in range(n):\n            node1, node2 = new_solution[i], new_solution[(i+1)%n]\n            score = other_matrix[node1, node2]\n            if score < best_score:\n                best_score = score\n                best_segment = i\n\n        if best_segment is not None:\n            # Dynamic segment length based on objective diversity ratio\n            segment_length = min(4, max(2, int(np.ceil(np.sqrt(n) * (diversity[least_diverse_obj] / np.sum(diversity))))))\n\n            worst_start = worst_segment\n            worst_end = (worst_segment + segment_length) % n\n            best_start = best_segment\n            best_end = (best_segment + segment_length) % n\n\n            # Extract segments\n            if worst_start < worst_end:\n                worst_segment_nodes = new_solution[worst_start:worst_end]\n            else:\n                worst_segment_nodes = np.concatenate([new_solution[worst_start:], new_solution[:worst_end]])\n\n            if best_start < best_end:\n                best_segment_nodes = new_solution[best_start:best_end]\n            else:\n                best_segment_nodes = np.concatenate([new_solution[best_start:], new_solution[:best_end]])\n\n            # Perform 2-opt* exchange\n            if worst_start < worst_end and best_start < best_end:\n                new_solution[worst_start:worst_end] = best_segment_nodes[::-1]\n                new_solution[best_start:best_end] = worst_segment_nodes[::-1]\n            else:\n                if worst_start > worst_end:\n                    temp = worst_segment_nodes[::-1].copy()\n                    new_solution[worst_start:] = temp[:len(new_solution[worst_start:])]\n                    new_solution[:worst_end] = temp[len(new_solution[worst_start:]):]\n\n                if best_start > best_end:\n                    temp = best_segment_nodes[::-1].copy()\n                    new_solution[best_start:] = temp[:len(new_solution[best_start:])]\n                    new_solution[:best_end] = temp[len(new_solution[best_start:]):]\n\n                if worst_start < worst_end:\n                    new_solution[worst_start:worst_end] = best_segment_nodes[::-1]\n                if best_start < best_end:\n                    new_solution[best_start:best_end] = worst_segment_nodes[::-1]\n\n    return new_solution\n\n",
        "score": [
            -0.6638537659017861,
            0.19781675338745117
        ]
    }
]