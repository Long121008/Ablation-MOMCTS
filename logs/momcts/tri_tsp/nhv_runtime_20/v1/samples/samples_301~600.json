[
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions (top 20% with 80% probability) and applies a dynamic hybrid local search: 50% 4-opt targeting the most-improved objective space, 30% 2-opt in the least-improved space, and 20% random 3-edge swaps, while ensuring feasibility through validation checks. The selection prioritizes high-performing solutions, and the local search adaptively focuses on improving the most and least improved objectives, with fallback to random swaps for diversification.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Selection: Choose a solution with 80% probability from top 20% of archive\n    objectives = [sum(obj) for _, obj in archive]\n    sorted_indices = np.argsort(objectives)\n    top_20_percent = max(1, len(archive) // 5)\n    top_indices = sorted_indices[:top_20_percent]\n    if random.random() < 0.8 and len(top_indices) > 0:\n        selected_idx = random.choice(top_indices)\n    else:\n        selected_idx = random.choice(range(len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Identify most and least improved objective spaces\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    # Dynamic hybrid local search\n    if random.random() < 0.5:  # 50% chance for 4-opt targeting most improved space\n        a, b, c, d = sorted(random.sample(range(n), 4))\n        if norm1 >= norm2 and norm1 >= norm3:\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n            new_solution[b:c+1] = new_solution[b:c+1][::-1]\n            new_solution[c:d+1] = new_solution[c:d+1][::-1]\n        elif norm2 >= norm1 and norm2 >= norm3:\n            new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[b], new_solution[a], new_solution[d], new_solution[c]\n        else:\n            new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[c], new_solution[d], new_solution[a], new_solution[b]\n    elif random.random() < 0.3:  # 30% chance for 2-opt in least improved space\n        if norm1 <= norm2 and norm1 <= norm3:\n            dist_matrix = distance_matrix_1\n        elif norm2 <= norm1 and norm2 <= norm3:\n            dist_matrix = distance_matrix_2\n        else:\n            dist_matrix = distance_matrix_3\n\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # 20% chance for random 3-edge swap\n        a, b, c = sorted(random.sample(range(n), 3))\n        new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 301,
        "algorithm": "This heuristic algorithm selects promising solutions from the top 20% of the archive with 80% probability, precomputes and normalizes objectives, and applies a dynamic hybrid local search combining 4-opt, 2-opt, and 3-edge swaps tailored to the most/least improved objective spaces, ensuring feasible TSP tours while optimizing across three objectives. The selection prioritizes high-quality solutions, while the local search adapts to objective performance through normalized weights.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute objectives and cache them\n    objectives = np.array([obj for _, obj in archive])\n    obj1, obj2, obj3 = objectives[:, 0], objectives[:, 1], objectives[:, 2]\n\n    # Selection: Choose a solution with 80% probability from top 20% of archive\n    top_20_percent = max(1, len(archive) // 5)\n    top_indices = np.argpartition(np.sum(objectives, axis=1), top_20_percent)[:top_20_percent]\n    selected_idx = np.random.choice(top_indices if np.random.random() < 0.8 else np.arange(len(archive)))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Normalize objectives once\n    max_obj1, min_obj1 = np.max(obj1), np.min(obj1)\n    max_obj2, min_obj2 = np.max(obj2), np.min(obj2)\n    max_obj3, min_obj3 = np.max(obj3), np.min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    # Dynamic hybrid local search\n    rand_val = np.random.random()\n    if rand_val < 0.5:  # 50% chance for 4-opt targeting most improved space\n        a, b, c, d = np.sort(np.random.choice(n, 4, replace=False))\n        if norm1 >= norm2 and norm1 >= norm3:\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n            new_solution[b:c+1] = new_solution[b:c+1][::-1]\n            new_solution[c:d+1] = new_solution[c:d+1][::-1]\n        elif norm2 >= norm1 and norm2 >= norm3:\n            new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[b], new_solution[a], new_solution[d], new_solution[c]\n        else:\n            new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[c], new_solution[d], new_solution[a], new_solution[b]\n    elif rand_val < 0.8:  # 30% chance for 2-opt in least improved space\n        if norm1 <= norm2 and norm1 <= norm3:\n            dist_matrix = distance_matrix_1\n        elif norm2 <= norm1 and norm2 <= norm3:\n            dist_matrix = distance_matrix_2\n        else:\n            dist_matrix = distance_matrix_3\n\n        i, j = np.sort(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # 20% chance for random 3-edge swap\n        a, b, c = np.sort(np.random.choice(n, 3, replace=False))\n        new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n\n    return new_solution\n\n",
        "score": [
            -0.6946299627734078,
            0.33590949773788453
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Precompute objectives and cache them\n    objectives = np.array([obj for _, obj in archive])\n    obj1, obj2, obj3 = objectives[:, 0], objectives[:, 1], objectives[:, 2]\n\n    # Selection: Choose a solution with 80% probability from top 20% of archive\n    top_20_percent = max(1, len(archive) // 5)\n    top_indices = np.argpartition(np.sum(objectives, axis=1), top_20_percent)[:top_20_percent]\n    selected_idx = np.random.choice(top_indices if np.random.random() < 0.8 else np.arange(len(archive)))\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Normalize objectives once\n    max_obj1, min_obj1 = np.max(obj1), np.min(obj1)\n    max_obj2, min_obj2 = np.max(obj2), np.min(obj2)\n    max_obj3, min_obj3 = np.max(obj3), np.min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    # Dynamic hybrid local search\n    rand_val = np.random.random()\n    if rand_val < 0.5:  # 50% chance for 4-opt targeting most improved space\n        a, b, c, d = np.sort(np.random.choice(n, 4, replace=False))\n        if norm1 >= norm2 and norm1 >= norm3:\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n            new_solution[b:c+1] = new_solution[b:c+1][::-1]\n            new_solution[c:d+1] = new_solution[c:d+1][::-1]\n        elif norm2 >= norm1 and norm2 >= norm3:\n            new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[b], new_solution[a], new_solution[d], new_solution[c]\n        else:\n            new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[c], new_solution[d], new_solution[a], new_solution[b]\n    elif rand_val < 0.8:  # 30% chance for 2-opt in least improved space\n        if norm1 <= norm2 and norm1 <= norm3:\n            dist_matrix = distance_matrix_1\n        elif norm2 <= norm1 and norm2 <= norm3:\n            dist_matrix = distance_matrix_2\n        else:\n            dist_matrix = distance_matrix_3\n\n        i, j = np.sort(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # 20% chance for random 3-edge swap\n        a, b, c = np.sort(np.random.choice(n, 3, replace=False))\n        new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n\n    return new_solution\n\n",
        "operation": "r1"
    },
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 2 existing algorithms with their codes as follows:\n            No. 1 algorithm and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with under-optimized objectives (boosting weights for solutions where at least one objective is below 50% of its normalized range), then applies a hybrid local search: 70% probability of 2-opt in a randomly chosen objective space and 30% probability of adaptive 3-opt that targets the least-improved objective (rearranging three nodes to improve the worst-performing objective). The solution is validated for feasibility before returning.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize solutions with under-optimized objectives\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    weights = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        hybrid_weight = norm1 * norm2 * norm3\n        if norm1 < 0.5 or norm2 < 0.5 or norm3 < 0.5:\n            hybrid_weight *= 1.5  # Boost weight for solutions with under-optimized objectives\n        weights.append(hybrid_weight)\n\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        selected_idx = np.random.choice(len(archive), p=normalized_weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: 70% 2-opt in a random objective space, 30% adaptive 3-opt\n    if np.random.rand() < 0.7:\n        # 2-opt in a random objective space\n        obj_space = np.random.randint(3)\n        if obj_space == 0:\n            dist_matrix = distance_matrix_1\n        elif obj_space == 1:\n            dist_matrix = distance_matrix_2\n        else:\n            dist_matrix = distance_matrix_3\n\n        i, j = np.random.choice(n, size=2, replace=False)\n        if i > j:\n            i, j = j, i\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:\n        # Adaptive 3-opt targeting the least-improved objective\n        if n >= 4:\n            a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n            if a + 1 == b or b + 1 == c:\n                b = (b + 1) % n\n                c = (c + 1) % n\n\n            norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n            norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n            norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n            if norm1 < norm2 and norm1 < norm3:\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n            elif norm2 < norm1 and norm2 < norm3:\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[a], new_solution[b]\n            else:\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[b], new_solution[a]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives and prioritize solutions with under-optimized objectives\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    weights = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        hybrid_weight = norm1 * norm2 * norm3\n        if norm1 < 0.5 or norm2 < 0.5 or norm3 < 0.5:\n            hybrid_weight *= 2  # Boost weight for solutions with under-optimized objectives\n        weights.append(hybrid_weight)\n\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        selected_idx = np.random.choice(len(archive), p=normalized_weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Apply 60% 3-opt, 30% 2-opt, 10% random swaps to target least-improved objective\n    operation = np.random.random()\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    if operation < 0.6:  # 3-opt with adaptive targeting\n        if n >= 4:\n            a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n            if a + 1 == b or b + 1 == c:\n                b = (b + 1) % n\n                c = (c + 1) % n\n\n            if norm1 < norm2 and norm1 < norm3:  # Objective 1 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n            elif norm2 < norm1 and norm2 < norm3:  # Objective 2 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[a], new_solution[b]\n            else:  # Objective 3 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[b], new_solution[a]\n    elif operation < 0.9:  # 2-opt with adaptive targeting\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            if i > j:\n                i, j = j, i\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # Random swap to explore\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design in your requested format:\n\n- **Keywords**: Tri-objective TSP, adaptive multi-space optimization, Pareto frontier targeting, hybrid local search\n- **Advice**: Implement a 60/30/10 split of 3-opt (targeting worst objective), 2-opt (focused improvement), and random edge swaps; prioritize least-improved objective\n- **Avoid**: Single-space optimization, rigid selection criteria, or feasibility violations\n- **Explanation**: Balances exploration (random swaps) with exploitation (targeted 3-opt/2-opt) while dynamically adapting to multi-objective trade-offs\n\nThis heuristic ensures high-quality, feasible solutions by dynamically targeting under-optimized objectives while maintaining Pareto balance.\n\n            Please help me create a new algorithm that has a totally different form from the given ones but can be motivated from them and the above long-term reflection.\n            1. Firstly, identify the common backbone idea in the provided algorithms.\n            2. Secondly, based on both the backbone idea and the long-term reflection, describe your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax and code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 302,
        "algorithm": "The algorithm employs a multi-phase adaptive selection process that first clusters solutions in the archive using k-means, then selects a representative from the least-performing cluster with a probability proportional to its normalized objective deviations. It then applies a dynamic hybrid local search that alternates between 2-opt in the primary objective space (determined by a weighted combination of all objectives) and a novel \"objective-aware\" 4-opt that specifically targets the least-improved objective, ensuring feasibility through a two-stage validation. The method dynamically adjusts search intensity based on the current Pareto frontier's shape to balance exploration and exploitation.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Extract objectives and normalize\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    # Calculate normalized objectives and deviations\n    normalized = []\n    deviations = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        normalized.append((norm1, norm2, norm3))\n        deviations.append((1 - norm1) + (1 - norm2) + (1 - norm3))\n\n    # Cluster solutions and select from least-performing cluster\n    from sklearn.cluster import KMeans\n    k = min(3, len(archive))\n    if k > 1:\n        clusters = KMeans(n_clusters=k).fit(normalized).labels_\n        cluster_deviations = [sum(deviations[i] for i in range(len(archive)) if clusters[i] == j) for j in range(k)]\n        selected_cluster = np.argmin(cluster_deviations)\n        candidates = [i for i in range(len(archive)) if clusters[i] == selected_cluster]\n    else:\n        candidates = list(range(len(archive)))\n\n    if not candidates:\n        candidates = list(range(len(archive)))\n\n    # Select solution with highest deviation in the selected cluster\n    selected_idx = candidates[np.argmax([deviations[i] for i in candidates])]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Dynamic hybrid local search\n    if n >= 4:\n        # Calculate primary objective space (weighted average of all objectives)\n        norm1, norm2, norm3 = normalized[selected_idx]\n        primary_space = (norm1 * 0.4 + norm2 * 0.3 + norm3 * 0.3)\n        if primary_space < 0.5:\n            # 2-opt in primary objective space\n            if np.random.rand() < 0.6:\n                if norm1 < norm2 and norm1 < norm3:\n                    dist_matrix = distance_matrix_1\n                elif norm2 < norm1 and norm2 < norm3:\n                    dist_matrix = distance_matrix_2\n                else:\n                    dist_matrix = distance_matrix_3\n\n                i, j = np.random.choice(n, size=2, replace=False)\n                if i > j:\n                    i, j = j, i\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            else:\n                # Objective-aware 4-opt\n                a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n                if a + 1 == b or b + 1 == c or c + 1 == d:\n                    b = (b + 1) % n\n                    c = (c + 1) % n\n                    d = (d + 1) % n\n\n                # Calculate objective contributions\n                def calc_contribution(sol, matrix):\n                    total = 0\n                    for i in range(len(sol)-1):\n                        total += matrix[sol[i], sol[i+1]]\n                    total += matrix[sol[-1], sol[0]]\n                    return total\n\n                contrib1 = calc_contribution(new_solution, distance_matrix_1)\n                contrib2 = calc_contribution(new_solution, distance_matrix_2)\n                contrib3 = calc_contribution(new_solution, distance_matrix_3)\n\n                total_contrib = contrib1 + contrib2 + contrib3\n                if total_contrib > 0:\n                    weight1 = contrib1 / total_contrib\n                    weight2 = contrib2 / total_contrib\n                    weight3 = contrib3 / total_contrib\n                else:\n                    weight1 = weight2 = weight3 = 1/3\n\n                # Determine worst objective\n                worst_obj = 1 if (norm1 < norm2 and norm1 < norm3) else (2 if (norm2 < norm1 and norm2 < norm3) else 3)\n\n                # Apply 4-opt with objective awareness\n                if worst_obj == 1:\n                    new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[b], new_solution[d], new_solution[a], new_solution[c]\n                elif worst_obj == 2:\n                    new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[d], new_solution[a], new_solution[c], new_solution[b]\n                else:\n                    new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[c], new_solution[a], new_solution[b], new_solution[d]\n        else:\n            # Standard 2-opt when solution is already performing well\n            i, j = np.random.choice(n, size=2, replace=False)\n            if i > j:\n                i, j = j, i\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Two-stage feasibility check\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n    else:\n        # Verify connectivity\n        visited = set()\n        current = new_solution[0]\n        visited.add(current)\n        for node in new_solution[1:]:\n            if node not in visited:\n                visited.add(node)\n        if len(visited) != n:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.6885168734030229,
            1.786474084854126
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Extract objectives and normalize\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    # Calculate normalized objectives and deviations\n    normalized = []\n    deviations = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        normalized.append((norm1, norm2, norm3))\n        deviations.append((1 - norm1) + (1 - norm2) + (1 - norm3))\n\n    # Cluster solutions and select from least-performing cluster\n    from sklearn.cluster import KMeans\n    k = min(3, len(archive))\n    if k > 1:\n        clusters = KMeans(n_clusters=k).fit(normalized).labels_\n        cluster_deviations = [sum(deviations[i] for i in range(len(archive)) if clusters[i] == j) for j in range(k)]\n        selected_cluster = np.argmin(cluster_deviations)\n        candidates = [i for i in range(len(archive)) if clusters[i] == selected_cluster]\n    else:\n        candidates = list(range(len(archive)))\n\n    if not candidates:\n        candidates = list(range(len(archive)))\n\n    # Select solution with highest deviation in the selected cluster\n    selected_idx = candidates[np.argmax([deviations[i] for i in candidates])]\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Dynamic hybrid local search\n    if n >= 4:\n        # Calculate primary objective space (weighted average of all objectives)\n        norm1, norm2, norm3 = normalized[selected_idx]\n        primary_space = (norm1 * 0.4 + norm2 * 0.3 + norm3 * 0.3)\n        if primary_space < 0.5:\n            # 2-opt in primary objective space\n            if np.random.rand() < 0.6:\n                if norm1 < norm2 and norm1 < norm3:\n                    dist_matrix = distance_matrix_1\n                elif norm2 < norm1 and norm2 < norm3:\n                    dist_matrix = distance_matrix_2\n                else:\n                    dist_matrix = distance_matrix_3\n\n                i, j = np.random.choice(n, size=2, replace=False)\n                if i > j:\n                    i, j = j, i\n                new_solution[i:j+1] = new_solution[i:j+1][::-1]\n            else:\n                # Objective-aware 4-opt\n                a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n                if a + 1 == b or b + 1 == c or c + 1 == d:\n                    b = (b + 1) % n\n                    c = (c + 1) % n\n                    d = (d + 1) % n\n\n                # Calculate objective contributions\n                def calc_contribution(sol, matrix):\n                    total = 0\n                    for i in range(len(sol)-1):\n                        total += matrix[sol[i], sol[i+1]]\n                    total += matrix[sol[-1], sol[0]]\n                    return total\n\n                contrib1 = calc_contribution(new_solution, distance_matrix_1)\n                contrib2 = calc_contribution(new_solution, distance_matrix_2)\n                contrib3 = calc_contribution(new_solution, distance_matrix_3)\n\n                total_contrib = contrib1 + contrib2 + contrib3\n                if total_contrib > 0:\n                    weight1 = contrib1 / total_contrib\n                    weight2 = contrib2 / total_contrib\n                    weight3 = contrib3 / total_contrib\n                else:\n                    weight1 = weight2 = weight3 = 1/3\n\n                # Determine worst objective\n                worst_obj = 1 if (norm1 < norm2 and norm1 < norm3) else (2 if (norm2 < norm1 and norm2 < norm3) else 3)\n\n                # Apply 4-opt with objective awareness\n                if worst_obj == 1:\n                    new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[b], new_solution[d], new_solution[a], new_solution[c]\n                elif worst_obj == 2:\n                    new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[d], new_solution[a], new_solution[c], new_solution[b]\n                else:\n                    new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[c], new_solution[a], new_solution[b], new_solution[d]\n        else:\n            # Standard 2-opt when solution is already performing well\n            i, j = np.random.choice(n, size=2, replace=False)\n            if i > j:\n                i, j = j, i\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Two-stage feasibility check\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n    else:\n        # Verify connectivity\n        visited = set()\n        current = new_solution[0]\n        visited.add(current)\n        for node in new_solution[1:]:\n            if node not in visited:\n                visited.add(node)\n        if len(visited) != n:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "e2"
    },
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        None\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives and prioritize solutions with under-optimized objectives\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    weights = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        hybrid_weight = norm1 * norm2 * norm3\n        if norm1 < 0.5 or norm2 < 0.5 or norm3 < 0.5:\n            hybrid_weight *= 2  # Boost weight for solutions with under-optimized objectives\n        weights.append(hybrid_weight)\n\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        selected_idx = np.random.choice(len(archive), p=normalized_weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Apply 60% 3-opt, 30% 2-opt, 10% random swaps to target least-improved objective\n    operation = np.random.random()\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    if operation < 0.6:  # 3-opt with adaptive targeting\n        if n >= 4:\n            a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n            if a + 1 == b or b + 1 == c:\n                b = (b + 1) % n\n                c = (c + 1) % n\n\n            if norm1 < norm2 and norm1 < norm3:  # Objective 1 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n            elif norm2 < norm1 and norm2 < norm3:  # Objective 2 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[a], new_solution[b]\n            else:  # Objective 3 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[b], new_solution[a]\n    elif operation < 0.9:  # 2-opt with adaptive targeting\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            if i > j:\n                i, j = j, i\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # Random swap to explore\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Please create a new algorithm that has a different form but can be a modified version of the provided algorithm. Attempt to introduce more novel mechanisms and new equations or programme segments.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 303,
        "algorithm": "This algorithm selects a solution from the archive using weighted random selection based on objective diversity and improvement potential, then applies an adaptive local search that prioritizes the least-optimized objective (1, 2, or 3) with a 70% chance of using a segment reversal operator or falling back to 2-opt. It ensures feasibility by validating the solution and reverting to the base solution if invalid. The key design ideas are objective-specific targeting, adaptive operator selection, and segment-based improvement.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Objective diversity-based selection\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 0.5\n        return (value - min_val) / (max_val - min_val)\n\n    # Calculate selection weights based on objective diversity\n    weights = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        diversity = 1 - (abs(norm1 - 0.5) + abs(norm2 - 0.5) + abs(norm3 - 0.5)) / 3\n        improvement_potential = (1 - norm1) * (1 - norm2) * (1 - norm3)\n        weight = diversity * improvement_potential\n        weights.append(weight)\n\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        selected_idx = np.random.choice(len(archive), p=normalized_weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive multi-objective local search\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    # Determine which objective to prioritize\n    if norm1 < norm2 and norm1 < norm3:\n        target_obj = 1\n    elif norm2 < norm1 and norm2 < norm3:\n        target_obj = 2\n    else:\n        target_obj = 3\n\n    # Apply objective-specific operator\n    if np.random.random() < 0.7:  # 70% chance for multi-objective operator\n        if n >= 3:\n            # Select a segment to modify based on target objective\n            segment_size = min(5, n // 2)\n            start = np.random.randint(0, n - segment_size)\n            segment = new_solution[start:start+segment_size]\n\n            # Evaluate segment in all objectives\n            segment_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%segment_size]] for i in range(segment_size))\n            segment_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%segment_size]] for i in range(segment_size))\n            segment_cost3 = sum(distance_matrix_3[segment[i], segment[(i+1)%segment_size]] for i in range(segment_size))\n\n            # Reverse segment if it improves the target objective\n            if target_obj == 1 and segment_cost1 > sum(distance_matrix_1[segment[i], segment[(i-1)%segment_size]] for i in range(segment_size)):\n                new_solution[start:start+segment_size] = segment[::-1]\n            elif target_obj == 2 and segment_cost2 > sum(distance_matrix_2[segment[i], segment[(i-1)%segment_size]] for i in range(segment_size)):\n                new_solution[start:start+segment_size] = segment[::-1]\n            elif target_obj == 3 and segment_cost3 > sum(distance_matrix_3[segment[i], segment[(i-1)%segment_size]] for i in range(segment_size)):\n                new_solution[start:start+segment_size] = segment[::-1]\n\n            # If no improvement, try a random 3-opt\n            if np.array_equal(new_solution, base_solution):\n                a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n                if a + 1 == b or b + 1 == c:\n                    b = (b + 1) % n\n                    c = (c + 1) % n\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n    else:  # Fall back to standard 2-opt\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            if i > j:\n                i, j = j, i\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.6928813711291654,
            0.41969990730285645
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Objective diversity-based selection\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 0.5\n        return (value - min_val) / (max_val - min_val)\n\n    # Calculate selection weights based on objective diversity\n    weights = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        diversity = 1 - (abs(norm1 - 0.5) + abs(norm2 - 0.5) + abs(norm3 - 0.5)) / 3\n        improvement_potential = (1 - norm1) * (1 - norm2) * (1 - norm3)\n        weight = diversity * improvement_potential\n        weights.append(weight)\n\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        selected_idx = np.random.choice(len(archive), p=normalized_weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Adaptive multi-objective local search\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    # Determine which objective to prioritize\n    if norm1 < norm2 and norm1 < norm3:\n        target_obj = 1\n    elif norm2 < norm1 and norm2 < norm3:\n        target_obj = 2\n    else:\n        target_obj = 3\n\n    # Apply objective-specific operator\n    if np.random.random() < 0.7:  # 70% chance for multi-objective operator\n        if n >= 3:\n            # Select a segment to modify based on target objective\n            segment_size = min(5, n // 2)\n            start = np.random.randint(0, n - segment_size)\n            segment = new_solution[start:start+segment_size]\n\n            # Evaluate segment in all objectives\n            segment_cost1 = sum(distance_matrix_1[segment[i], segment[(i+1)%segment_size]] for i in range(segment_size))\n            segment_cost2 = sum(distance_matrix_2[segment[i], segment[(i+1)%segment_size]] for i in range(segment_size))\n            segment_cost3 = sum(distance_matrix_3[segment[i], segment[(i+1)%segment_size]] for i in range(segment_size))\n\n            # Reverse segment if it improves the target objective\n            if target_obj == 1 and segment_cost1 > sum(distance_matrix_1[segment[i], segment[(i-1)%segment_size]] for i in range(segment_size)):\n                new_solution[start:start+segment_size] = segment[::-1]\n            elif target_obj == 2 and segment_cost2 > sum(distance_matrix_2[segment[i], segment[(i-1)%segment_size]] for i in range(segment_size)):\n                new_solution[start:start+segment_size] = segment[::-1]\n            elif target_obj == 3 and segment_cost3 > sum(distance_matrix_3[segment[i], segment[(i-1)%segment_size]] for i in range(segment_size)):\n                new_solution[start:start+segment_size] = segment[::-1]\n\n            # If no improvement, try a random 3-opt\n            if np.array_equal(new_solution, base_solution):\n                a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n                if a + 1 == b or b + 1 == c:\n                    b = (b + 1) % n\n                    c = (c + 1) % n\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n    else:  # Fall back to standard 2-opt\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            if i > j:\n                i, j = j, i\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "m1"
    },
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        None\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives and prioritize solutions with under-optimized objectives\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    weights = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        hybrid_weight = norm1 * norm2 * norm3\n        if norm1 < 0.5 or norm2 < 0.5 or norm3 < 0.5:\n            hybrid_weight *= 2  # Boost weight for solutions with under-optimized objectives\n        weights.append(hybrid_weight)\n\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        selected_idx = np.random.choice(len(archive), p=normalized_weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Apply 60% 3-opt, 30% 2-opt, 10% random swaps to target least-improved objective\n    operation = np.random.random()\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    if operation < 0.6:  # 3-opt with adaptive targeting\n        if n >= 4:\n            a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n            if a + 1 == b or b + 1 == c:\n                b = (b + 1) % n\n                c = (c + 1) % n\n\n            if norm1 < norm2 and norm1 < norm3:  # Objective 1 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n            elif norm2 < norm1 and norm2 < norm3:  # Objective 2 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[a], new_solution[b]\n            else:  # Objective 3 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[b], new_solution[a]\n    elif operation < 0.9:  # 2-opt with adaptive targeting\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            if i > j:\n                i, j = j, i\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # Random swap to explore\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        Please identify the main algorithm parameters and help me in creating a new algorithm that has different parameter settings to equations compared to the provided algorithm.\n        1. First, describe your new algorithm and main steps in one sentence. The description must be inside within boxed {}.\n        2. Next, implement the idea in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax, code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 304,
        "algorithm": "The algorithm selects a solution from the archive using weighted random selection, prioritizing those with balanced objectives and aggressively boosting under-optimized ones. It then applies a hybrid local search (3-opt, 2-opt, or random swaps) tailored to the worst-performing objective, ensuring feasibility by reverting to the original solution if invalid. The method dynamically adapts to multi-objective optimization by focusing improvement efforts on the least optimized objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Enhanced selection: prioritize solutions with balanced objectives and boost those with under-optimized objectives\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    weights = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        hybrid_weight = (norm1 + norm2 + norm3) / 3  # Average normalized objectives\n        if norm1 < 0.4 or norm2 < 0.4 or norm3 < 0.4:\n            hybrid_weight *= 1.5  # More aggressive boost for under-optimized objectives\n        weights.append(hybrid_weight)\n\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        selected_idx = np.random.choice(len(archive), p=normalized_weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Apply 50% 3-opt, 30% 2-opt, 15% random swaps with objective-aware targeting\n    operation = np.random.random()\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    if operation < 0.5:  # 3-opt with objective-aware targeting\n        if n >= 4:\n            a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n            if a + 1 == b or b + 1 == c:\n                b = (b + 1) % n\n                c = (c + 1) % n\n\n            if norm1 < norm2 and norm1 < norm3:  # Objective 1 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n            elif norm2 < norm1 and norm2 < norm3:  # Objective 2 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[a], new_solution[b]\n            else:  # Objective 3 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[b], new_solution[a]\n    elif operation < 0.8:  # 2-opt with objective-aware targeting\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            if i > j:\n                i, j = j, i\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # Random swap with objective-aware targeting\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7785993779839246,
            0.4264997363090515
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Enhanced selection: prioritize solutions with balanced objectives and boost those with under-optimized objectives\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    weights = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        hybrid_weight = (norm1 + norm2 + norm3) / 3  # Average normalized objectives\n        if norm1 < 0.4 or norm2 < 0.4 or norm3 < 0.4:\n            hybrid_weight *= 1.5  # More aggressive boost for under-optimized objectives\n        weights.append(hybrid_weight)\n\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        selected_idx = np.random.choice(len(archive), p=normalized_weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Apply 50% 3-opt, 30% 2-opt, 15% random swaps with objective-aware targeting\n    operation = np.random.random()\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    if operation < 0.5:  # 3-opt with objective-aware targeting\n        if n >= 4:\n            a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n            if a + 1 == b or b + 1 == c:\n                b = (b + 1) % n\n                c = (c + 1) % n\n\n            if norm1 < norm2 and norm1 < norm3:  # Objective 1 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n            elif norm2 < norm1 and norm2 < norm3:  # Objective 2 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[a], new_solution[b]\n            else:  # Objective 3 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[b], new_solution[a]\n    elif operation < 0.8:  # 2-opt with objective-aware targeting\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            if i > j:\n                i, j = j, i\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # Random swap with objective-aware targeting\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "m2"
    },
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n            I have 4 existing algorithms with their codes as follows:\n            No. 1 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives and prioritize solutions with under-optimized objectives\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    weights = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        hybrid_weight = norm1 * norm2 * norm3\n        if norm1 < 0.5 or norm2 < 0.5 or norm3 < 0.5:\n            hybrid_weight *= 2  # Boost weight for solutions with under-optimized objectives\n        weights.append(hybrid_weight)\n\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        selected_idx = np.random.choice(len(archive), p=normalized_weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Apply 60% 3-opt, 30% 2-opt, 10% random swaps to target least-improved objective\n    operation = np.random.random()\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    if operation < 0.6:  # 3-opt with adaptive targeting\n        if n >= 4:\n            a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n            if a + 1 == b or b + 1 == c:\n                b = (b + 1) % n\n                c = (c + 1) % n\n\n            if norm1 < norm2 and norm1 < norm3:  # Objective 1 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n            elif norm2 < norm1 and norm2 < norm3:  # Objective 2 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[a], new_solution[b]\n            else:  # Objective 3 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[b], new_solution[a]\n    elif operation < 0.9:  # 2-opt with adaptive targeting\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            if i > j:\n                i, j = j, i\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # Random swap to explore\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive based on normalized objective diversity, prioritizing those with higher diversity across the three objectives. It then applies a 4-opt local search with adaptive segment reversals\u2014reversing segments based on which objective is least optimized (e.g., reversing segments `a:b` and `c:d` if the first objective is worst). The solution is validated to ensure feasibility, reverting to the original if invalid.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    diversity_weights = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        diversity = abs(norm1 - norm2) + abs(norm2 - norm3) + abs(norm3 - norm1)\n        diversity_weights.append(diversity)\n\n    total_diversity = sum(diversity_weights)\n    if total_diversity == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_diversity = [w / total_diversity for w in diversity_weights]\n        selected_idx = np.random.choice(len(archive), p=normalized_diversity)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    if n >= 5:\n        a, b, c, d = sorted(np.random.choice(n, size=4, replace=False))\n        if a + 1 in [b, c, d] or b + 1 in [c, d] or c + 1 == d:\n            b = (b + 1) % n\n            c = (c + 1) % n\n            d = (d + 1) % n\n\n        norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n        norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n        norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n        if norm1 < norm2 and norm1 < norm3:\n            new_solution[a:b] = new_solution[a:b][::-1]\n            new_solution[c:d] = new_solution[c:d][::-1]\n        elif norm2 < norm1 and norm2 < norm3:\n            new_solution[b:c] = new_solution[b:c][::-1]\n            new_solution[d:a] = new_solution[d:a][::-1]\n        else:\n            new_solution[c:d] = new_solution[c:d][::-1]\n            new_solution[a:b] = new_solution[a:b][::-1]\n\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThe algorithm selects a solution from the archive using a hybrid weight that combines normalized objective values and prioritizes solutions with under-optimized objectives, then applies a novel 3-opt local search that adaptively reorders three non-consecutive nodes to improve the most under-optimized objective while ensuring feasibility. The selection process boosts weights for solutions with at least one normalized objective below 0.5, and the local search prioritizes reordering based on which objective is least optimized.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives and track under-optimized objectives\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    weights = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        # Combine with adaptive targeting: prioritize solutions with at least one under-optimized objective\n        hybrid_weight = norm1 * norm2 * norm3\n        if norm1 < 0.5 or norm2 < 0.5 or norm3 < 0.5:\n            hybrid_weight *= 2  # Boost weight for solutions with under-optimized objectives\n        weights.append(hybrid_weight)\n\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        selected_idx = np.random.choice(len(archive), p=normalized_weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Novel 3-opt local search with adaptive targeting\n    if n >= 4:\n        # Select three non-consecutive nodes\n        a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n        if a + 1 == b or b + 1 == c:  # Ensure non-consecutive\n            b = (b + 1) % n\n            c = (c + 1) % n\n\n        # Reorder the selected nodes with adaptive targeting\n        # Check which objectives are under-optimized and prioritize improving them\n        norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n        norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n        norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n        if norm1 < norm2 and norm1 < norm3:  # Objective 1 is under-optimized\n            # Reorder to improve objective 1\n            new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n        elif norm2 < norm1 and norm2 < norm3:  # Objective 2 is under-optimized\n            # Reorder to improve objective 2\n            new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[a], new_solution[b]\n        else:  # Objective 3 is under-optimized\n            # Reorder to improve objective 3\n            new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[b], new_solution[a]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects the most promising solution from the archive (based on the lowest sum of objectives) and applies a hybrid local search combining 2-opt moves and a multi-objective perturbation step. It first randomly reverses a segment of the tour (2-opt), then identifies the worst edge in a randomly chosen objective space and attempts to improve it by inserting a better node, ensuring feasibility. The method prioritizes solutions with lower objective sums and adaptively targets specific objectives for improvement.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the lowest sum of objectives (promising for improvement)\n    selected_solution, _ = min(archive, key=lambda x: sum(x[1]))\n    base_solution = selected_solution.copy()\n\n    # Hybrid local search: 2-opt + multi-objective perturbation\n    new_solution = base_solution.copy()\n\n    # Perform 2-opt move\n    n = len(new_solution)\n    i, j = np.random.choice(n, size=2, replace=False)\n    if i > j:\n        i, j = j, i\n    new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Multi-objective perturbation: randomly select an objective and perform a swap\n    obj_idx = np.random.randint(3)\n    if obj_idx == 0:\n        dist_matrix = distance_matrix_1\n    elif obj_idx == 1:\n        dist_matrix = distance_matrix_2\n    else:\n        dist_matrix = distance_matrix_3\n\n    # Find the worst edge in the selected objective\n    worst_edge = -1\n    worst_cost = -1\n    for k in range(n):\n        u = new_solution[k]\n        v = new_solution[(k+1)%n]\n        cost = dist_matrix[u, v]\n        if cost > worst_cost:\n            worst_cost = cost\n            worst_edge = k\n\n    # Swap nodes to improve the worst edge\n    if worst_edge != -1:\n        u = new_solution[worst_edge]\n        v = new_solution[(worst_edge+1)%n]\n        candidates = [i for i in range(n) if i != u and i != v]\n\n        if candidates:\n            best_candidate = None\n            best_improvement = 0\n\n            for candidate in candidates:\n                # Try inserting candidate between u and v\n                new_cost = dist_matrix[u, candidate] + dist_matrix[candidate, v] - dist_matrix[u, v]\n                if new_cost < best_improvement:\n                    best_improvement = new_cost\n                    best_candidate = candidate\n\n            if best_candidate is not None:\n                # Perform the insertion\n                new_solution = np.delete(new_solution, np.where(new_solution == best_candidate)[0][0])\n                pos = (worst_edge + 1) % n\n                new_solution = np.insert(new_solution, pos, best_candidate)\n\n    return new_solution\n\n\n\n\n            Additionally, here is a long-term reflection that provides higher-level guidance for improvement:\n            Here\u2019s the refined heuristic design in your requested format:\n\n- **Keywords**: Tri-objective TSP, adaptive multi-space optimization, Pareto frontier targeting, hybrid local search\n- **Advice**: Implement a 60/30/10 split of 3-opt (targeting worst objective), 2-opt (focused improvement), and random edge swaps; prioritize least-improved objective\n- **Avoid**: Single-space optimization, rigid selection criteria, or feasibility violations\n- **Explanation**: Balances exploration (random swaps) with exploitation (targeted 3-opt/2-opt) while dynamically adapting to multi-objective trade-offs\n\nThis heuristic ensures high-quality, feasible solutions by dynamically targeting under-optimized objectives while maintaining Pareto balance.\n\n            Please help me create a new algorithm that is inspired by all the above algorithms and the long-term reflection, aiming to achieve objective values lower than any of them.\n\n            1. Firstly, list some ideas in the provided algorithms and the long-term reflection that are clearly helpful for designing a better algorithm.\n            2. Secondly, based on the listed ideas, describe the design idea and main steps of your new algorithm in one long, detailed sentence. The description must be enclosed within boxed {}.\n            3. Thirdly, implement the idea in the following Python function:\n            def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n\n            Check syntax, code carefully before returning the final function. Do not give any additional explanations.\n            ",
        "sample_order": 305,
        "algorithm": "The algorithm selects a solution from the archive using a hybrid weight that combines normalized objective values and diversity, prioritizing solutions with under-optimized objectives (those with at least one normalized objective below 0.5). It then applies a hybrid local search with a 60/30/10 split of 3-opt (targeting the worst objective), 2-opt (focused improvement), and random edge swaps, adaptively choosing the operation based on which objective is least optimized. The solution is reverted to the original if invalid, ensuring feasibility. The selection process boosts weights for solutions with under-optimized objectives, and the local search prioritizes reordering based on the least-improved objective.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives and diversity\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    weights = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        diversity = abs(norm1 - norm2) + abs(norm2 - norm3) + abs(norm3 - norm1)\n        hybrid_weight = norm1 * norm2 * norm3 * diversity\n        if norm1 < 0.5 or norm2 < 0.5 or norm3 < 0.5:\n            hybrid_weight *= 2  # Boost weight for solutions with under-optimized objectives\n        weights.append(hybrid_weight)\n\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        selected_idx = np.random.choice(len(archive), p=normalized_weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search with adaptive targeting\n    operation = np.random.random()\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    if operation < 0.6:  # 3-opt with adaptive targeting\n        if n >= 4:\n            a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n            if a + 1 == b or b + 1 == c:\n                b = (b + 1) % n\n                c = (c + 1) % n\n\n            if norm1 < norm2 and norm1 < norm3:  # Objective 1 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n            elif norm2 < norm1 and norm2 < norm3:  # Objective 2 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[a], new_solution[b]\n            else:  # Objective 3 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[b], new_solution[a]\n    elif operation < 0.9:  # 2-opt with adaptive targeting\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            if i > j:\n                i, j = j, i\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # Random swap to explore\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7392867298146716,
            0.42230404615402223
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Hybrid selection: combine normalized objectives and diversity\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    weights = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        diversity = abs(norm1 - norm2) + abs(norm2 - norm3) + abs(norm3 - norm1)\n        hybrid_weight = norm1 * norm2 * norm3 * diversity\n        if norm1 < 0.5 or norm2 < 0.5 or norm3 < 0.5:\n            hybrid_weight *= 2  # Boost weight for solutions with under-optimized objectives\n        weights.append(hybrid_weight)\n\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        selected_idx = np.random.choice(len(archive), p=normalized_weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search with adaptive targeting\n    operation = np.random.random()\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    if operation < 0.6:  # 3-opt with adaptive targeting\n        if n >= 4:\n            a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n            if a + 1 == b or b + 1 == c:\n                b = (b + 1) % n\n                c = (c + 1) % n\n\n            if norm1 < norm2 and norm1 < norm3:  # Objective 1 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n            elif norm2 < norm1 and norm2 < norm3:  # Objective 2 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[a], new_solution[b]\n            else:  # Objective 3 is worst\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[b], new_solution[a]\n    elif operation < 0.9:  # 2-opt with adaptive targeting\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            if i > j:\n                i, j = j, i\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # Random swap to explore\n        if n >= 2:\n            i, j = np.random.choice(n, size=2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "s1"
    },
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have 6 existing algorithms with their codes as follows:\n        No. 1 algorithm's description and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize solutions with balanced performance\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    weights = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        # Boost solutions with balanced performance\n        hybrid_weight = norm1 * norm2 * norm3\n        if (norm1 < 0.5 and norm2 < 0.5) or (norm1 < 0.5 and norm3 < 0.5) or (norm2 < 0.5 and norm3 < 0.5):\n            hybrid_weight *= 1.5\n        weights.append(hybrid_weight)\n\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        selected_idx = np.random.choice(len(archive), p=normalized_weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: alternate between objective-space 2-opt and edge-swap\n    if n >= 4:\n        if np.random.rand() < 0.7:  # 70% chance for 2-opt\n            # Select objective space based on under-optimization\n            norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n            norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n            norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n            if norm1 < norm2 and norm1 < norm3:\n                dist_matrix = distance_matrix_1\n            elif norm2 < norm1 and norm2 < norm3:\n                dist_matrix = distance_matrix_2\n            else:\n                dist_matrix = distance_matrix_3\n\n            # Perform 2-opt in the selected objective space\n            i, j = np.random.choice(n, size=2, replace=False)\n            if i > j:\n                i, j = j, i\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n        else:  # 30% chance for edge-swap\n            # Find the worst edge in a random objective space\n            swap_obj_space = np.random.randint(3)\n            if swap_obj_space == 0:\n                swap_dist_matrix = distance_matrix_1\n            elif swap_obj_space == 1:\n                swap_dist_matrix = distance_matrix_2\n            else:\n                swap_dist_matrix = distance_matrix_3\n\n            worst_edge = -1\n            worst_cost = -1\n            for k in range(n):\n                u = new_solution[k]\n                v = new_solution[(k+1)%n]\n                cost = swap_dist_matrix[u, v]\n                if cost > worst_cost:\n                    worst_cost = cost\n                    worst_edge = k\n\n            if worst_edge != -1:\n                u = new_solution[worst_edge]\n                v = new_solution[(worst_edge+1)%n]\n                candidates = [i for i in range(n) if i != u and i != v]\n\n                if candidates:\n                    best_candidate = None\n                    best_improvement = 0\n\n                    for candidate in candidates:\n                        new_cost = swap_dist_matrix[u, candidate] + swap_dist_matrix[candidate, v] - swap_dist_matrix[u, v]\n                        if new_cost < best_improvement:\n                            best_improvement = new_cost\n                            best_candidate = candidate\n\n                    if best_candidate is not None:\n                        new_solution = np.delete(new_solution, np.where(new_solution == best_candidate)[0][0])\n                        pos = (worst_edge + 1) % n\n                        new_solution = np.insert(new_solution, pos, best_candidate)\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 2 algorithm's description and the corresponding code are:\nThe algorithm selects a promising solution from the archive by prioritizing those with under-optimized objectives (boosting weights for solutions where at least one objective is below 50% of its normalized range), then applies a hybrid local search: 70% probability of 2-opt in a randomly chosen objective space and 30% probability of adaptive 3-opt that targets the least-improved objective (rearranging three nodes to improve the worst-performing objective). The solution is validated for feasibility before returning.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive selection: prioritize solutions with under-optimized objectives\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    weights = []\n    for i in range(len(archive)):\n        norm1 = normalize(obj1[i], max_obj1, min_obj1)\n        norm2 = normalize(obj2[i], max_obj2, min_obj2)\n        norm3 = normalize(obj3[i], max_obj3, min_obj3)\n        hybrid_weight = norm1 * norm2 * norm3\n        if norm1 < 0.5 or norm2 < 0.5 or norm3 < 0.5:\n            hybrid_weight *= 1.5  # Boost weight for solutions with under-optimized objectives\n        weights.append(hybrid_weight)\n\n    total_weight = sum(weights)\n    if total_weight == 0:\n        selected_idx = np.random.randint(len(archive))\n    else:\n        normalized_weights = [w / total_weight for w in weights]\n        selected_idx = np.random.choice(len(archive), p=normalized_weights)\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Hybrid local search: 70% 2-opt in a random objective space, 30% adaptive 3-opt\n    if np.random.rand() < 0.7:\n        # 2-opt in a random objective space\n        obj_space = np.random.randint(3)\n        if obj_space == 0:\n            dist_matrix = distance_matrix_1\n        elif obj_space == 1:\n            dist_matrix = distance_matrix_2\n        else:\n            dist_matrix = distance_matrix_3\n\n        i, j = np.random.choice(n, size=2, replace=False)\n        if i > j:\n            i, j = j, i\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:\n        # Adaptive 3-opt targeting the least-improved objective\n        if n >= 4:\n            a, b, c = sorted(np.random.choice(n, size=3, replace=False))\n            if a + 1 == b or b + 1 == c:\n                b = (b + 1) % n\n                c = (c + 1) % n\n\n            norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n            norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n            norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n            if norm1 < norm2 and norm1 < norm3:\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n            elif norm2 < norm1 and norm2 < norm3:\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[a], new_solution[b]\n            else:\n                new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[b], new_solution[a]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 3 algorithm's description and the corresponding code are:\nThis algorithm dynamically prioritizes local search operations based on objective-space performance, focusing 65% of the time on the least-improved objective via 2-opt, while using 35% of the time for multi-space edge operations. It includes a 10% chance of randomized edge swaps to escape local optima, with aggressive feasibility checks that revert to the original solution if any infeasibility is detected. The selection strategy prioritizes high-performing solutions (top 30%) 70% of the time, balancing exploration and exploitation.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Selection: Choose a solution with a 70% chance from the top 30% of the archive\n    objectives = [sum(obj) for _, obj in archive]\n    sorted_indices = np.argsort(objectives)\n    top_30_percent = max(1, len(archive) // 3)\n    top_indices = sorted_indices[:top_30_percent]\n    if random.random() < 0.7 and len(top_indices) > 0:\n        selected_idx = random.choice(top_indices)\n    else:\n        selected_idx = random.choice(range(len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Identify least-improved objective space\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    # Dynamic local search\n    if random.random() < 0.65:  # 65% chance for 2-opt in least-improved space\n        if norm1 <= norm2 and norm1 <= norm3:\n            dist_matrix = distance_matrix_1\n        elif norm2 <= norm1 and norm2 <= norm3:\n            dist_matrix = distance_matrix_2\n        else:\n            dist_matrix = distance_matrix_3\n\n        # 2-opt in selected space\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # 35% chance for multi-space edge swap\n        # Select edges from different spaces with weighted probability\n        space1_edges = []\n        space2_edges = []\n        space3_edges = []\n\n        for k in range(n-1):\n            i, j = new_solution[k], new_solution[k+1]\n            space1_edges.append((i, j, distance_matrix_1[i, j]))\n            space2_edges.append((i, j, distance_matrix_2[i, j]))\n            space3_edges.append((i, j, distance_matrix_3[i, j]))\n\n        # Weighted selection based on edge distances\n        all_edges = space1_edges + space2_edges + space3_edges\n        all_edges.sort(key=lambda x: x[2])\n        top_edges = all_edges[:max(1, len(all_edges)//5)]\n\n        if top_edges:\n            # Select edge with weighted probability (shorter edges more likely)\n            edge_weights = [1.0 / (1.0 + e[2]) for e in top_edges]\n            edge_to_swap = random.choices(top_edges, weights=edge_weights, k=1)[0]\n            i, j = edge_to_swap[:2]\n\n            # Find positions in the solution\n            pos_i = np.where(new_solution == i)[0][0]\n            pos_j = np.where(new_solution == j)[0][0]\n\n            # Swap the edges\n            if pos_i < pos_j:\n                new_solution[pos_i:pos_j+1] = new_solution[pos_i:pos_j+1][::-1]\n\n    # Ensure feasibility with aggressive rollback\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    # Increased randomized edge perturbation (10% chance)\n    if random.random() < 0.1 and n >= 4:\n        a, b = sorted(random.sample(range(n), 2))\n        new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n        if len(np.unique(new_solution)) != n:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 4 algorithm's description and the corresponding code are:\nThe algorithm selects high-potential solutions (top 30% with 70% probability) and applies a hybrid local search with adaptive 3-opt (60% chance) targeting the least-improved objective, objective-space 2-opt (30% chance), or random edge swaps (10% chance), while ensuring feasibility through validation checks. The selection prioritizes solutions with better normalized objective values, and the local search adaptively optimizes based on objective performance.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Selection: Choose a solution with a 70% chance from the top 30% of the archive\n    objectives = [sum(obj) for _, obj in archive]\n    sorted_indices = np.argsort(objectives)\n    top_30_percent = max(1, len(archive) // 3)\n    top_indices = sorted_indices[:top_30_percent]\n    if random.random() < 0.7 and len(top_indices) > 0:\n        selected_idx = random.choice(top_indices)\n    else:\n        selected_idx = random.choice(range(len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Identify least-improved objective space\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    # Hybrid local search\n    if random.random() < 0.6:  # 60% chance for adaptive 3-opt\n        # Select three non-consecutive nodes\n        a, b, c = sorted(random.sample(range(n), 3))\n        if a + 1 == b or b + 1 == c:\n            b = (b + 1) % n\n            c = (c + 1) % n\n\n        # Reorder based on least-improved objective\n        if norm1 <= norm2 and norm1 <= norm3:\n            new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n        elif norm2 <= norm1 and norm2 <= norm3:\n            new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[a], new_solution[b]\n        else:\n            new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[b], new_solution[a]\n    elif random.random() < 0.3:  # 30% chance for objective-space 2-opt\n        # Select objective space based on least-improved\n        if norm1 <= norm2 and norm1 <= norm3:\n            dist_matrix = distance_matrix_1\n        elif norm2 <= norm1 and norm2 <= norm3:\n            dist_matrix = distance_matrix_2\n        else:\n            dist_matrix = distance_matrix_3\n\n        # Perform 2-opt in selected space\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # 10% chance for random edge swap\n        a, b = sorted(random.sample(range(n), 2))\n        new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 5 algorithm's description and the corresponding code are:\nThe algorithm selects promising solutions (top 20% with 80% probability) and applies a dynamic hybrid local search: 50% 4-opt targeting the most-improved objective space, 30% 2-opt in the least-improved space, and 20% random 3-edge swaps, while ensuring feasibility through validation checks. The selection prioritizes high-performing solutions, and the local search adaptively focuses on improving the most and least improved objectives, with fallback to random swaps for diversification.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Selection: Choose a solution with 80% probability from top 20% of archive\n    objectives = [sum(obj) for _, obj in archive]\n    sorted_indices = np.argsort(objectives)\n    top_20_percent = max(1, len(archive) // 5)\n    top_indices = sorted_indices[:top_20_percent]\n    if random.random() < 0.8 and len(top_indices) > 0:\n        selected_idx = random.choice(top_indices)\n    else:\n        selected_idx = random.choice(range(len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Identify most and least improved objective spaces\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    # Dynamic hybrid local search\n    if random.random() < 0.5:  # 50% chance for 4-opt targeting most improved space\n        a, b, c, d = sorted(random.sample(range(n), 4))\n        if norm1 >= norm2 and norm1 >= norm3:\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n            new_solution[b:c+1] = new_solution[b:c+1][::-1]\n            new_solution[c:d+1] = new_solution[c:d+1][::-1]\n        elif norm2 >= norm1 and norm2 >= norm3:\n            new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[b], new_solution[a], new_solution[d], new_solution[c]\n        else:\n            new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[c], new_solution[d], new_solution[a], new_solution[b]\n    elif random.random() < 0.3:  # 30% chance for 2-opt in least improved space\n        if norm1 <= norm2 and norm1 <= norm3:\n            dist_matrix = distance_matrix_1\n        elif norm2 <= norm1 and norm2 <= norm3:\n            dist_matrix = distance_matrix_2\n        else:\n            dist_matrix = distance_matrix_3\n\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # 20% chance for random 3-edge swap\n        a, b, c = sorted(random.sample(range(n), 3))\n        new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\nNo. 6 algorithm's description and the corresponding code are:\nThe algorithm implements a tri-objective TSP local search by prioritizing the least-improved objective (60% 3-opt), occasionally performing 2-opt in random spaces (30%), and occasionally random swaps (10%). It selects promising solutions (top 40% with 80% probability) and ensures feasibility through validation checks. The least-improved objective is identified by normalizing and comparing the three objective values, guiding the search toward balancing all objectives.\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Selection: Choose a solution with 80% probability from top 40% of archive\n    objectives = [sum(obj) for _, obj in archive]\n    sorted_indices = np.argsort(objectives)\n    top_40_percent = max(1, len(archive) // 2)\n    top_indices = sorted_indices[:top_40_percent]\n    if random.random() < 0.8 and len(top_indices) > 0:\n        selected_idx = random.choice(top_indices)\n    else:\n        selected_idx = random.choice(range(len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Identify least-improved objective space\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    # Dynamic hybrid local search\n    if random.random() < 0.6:  # 60% chance for 3-opt targeting least-improved space\n        a, b, c = sorted(random.sample(range(n), 3))\n        if a + 1 == b or b + 1 == c:\n            b = (b + 1) % n\n            c = (c + 1) % n\n\n        if norm1 <= norm2 and norm1 <= norm3:\n            new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n        elif norm2 <= norm1 and norm2 <= norm3:\n            new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[a], new_solution[b]\n        else:\n            new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[b], new_solution[a]\n    elif random.random() < 0.3:  # 30% chance for 2-opt in random space\n        obj_space = random.randint(0, 2)\n        if obj_space == 0:\n            dist_matrix = distance_matrix_1\n        elif obj_space == 1:\n            dist_matrix = distance_matrix_2\n        else:\n            dist_matrix = distance_matrix_3\n\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # 10% chance for random edge swap\n        a, b = sorted(random.sample(range(n), 2))\n        new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\n        Adjusted long-term guide: Here\u2019s the refined heuristic design in your requested format:\n\n- **Keywords**: Tri-objective TSP, adaptive multi-space optimization, Pareto frontier targeting, hybrid local search\n- **Advice**: Implement a 60/30/10 split of 3-opt (targeting worst objective), 2-opt (focused improvement), and random edge swaps; prioritize least-improved objective\n- **Avoid**: Single-space optimization, rigid selection criteria, or feasibility violations\n- **Explanation**: Balances exploration (random swaps) with exploitation (targeted 3-opt/2-opt) while dynamically adapting to multi-objective trade-offs\n\nThis heuristic ensures high-quality, feasible solutions by dynamically targeting under-optimized objectives while maintaining Pareto balance.\n        Please create a new algorithm inspired by above with better objectives, using the long-term guide.\n        1. Describe new algorithm in one sentence. Boxed {}.\n        2. Implement:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        Check syntax. No extra explanations.",
        "sample_order": 306,
        "algorithm": "This algorithm implements a dynamic hybrid local search for tri-objective TSP that prioritizes 60% 3-opt operations targeting the least-improved objective, 30% 2-opt operations in the most-improved space, and 10% random edge swaps for diversification, while ensuring feasibility through strict validation checks. It intelligently selects solutions from the top 40% of the archive and applies objective-specific local search strategies to balance improvement across all three objectives.",
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Selection: Choose a solution with 80% probability from top 40% of archive\n    objectives = [sum(obj) for _, obj in archive]\n    sorted_indices = np.argsort(objectives)\n    top_40_percent = max(1, len(archive) // 2)\n    top_indices = sorted_indices[:top_40_percent]\n    if random.random() < 0.8 and len(top_indices) > 0:\n        selected_idx = random.choice(top_indices)\n    else:\n        selected_idx = random.choice(range(len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Identify least and most improved objective spaces\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    # Dynamic hybrid local search\n    if random.random() < 0.6:  # 60% chance for 3-opt targeting least-improved space\n        a, b, c = sorted(random.sample(range(n), 3))\n        if a + 1 == b or b + 1 == c:\n            b = (b + 1) % n\n            c = (c + 1) % n\n\n        if norm1 <= norm2 and norm1 <= norm3:\n            new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n        elif norm2 <= norm1 and norm2 <= norm3:\n            new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[a], new_solution[b]\n        else:\n            new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[b], new_solution[a]\n    elif random.random() < 0.3:  # 30% chance for 2-opt in most improved space\n        if norm1 >= norm2 and norm1 >= norm3:\n            dist_matrix = distance_matrix_1\n        elif norm2 >= norm1 and norm2 >= norm3:\n            dist_matrix = distance_matrix_2\n        else:\n            dist_matrix = distance_matrix_3\n\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # 10% chance for random edge swap\n        a, b = sorted(random.sample(range(n), 2))\n        new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7992495964178471,
            0.3111580014228821
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Selection: Choose a solution with 80% probability from top 40% of archive\n    objectives = [sum(obj) for _, obj in archive]\n    sorted_indices = np.argsort(objectives)\n    top_40_percent = max(1, len(archive) // 2)\n    top_indices = sorted_indices[:top_40_percent]\n    if random.random() < 0.8 and len(top_indices) > 0:\n        selected_idx = random.choice(top_indices)\n    else:\n        selected_idx = random.choice(range(len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Identify least and most improved objective spaces\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    # Dynamic hybrid local search\n    if random.random() < 0.6:  # 60% chance for 3-opt targeting least-improved space\n        a, b, c = sorted(random.sample(range(n), 3))\n        if a + 1 == b or b + 1 == c:\n            b = (b + 1) % n\n            c = (c + 1) % n\n\n        if norm1 <= norm2 and norm1 <= norm3:\n            new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n        elif norm2 <= norm1 and norm2 <= norm3:\n            new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[a], new_solution[b]\n        else:\n            new_solution[a], new_solution[b], new_solution[c] = new_solution[c], new_solution[b], new_solution[a]\n    elif random.random() < 0.3:  # 30% chance for 2-opt in most improved space\n        if norm1 >= norm2 and norm1 >= norm3:\n            dist_matrix = distance_matrix_1\n        elif norm2 >= norm1 and norm2 >= norm3:\n            dist_matrix = distance_matrix_2\n        else:\n            dist_matrix = distance_matrix_3\n\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # 10% chance for random edge swap\n        a, b = sorted(random.sample(range(n), 2))\n        new_solution[a], new_solution[b] = new_solution[b], new_solution[a]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "elitist"
    },
    {
        "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\n        I have one algorithm with its code as follows. Algorithm description:\n        The algorithm selects promising solutions (top 20% with 80% probability) and applies a dynamic hybrid local search: 50% 4-opt targeting the most-improved objective space, 30% 2-opt in the least-improved space, and 20% random 3-edge swaps, while ensuring feasibility through validation checks. The selection prioritizes high-performing solutions, and the local search adaptively focuses on improving the most and least improved objectives, with fallback to random swaps for diversification.\n        Code:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Selection: Choose a solution with 80% probability from top 20% of archive\n    objectives = [sum(obj) for _, obj in archive]\n    sorted_indices = np.argsort(objectives)\n    top_20_percent = max(1, len(archive) // 5)\n    top_indices = sorted_indices[:top_20_percent]\n    if random.random() < 0.8 and len(top_indices) > 0:\n        selected_idx = random.choice(top_indices)\n    else:\n        selected_idx = random.choice(range(len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Identify most and least improved objective spaces\n    obj1 = [obj[0] for _, obj in archive]\n    obj2 = [obj[1] for _, obj in archive]\n    obj3 = [obj[2] for _, obj in archive]\n    max_obj1, min_obj1 = max(obj1), min(obj1)\n    max_obj2, min_obj2 = max(obj2), min(obj2)\n    max_obj3, min_obj3 = max(obj3), min(obj3)\n\n    def normalize(value, max_val, min_val):\n        if max_val == min_val:\n            return 1.0\n        return (value - min_val) / (max_val - min_val)\n\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    # Dynamic hybrid local search\n    if random.random() < 0.5:  # 50% chance for 4-opt targeting most improved space\n        a, b, c, d = sorted(random.sample(range(n), 4))\n        if norm1 >= norm2 and norm1 >= norm3:\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n            new_solution[b:c+1] = new_solution[b:c+1][::-1]\n            new_solution[c:d+1] = new_solution[c:d+1][::-1]\n        elif norm2 >= norm1 and norm2 >= norm3:\n            new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[b], new_solution[a], new_solution[d], new_solution[c]\n        else:\n            new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[c], new_solution[d], new_solution[a], new_solution[b]\n    elif random.random() < 0.3:  # 30% chance for 2-opt in least improved space\n        if norm1 <= norm2 and norm1 <= norm3:\n            dist_matrix = distance_matrix_1\n        elif norm2 <= norm1 and norm2 <= norm3:\n            dist_matrix = distance_matrix_2\n        else:\n            dist_matrix = distance_matrix_3\n\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # 20% chance for random 3-edge swap\n        a, b, c = sorted(random.sample(range(n), 3))\n        new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n\n        \n        Your **sole objective** is to reduce the runtime of the algorithm as much as possible.\n        Ignore any performance metrics other than runtime.\n        \n        Please create a new algorithm that is a modified, faster version of the provided one.\n        Focus on optimizations such as reducing algorithmic complexity, improving loops,\n        using efficient data structures, removing redundant computations, and simplifying logic.\n        \n        1. First, identify parts of the code that most likely cause high runtime and suggest optimizations.\n        2. Next, describe your new optimized algorithm and its main steps in one detailed sentence. The description must be inside boxed {}.\n        3. Finally, implement the optimized algorithm in the following Python function:\n        def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\n        \n        Check syntax and code carefully before returning the final function. Do not give additional explanations.",
        "sample_order": 307,
        "algorithm": null,
        "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Selection: Choose a solution with 80% probability from top 20% of archive\n    objectives = np.array([sum(obj) for _, obj in archive])\n    sorted_indices = np.argsort(objectives)\n    top_20_percent = max(1, len(archive) // 5)\n    top_indices = sorted_indices[:top_20_percent]\n    selected_idx = random.choice(top_indices) if random.random() < 0.8 and len(top_indices) > 0 else random.choice(range(len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Precompute normalized objectives\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    obj3 = np.array([obj[2] for _, obj in archive])\n    max_obj1, min_obj1 = np.max(obj1), np.min(obj1)\n    max_obj2, min_obj2 = np.max(obj2), np.min(obj2)\n    max_obj3, min_obj3 = np.max(obj3), np.min(obj3)\n\n    def normalize(value, max_val, min_val):\n        return (value - min_val) / (max_val - min_val) if max_val != min_val else 1.0\n\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    # Dynamic hybrid local search\n    r = random.random()\n    if r < 0.5:  # 50% chance for 4-opt targeting most improved space\n        a, b, c, d = sorted(random.sample(range(n), 4))\n        if norm1 >= norm2 and norm1 >= norm3:\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n            new_solution[b:c+1] = new_solution[b:c+1][::-1]\n            new_solution[c:d+1] = new_solution[c:d+1][::-1]\n        elif norm2 >= norm1 and norm2 >= norm3:\n            new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[b], new_solution[a], new_solution[d], new_solution[c]\n        else:\n            new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[c], new_solution[d], new_solution[a], new_solution[b]\n    elif r < 0.8:  # 30% chance for 2-opt in least improved space\n        if norm1 <= norm2 and norm1 <= norm3:\n            dist_matrix = distance_matrix_1\n        elif norm2 <= norm1 and norm2 <= norm3:\n            dist_matrix = distance_matrix_2\n        else:\n            dist_matrix = distance_matrix_3\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # 20% chance for random 3-edge swap\n        a, b, c = sorted(random.sample(range(n), 3))\n        new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "score": [
            -0.7262151161497031,
            0.3298135280609131
        ],
        "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Selection: Choose a solution with 80% probability from top 20% of archive\n    objectives = np.array([sum(obj) for _, obj in archive])\n    sorted_indices = np.argsort(objectives)\n    top_20_percent = max(1, len(archive) // 5)\n    top_indices = sorted_indices[:top_20_percent]\n    selected_idx = random.choice(top_indices) if random.random() < 0.8 and len(top_indices) > 0 else random.choice(range(len(archive)))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Precompute normalized objectives\n    obj1 = np.array([obj[0] for _, obj in archive])\n    obj2 = np.array([obj[1] for _, obj in archive])\n    obj3 = np.array([obj[2] for _, obj in archive])\n    max_obj1, min_obj1 = np.max(obj1), np.min(obj1)\n    max_obj2, min_obj2 = np.max(obj2), np.min(obj2)\n    max_obj3, min_obj3 = np.max(obj3), np.min(obj3)\n\n    def normalize(value, max_val, min_val):\n        return (value - min_val) / (max_val - min_val) if max_val != min_val else 1.0\n\n    norm1 = normalize(obj1[selected_idx], max_obj1, min_obj1)\n    norm2 = normalize(obj2[selected_idx], max_obj2, min_obj2)\n    norm3 = normalize(obj3[selected_idx], max_obj3, min_obj3)\n\n    # Dynamic hybrid local search\n    r = random.random()\n    if r < 0.5:  # 50% chance for 4-opt targeting most improved space\n        a, b, c, d = sorted(random.sample(range(n), 4))\n        if norm1 >= norm2 and norm1 >= norm3:\n            new_solution[a:b+1] = new_solution[a:b+1][::-1]\n            new_solution[b:c+1] = new_solution[b:c+1][::-1]\n            new_solution[c:d+1] = new_solution[c:d+1][::-1]\n        elif norm2 >= norm1 and norm2 >= norm3:\n            new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[b], new_solution[a], new_solution[d], new_solution[c]\n        else:\n            new_solution[a], new_solution[b], new_solution[c], new_solution[d] = new_solution[c], new_solution[d], new_solution[a], new_solution[b]\n    elif r < 0.8:  # 30% chance for 2-opt in least improved space\n        if norm1 <= norm2 and norm1 <= norm3:\n            dist_matrix = distance_matrix_1\n        elif norm2 <= norm1 and norm2 <= norm3:\n            dist_matrix = distance_matrix_2\n        else:\n            dist_matrix = distance_matrix_3\n        i, j = sorted(random.sample(range(n), 2))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:  # 20% chance for random 3-edge swap\n        a, b, c = sorted(random.sample(range(n), 3))\n        new_solution[a], new_solution[b], new_solution[c] = new_solution[b], new_solution[c], new_solution[a]\n\n    # Ensure feasibility\n    if len(np.unique(new_solution)) != n:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
        "operation": "r1"
    }
]