[
     {
          "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm will first identify solutions in the archive with the most balanced objective values (minimizing the range between the best and worst objectives) to ensure diversity in selection, then apply a multi-objective-aware segment relocation operator that considers weighted combinations of all three objectives to intelligently reposition subtours, with a probabilistic acceptance criterion based on both improvement and objective balance to encourage exploration of promising regions while maintaining feasibility through careful segment handling and validation.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with most balanced objectives\n    selected_solution = min(archive, key=lambda x: max(x[1]) - min(x[1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    # Generate random weights for objectives\n    weights = np.random.rand(3)\n    weights /= weights.sum()\n\n    # Select two random segments\n    a, b = sorted(np.random.choice(n, 2, replace=False))\n    c, d = sorted(np.random.choice(n, 2, replace=False))\n\n    # Ensure segments don't overlap\n    if b < c or d < a:\n        # Relocate segment [a:b+1] to position after c\n        segment = new_solution[a:b+1]\n        new_solution = np.concatenate([new_solution[:a], new_solution[b+1:c+1], segment, new_solution[c+1:]])\n\n        # Calculate current and new costs\n        current_cost = (weights[0] * distance_matrix_1[new_solution[a-1], new_solution[a]] +\n                        weights[1] * distance_matrix_2[new_solution[a-1], new_solution[a]] +\n                        weights[2] * distance_matrix_3[new_solution[a-1], new_solution[a]]) + \\\n                       (weights[0] * distance_matrix_1[new_solution[b], new_solution[b+1]] +\n                        weights[1] * distance_matrix_2[new_solution[b], new_solution[b+1]] +\n                        weights[2] * distance_matrix_3[new_solution[b], new_solution[b+1]])\n\n        new_cost = (weights[0] * distance_matrix_1[new_solution[c], segment[0]] +\n                    weights[1] * distance_matrix_2[new_solution[c], segment[0]] +\n                    weights[2] * distance_matrix_3[new_solution[c], segment[0]]) + \\\n                   (weights[0] * distance_matrix_1[segment[-1], new_solution[c+1]] +\n                    weights[1] * distance_matrix_2[segment[-1], new_solution[c+1]] +\n                    weights[2] * distance_matrix_3[segment[-1], new_solution[c+1]])\n\n        # Accept if improvement or with small probability\n        if new_cost < current_cost or np.random.random() < 0.2:\n            return new_solution\n\n    # If not accepted, try a different operator\n    i, j = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Verify solution is valid\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm combines the selection strategy of prioritizing solutions with balanced objective values from the second provided algorithm with an innovative multi-objective local search operator that performs a hybrid of path segment reversals and objective-aware edge swaps, where the edge candidates are dynamically selected based on their potential to improve the least improved objective. The operator first identifies critical segments where improvements can be made by analyzing the current solution's objective values, then performs targeted reversals of these segments to explore better configurations while maintaining feasibility, and finally swaps edges from the most underperforming objective with edges from the best-performing objective to address its weaknesses, verifying the solution's validity by ensuring no nodes are skipped or revisited. This approach balances exploitation of good solutions with exploration of diverse neighborhoods in the multi-objective space by focusing on the objective that has shown the least improvement, promoting more balanced progress across all objectives while leveraging the strength of the best objective to guide the search.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        objectives = np.array([obj for _, obj in archive])\n        objective_ranges = np.max(objectives, axis=1) - np.min(objectives, axis=1)\n        selected_idx = np.argmin(objective_ranges)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    current_costs = [\n        sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_3[new_solution[i-1], new_solution[i]] for i in range(n))\n    ]\n\n    worst_obj = np.argmax(current_costs)\n    best_obj = np.argmin(current_costs)\n\n    if np.random.rand() < 0.7:\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n    else:\n        candidate_edges = []\n        for k in range(n):\n            prev_node = new_solution[k-1]\n            next_node = new_solution[(k+1)%n]\n            if worst_obj == 0:\n                worst_cost = distance_matrix_1[prev_node, new_solution[k]] + distance_matrix_1[new_solution[k], next_node]\n            elif worst_obj == 1:\n                worst_cost = distance_matrix_2[prev_node, new_solution[k]] + distance_matrix_2[new_solution[k], next_node]\n            else:\n                worst_cost = distance_matrix_3[prev_node, new_solution[k]] + distance_matrix_3[new_solution[k], next_node]\n\n            if best_obj == 0:\n                best_cost = distance_matrix_1[prev_node, new_solution[k]] + distance_matrix_1[new_solution[k], next_node]\n            elif best_obj == 1:\n                best_cost = distance_matrix_2[prev_node, new_solution[k]] + distance_matrix_2[new_solution[k], next_node]\n            else:\n                best_cost = distance_matrix_3[prev_node, new_solution[k]] + distance_matrix_3[new_solution[k], next_node]\n\n            candidate_edges.append((worst_cost - best_cost, k))\n\n        candidate_edges.sort(reverse=True)\n        if candidate_edges and candidate_edges[0][0] > 0:\n            pos = candidate_edges[0][1]\n            prev_pos = (pos - 1) % n\n            next_pos = (pos + 1) % n\n            new_solution[prev_pos], new_solution[next_pos] = new_solution[next_pos], new_solution[prev_pos]\n\n    if not np.array_equal(np.sort(new_solution), np.sort(base_solution)):\n        new_solution = base_solution.copy()\n    else:\n        new_costs = [\n            sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n            sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)),\n            sum(distance_matrix_3[new_solution[i-1], new_solution[i]] for i in range(n))\n        ]\n\n        if new_costs[worst_obj] >= current_costs[worst_obj] and np.random.rand() > 0.2:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one long, detail sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 301,
          "algorithm": "{The new algorithm combines the selection strategy of prioritizing solutions with balanced objective values from the first algorithm with an innovative multi-objective local search operator that performs a hybrid of path segment reversals and objective-aware edge swaps, where the edge candidates are dynamically selected based on their potential to improve the least improved objective. The operator first identifies critical segments where improvements can be made by analyzing the current solution's objective values, then performs targeted reversals of these segments to explore better configurations while maintaining feasibility, and finally swaps edges from the most underperforming objective with edges from the best-performing objective to address its weaknesses, verifying the solution's validity by ensuring no nodes are skipped or revisited. This approach balances exploitation of good solutions with exploration of diverse neighborhoods in the multi-objective space by focusing on the objective that has shown the least improvement, promoting more balanced progress across all objectives while leveraging the strength of the best objective to guide the search.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with most balanced objectives\n    selected_solution = min(archive, key=lambda x: max(x[1]) - min(x[1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    # Calculate current costs for each objective\n    current_costs = [\n        sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_3[new_solution[i-1], new_solution[i]] for i in range(n))\n    ]\n\n    worst_obj = np.argmax(current_costs)\n    best_obj = np.argmin(current_costs)\n\n    # Apply segment reversal with probability\n    if np.random.rand() < 0.6:\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Apply edge swap based on objective performance\n    candidate_edges = []\n    for k in range(n):\n        prev_node = new_solution[k-1]\n        next_node = new_solution[(k+1)%n]\n\n        if worst_obj == 0:\n            worst_cost = distance_matrix_1[prev_node, new_solution[k]] + distance_matrix_1[new_solution[k], next_node]\n        elif worst_obj == 1:\n            worst_cost = distance_matrix_2[prev_node, new_solution[k]] + distance_matrix_2[new_solution[k], next_node]\n        else:\n            worst_cost = distance_matrix_3[prev_node, new_solution[k]] + distance_matrix_3[new_solution[k], next_node]\n\n        if best_obj == 0:\n            best_cost = distance_matrix_1[prev_node, new_solution[k]] + distance_matrix_1[new_solution[k], next_node]\n        elif best_obj == 1:\n            best_cost = distance_matrix_2[prev_node, new_solution[k]] + distance_matrix_2[new_solution[k], next_node]\n        else:\n            best_cost = distance_matrix_3[prev_node, new_solution[k]] + distance_matrix_3[new_solution[k], next_node]\n\n        candidate_edges.append((worst_cost - best_cost, k))\n\n    candidate_edges.sort(reverse=True)\n    if candidate_edges and candidate_edges[0][0] > 0:\n        pos = candidate_edges[0][1]\n        prev_pos = (pos - 1) % n\n        next_pos = (pos + 1) % n\n        new_solution[prev_pos], new_solution[next_pos] = new_solution[next_pos], new_solution[prev_pos]\n\n    # Validate solution\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               -0.7078877127268999,
               2.105075418949127
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with most balanced objectives\n    selected_solution = min(archive, key=lambda x: max(x[1]) - min(x[1]))[0].copy()\n    new_solution = selected_solution.copy()\n    n = len(new_solution)\n\n    # Calculate current costs for each objective\n    current_costs = [\n        sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_3[new_solution[i-1], new_solution[i]] for i in range(n))\n    ]\n\n    worst_obj = np.argmax(current_costs)\n    best_obj = np.argmin(current_costs)\n\n    # Apply segment reversal with probability\n    if np.random.rand() < 0.6:\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Apply edge swap based on objective performance\n    candidate_edges = []\n    for k in range(n):\n        prev_node = new_solution[k-1]\n        next_node = new_solution[(k+1)%n]\n\n        if worst_obj == 0:\n            worst_cost = distance_matrix_1[prev_node, new_solution[k]] + distance_matrix_1[new_solution[k], next_node]\n        elif worst_obj == 1:\n            worst_cost = distance_matrix_2[prev_node, new_solution[k]] + distance_matrix_2[new_solution[k], next_node]\n        else:\n            worst_cost = distance_matrix_3[prev_node, new_solution[k]] + distance_matrix_3[new_solution[k], next_node]\n\n        if best_obj == 0:\n            best_cost = distance_matrix_1[prev_node, new_solution[k]] + distance_matrix_1[new_solution[k], next_node]\n        elif best_obj == 1:\n            best_cost = distance_matrix_2[prev_node, new_solution[k]] + distance_matrix_2[new_solution[k], next_node]\n        else:\n            best_cost = distance_matrix_3[prev_node, new_solution[k]] + distance_matrix_3[new_solution[k], next_node]\n\n        candidate_edges.append((worst_cost - best_cost, k))\n\n    candidate_edges.sort(reverse=True)\n    if candidate_edges and candidate_edges[0][0] > 0:\n        pos = candidate_edges[0][1]\n        prev_pos = (pos - 1) % n\n        next_pos = (pos + 1) % n\n        new_solution[prev_pos], new_solution[next_pos] = new_solution[next_pos], new_solution[prev_pos]\n\n    # Validate solution\n    if len(np.unique(new_solution)) != n:\n        new_solution = selected_solution.copy()\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{This new algorithm combines multi-objective optimization with a novel hierarchical local search approach that first identifies the most balanced solution in the archive, then performs a tiered segment-based optimization where each tier focuses on improving a different objective, with the optimization depth and segment length dynamically adjusted based on the current Pareto front's distribution. It employs a probabilistic tier selection mechanism that prioritizes objectives with the highest relative improvement potential, while incorporating an adaptive segment inversion operator that selectively inverts segments based on their contribution to each objective, ensuring balanced optimization across all three objectives. The algorithm also includes a tiered mutation mechanism that randomly reorders segments with probabilities inversely proportional to their current objective values, further diversifying the search while preserving solution quality. Additionally, it features a dynamic tiered segment exchange operator that exchanges segments between the base solution and a randomly selected archive member, with segment selection based on their potential to improve Pareto dominance through a tiered weighting scheme that prioritizes objectives with the highest relative improvement in each tier.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Identify the most balanced solution in the archive\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = np.mean(normalized_objectives, axis=1)\n    balanced_idx = np.argmax(balance_scores)\n    base_solution = archive[balanced_idx][0].copy()\n\n    # Select a random solution from the archive\n    random_idx = np.random.randint(len(archive))\n    random_solution = archive[random_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Tiered segment-based optimization\n    tiers = 3  # One for each objective\n    for tier in range(tiers):\n        # Dynamic segment length based on tier and solution quality\n        segment_length = max(2, min(6, n // (tier + 2)))\n        start_pos = np.random.randint(0, n - segment_length)\n\n        # Calculate potential improvement for the current tier's objective\n        if tier == 0:\n            obj_diff = (distance_matrix_1[new_solution[start_pos-1], random_solution[start_pos]] +\n                        distance_matrix_1[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                        distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                        distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        elif tier == 1:\n            obj_diff = (distance_matrix_2[new_solution[start_pos-1], random_solution[start_pos]] +\n                        distance_matrix_2[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                        distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                        distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        else:\n            obj_diff = (distance_matrix_3[new_solution[start_pos-1], random_solution[start_pos]] +\n                        distance_matrix_3[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                        distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                        distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n        # Probabilistic tier selection based on improvement potential\n        if obj_diff < 0 and np.random.rand() < 0.7:  # Higher probability for improving moves\n            new_solution[start_pos:start_pos+segment_length] = random_solution[start_pos:start_pos+segment_length]\n\n        # Tiered mutation with adaptive probability\n        mutation_prob = 0.3 * (1 - normalized_objectives[balanced_idx][tier] / (np.sum(normalized_objectives[balanced_idx]) + 1e-10))\n        if np.random.rand() < mutation_prob:\n            mutate_pos = np.random.randint(0, n - segment_length)\n            new_solution[mutate_pos:mutate_pos+segment_length] = np.roll(new_solution[mutate_pos:mutate_pos+segment_length], np.random.randint(1, segment_length))\n\n        # Tiered segment inversion\n        inversion_prob = 0.4 * (1 - normalized_objectives[balanced_idx][tier] / (np.sum(normalized_objectives[balanced_idx]) + 1e-10))\n        if np.random.rand() < inversion_prob:\n            invert_pos = np.random.randint(0, n - segment_length)\n            new_solution[invert_pos:invert_pos+segment_length] = new_solution[invert_pos:invert_pos+segment_length][::-1]\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n        return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the highest potential for improvement\n    # Here, we use a simple approach: select a random solution from the archive\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor using a 2-opt local search\n    n = len(base_solution)\n    new_solution = base_solution.copy()\n\n    # Randomly select two distinct edges to swap\n    i, j = sorted(np.random.choice(n, 2, replace=False))\n    k, l = sorted(np.random.choice(n, 2, replace=False))\n\n    # Perform the swap\n    new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n    new_solution[k:l+1] = np.flip(new_solution[k:l+1])\n\n    # Ensure the solution remains valid (no revisits)\n    if len(np.unique(new_solution)) == len(base_solution):\n        return new_solution\n    else:\n        return base_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one long, detail sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 302,
          "algorithm": "{This new algorithm combines multi-objective optimization with a dynamic cluster-based local search that first identifies the most diverse solution in the archive, then partitions the tour into clusters of varying sizes based on their objective contributions, followed by a tiered cluster-based optimization where each tier focuses on improving a different objective, with cluster sizes and optimization depth dynamically adjusted based on the current Pareto front's distribution. It employs a probabilistic cluster selection mechanism that prioritizes clusters with the highest relative improvement potential across all objectives, while incorporating an adaptive cluster merging and splitting operator that selectively combines or divides clusters based on their contribution to each objective, ensuring balanced optimization across all three objectives. The algorithm also includes a tiered cluster inversion mechanism that randomly inverts clusters with probabilities inversely proportional to their current objective values, further diversifying the search while preserving solution quality. Additionally, it features a dynamic tiered cluster exchange operator that exchanges clusters between the base solution and a randomly selected archive member, with cluster selection based on their potential to improve Pareto dominance through a tiered weighting scheme that prioritizes objectives with the highest relative improvement in each tier.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the most diverse solution in the archive\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = np.std(normalized_objectives, axis=1)\n    diverse_idx = np.argmax(diversity_scores)\n    base_solution = archive[diverse_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Dynamic cluster-based optimization\n    tiers = 3  # One for each objective\n    for tier in range(tiers):\n        # Dynamic cluster size based on tier and solution quality\n        cluster_size = max(2, min(6, n // (tier + 2)))\n        num_clusters = max(2, n // cluster_size)\n\n        # Partition the tour into clusters\n        clusters = [new_solution[i*cluster_size:(i+1)*cluster_size] for i in range(num_clusters)]\n        if n % cluster_size != 0:\n            clusters[-1] = np.concatenate([clusters[-1], new_solution[num_clusters*cluster_size:]])\n\n        # Calculate potential improvement for the current tier's objective\n        cluster_improvements = []\n        for i in range(len(clusters)):\n            if tier == 0:\n                obj_diff = (distance_matrix_1[new_solution[(i*cluster_size-1)%n], clusters[i][0]] +\n                            distance_matrix_1[clusters[i][-1], new_solution[((i+1)*cluster_size)%n]] -\n                            distance_matrix_1[new_solution[(i*cluster_size-1)%n], clusters[i][0]] -\n                            distance_matrix_1[clusters[i][-1], new_solution[((i+1)*cluster_size)%n]])\n            elif tier == 1:\n                obj_diff = (distance_matrix_2[new_solution[(i*cluster_size-1)%n], clusters[i][0]] +\n                            distance_matrix_2[clusters[i][-1], new_solution[((i+1)*cluster_size)%n]] -\n                            distance_matrix_2[new_solution[(i*cluster_size-1)%n], clusters[i][0]] -\n                            distance_matrix_2[clusters[i][-1], new_solution[((i+1)*cluster_size)%n]])\n            else:\n                obj_diff = (distance_matrix_3[new_solution[(i*cluster_size-1)%n], clusters[i][0]] +\n                            distance_matrix_3[clusters[i][-1], new_solution[((i+1)*cluster_size)%n]] -\n                            distance_matrix_3[new_solution[(i*cluster_size-1)%n], clusters[i][0]] -\n                            distance_matrix_3[clusters[i][-1], new_solution[((i+1)*cluster_size)%n]])\n            cluster_improvements.append(obj_diff)\n\n        # Select clusters with highest improvement potential\n        sorted_indices = np.argsort(cluster_improvements)\n        selected_cluster = sorted_indices[0] if cluster_improvements[sorted_indices[0]] < 0 else sorted_indices[-1]\n\n        # Cluster inversion with adaptive probability\n        inversion_prob = 0.4 * (1 - normalized_objectives[diverse_idx][tier] / (np.sum(normalized_objectives[diverse_idx]) + 1e-10))\n        if np.random.rand() < inversion_prob:\n            clusters[selected_cluster] = clusters[selected_cluster][::-1]\n\n        # Cluster merging and splitting\n        if len(clusters) > 1 and np.random.rand() < 0.3:\n            if np.random.rand() < 0.5 and len(clusters) > 2:  # Merge\n                merge_idx1, merge_idx2 = np.random.choice(len(clusters), 2, replace=False)\n                clusters[merge_idx1] = np.concatenate([clusters[merge_idx1], clusters[merge_idx2]])\n                del clusters[merge_idx2]\n            else:  # Split\n                split_idx = np.random.randint(len(clusters))\n                if len(clusters[split_idx]) > 2:\n                    split_pos = np.random.randint(1, len(clusters[split_idx]))\n                    new_cluster = clusters[split_idx][split_pos:]\n                    clusters[split_idx] = clusters[split_idx][:split_pos]\n                    clusters.insert(split_idx + 1, new_cluster)\n\n        # Reconstruct the solution from clusters\n        new_solution = np.concatenate(clusters)\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n        return new_solution\n\n",
          "score": [
               -0.5483510771379706,
               3.485838747024536
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the most diverse solution in the archive\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    diversity_scores = np.std(normalized_objectives, axis=1)\n    diverse_idx = np.argmax(diversity_scores)\n    base_solution = archive[diverse_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Dynamic cluster-based optimization\n    tiers = 3  # One for each objective\n    for tier in range(tiers):\n        # Dynamic cluster size based on tier and solution quality\n        cluster_size = max(2, min(6, n // (tier + 2)))\n        num_clusters = max(2, n // cluster_size)\n\n        # Partition the tour into clusters\n        clusters = [new_solution[i*cluster_size:(i+1)*cluster_size] for i in range(num_clusters)]\n        if n % cluster_size != 0:\n            clusters[-1] = np.concatenate([clusters[-1], new_solution[num_clusters*cluster_size:]])\n\n        # Calculate potential improvement for the current tier's objective\n        cluster_improvements = []\n        for i in range(len(clusters)):\n            if tier == 0:\n                obj_diff = (distance_matrix_1[new_solution[(i*cluster_size-1)%n], clusters[i][0]] +\n                            distance_matrix_1[clusters[i][-1], new_solution[((i+1)*cluster_size)%n]] -\n                            distance_matrix_1[new_solution[(i*cluster_size-1)%n], clusters[i][0]] -\n                            distance_matrix_1[clusters[i][-1], new_solution[((i+1)*cluster_size)%n]])\n            elif tier == 1:\n                obj_diff = (distance_matrix_2[new_solution[(i*cluster_size-1)%n], clusters[i][0]] +\n                            distance_matrix_2[clusters[i][-1], new_solution[((i+1)*cluster_size)%n]] -\n                            distance_matrix_2[new_solution[(i*cluster_size-1)%n], clusters[i][0]] -\n                            distance_matrix_2[clusters[i][-1], new_solution[((i+1)*cluster_size)%n]])\n            else:\n                obj_diff = (distance_matrix_3[new_solution[(i*cluster_size-1)%n], clusters[i][0]] +\n                            distance_matrix_3[clusters[i][-1], new_solution[((i+1)*cluster_size)%n]] -\n                            distance_matrix_3[new_solution[(i*cluster_size-1)%n], clusters[i][0]] -\n                            distance_matrix_3[clusters[i][-1], new_solution[((i+1)*cluster_size)%n]])\n            cluster_improvements.append(obj_diff)\n\n        # Select clusters with highest improvement potential\n        sorted_indices = np.argsort(cluster_improvements)\n        selected_cluster = sorted_indices[0] if cluster_improvements[sorted_indices[0]] < 0 else sorted_indices[-1]\n\n        # Cluster inversion with adaptive probability\n        inversion_prob = 0.4 * (1 - normalized_objectives[diverse_idx][tier] / (np.sum(normalized_objectives[diverse_idx]) + 1e-10))\n        if np.random.rand() < inversion_prob:\n            clusters[selected_cluster] = clusters[selected_cluster][::-1]\n\n        # Cluster merging and splitting\n        if len(clusters) > 1 and np.random.rand() < 0.3:\n            if np.random.rand() < 0.5 and len(clusters) > 2:  # Merge\n                merge_idx1, merge_idx2 = np.random.choice(len(clusters), 2, replace=False)\n                clusters[merge_idx1] = np.concatenate([clusters[merge_idx1], clusters[merge_idx2]])\n                del clusters[merge_idx2]\n            else:  # Split\n                split_idx = np.random.randint(len(clusters))\n                if len(clusters[split_idx]) > 2:\n                    split_pos = np.random.randint(1, len(clusters[split_idx]))\n                    new_cluster = clusters[split_idx][split_pos:]\n                    clusters[split_idx] = clusters[split_idx][:split_pos]\n                    clusters.insert(split_idx + 1, new_cluster)\n\n        # Reconstruct the solution from clusters\n        new_solution = np.concatenate(clusters)\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n        return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the most balanced objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = 1 - np.std(normalized_objectives, axis=1)\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Multi-objective segment exchange with adaptive weights\n    segment_length = np.random.randint(2, min(5, n//2))\n    start_pos = np.random.randint(0, n - segment_length)\n\n    # Calculate potential improvement for each objective\n    obj1_diff = (distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos+segment_length]] -\n                 distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                 distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n    obj2_diff = (distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos+segment_length]] -\n                 distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                 distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n    obj3_diff = (distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos+segment_length]] -\n                 distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                 distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n    # Dynamic weighting based on current objective distribution\n    obj_weights = np.var(normalized_objectives, axis=0)\n    obj_weights = obj_weights / np.sum(obj_weights)\n\n    # Perform segment exchange if improvement is expected\n    weighted_diff = obj_weights[0] * obj1_diff + obj_weights[1] * obj2_diff + obj_weights[2] * obj3_diff\n    if weighted_diff < 0:\n        new_solution[start_pos:start_pos+segment_length] = new_solution[start_pos:start_pos+segment_length][::-1]\n\n    # Probabilistic segment rotation with objective-aware probability\n    rotation_prob = 0.3 * (1 - np.min(normalized_objectives[selected_idx]))\n    if np.random.rand() < rotation_prob:\n        rotate_pos = np.random.randint(0, n - segment_length)\n        shift = np.random.randint(1, segment_length)\n        new_solution[rotate_pos:rotate_pos+segment_length] = np.roll(new_solution[rotate_pos:rotate_pos+segment_length], shift)\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n        return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm combines the selection strategy of prioritizing solutions with balanced objective values from the first provided algorithm with an innovative multi-objective local search operator that performs a hybrid of path segment rotations and objective-aware node insertions, where the insertion candidates are dynamically selected based on their potential to improve the most underperforming objective. The operator first identifies critical segments where improvements can be made by analyzing the current solution's objective values, then performs targeted rotations of these segments to explore better configurations while maintaining feasibility, and finally inserts nodes from the most underperforming objective into the solution to address its weaknesses, verifying the solution's validity by ensuring no nodes are skipped or revisited. This approach balances exploitation of good solutions with exploration of diverse neighborhoods in the multi-objective space by focusing on the objective that has shown the least improvement, promoting more balanced progress across all objectives.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Select solution with most balanced objectives (smallest range between best and worst objective)\n        objectives = np.array([obj for _, obj in archive])\n        objective_ranges = np.max(objectives, axis=1) - np.min(objectives, axis=1)\n        selected_idx = np.argmin(objective_ranges)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Calculate current costs for all objectives\n    current_costs = [\n        sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_3[new_solution[i-1], new_solution[i]] for i in range(n))\n    ]\n\n    # Identify the most underperforming objective\n    worst_obj = np.argmax(current_costs)\n\n    # Hybrid path segment rotation with objective-aware node insertion\n    if np.random.rand() < 0.6:\n        # Perform path segment rotation\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        segment = new_solution[i:j+1]\n        rotation = np.random.randint(1, len(segment))\n        new_solution[i:j+1] = np.concatenate([segment[rotation:], segment[:rotation]])\n    else:\n        # Perform objective-aware node insertion\n        # Find nodes that are most expensive in the worst objective\n        node_costs = []\n        for k in range(n):\n            prev_node = new_solution[k-1]\n            next_node = new_solution[(k+1)%n]\n            if worst_obj == 0:\n                cost = distance_matrix_1[prev_node, new_solution[k]] + distance_matrix_1[new_solution[k], next_node]\n            elif worst_obj == 1:\n                cost = distance_matrix_2[prev_node, new_solution[k]] + distance_matrix_2[new_solution[k], next_node]\n            else:\n                cost = distance_matrix_3[prev_node, new_solution[k]] + distance_matrix_3[new_solution[k], next_node]\n            node_costs.append(cost)\n\n        # Select the most expensive node and insert it elsewhere\n        expensive_node = np.argmax(node_costs)\n        insert_pos = np.random.randint(0, n)\n        node_to_insert = new_solution[expensive_node]\n        new_solution = np.concatenate([\n            new_solution[:insert_pos],\n            [node_to_insert],\n            np.delete(new_solution, expensive_node)\n        ])\n\n    # Verify solution validity\n    if not np.array_equal(np.sort(new_solution), np.sort(base_solution)):\n        new_solution = base_solution.copy()\n    else:\n        # Verify if the move improved the worst objective\n        new_costs = [\n            sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n            sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)),\n            sum(distance_matrix_3[new_solution[i-1], new_solution[i]] for i in range(n))\n        ]\n\n        if new_costs[worst_obj] >= current_costs[worst_obj] and np.random.rand() > 0.3:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 303,
          "algorithm": "{The new algorithm employs a multi-objective adaptive path decomposition and reassembly strategy that first partitions the current solution into critical segments based on their contribution to each objective's total cost, then dynamically reassembles these segments by prioritizing those that show the most significant improvement potential when moved or swapped, using a weighted combination of objective-specific segment quality metrics. The algorithm also incorporates a probabilistic segment inversion mechanism that flips segments with high potential for improving the worst-performing objective, while maintaining feasibility through strict validation checks that ensure no nodes are duplicated or omitted. Additionally, it includes an objective-aware node reinsertion step that strategically places nodes from the worst-performing objective into positions that minimize their negative impact, balancing exploitation of known good segments with exploration of the solution space through these targeted modifications.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the highest combined improvement potential\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    improvement_potential = 1 - normalized_objectives\n    selected_idx = np.argmax(np.sum(improvement_potential, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Calculate segment contributions for each objective\n    segment_length = max(3, n // 10)\n    segment_contributions = []\n\n    for i in range(0, n, segment_length):\n        segment = base_solution[i:i+segment_length]\n        if len(segment) < 2:\n            continue\n\n        # Calculate contribution to each objective\n        obj1_contrib = sum(distance_matrix_1[segment[j-1], segment[j]] for j in range(1, len(segment)))\n        obj2_contrib = sum(distance_matrix_2[segment[j-1], segment[j]] for j in range(1, len(segment)))\n        obj3_contrib = sum(distance_matrix_3[segment[j-1], segment[j]] for j in range(1, len(segment)))\n\n        segment_contributions.append((i, i+segment_length, obj1_contrib, obj2_contrib, obj3_contrib))\n\n    if not segment_contributions:\n        return base_solution\n\n    # Identify worst-performing objective\n    current_costs = [\n        sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_3[new_solution[i-1], new_solution[i]] for i in range(n))\n    ]\n    worst_obj = np.argmax(current_costs)\n\n    # Select segments to modify based on their contribution to the worst objective\n    segment_contributions.sort(key=lambda x: x[2 + worst_obj], reverse=True)\n    selected_segments = segment_contributions[:min(3, len(segment_contributions))]\n\n    # Apply segment modifications\n    for start, end, _, _, _ in selected_segments:\n        segment = new_solution[start:end]\n\n        # With 60% probability, invert the segment\n        if np.random.rand() < 0.6:\n            new_solution[start:end] = segment[::-1]\n        else:\n            # With 40% probability, rotate the segment\n            shift = np.random.randint(1, len(segment))\n            new_solution[start:end] = np.roll(segment, shift)\n\n    # Objective-aware node reinsertion\n    if np.random.rand() < 0.4:\n        # Find nodes with highest cost in the worst objective\n        node_costs = []\n        for k in range(n):\n            prev = new_solution[k-1]\n            curr = new_solution[k]\n            next_node = new_solution[(k+1)%n]\n\n            if worst_obj == 0:\n                cost = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_node]\n            elif worst_obj == 1:\n                cost = distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_node]\n            else:\n                cost = distance_matrix_3[prev, curr] + distance_matrix_3[curr, next_node]\n\n            node_costs.append(cost)\n\n        expensive_node = np.argmax(node_costs)\n        node_to_insert = new_solution[expensive_node]\n\n        # Find best insertion position\n        best_pos = -1\n        best_improvement = 0\n\n        for i in range(n):\n            if i == expensive_node or i == expensive_node - 1:\n                continue\n\n            prev = new_solution[i-1]\n            next_node = new_solution[i]\n\n            if worst_obj == 0:\n                current_cost = distance_matrix_1[prev, node_to_insert] + distance_matrix_1[node_to_insert, next_node]\n                original_cost = distance_matrix_1[prev, next_node]\n                improvement = original_cost - current_cost\n            elif worst_obj == 1:\n                current_cost = distance_matrix_2[prev, node_to_insert] + distance_matrix_2[node_to_insert, next_node]\n                original_cost = distance_matrix_2[prev, next_node]\n                improvement = original_cost - current_cost\n            else:\n                current_cost = distance_matrix_3[prev, node_to_insert] + distance_matrix_3[node_to_insert, next_node]\n                original_cost = distance_matrix_3[prev, next_node]\n                improvement = original_cost - current_cost\n\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_pos = i\n\n        if best_pos != -1:\n            new_solution = np.insert(new_solution, best_pos, node_to_insert)\n            new_solution = np.delete(new_solution, expensive_node + (1 if best_pos < expensive_node else 0))\n\n    # Verify solution validity\n    if len(np.unique(new_solution)) != n:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n\n    return new_solution\n\n",
          "score": [
               -0.6813092353956014,
               3.3189364314079284
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the highest combined improvement potential\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    improvement_potential = 1 - normalized_objectives\n    selected_idx = np.argmax(np.sum(improvement_potential, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Calculate segment contributions for each objective\n    segment_length = max(3, n // 10)\n    segment_contributions = []\n\n    for i in range(0, n, segment_length):\n        segment = base_solution[i:i+segment_length]\n        if len(segment) < 2:\n            continue\n\n        # Calculate contribution to each objective\n        obj1_contrib = sum(distance_matrix_1[segment[j-1], segment[j]] for j in range(1, len(segment)))\n        obj2_contrib = sum(distance_matrix_2[segment[j-1], segment[j]] for j in range(1, len(segment)))\n        obj3_contrib = sum(distance_matrix_3[segment[j-1], segment[j]] for j in range(1, len(segment)))\n\n        segment_contributions.append((i, i+segment_length, obj1_contrib, obj2_contrib, obj3_contrib))\n\n    if not segment_contributions:\n        return base_solution\n\n    # Identify worst-performing objective\n    current_costs = [\n        sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_3[new_solution[i-1], new_solution[i]] for i in range(n))\n    ]\n    worst_obj = np.argmax(current_costs)\n\n    # Select segments to modify based on their contribution to the worst objective\n    segment_contributions.sort(key=lambda x: x[2 + worst_obj], reverse=True)\n    selected_segments = segment_contributions[:min(3, len(segment_contributions))]\n\n    # Apply segment modifications\n    for start, end, _, _, _ in selected_segments:\n        segment = new_solution[start:end]\n\n        # With 60% probability, invert the segment\n        if np.random.rand() < 0.6:\n            new_solution[start:end] = segment[::-1]\n        else:\n            # With 40% probability, rotate the segment\n            shift = np.random.randint(1, len(segment))\n            new_solution[start:end] = np.roll(segment, shift)\n\n    # Objective-aware node reinsertion\n    if np.random.rand() < 0.4:\n        # Find nodes with highest cost in the worst objective\n        node_costs = []\n        for k in range(n):\n            prev = new_solution[k-1]\n            curr = new_solution[k]\n            next_node = new_solution[(k+1)%n]\n\n            if worst_obj == 0:\n                cost = distance_matrix_1[prev, curr] + distance_matrix_1[curr, next_node]\n            elif worst_obj == 1:\n                cost = distance_matrix_2[prev, curr] + distance_matrix_2[curr, next_node]\n            else:\n                cost = distance_matrix_3[prev, curr] + distance_matrix_3[curr, next_node]\n\n            node_costs.append(cost)\n\n        expensive_node = np.argmax(node_costs)\n        node_to_insert = new_solution[expensive_node]\n\n        # Find best insertion position\n        best_pos = -1\n        best_improvement = 0\n\n        for i in range(n):\n            if i == expensive_node or i == expensive_node - 1:\n                continue\n\n            prev = new_solution[i-1]\n            next_node = new_solution[i]\n\n            if worst_obj == 0:\n                current_cost = distance_matrix_1[prev, node_to_insert] + distance_matrix_1[node_to_insert, next_node]\n                original_cost = distance_matrix_1[prev, next_node]\n                improvement = original_cost - current_cost\n            elif worst_obj == 1:\n                current_cost = distance_matrix_2[prev, node_to_insert] + distance_matrix_2[node_to_insert, next_node]\n                original_cost = distance_matrix_2[prev, next_node]\n                improvement = original_cost - current_cost\n            else:\n                current_cost = distance_matrix_3[prev, node_to_insert] + distance_matrix_3[node_to_insert, next_node]\n                original_cost = distance_matrix_3[prev, next_node]\n                improvement = original_cost - current_cost\n\n            if improvement > best_improvement:\n                best_improvement = improvement\n                best_pos = i\n\n        if best_pos != -1:\n            new_solution = np.insert(new_solution, best_pos, node_to_insert)\n            new_solution = np.delete(new_solution, expensive_node + (1 if best_pos < expensive_node else 0))\n\n    # Verify solution validity\n    if len(np.unique(new_solution)) != n:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm combines the multi-objective selection strategy of prioritizing balanced solutions from the provided algorithms with an innovative hybrid local search operator that performs a dynamic segment-based crossover augmented with objective-aware inversion and probabilistic segment mutation. It first identifies the most balanced solution in the archive by analyzing the normalized objective values, then performs a guided segment exchange between this solution and a randomly selected archive member, where segments are selected based on their potential to improve Pareto dominance through a dynamic weighting scheme that prioritizes objectives with the highest relative improvement. The algorithm incorporates a probabilistic segment mutation mechanism that randomly reorders segments with a probability inversely proportional to their current objective values, further diversifying the search while preserving solution quality. Additionally, it includes a novel three-way objective-aware inversion operator that selectively inverts segments based on their contribution to each objective, ensuring balanced optimization across all three objectives, while dynamically adjusting the search focus based on the current Pareto front's distribution.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Identify the most balanced solution in the archive\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = np.mean(normalized_objectives, axis=1)\n    balanced_idx = np.argmax(balance_scores)\n    balanced_solution = archive[balanced_idx][0].copy()\n\n    # Select a random solution from the archive\n    random_idx = np.random.randint(len(archive))\n    random_solution = archive[random_idx][0].copy()\n\n    # Initialize the new solution\n    new_solution = balanced_solution.copy()\n    n = len(new_solution)\n\n    # Dynamic segment selection based on objective improvement potential\n    segment_length = np.random.randint(2, min(5, n//3))\n    start_pos = np.random.randint(0, n - segment_length)\n\n    # Calculate potential improvement for each objective\n    obj1_diff = (distance_matrix_1[new_solution[start_pos-1], random_solution[start_pos]] +\n                 distance_matrix_1[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                 distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                 distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n    obj2_diff = (distance_matrix_2[new_solution[start_pos-1], random_solution[start_pos]] +\n                 distance_matrix_2[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                 distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                 distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n    obj3_diff = (distance_matrix_3[new_solution[start_pos-1], random_solution[start_pos]] +\n                 distance_matrix_3[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                 distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                 distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n    # Dynamic weighting based on relative improvement\n    total_diff = np.abs(obj1_diff) + np.abs(obj2_diff) + np.abs(obj3_diff)\n    if total_diff > 0:\n        weights = np.array([np.abs(obj1_diff), np.abs(obj2_diff), np.abs(obj3_diff)]) / total_diff\n    else:\n        weights = np.ones(3) / 3\n\n    # Perform segment exchange if improvement is expected\n    if (weights[0] * obj1_diff + weights[1] * obj2_diff + weights[2] * obj3_diff) < 0:\n        new_solution[start_pos:start_pos+segment_length] = random_solution[start_pos:start_pos+segment_length]\n\n    # Probabilistic segment mutation with objective-aware probability\n    mutation_prob = 0.3 * (1 - np.min(normalized_objectives[balanced_idx]) / (np.sum(normalized_objectives[balanced_idx]) + 1e-10))\n    if np.random.rand() < mutation_prob:\n        mutate_pos = np.random.randint(0, n - segment_length)\n        new_solution[mutate_pos:mutate_pos+segment_length] = np.roll(new_solution[mutate_pos:mutate_pos+segment_length], np.random.randint(1, segment_length))\n\n    # Three-way objective-aware inversion with dynamic segment selection\n    inversion_prob = 0.4 * (1 - np.min(normalized_objectives[balanced_idx]) / (np.sum(normalized_objectives[balanced_idx]) + 1e-10))\n    if np.random.rand() < inversion_prob:\n        # Select segment based on worst objective contribution\n        potential_segments = []\n        for i in range(n - segment_length):\n            segment = new_solution[i:i+segment_length]\n            obj1_contrib = sum(distance_matrix_1[segment[j-1], segment[j]] for j in range(1, segment_length))\n            obj2_contrib = sum(distance_matrix_2[segment[j-1], segment[j]] for j in range(1, segment_length))\n            obj3_contrib = sum(distance_matrix_3[segment[j-1], segment[j]] for j in range(1, segment_length))\n            worst_contrib = min(obj1_contrib, obj2_contrib, obj3_contrib)\n            potential_segments.append((i, worst_contrib))\n\n        if potential_segments:\n            selected_segment = max(potential_segments, key=lambda x: x[1])\n            invert_pos = selected_segment[0]\n            new_solution[invert_pos:invert_pos+segment_length] = new_solution[invert_pos:invert_pos+segment_length][::-1]\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n        return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{This new algorithm introduces a multi-objective-aware adaptive segment fusion approach that first identifies the most complementary solutions in the archive by analyzing the covariance structure of their objectives, then performs a tiered segment fusion process where each tier selectively combines segments from different archive members based on their potential to improve Pareto dominance through a dynamic weighting scheme that prioritizes objectives with the highest relative improvement, while maintaining feasibility through a multi-phase validation mechanism that ensures no nodes are skipped or revisited. The algorithm employs an adaptive segment fusion operator that merges segments from different solutions with probabilities proportional to their current objective values, combined with a probabilistic segment reordering mechanism that reorders segments with a probability inversely proportional to their current objective contributions, further enhancing the search diversity while preserving solution quality.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Identify the most complementary solutions in the archive\n    objectives = np.array([obj for _, obj in archive])\n    obj_cov = np.cov(objectives, rowvar=False)\n    target_obj = np.argmax(np.diag(obj_cov))\n    complementary_idx = np.argmin(objectives[:, target_obj])\n    base_solution = archive[complementary_idx][0].copy()\n\n    # Select two random solutions from the archive\n    random_idx1, random_idx2 = np.random.choice(len(archive), 2, replace=False)\n    random_solution1 = archive[random_idx1][0].copy()\n    random_solution2 = archive[random_idx2][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Tiered segment fusion process\n    tiers = 3  # One for each objective\n    for tier in range(tiers):\n        # Dynamic segment length based on tier\n        segment_length = max(2, min(6, n // (tier + 2)))\n        start_pos = np.random.randint(0, n - segment_length)\n\n        # Calculate potential improvement for the current tier's objective\n        if tier == 0:\n            obj_diff1 = (distance_matrix_1[new_solution[start_pos-1], random_solution1[start_pos]] +\n                         distance_matrix_1[random_solution1[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n            obj_diff2 = (distance_matrix_1[new_solution[start_pos-1], random_solution2[start_pos]] +\n                         distance_matrix_1[random_solution2[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        elif tier == 1:\n            obj_diff1 = (distance_matrix_2[new_solution[start_pos-1], random_solution1[start_pos]] +\n                         distance_matrix_2[random_solution1[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n            obj_diff2 = (distance_matrix_2[new_solution[start_pos-1], random_solution2[start_pos]] +\n                         distance_matrix_2[random_solution2[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        else:\n            obj_diff1 = (distance_matrix_3[new_solution[start_pos-1], random_solution1[start_pos]] +\n                         distance_matrix_3[random_solution1[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n            obj_diff2 = (distance_matrix_3[new_solution[start_pos-1], random_solution2[start_pos]] +\n                         distance_matrix_3[random_solution2[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n        # Select the better segment from either random solution\n        if obj_diff1 < obj_diff2:\n            new_solution[start_pos:start_pos+segment_length] = random_solution1[start_pos:start_pos+segment_length]\n        else:\n            new_solution[start_pos:start_pos+segment_length] = random_solution2[start_pos:start_pos+segment_length]\n\n        # Probabilistic segment reordering\n        reorder_prob = 0.3 * (1 - objectives[complementary_idx][tier] / (np.sum(objectives[complementary_idx]) + 1e-10))\n        if np.random.rand() < reorder_prob:\n            reorder_pos = np.random.randint(0, n - segment_length)\n            new_solution[reorder_pos:reorder_pos+segment_length] = np.roll(new_solution[reorder_pos:reorder_pos+segment_length], np.random.randint(1, segment_length))\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n        return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 304,
          "algorithm": "{This novel algorithm introduces a multi-objective-aware adaptive segment fusion approach that first identifies the most complementary solutions in the archive by analyzing the covariance structure of their objectives, then performs a tiered segment fusion process where each tier selectively combines segments from different archive members based on their potential to improve Pareto dominance through a dynamic weighting scheme that prioritizes objectives with the highest relative improvement, while maintaining feasibility through a multi-phase validation mechanism that ensures no nodes are skipped or revisited. The algorithm employs an adaptive segment fusion operator that merges segments from different solutions with probabilities proportional to their current objective values, combined with a probabilistic segment reordering mechanism that reorders segments with a probability inversely proportional to their current objective contributions, further enhancing the search diversity while preserving solution quality.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Identify the most complementary solutions in the archive\n    objectives = np.array([obj for _, obj in archive])\n    obj_cov = np.cov(objectives, rowvar=False)\n    target_obj = np.argmax(np.diag(obj_cov))\n    complementary_idx = np.argmin(objectives[:, target_obj])\n    base_solution = archive[complementary_idx][0].copy()\n\n    # Select two random solutions from the archive\n    random_idx1, random_idx2 = np.random.choice(len(archive), 2, replace=False)\n    random_solution1 = archive[random_idx1][0].copy()\n    random_solution2 = archive[random_idx2][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Tiered segment fusion process\n    tiers = 3  # One for each objective\n    for tier in range(tiers):\n        # Dynamic segment length based on tier\n        segment_length = max(2, min(6, n // (tier + 2)))\n        start_pos = np.random.randint(0, n - segment_length)\n\n        # Calculate potential improvement for the current tier's objective\n        if tier == 0:\n            obj_diff1 = (distance_matrix_1[new_solution[start_pos-1], random_solution1[start_pos]] +\n                         distance_matrix_1[random_solution1[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n            obj_diff2 = (distance_matrix_1[new_solution[start_pos-1], random_solution2[start_pos]] +\n                         distance_matrix_1[random_solution2[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        elif tier == 1:\n            obj_diff1 = (distance_matrix_2[new_solution[start_pos-1], random_solution1[start_pos]] +\n                         distance_matrix_2[random_solution1[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n            obj_diff2 = (distance_matrix_2[new_solution[start_pos-1], random_solution2[start_pos]] +\n                         distance_matrix_2[random_solution2[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        else:\n            obj_diff1 = (distance_matrix_3[new_solution[start_pos-1], random_solution1[start_pos]] +\n                         distance_matrix_3[random_solution1[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n            obj_diff2 = (distance_matrix_3[new_solution[start_pos-1], random_solution2[start_pos]] +\n                         distance_matrix_3[random_solution2[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n        # Select the better segment from either random solution\n        if obj_diff1 < obj_diff2:\n            new_solution[start_pos:start_pos+segment_length] = random_solution1[start_pos:start_pos+segment_length]\n        else:\n            new_solution[start_pos:start_pos+segment_length] = random_solution2[start_pos:start_pos+segment_length]\n\n        # Probabilistic segment reordering\n        reorder_prob = 0.3 * (1 - objectives[complementary_idx][tier] / (np.sum(objectives[complementary_idx]) + 1e-10))\n        if np.random.rand() < reorder_prob:\n            reorder_pos = np.random.randint(0, n - segment_length)\n            new_solution[reorder_pos:reorder_pos+segment_length] = np.roll(new_solution[reorder_pos:reorder_pos+segment_length], np.random.randint(1, segment_length))\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n        return new_solution\n\n",
          "score": [
               -0.5256491043168537,
               0.9933953404426574
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Identify the most complementary solutions in the archive\n    objectives = np.array([obj for _, obj in archive])\n    obj_cov = np.cov(objectives, rowvar=False)\n    target_obj = np.argmax(np.diag(obj_cov))\n    complementary_idx = np.argmin(objectives[:, target_obj])\n    base_solution = archive[complementary_idx][0].copy()\n\n    # Select two random solutions from the archive\n    random_idx1, random_idx2 = np.random.choice(len(archive), 2, replace=False)\n    random_solution1 = archive[random_idx1][0].copy()\n    random_solution2 = archive[random_idx2][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Tiered segment fusion process\n    tiers = 3  # One for each objective\n    for tier in range(tiers):\n        # Dynamic segment length based on tier\n        segment_length = max(2, min(6, n // (tier + 2)))\n        start_pos = np.random.randint(0, n - segment_length)\n\n        # Calculate potential improvement for the current tier's objective\n        if tier == 0:\n            obj_diff1 = (distance_matrix_1[new_solution[start_pos-1], random_solution1[start_pos]] +\n                         distance_matrix_1[random_solution1[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n            obj_diff2 = (distance_matrix_1[new_solution[start_pos-1], random_solution2[start_pos]] +\n                         distance_matrix_1[random_solution2[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        elif tier == 1:\n            obj_diff1 = (distance_matrix_2[new_solution[start_pos-1], random_solution1[start_pos]] +\n                         distance_matrix_2[random_solution1[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n            obj_diff2 = (distance_matrix_2[new_solution[start_pos-1], random_solution2[start_pos]] +\n                         distance_matrix_2[random_solution2[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        else:\n            obj_diff1 = (distance_matrix_3[new_solution[start_pos-1], random_solution1[start_pos]] +\n                         distance_matrix_3[random_solution1[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n            obj_diff2 = (distance_matrix_3[new_solution[start_pos-1], random_solution2[start_pos]] +\n                         distance_matrix_3[random_solution2[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                         distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                         distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n        # Select the better segment from either random solution\n        if obj_diff1 < obj_diff2:\n            new_solution[start_pos:start_pos+segment_length] = random_solution1[start_pos:start_pos+segment_length]\n        else:\n            new_solution[start_pos:start_pos+segment_length] = random_solution2[start_pos:start_pos+segment_length]\n\n        # Probabilistic segment reordering\n        reorder_prob = 0.3 * (1 - objectives[complementary_idx][tier] / (np.sum(objectives[complementary_idx]) + 1e-10))\n        if np.random.rand() < reorder_prob:\n            reorder_pos = np.random.randint(0, n - segment_length)\n            new_solution[reorder_pos:reorder_pos+segment_length] = np.roll(new_solution[reorder_pos:reorder_pos+segment_length], np.random.randint(1, segment_length))\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n        return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{This new algorithm combines multi-objective optimization with a novel hierarchical local search approach that first identifies the most balanced solution in the archive, then performs a tiered segment-based optimization where each tier focuses on improving a different objective, with the optimization depth and segment length dynamically adjusted based on the current Pareto front's distribution. It employs a probabilistic tier selection mechanism that prioritizes objectives with the highest relative improvement potential, while incorporating an adaptive segment inversion operator that selectively inverts segments based on their contribution to each objective, ensuring balanced optimization across all three objectives. The algorithm also includes a tiered mutation mechanism that randomly reorders segments with probabilities inversely proportional to their current objective values, further diversifying the search while preserving solution quality. Additionally, it features a dynamic tiered segment exchange operator that exchanges segments between the base solution and a randomly selected archive member, with segment selection based on their potential to improve Pareto dominance through a tiered weighting scheme that prioritizes objectives with the highest relative improvement in each tier.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Identify the most balanced solution in the archive\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = np.mean(normalized_objectives, axis=1)\n    balanced_idx = np.argmax(balance_scores)\n    base_solution = archive[balanced_idx][0].copy()\n\n    # Select a random solution from the archive\n    random_idx = np.random.randint(len(archive))\n    random_solution = archive[random_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Tiered segment-based optimization\n    tiers = 3  # One for each objective\n    for tier in range(tiers):\n        # Dynamic segment length based on tier and solution quality\n        segment_length = max(2, min(6, n // (tier + 2)))\n        start_pos = np.random.randint(0, n - segment_length)\n\n        # Calculate potential improvement for the current tier's objective\n        if tier == 0:\n            obj_diff = (distance_matrix_1[new_solution[start_pos-1], random_solution[start_pos]] +\n                        distance_matrix_1[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                        distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                        distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        elif tier == 1:\n            obj_diff = (distance_matrix_2[new_solution[start_pos-1], random_solution[start_pos]] +\n                        distance_matrix_2[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                        distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                        distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        else:\n            obj_diff = (distance_matrix_3[new_solution[start_pos-1], random_solution[start_pos]] +\n                        distance_matrix_3[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                        distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                        distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n        # Probabilistic tier selection based on improvement potential\n        if obj_diff < 0 and np.random.rand() < 0.7:  # Higher probability for improving moves\n            new_solution[start_pos:start_pos+segment_length] = random_solution[start_pos:start_pos+segment_length]\n\n        # Tiered mutation with adaptive probability\n        mutation_prob = 0.3 * (1 - normalized_objectives[balanced_idx][tier] / (np.sum(normalized_objectives[balanced_idx]) + 1e-10))\n        if np.random.rand() < mutation_prob:\n            mutate_pos = np.random.randint(0, n - segment_length)\n            new_solution[mutate_pos:mutate_pos+segment_length] = np.roll(new_solution[mutate_pos:mutate_pos+segment_length], np.random.randint(1, segment_length))\n\n        # Tiered segment inversion\n        inversion_prob = 0.4 * (1 - normalized_objectives[balanced_idx][tier] / (np.sum(normalized_objectives[balanced_idx]) + 1e-10))\n        if np.random.rand() < inversion_prob:\n            invert_pos = np.random.randint(0, n - segment_length)\n            new_solution[invert_pos:invert_pos+segment_length] = new_solution[invert_pos:invert_pos+segment_length][::-1]\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n        return new_solution\n\nNo. 2 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the highest potential for improvement\n    # Here, we use a simple approach: select a random solution from the archive\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor using a 2-opt local search\n    n = len(base_solution)\n    new_solution = base_solution.copy()\n\n    # Randomly select two distinct edges to swap\n    i, j = sorted(np.random.choice(n, 2, replace=False))\n    k, l = sorted(np.random.choice(n, 2, replace=False))\n\n    # Perform the swap\n    new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n    new_solution[k:l+1] = np.flip(new_solution[k:l+1])\n\n    # Ensure the solution remains valid (no revisits)\n    if len(np.unique(new_solution)) == len(base_solution):\n        return new_solution\n    else:\n        return base_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one long, detail sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 305,
          "algorithm": "{This new algorithm employs a multi-objective aware segment exchange and inversion strategy that first identifies solutions with the highest potential for improvement across all three objectives by analyzing their normalized objective values and their relative positions in the Pareto front, then performs a tiered segment-based optimization where each tier focuses on improving a specific objective while maintaining a balance across all objectives, using a novel adaptive segment exchange mechanism that selects segments based on their potential to improve Pareto dominance through a tiered weighting scheme that prioritizes objectives with the highest relative improvement in each tier, combined with a probabilistic segment inversion operator that selectively inverts segments based on their contribution to each objective and their position in the current Pareto front, ensuring a diverse and balanced exploration of the search space while preserving solution quality.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Analyze objectives to identify solutions with improvement potential\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    improvement_potential = np.sum(normalized_objectives, axis=1) - np.mean(normalized_objectives, axis=1)\n    selected_idx = np.argmax(improvement_potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Tiered segment exchange and inversion\n    tiers = 3\n    for tier in range(tiers):\n        # Select segment based on objective improvement potential\n        segment_length = max(2, min(5, n // (tier + 2)))\n        start_pos = np.random.randint(0, n - segment_length)\n\n        # Calculate potential improvement for each objective\n        obj1_diff = (distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos+segment_length]] -\n                     distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                     distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        obj2_diff = (distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos+segment_length]] -\n                     distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                     distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        obj3_diff = (distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos+segment_length]] -\n                     distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                     distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n        # Tiered weighting scheme\n        if tier == 0:\n            weight1, weight2, weight3 = 0.6, 0.3, 0.1\n        elif tier == 1:\n            weight1, weight2, weight3 = 0.3, 0.6, 0.1\n        else:\n            weight1, weight2, weight3 = 0.1, 0.3, 0.6\n\n        total_diff = weight1 * obj1_diff + weight2 * obj2_diff + weight3 * obj3_diff\n\n        # Probabilistic segment exchange\n        if total_diff < 0 and np.random.rand() < 0.6:\n            exchange_idx = np.random.randint(len(archive))\n            exchange_solution = archive[exchange_idx][0].copy()\n            new_solution[start_pos:start_pos+segment_length] = exchange_solution[start_pos:start_pos+segment_length]\n\n        # Probabilistic segment inversion\n        inversion_prob = 0.5 * (1 - normalized_objectives[selected_idx][tier] / (np.sum(normalized_objectives[selected_idx]) + 1e-10))\n        if np.random.rand() < inversion_prob:\n            new_solution[start_pos:start_pos+segment_length] = new_solution[start_pos:start_pos+segment_length][::-1]\n\n    # Verify solution validity\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # Repair with random swap if invalid\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n",
          "score": [
               -0.6710593659470591,
               1.0833080887794495
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Analyze objectives to identify solutions with improvement potential\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    improvement_potential = np.sum(normalized_objectives, axis=1) - np.mean(normalized_objectives, axis=1)\n    selected_idx = np.argmax(improvement_potential)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Tiered segment exchange and inversion\n    tiers = 3\n    for tier in range(tiers):\n        # Select segment based on objective improvement potential\n        segment_length = max(2, min(5, n // (tier + 2)))\n        start_pos = np.random.randint(0, n - segment_length)\n\n        # Calculate potential improvement for each objective\n        obj1_diff = (distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos+segment_length]] -\n                     distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                     distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        obj2_diff = (distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos+segment_length]] -\n                     distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                     distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        obj3_diff = (distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos+segment_length]] -\n                     distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                     distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n        # Tiered weighting scheme\n        if tier == 0:\n            weight1, weight2, weight3 = 0.6, 0.3, 0.1\n        elif tier == 1:\n            weight1, weight2, weight3 = 0.3, 0.6, 0.1\n        else:\n            weight1, weight2, weight3 = 0.1, 0.3, 0.6\n\n        total_diff = weight1 * obj1_diff + weight2 * obj2_diff + weight3 * obj3_diff\n\n        # Probabilistic segment exchange\n        if total_diff < 0 and np.random.rand() < 0.6:\n            exchange_idx = np.random.randint(len(archive))\n            exchange_solution = archive[exchange_idx][0].copy()\n            new_solution[start_pos:start_pos+segment_length] = exchange_solution[start_pos:start_pos+segment_length]\n\n        # Probabilistic segment inversion\n        inversion_prob = 0.5 * (1 - normalized_objectives[selected_idx][tier] / (np.sum(normalized_objectives[selected_idx]) + 1e-10))\n        if np.random.rand() < inversion_prob:\n            new_solution[start_pos:start_pos+segment_length] = new_solution[start_pos:start_pos+segment_length][::-1]\n\n    # Verify solution validity\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # Repair with random swap if invalid\n        i, j = np.random.choice(n, 2, replace=False)\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Tri-objective Travelling Salesman Problem (bi-TSP), where each node has three different 2D coordinates: (x1, y1), (x2, y2) and (x3, y3), representing its position in three objective spaces. The goal is to find a tour visiting each node exactly once and returning to the starting node, while minimizing three objectives simultaneously: the total tour length in each coordinate space. Given an archive of non-dominated solutions, where each solution is a numpy array representing a TSP tour, and its corresponding objective is a tuple of three values (cost in each space), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the solution must represent a valid TSP tour: it visits each node exactly once, ensuring no node is skipped or revisited. Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement.Using a creative local search strategy of your own design, specifically tailored to effectively optimize across three objectives, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\nNone\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Evaluate potential improvement for each solution\n    potential = []\n    for sol, obj in archive:\n        # Calculate potential as inverse of objective sum (lower objectives are better)\n        # and add some randomness to avoid bias\n        potential.append((1 / (sum(obj) + 1e-6)) * (1 + np.random.rand()))\n\n    # Select a solution using roulette wheel selection\n    selected_idx = np.random.choice(len(archive), p=np.array(potential)/sum(potential))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Try 2-opt first\n    i, j = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Check if the solution is valid\n    if len(np.unique(new_solution)) != n:\n        # If not valid, revert to original\n        new_solution = base_solution.copy()\n\n    # Then try 3-objective-aware perturbation\n    if np.random.rand() < 0.5:  # 50% chance to apply this\n        start, end = sorted(np.random.choice(n, 2, replace=False))\n        subtour = new_solution[start:end+1]\n\n        # Calculate weighted distances for subtour\n        weights = np.random.rand(3)  # Random weights for objectives\n        weights /= weights.sum()     # Normalize\n\n        # Calculate total weighted distance for current order\n        current_dist = 0\n        for k in range(len(subtour)-1):\n            i, j = subtour[k], subtour[k+1]\n            current_dist += weights[0] * distance_matrix_1[i, j] + \\\n                           weights[1] * distance_matrix_2[i, j] + \\\n                           weights[2] * distance_matrix_3[i, j]\n\n        # Try random permutation of subtour\n        new_subtour = subtour.copy()\n        np.random.shuffle(new_subtour)\n\n        # Calculate new weighted distance\n        new_dist = 0\n        for k in range(len(new_subtour)-1):\n            i, j = new_subtour[k], new_subtour[k+1]\n            new_dist += weights[0] * distance_matrix_1[i, j] + \\\n                       weights[1] * distance_matrix_2[i, j] + \\\n                       weights[2] * distance_matrix_3[i, j]\n\n        # Accept if better\n        if new_dist < current_dist:\n            new_solution[start:end+1] = new_subtour\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{This new algorithm combines multi-objective optimization with a novel hierarchical local search approach that first identifies the most balanced solution in the archive, then performs a tiered segment-based optimization where each tier focuses on improving a different objective, with the optimization depth and segment length dynamically adjusted based on the current Pareto front's distribution. It employs a probabilistic tier selection mechanism that prioritizes objectives with the highest relative improvement potential, while incorporating an adaptive segment inversion operator that selectively inverts segments based on their contribution to each objective, ensuring balanced optimization across all three objectives. The algorithm also includes a tiered mutation mechanism that randomly reorders segments with probabilities inversely proportional to their current objective values, further diversifying the search while preserving solution quality. Additionally, it features a dynamic tiered segment exchange operator that exchanges segments between the base solution and a randomly selected archive member, with segment selection based on their potential to improve Pareto dominance through a tiered weighting scheme that prioritizes objectives with the highest relative improvement in each tier.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Identify the most balanced solution in the archive\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = np.mean(normalized_objectives, axis=1)\n    balanced_idx = np.argmax(balance_scores)\n    base_solution = archive[balanced_idx][0].copy()\n\n    # Select a random solution from the archive\n    random_idx = np.random.randint(len(archive))\n    random_solution = archive[random_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Tiered segment-based optimization\n    tiers = 3  # One for each objective\n    for tier in range(tiers):\n        # Dynamic segment length based on tier and solution quality\n        segment_length = max(2, min(6, n // (tier + 2)))\n        start_pos = np.random.randint(0, n - segment_length)\n\n        # Calculate potential improvement for the current tier's objective\n        if tier == 0:\n            obj_diff = (distance_matrix_1[new_solution[start_pos-1], random_solution[start_pos]] +\n                        distance_matrix_1[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                        distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                        distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        elif tier == 1:\n            obj_diff = (distance_matrix_2[new_solution[start_pos-1], random_solution[start_pos]] +\n                        distance_matrix_2[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                        distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                        distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        else:\n            obj_diff = (distance_matrix_3[new_solution[start_pos-1], random_solution[start_pos]] +\n                        distance_matrix_3[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                        distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                        distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n        # Probabilistic tier selection based on improvement potential\n        if obj_diff < 0 and np.random.rand() < 0.7:  # Higher probability for improving moves\n            new_solution[start_pos:start_pos+segment_length] = random_solution[start_pos:start_pos+segment_length]\n\n        # Tiered mutation with adaptive probability\n        mutation_prob = 0.3 * (1 - normalized_objectives[balanced_idx][tier] / (np.sum(normalized_objectives[balanced_idx]) + 1e-10))\n        if np.random.rand() < mutation_prob:\n            mutate_pos = np.random.randint(0, n - segment_length)\n            new_solution[mutate_pos:mutate_pos+segment_length] = np.roll(new_solution[mutate_pos:mutate_pos+segment_length], np.random.randint(1, segment_length))\n\n        # Tiered segment inversion\n        inversion_prob = 0.4 * (1 - normalized_objectives[balanced_idx][tier] / (np.sum(normalized_objectives[balanced_idx]) + 1e-10))\n        if np.random.rand() < inversion_prob:\n            invert_pos = np.random.randint(0, n - segment_length)\n            new_solution[invert_pos:invert_pos+segment_length] = new_solution[invert_pos:invert_pos+segment_length][::-1]\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n        return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 306,
          "algorithm": "{This new algorithm employs a multi-objective evolutionary approach that combines a novel adaptive segment clustering technique with a tiered objective-weighted path optimization strategy. It first identifies clusters of nodes in the solution based on their relative positions in all three objective spaces, then performs a hierarchical optimization where each tier focuses on improving a different objective, with the optimization depth and segment length dynamically adjusted based on the cluster properties and current Pareto front distribution. The algorithm uses a probabilistic cluster selection mechanism that prioritizes clusters with the highest potential for multi-objective improvement, while incorporating an adaptive path inversion operator that selectively inverts segments based on their contribution to each objective, ensuring balanced optimization across all three objectives. Additionally, it features a dynamic cluster-based mutation mechanism that randomly reorders segments within clusters with probabilities inversely proportional to their current objective values, further diversifying the search while preserving solution quality. The algorithm also includes a tiered cluster exchange operator that exchanges segments between the base solution and a randomly selected archive member, with segment selection based on their potential to improve Pareto dominance through a cluster-weighted weighting scheme that prioritizes objectives with the highest relative improvement in each tier.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the best overall objective trade-off\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    tradeoff_scores = np.prod(normalized_objectives, axis=1)  # Product of normalized objectives\n    selected_idx = np.argmax(tradeoff_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Cluster nodes based on their positions in all three objective spaces\n    clusters = []\n    current_cluster = [new_solution[0]]\n    for i in range(1, n):\n        # Calculate distance to previous node in all three spaces\n        dist1 = distance_matrix_1[new_solution[i-1], new_solution[i]]\n        dist2 = distance_matrix_2[new_solution[i-1], new_solution[i]]\n        dist3 = distance_matrix_3[new_solution[i-1], new_solution[i]]\n\n        # Calculate average distance across objectives\n        avg_dist = (dist1 + dist2 + dist3) / 3\n\n        # If distance is above a threshold, start a new cluster\n        if avg_dist > np.mean([distance_matrix_1.mean(), distance_matrix_2.mean(), distance_matrix_3.mean()]):\n            clusters.append(current_cluster)\n            current_cluster = [new_solution[i]]\n        else:\n            current_cluster.append(new_solution[i])\n    clusters.append(current_cluster)\n\n    # Tiered cluster-based optimization\n    for tier in range(3):  # One tier for each objective\n        if not clusters:\n            break\n\n        # Select a cluster to optimize\n        cluster_probs = []\n        for cluster in clusters:\n            # Calculate cluster's contribution to each objective\n            cluster_dist1 = sum(distance_matrix_1[cluster[i-1], cluster[i]] for i in range(1, len(cluster)))\n            cluster_dist2 = sum(distance_matrix_2[cluster[i-1], cluster[i]] for i in range(1, len(cluster)))\n            cluster_dist3 = sum(distance_matrix_3[cluster[i-1], cluster[i]] for i in range(1, len(cluster)))\n\n            # Normalize contributions\n            total_dist = cluster_dist1 + cluster_dist2 + cluster_dist3\n            if total_dist == 0:\n                cluster_probs.append(0)\n            else:\n                if tier == 0:\n                    prob = cluster_dist1 / total_dist\n                elif tier == 1:\n                    prob = cluster_dist2 / total_dist\n                else:\n                    prob = cluster_dist3 / total_dist\n                cluster_probs.append(prob)\n\n        if not cluster_probs or sum(cluster_probs) == 0:\n            continue\n\n        # Normalize probabilities\n        cluster_probs = np.array(cluster_probs)\n        cluster_probs = cluster_probs / cluster_probs.sum()\n\n        # Select cluster to optimize\n        selected_cluster_idx = np.random.choice(len(clusters), p=cluster_probs)\n        selected_cluster = clusters[selected_cluster_idx]\n\n        # Optimize the selected cluster\n        if len(selected_cluster) > 1:\n            # Try different operations based on tier\n            if tier == 0:  # First objective\n                # Reverse the cluster\n                new_cluster = selected_cluster[::-1]\n            elif tier == 1:  # Second objective\n                # Rotate the cluster\n                rotation = np.random.randint(1, len(selected_cluster))\n                new_cluster = np.roll(selected_cluster, rotation)\n            else:  # Third objective\n                # Randomly shuffle the cluster\n                new_cluster = selected_cluster.copy()\n                np.random.shuffle(new_cluster)\n\n            # Calculate the change in objectives\n            old_dist1 = sum(distance_matrix_1[selected_cluster[i-1], selected_cluster[i]] for i in range(1, len(selected_cluster)))\n            old_dist2 = sum(distance_matrix_2[selected_cluster[i-1], selected_cluster[i]] for i in range(1, len(selected_cluster)))\n            old_dist3 = sum(distance_matrix_3[selected_cluster[i-1], selected_cluster[i]] for i in range(1, len(selected_cluster)))\n\n            new_dist1 = sum(distance_matrix_1[new_cluster[i-1], new_cluster[i]] for i in range(1, len(new_cluster)))\n            new_dist2 = sum(distance_matrix_2[new_cluster[i-1], new_cluster[i]] for i in range(1, len(new_cluster)))\n            new_dist3 = sum(distance_matrix_3[new_cluster[i-1], new_cluster[i]] for i in range(1, len(new_cluster)))\n\n            # Accept if at least one objective improves\n            if (new_dist1 < old_dist1) or (new_dist2 < old_dist2) or (new_dist3 < old_dist3):\n                # Find the cluster in the solution and replace it\n                cluster_start = -1\n                for i in range(n - len(selected_cluster) + 1):\n                    if np.array_equal(new_solution[i:i+len(selected_cluster)], selected_cluster):\n                        cluster_start = i\n                        break\n                if cluster_start != -1:\n                    new_solution[cluster_start:cluster_start+len(selected_cluster)] = new_cluster\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple swap to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n",
          "score": [
               -0.6832455683007825,
               4.4227359056472775
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a numpy array of node IDs.\n             Each objective is a tuple of three float values.\n    instance: Numpy array of shape (N, 4). Each row corresponds to a node and contains its coordinates in two 2D spaces: (x1, y1, x2, y2).\n    distance_matrix_1: Distance matrix in the first objective space.\n    distance_matrix_2: Distance matrix in the second objective space.\n    distance_matrix_3: Distance matrix in the third objective space.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the best overall objective trade-off\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    tradeoff_scores = np.prod(normalized_objectives, axis=1)  # Product of normalized objectives\n    selected_idx = np.argmax(tradeoff_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Cluster nodes based on their positions in all three objective spaces\n    clusters = []\n    current_cluster = [new_solution[0]]\n    for i in range(1, n):\n        # Calculate distance to previous node in all three spaces\n        dist1 = distance_matrix_1[new_solution[i-1], new_solution[i]]\n        dist2 = distance_matrix_2[new_solution[i-1], new_solution[i]]\n        dist3 = distance_matrix_3[new_solution[i-1], new_solution[i]]\n\n        # Calculate average distance across objectives\n        avg_dist = (dist1 + dist2 + dist3) / 3\n\n        # If distance is above a threshold, start a new cluster\n        if avg_dist > np.mean([distance_matrix_1.mean(), distance_matrix_2.mean(), distance_matrix_3.mean()]):\n            clusters.append(current_cluster)\n            current_cluster = [new_solution[i]]\n        else:\n            current_cluster.append(new_solution[i])\n    clusters.append(current_cluster)\n\n    # Tiered cluster-based optimization\n    for tier in range(3):  # One tier for each objective\n        if not clusters:\n            break\n\n        # Select a cluster to optimize\n        cluster_probs = []\n        for cluster in clusters:\n            # Calculate cluster's contribution to each objective\n            cluster_dist1 = sum(distance_matrix_1[cluster[i-1], cluster[i]] for i in range(1, len(cluster)))\n            cluster_dist2 = sum(distance_matrix_2[cluster[i-1], cluster[i]] for i in range(1, len(cluster)))\n            cluster_dist3 = sum(distance_matrix_3[cluster[i-1], cluster[i]] for i in range(1, len(cluster)))\n\n            # Normalize contributions\n            total_dist = cluster_dist1 + cluster_dist2 + cluster_dist3\n            if total_dist == 0:\n                cluster_probs.append(0)\n            else:\n                if tier == 0:\n                    prob = cluster_dist1 / total_dist\n                elif tier == 1:\n                    prob = cluster_dist2 / total_dist\n                else:\n                    prob = cluster_dist3 / total_dist\n                cluster_probs.append(prob)\n\n        if not cluster_probs or sum(cluster_probs) == 0:\n            continue\n\n        # Normalize probabilities\n        cluster_probs = np.array(cluster_probs)\n        cluster_probs = cluster_probs / cluster_probs.sum()\n\n        # Select cluster to optimize\n        selected_cluster_idx = np.random.choice(len(clusters), p=cluster_probs)\n        selected_cluster = clusters[selected_cluster_idx]\n\n        # Optimize the selected cluster\n        if len(selected_cluster) > 1:\n            # Try different operations based on tier\n            if tier == 0:  # First objective\n                # Reverse the cluster\n                new_cluster = selected_cluster[::-1]\n            elif tier == 1:  # Second objective\n                # Rotate the cluster\n                rotation = np.random.randint(1, len(selected_cluster))\n                new_cluster = np.roll(selected_cluster, rotation)\n            else:  # Third objective\n                # Randomly shuffle the cluster\n                new_cluster = selected_cluster.copy()\n                np.random.shuffle(new_cluster)\n\n            # Calculate the change in objectives\n            old_dist1 = sum(distance_matrix_1[selected_cluster[i-1], selected_cluster[i]] for i in range(1, len(selected_cluster)))\n            old_dist2 = sum(distance_matrix_2[selected_cluster[i-1], selected_cluster[i]] for i in range(1, len(selected_cluster)))\n            old_dist3 = sum(distance_matrix_3[selected_cluster[i-1], selected_cluster[i]] for i in range(1, len(selected_cluster)))\n\n            new_dist1 = sum(distance_matrix_1[new_cluster[i-1], new_cluster[i]] for i in range(1, len(new_cluster)))\n            new_dist2 = sum(distance_matrix_2[new_cluster[i-1], new_cluster[i]] for i in range(1, len(new_cluster)))\n            new_dist3 = sum(distance_matrix_3[new_cluster[i-1], new_cluster[i]] for i in range(1, len(new_cluster)))\n\n            # Accept if at least one objective improves\n            if (new_dist1 < old_dist1) or (new_dist2 < old_dist2) or (new_dist3 < old_dist3):\n                # Find the cluster in the solution and replace it\n                cluster_start = -1\n                for i in range(n - len(selected_cluster) + 1):\n                    if np.array_equal(new_solution[i:i+len(selected_cluster)], selected_cluster):\n                        cluster_start = i\n                        break\n                if cluster_start != -1:\n                    new_solution[cluster_start:cluster_start+len(selected_cluster)] = new_cluster\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple swap to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n        return new_solution\n\n"
     }
]