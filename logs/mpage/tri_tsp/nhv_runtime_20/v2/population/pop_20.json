[
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Evaluate potential improvement for each solution\n    potential = []\n    for sol, obj in archive:\n        # Calculate potential as inverse of objective sum (lower objectives are better)\n        # and add some randomness to avoid bias\n        potential.append((1 / (sum(obj) + 1e-6)) * (1 + np.random.rand()))\n\n    # Select a solution using roulette wheel selection\n    selected_idx = np.random.choice(len(archive), p=np.array(potential)/sum(potential))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Try 2-opt first\n    i, j = sorted(np.random.choice(n, 2, replace=False))\n    new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Check if the solution is valid\n    if len(np.unique(new_solution)) != n:\n        # If not valid, revert to original\n        new_solution = base_solution.copy()\n\n    # Then try 3-objective-aware perturbation\n    if np.random.rand() < 0.5:  # 50% chance to apply this\n        start, end = sorted(np.random.choice(n, 2, replace=False))\n        subtour = new_solution[start:end+1]\n\n        # Calculate weighted distances for subtour\n        weights = np.random.rand(3)  # Random weights for objectives\n        weights /= weights.sum()     # Normalize\n\n        # Calculate total weighted distance for current order\n        current_dist = 0\n        for k in range(len(subtour)-1):\n            i, j = subtour[k], subtour[k+1]\n            current_dist += weights[0] * distance_matrix_1[i, j] + \\\n                           weights[1] * distance_matrix_2[i, j] + \\\n                           weights[2] * distance_matrix_3[i, j]\n\n        # Try random permutation of subtour\n        new_subtour = subtour.copy()\n        np.random.shuffle(new_subtour)\n\n        # Calculate new weighted distance\n        new_dist = 0\n        for k in range(len(new_subtour)-1):\n            i, j = new_subtour[k], new_subtour[k+1]\n            new_dist += weights[0] * distance_matrix_1[i, j] + \\\n                       weights[1] * distance_matrix_2[i, j] + \\\n                       weights[2] * distance_matrix_3[i, j]\n\n        # Accept if better\n        if new_dist < current_dist:\n            new_solution[start:end+1] = new_subtour\n\n    return new_solution\n\n",
          "score": [
               -0.8149859994248885,
               1.1998218536376952
          ]
     },
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the highest potential for improvement\n    # Here, we use a simple approach: select a random solution from the archive\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a neighbor using a 2-opt local search\n    n = len(base_solution)\n    new_solution = base_solution.copy()\n\n    # Randomly select two distinct edges to swap\n    i, j = sorted(np.random.choice(n, 2, replace=False))\n    k, l = sorted(np.random.choice(n, 2, replace=False))\n\n    # Perform the swap\n    new_solution[i:j+1] = np.flip(new_solution[i:j+1])\n    new_solution[k:l+1] = np.flip(new_solution[k:l+1])\n\n    # Ensure the solution remains valid (no revisits)\n    if len(np.unique(new_solution)) == len(base_solution):\n        return new_solution\n    else:\n        return base_solution\n\n",
          "score": [
               -0.7773360332534743,
               0.8836707472801208
          ]
     },
     {
          "algorithm": "{The new algorithm combines the selection strategy of prioritizing solutions with balanced objective values from the first provided algorithm with an innovative multi-objective local search operator that performs a hybrid of path segment rotations and objective-aware node insertions, where the insertion candidates are dynamically selected based on their potential to improve the most underperforming objective. The operator first identifies critical segments where improvements can be made by analyzing the current solution's objective values, then performs targeted rotations of these segments to explore better configurations while maintaining feasibility, and finally inserts nodes from the most underperforming objective into the solution to address its weaknesses, verifying the solution's validity by ensuring no nodes are skipped or revisited. This approach balances exploitation of good solutions with exploration of diverse neighborhoods in the multi-objective space by focusing on the objective that has shown the least improvement, promoting more balanced progress across all objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Select solution with most balanced objectives (smallest range between best and worst objective)\n        objectives = np.array([obj for _, obj in archive])\n        objective_ranges = np.max(objectives, axis=1) - np.min(objectives, axis=1)\n        selected_idx = np.argmin(objective_ranges)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Calculate current costs for all objectives\n    current_costs = [\n        sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_3[new_solution[i-1], new_solution[i]] for i in range(n))\n    ]\n\n    # Identify the most underperforming objective\n    worst_obj = np.argmax(current_costs)\n\n    # Hybrid path segment rotation with objective-aware node insertion\n    if np.random.rand() < 0.6:\n        # Perform path segment rotation\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        segment = new_solution[i:j+1]\n        rotation = np.random.randint(1, len(segment))\n        new_solution[i:j+1] = np.concatenate([segment[rotation:], segment[:rotation]])\n    else:\n        # Perform objective-aware node insertion\n        # Find nodes that are most expensive in the worst objective\n        node_costs = []\n        for k in range(n):\n            prev_node = new_solution[k-1]\n            next_node = new_solution[(k+1)%n]\n            if worst_obj == 0:\n                cost = distance_matrix_1[prev_node, new_solution[k]] + distance_matrix_1[new_solution[k], next_node]\n            elif worst_obj == 1:\n                cost = distance_matrix_2[prev_node, new_solution[k]] + distance_matrix_2[new_solution[k], next_node]\n            else:\n                cost = distance_matrix_3[prev_node, new_solution[k]] + distance_matrix_3[new_solution[k], next_node]\n            node_costs.append(cost)\n\n        # Select the most expensive node and insert it elsewhere\n        expensive_node = np.argmax(node_costs)\n        insert_pos = np.random.randint(0, n)\n        node_to_insert = new_solution[expensive_node]\n        new_solution = np.concatenate([\n            new_solution[:insert_pos],\n            [node_to_insert],\n            np.delete(new_solution, expensive_node)\n        ])\n\n    # Verify solution validity\n    if not np.array_equal(np.sort(new_solution), np.sort(base_solution)):\n        new_solution = base_solution.copy()\n    else:\n        # Verify if the move improved the worst objective\n        new_costs = [\n            sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n            sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)),\n            sum(distance_matrix_3[new_solution[i-1], new_solution[i]] for i in range(n))\n        ]\n\n        if new_costs[worst_obj] >= current_costs[worst_obj] and np.random.rand() > 0.3:\n            new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               -0.8675143517132626,
               2.784900164604187
          ]
     },
     {
          "algorithm": "{The new algorithm combines adaptive objective weighting with geometric fragmentation to create a solution selection strategy that dynamically prioritizes objectives based on their relative performance in the archive, then fragments the solution into spatially coherent segments that are reassembled using a novel \"objective-aware inversion\" operator. This operator inverts segments while considering the weighted contribution of each objective to the tour's cost, ensuring that improvements in multiple objectives are simultaneously pursued. The method incorporates a \"diversity-aware\" selection mechanism that prefers solutions from underrepresented regions of the objective space, and employs a multi-phase local search that first explores large-scale structural changes before fine-tuning with smaller perturbations.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Calculate objective weights based on archive performance\n    objectives = np.array([obj for _, obj in archive])\n    objective_ranges = np.max(objectives, axis=1) - np.min(objectives, axis=1)\n    normalized_weights = 1 / (objective_ranges + 1e-6)\n    weights = normalized_weights / np.sum(normalized_weights)\n\n    # Select solution with probability proportional to its normalized weight\n    probs = weights / np.sum(weights)\n    selected_idx = np.random.choice(len(archive), p=probs)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Geometric fragmentation and reassembly\n    if np.random.rand() < 0.8:\n        # Calculate spatial centroids for each objective space\n        coords1 = instance[base_solution, :2]\n        coords2 = instance[base_solution, 2:4]\n        centroid1 = np.mean(coords1, axis=0)\n        centroid2 = np.mean(coords2, axis=0)\n\n        # Find nodes closest to centroids in each space\n        dist1 = np.linalg.norm(coords1 - centroid1, axis=1)\n        dist2 = np.linalg.norm(coords2 - centroid2, axis=1)\n        closest1 = np.argmin(dist1)\n        closest2 = np.argmin(dist2)\n\n        # Determine fragmentation points\n        if closest1 < closest2:\n            frag1, frag2 = closest1, closest2\n        else:\n            frag1, frag2 = closest2, closest1\n\n        # Create segments\n        seg1 = new_solution[:frag1+1]\n        seg2 = new_solution[frag1+1:frag2+1]\n        seg3 = new_solution[frag2+1:]\n\n        # Reassemble with objective-aware inversion\n        if np.random.rand() < 0.5:\n            seg2 = seg2[::-1]  # Invert middle segment\n\n        # Reconstruct solution\n        new_solution = np.concatenate([seg1, seg2, seg3])\n\n        # Verify solution validity\n        if len(np.unique(new_solution)) != n:\n            new_solution = base_solution.copy()\n\n    # Apply weighted objective improvement check\n    current_costs = [\n        sum(distance_matrix_1[base_solution[i-1], base_solution[i]] for i in range(n)),\n        sum(distance_matrix_2[base_solution[i-1], base_solution[i]] for i in range(n)),\n        sum(distance_matrix_3[base_solution[i-1], base_solution[i]] for i in range(n))\n    ]\n\n    new_costs = [\n        sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)),\n        sum(distance_matrix_3[new_solution[i-1], new_solution[i]] for i in range(n))\n    ]\n\n    # Check for weighted improvement\n    weighted_current = sum(w * c for w, c in zip(weights, current_costs))\n    weighted_new = sum(w * c for w, c in zip(weights, new_costs))\n\n    if weighted_new >= weighted_current:\n        # Fall back to small perturbation if no improvement\n        if np.random.rand() < 0.3:\n            i, j = sorted(np.random.choice(n, 2, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n        else:\n            # Swap two random nodes\n            i, j = np.random.choice(n, 2, replace=False)\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
          "score": [
               -0.8651671293360679,
               2.2961432099342347
          ]
     },
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the most balanced objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = 1 - np.std(normalized_objectives, axis=1)\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Multi-objective segment exchange with adaptive weights\n    segment_length = np.random.randint(2, min(5, n//2))\n    start_pos = np.random.randint(0, n - segment_length)\n\n    # Calculate potential improvement for each objective\n    obj1_diff = (distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos+segment_length]] -\n                 distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                 distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n    obj2_diff = (distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos+segment_length]] -\n                 distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                 distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n    obj3_diff = (distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos+segment_length]] -\n                 distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                 distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n    # Dynamic weighting based on current objective distribution\n    obj_weights = np.var(normalized_objectives, axis=0)\n    obj_weights = obj_weights / np.sum(obj_weights)\n\n    # Perform segment exchange if improvement is expected\n    weighted_diff = obj_weights[0] * obj1_diff + obj_weights[1] * obj2_diff + obj_weights[2] * obj3_diff\n    if weighted_diff < 0:\n        new_solution[start_pos:start_pos+segment_length] = new_solution[start_pos:start_pos+segment_length][::-1]\n\n    # Probabilistic segment rotation with objective-aware probability\n    rotation_prob = 0.3 * (1 - np.min(normalized_objectives[selected_idx]))\n    if np.random.rand() < rotation_prob:\n        rotate_pos = np.random.randint(0, n - segment_length)\n        shift = np.random.randint(1, segment_length)\n        new_solution[rotate_pos:rotate_pos+segment_length] = np.roll(new_solution[rotate_pos:rotate_pos+segment_length], shift)\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n        return new_solution\n\n",
          "score": [
               -0.8178225080550575,
               2.1869946360588073
          ]
     },
     {
          "algorithm": "{The new algorithm combines the multi-objective selection strategy of prioritizing balanced solutions from the provided algorithms with an innovative hybrid local search operator that performs a dynamic segment-based crossover augmented with objective-aware inversion and probabilistic segment mutation. It first identifies the most balanced solution in the archive by analyzing the normalized objective values, then performs a guided segment exchange between this solution and a randomly selected archive member, where segments are selected based on their potential to improve Pareto dominance through a dynamic weighting scheme that prioritizes objectives with the highest relative improvement. The algorithm incorporates a probabilistic segment mutation mechanism that randomly reorders segments with a probability inversely proportional to their current objective values, further diversifying the search while preserving solution quality. Additionally, it includes a novel three-way objective-aware inversion operator that selectively inverts segments based on their contribution to each objective, ensuring balanced optimization across all three objectives, while dynamically adjusting the search focus based on the current Pareto front's distribution.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Identify the most balanced solution in the archive\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = np.mean(normalized_objectives, axis=1)\n    balanced_idx = np.argmax(balance_scores)\n    balanced_solution = archive[balanced_idx][0].copy()\n\n    # Select a random solution from the archive\n    random_idx = np.random.randint(len(archive))\n    random_solution = archive[random_idx][0].copy()\n\n    # Initialize the new solution\n    new_solution = balanced_solution.copy()\n    n = len(new_solution)\n\n    # Dynamic segment selection based on objective improvement potential\n    segment_length = np.random.randint(2, min(5, n//3))\n    start_pos = np.random.randint(0, n - segment_length)\n\n    # Calculate potential improvement for each objective\n    obj1_diff = (distance_matrix_1[new_solution[start_pos-1], random_solution[start_pos]] +\n                 distance_matrix_1[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                 distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                 distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n    obj2_diff = (distance_matrix_2[new_solution[start_pos-1], random_solution[start_pos]] +\n                 distance_matrix_2[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                 distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                 distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n    obj3_diff = (distance_matrix_3[new_solution[start_pos-1], random_solution[start_pos]] +\n                 distance_matrix_3[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                 distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                 distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n    # Dynamic weighting based on relative improvement\n    total_diff = np.abs(obj1_diff) + np.abs(obj2_diff) + np.abs(obj3_diff)\n    if total_diff > 0:\n        weights = np.array([np.abs(obj1_diff), np.abs(obj2_diff), np.abs(obj3_diff)]) / total_diff\n    else:\n        weights = np.ones(3) / 3\n\n    # Perform segment exchange if improvement is expected\n    if (weights[0] * obj1_diff + weights[1] * obj2_diff + weights[2] * obj3_diff) < 0:\n        new_solution[start_pos:start_pos+segment_length] = random_solution[start_pos:start_pos+segment_length]\n\n    # Probabilistic segment mutation with objective-aware probability\n    mutation_prob = 0.3 * (1 - np.min(normalized_objectives[balanced_idx]) / (np.sum(normalized_objectives[balanced_idx]) + 1e-10))\n    if np.random.rand() < mutation_prob:\n        mutate_pos = np.random.randint(0, n - segment_length)\n        new_solution[mutate_pos:mutate_pos+segment_length] = np.roll(new_solution[mutate_pos:mutate_pos+segment_length], np.random.randint(1, segment_length))\n\n    # Three-way objective-aware inversion with dynamic segment selection\n    inversion_prob = 0.4 * (1 - np.min(normalized_objectives[balanced_idx]) / (np.sum(normalized_objectives[balanced_idx]) + 1e-10))\n    if np.random.rand() < inversion_prob:\n        # Select segment based on worst objective contribution\n        potential_segments = []\n        for i in range(n - segment_length):\n            segment = new_solution[i:i+segment_length]\n            obj1_contrib = sum(distance_matrix_1[segment[j-1], segment[j]] for j in range(1, segment_length))\n            obj2_contrib = sum(distance_matrix_2[segment[j-1], segment[j]] for j in range(1, segment_length))\n            obj3_contrib = sum(distance_matrix_3[segment[j-1], segment[j]] for j in range(1, segment_length))\n            worst_contrib = min(obj1_contrib, obj2_contrib, obj3_contrib)\n            potential_segments.append((i, worst_contrib))\n\n        if potential_segments:\n            selected_segment = max(potential_segments, key=lambda x: x[1])\n            invert_pos = selected_segment[0]\n            new_solution[invert_pos:invert_pos+segment_length] = new_solution[invert_pos:invert_pos+segment_length][::-1]\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n        return new_solution\n\n",
          "score": [
               -0.7977656129040049,
               1.407644307613373
          ]
     },
     {
          "algorithm": "{This new algorithm employs a multi-objective-aware path relinking strategy that combines features from both existing approaches while introducing novel elements. It first identifies the most diverse solution in the archive by analyzing the variance of objectives, then performs a guided path relinking between this solution and a randomly selected archive member, where the path is constructed by selectively swapping nodes based on their potential to improve Pareto dominance through a weighted combination of objective improvements. The algorithm dynamically adjusts the weights during the relinking process to prioritize objectives that show the most improvement potential, while maintaining feasibility through a two-phase validation step that ensures no nodes are skipped or revisited. Additionally, it incorporates a probabilistic segment inversion mechanism that flips segments of the tour with a probability proportional to their current objective values, further diversifying the search while preserving solution quality.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Identify the most diverse solution in the archive\n    objectives = np.array([obj for _, obj in archive])\n    obj_variances = np.var(objectives, axis=0)\n    target_obj = np.argmax(obj_variances)\n    diverse_idx = np.argmax(objectives[:, target_obj])\n    diverse_solution = archive[diverse_idx][0].copy()\n\n    # Select a random solution from the archive\n    random_idx = np.random.randint(len(archive))\n    random_solution = archive[random_idx][0].copy()\n\n    # Initialize the new solution\n    new_solution = diverse_solution.copy()\n    n = len(new_solution)\n\n    # Perform guided path relinking\n    for i in range(n):\n        if np.random.rand() < 0.3:  # Probability of swapping nodes\n            # Calculate potential improvement for each objective\n            obj1_diff = distance_matrix_1[new_solution[i-1], random_solution[i]] + distance_matrix_1[random_solution[i], new_solution[(i+1)%n]] - \\\n                        distance_matrix_1[new_solution[i-1], new_solution[i]] - distance_matrix_1[new_solution[i], new_solution[(i+1)%n]]\n            obj2_diff = distance_matrix_2[new_solution[i-1], random_solution[i]] + distance_matrix_2[random_solution[i], new_solution[(i+1)%n]] - \\\n                        distance_matrix_2[new_solution[i-1], new_solution[i]] - distance_matrix_2[new_solution[i], new_solution[(i+1)%n]]\n            obj3_diff = distance_matrix_3[new_solution[i-1], random_solution[i]] + distance_matrix_3[random_solution[i], new_solution[(i+1)%n]] - \\\n                        distance_matrix_3[new_solution[i-1], new_solution[i]] - distance_matrix_3[new_solution[i], new_solution[(i+1)%n]]\n\n            # Weighted improvement score\n            weights = np.random.rand(3)\n            weights /= weights.sum()\n            improvement = weights[0] * obj1_diff + weights[1] * obj2_diff + weights[2] * obj3_diff\n\n            if improvement < 0:  # If improvement is negative, perform the swap\n                new_solution[i] = random_solution[i]\n\n    # Probabilistic segment inversion\n    if np.random.rand() < 0.5:\n        start, end = sorted(np.random.choice(n, 2, replace=False))\n        if np.random.rand() < 0.7:  # Higher probability to invert segments with better objectives\n            new_solution[start:end+1] = new_solution[start:end+1][::-1]\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n        return new_solution\n\n",
          "score": [
               -0.5910338529569468,
               0.9789687633514405
          ]
     },
     {
          "algorithm": "{This new algorithm combines multi-objective optimization with a novel hierarchical local search approach that first identifies the most balanced solution in the archive, then performs a tiered segment-based optimization where each tier focuses on improving a different objective, with the optimization depth and segment length dynamically adjusted based on the current Pareto front's distribution. It employs a probabilistic tier selection mechanism that prioritizes objectives with the highest relative improvement potential, while incorporating an adaptive segment inversion operator that selectively inverts segments based on their contribution to each objective, ensuring balanced optimization across all three objectives. The algorithm also includes a tiered mutation mechanism that randomly reorders segments with probabilities inversely proportional to their current objective values, further diversifying the search while preserving solution quality. Additionally, it features a dynamic tiered segment exchange operator that exchanges segments between the base solution and a randomly selected archive member, with segment selection based on their potential to improve Pareto dominance through a tiered weighting scheme that prioritizes objectives with the highest relative improvement in each tier.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Identify the most balanced solution in the archive\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = np.mean(normalized_objectives, axis=1)\n    balanced_idx = np.argmax(balance_scores)\n    base_solution = archive[balanced_idx][0].copy()\n\n    # Select a random solution from the archive\n    random_idx = np.random.randint(len(archive))\n    random_solution = archive[random_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Tiered segment-based optimization\n    tiers = 3  # One for each objective\n    for tier in range(tiers):\n        # Dynamic segment length based on tier and solution quality\n        segment_length = max(2, min(6, n // (tier + 2)))\n        start_pos = np.random.randint(0, n - segment_length)\n\n        # Calculate potential improvement for the current tier's objective\n        if tier == 0:\n            obj_diff = (distance_matrix_1[new_solution[start_pos-1], random_solution[start_pos]] +\n                        distance_matrix_1[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                        distance_matrix_1[new_solution[start_pos-1], new_solution[start_pos]] -\n                        distance_matrix_1[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        elif tier == 1:\n            obj_diff = (distance_matrix_2[new_solution[start_pos-1], random_solution[start_pos]] +\n                        distance_matrix_2[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                        distance_matrix_2[new_solution[start_pos-1], new_solution[start_pos]] -\n                        distance_matrix_2[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n        else:\n            obj_diff = (distance_matrix_3[new_solution[start_pos-1], random_solution[start_pos]] +\n                        distance_matrix_3[random_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]] -\n                        distance_matrix_3[new_solution[start_pos-1], new_solution[start_pos]] -\n                        distance_matrix_3[new_solution[start_pos+segment_length-1], new_solution[start_pos+segment_length]])\n\n        # Probabilistic tier selection based on improvement potential\n        if obj_diff < 0 and np.random.rand() < 0.7:  # Higher probability for improving moves\n            new_solution[start_pos:start_pos+segment_length] = random_solution[start_pos:start_pos+segment_length]\n\n        # Tiered mutation with adaptive probability\n        mutation_prob = 0.3 * (1 - normalized_objectives[balanced_idx][tier] / (np.sum(normalized_objectives[balanced_idx]) + 1e-10))\n        if np.random.rand() < mutation_prob:\n            mutate_pos = np.random.randint(0, n - segment_length)\n            new_solution[mutate_pos:mutate_pos+segment_length] = np.roll(new_solution[mutate_pos:mutate_pos+segment_length], np.random.randint(1, segment_length))\n\n        # Tiered segment inversion\n        inversion_prob = 0.4 * (1 - normalized_objectives[balanced_idx][tier] / (np.sum(normalized_objectives[balanced_idx]) + 1e-10))\n        if np.random.rand() < inversion_prob:\n            invert_pos = np.random.randint(0, n - segment_length)\n            new_solution[invert_pos:invert_pos+segment_length] = new_solution[invert_pos:invert_pos+segment_length][::-1]\n\n    # Verify the solution is valid\n    if len(np.unique(new_solution)) == n:\n        return new_solution\n    else:\n        # If invalid, perform a simple 2-opt move to repair\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j] = new_solution[i:j][::-1]\n        return new_solution\n\n",
          "score": [
               -0.7679118231989317,
               1.054365599155426
          ]
     },
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    selected_solution = min(archive, key=lambda x: max(x[1]) - min(x[1]))[0].copy()\n\n    # Multi-objective path inversion operator\n    n = len(selected_solution)\n    new_solution = selected_solution.copy()\n\n    # Select random segment to invert\n    i, j = sorted(np.random.choice(n, 2, replace=False))\n\n    # Calculate current and potential costs for all objectives\n    current_cost1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(1, n)) + distance_matrix_1[new_solution[-1], new_solution[0]]\n    current_cost2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(1, n)) + distance_matrix_2[new_solution[-1], new_solution[0]]\n    current_cost3 = sum(distance_matrix_3[new_solution[k-1], new_solution[k]] for k in range(1, n)) + distance_matrix_3[new_solution[-1], new_solution[0]]\n\n    # Perform inversion\n    new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    # Calculate new costs\n    new_cost1 = sum(distance_matrix_1[new_solution[k-1], new_solution[k]] for k in range(1, n)) + distance_matrix_1[new_solution[-1], new_solution[0]]\n    new_cost2 = sum(distance_matrix_2[new_solution[k-1], new_solution[k]] for k in range(1, n)) + distance_matrix_2[new_solution[-1], new_solution[0]]\n    new_cost3 = sum(distance_matrix_3[new_solution[k-1], new_solution[k]] for k in range(1, n)) + distance_matrix_3[new_solution[-1], new_solution[0]]\n\n    # Weighted improvement calculation\n    weights = [0.3, 0.4, 0.3]  # Example weights for three objectives\n    current_weighted = sum(w * c for w, c in zip(weights, [current_cost1, current_cost2, current_cost3]))\n    new_weighted = sum(w * c for w, c in zip(weights, [new_cost1, new_cost2, new_cost3]))\n\n    # Accept if improvement or with small probability\n    if new_weighted < current_weighted or np.random.random() < 0.1:\n        return new_solution\n    else:\n        # If not accepted, restore original and try random swap\n        new_solution = selected_solution.copy()\n        k, l = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[k], new_solution[l] = new_solution[l], new_solution[k]\n        return new_solution\n\n",
          "score": [
               -0.861910730098753,
               2.3665157318115235
          ]
     },
     {
          "algorithm": "{The new algorithm employs a hierarchical clustering-based selection strategy that groups solutions based on their objective similarities, then probabilistically selects a cluster center with a bias toward solutions in the lower quartile of the most balanced objective values. It then applies a novel \"objective-aware crossover\" operator that dynamically selects crossover points by analyzing the spatial distribution of nodes in the coordinate spaces, combining segments from different solutions while ensuring feasibility through a validity-preserving repair mechanism. The operator also incorporates a multi-objective improvement check that verifies the new solution's Pareto dominance over the parent solutions, falling back to a random two-opt move if no improvement is found. This approach uniquely combines clustering for solution selection with a geometric crossover operator, creating a balance between exploration and exploitation in the multi-objective space.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], instance: np.ndarray, distance_matrix_1: np.ndarray, distance_matrix_2: np.ndarray, distance_matrix_3: np.ndarray) -> np.ndarray:\n    if len(archive) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Hierarchical clustering selection\n        objectives = np.array([obj for _, obj in archive])\n        objective_ranges = np.max(objectives, axis=1) - np.min(objectives, axis=1)\n        selected_idx = np.argmin(objective_ranges)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n = len(new_solution)\n\n    # Objective-aware crossover operator\n    if len(archive) > 1 and np.random.rand() < 0.7:\n        # Select a random solution from archive\n        other_solution = archive[np.random.randint(len(archive))][0]\n\n        # Find crossover points based on spatial distribution\n        coords1 = instance[base_solution, :2]\n        coords2 = instance[other_solution, :2]\n\n        # Calculate centroids\n        centroid1 = np.mean(coords1, axis=0)\n        centroid2 = np.mean(coords2, axis=0)\n\n        # Find nodes closest to opposite centroids\n        dist1 = np.linalg.norm(coords1 - centroid2, axis=1)\n        dist2 = np.linalg.norm(coords2 - centroid1, axis=1)\n\n        # Select crossover points\n        i = np.argmin(dist1)\n        j = np.argmin(dist2)\n\n        # Create new solution by combining segments\n        new_solution = np.concatenate([\n            base_solution[:i],\n            other_solution[j:],\n            base_solution[i:j],\n            other_solution[:j]\n        ])\n\n        # Remove duplicates and repair\n        _, unique_idx = np.unique(new_solution, return_index=True)\n        new_solution = new_solution[np.sort(unique_idx)]\n\n        # Fill missing nodes\n        missing = np.setdiff1d(np.arange(n), new_solution)\n        if len(missing) > 0:\n            insert_pos = np.random.choice(len(new_solution), len(missing), replace=False)\n            new_solution = np.insert(new_solution, insert_pos, missing)\n\n        # Verify solution validity\n        if len(new_solution) != n or not np.array_equal(np.sort(new_solution), np.arange(n)):\n            new_solution = base_solution.copy()\n\n        # Check for multi-objective improvement\n        current_costs = [\n            sum(distance_matrix_1[base_solution[i-1], base_solution[i]] for i in range(n)),\n            sum(distance_matrix_2[base_solution[i-1], base_solution[i]] for i in range(n)),\n            sum(distance_matrix_3[base_solution[i-1], base_solution[i]] for i in range(n))\n        ]\n\n        new_costs = [\n            sum(distance_matrix_1[new_solution[i-1], new_solution[i]] for i in range(n)),\n            sum(distance_matrix_2[new_solution[i-1], new_solution[i]] for i in range(n)),\n            sum(distance_matrix_3[new_solution[i-1], new_solution[i]] for i in range(n))\n        ]\n\n        # Check if new solution is Pareto-dominant\n        improvement = False\n        for i in range(3):\n            if new_costs[i] < current_costs[i]:\n                improvement = True\n                break\n\n        if not improvement:\n            # Fall back to random 2-opt move\n            i, j = sorted(np.random.choice(n, 2, replace=False))\n            new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    else:\n        # Standard 2-opt move\n        i, j = sorted(np.random.choice(n, 2, replace=False))\n        new_solution[i:j+1] = new_solution[i:j+1][::-1]\n\n    return new_solution\n\n",
          "score": [
               -0.8140337935853852,
               2.366222929954529
          ]
     }
]