[
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective value\n    objectives = np.array([obj for _, obj in archive])\n    combined_scores = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-specific item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-specific efficiencies\n    value1_efficiency = value1_lst / (weight_lst + 1e-10)\n    value2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by efficiency for each objective\n    sorted_items1 = np.argsort(-value1_efficiency)\n    sorted_items2 = np.argsort(-value2_efficiency)\n\n    # Perform objective-specific replacements\n    for i in sorted_items1:\n        if new_solution[i] == 1:\n            # Try to replace with best value2 item\n            for j in sorted_items2:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if value2_lst[j] > value2_lst[i]:\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Capacity-aware perturbation\n    perturbation_prob = 0.3\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_prob:\n            if new_solution[idx] == 1 and np.random.rand() < 0.5:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Solution merging with random elite\n    if len(archive) > 1:\n        elite_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n        elite_solution = archive[elite_idx][0]\n\n        # Create merged solution\n        merged_solution = np.zeros_like(new_solution)\n        current_weight = 0\n\n        # Add items from current solution\n        for idx in np.where(new_solution == 1)[0]:\n            if weight_lst[idx] <= (capacity - current_weight):\n                merged_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Add items from elite solution if not already added\n        for idx in np.where(elite_solution == 1)[0]:\n            if merged_solution[idx] == 0 and weight_lst[idx] <= (capacity - current_weight):\n                merged_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        new_solution = merged_solution\n\n    return new_solution\n\n",
          "score": [
               -17.2550542197848,
               -19.57503134882105
          ]
     },
     {
          "algorithm": "{The proposed algorithm integrates a hybrid exploration-exploitation strategy with dynamic objective prioritization, where it first identifies solutions with high potential for improvement by analyzing their objective contributions and neighborhood diversity, then applies a multi-stage local search that combines probabilistic item selection based on adaptive objective weights, a guided item replacement mechanism that strategically enhances both objectives while maintaining feasibility, and a solution refinement phase that leverages both the base solution and a candidate solution generated through a diversity-aware construction heuristic to systematically explore the neighborhood while dynamically adjusting the exploration-exploitation balance through temperature-based acceptance criteria and penalty-based feasibility checks.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    base_idx = np.argmax(np.max(objectives, axis=0) - np.min(objectives, axis=0))\n    base_solution = archive[base_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Generate candidate solution with dynamic prioritization\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    beta = np.random.uniform(0.4, 0.6)  # Dynamic prioritization factor\n    priority_scores = beta * value1_lst + (1 - beta) * value2_lst\n    priority_scores /= (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-priority_scores)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Hybrid neighborhood exploration\n    new_solution = base_solution.copy()\n    temperature = 0.6\n    for _ in range(4):\n        # Calculate adaptive mutation scores\n        marginal1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n        marginal2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n        weight_impact = weight_lst * (1 - 2 * new_solution)\n\n        # Combine objectives with temperature-based acceptance\n        scores = (marginal1 + marginal2) / (1 + abs(weight_impact))\n        temp_weight = current_weight + weight_impact\n        scores[temp_weight > capacity] = -np.inf\n\n        if np.all(scores <= -np.inf):\n            break\n\n        # Apply temperature-based selection\n        probs = np.exp(scores / temperature)\n        probs /= np.sum(probs)\n        selected_item = np.random.choice(len(scores), p=probs)\n\n        # Update solution and temperature\n        new_solution[selected_item] = 1 - new_solution[selected_item]\n        current_weight += weight_impact[selected_item]\n        temperature *= 0.85\n\n    # Step 4: Solution refinement with candidate merging\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -19.295790774938155,
               -18.457964896102936
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Multi-Objective Adaptive Diversification with Hybrid Objective-Guided Exploration (MO-AD-HOGE)\", employs a four-stage approach that first identifies solutions with high diversity in their objective contributions through a novel adaptive clustering mechanism, then performs a hybrid neighborhood exploration that dynamically balances between objective improvements and solution diversification using a probabilistic item swapping mechanism that incorporates both objective-specific and capacity-aware criteria, and finally applies a solution refinement step that combines features from diverse elite solutions while systematically exploring the neighborhood through a novel adaptive perturbation mechanism that alternates between objective-centric and capacity-focused operations, ensuring both high-quality and diverse solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select diverse solution through adaptive clustering\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n\n    # Calculate diversity scores\n    diversity_scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        distances = np.sqrt(np.sum((normalized_obj - normalized_obj[i])**2, axis=1))\n        diversity_scores[i] = np.mean(distances)\n\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Hybrid objective-guided exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate adaptive objective weights\n    obj_weights = np.random.dirichlet([1, 1, 1])[:2]\n    weighted_values = obj_weights[0] * value1_lst + obj_weights[1] * value2_lst\n    value_efficiency = weighted_values / (weight_lst + 1e-10)\n\n    # Sort items by efficiency\n    sorted_items = np.argsort(-value_efficiency)\n\n    # Probabilistic item swapping with capacity check\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    for i in in_items:\n        for j in out_items:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i] and np.random.rand() < 0.5:\n                if (value1_lst[j] > value1_lst[i] or value2_lst[j] > value2_lst[i]) and np.random.rand() < 0.7:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 3: Adaptive perturbation mechanism\n    perturbation_intensity = min(0.7, 1.0 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.sum(value1_lst) + np.sum(value2_lst)))\n\n    for idx in sorted_items:\n        if new_solution[idx] == 1 and np.random.rand() < perturbation_intensity * 0.5:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n        elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity and np.random.rand() < perturbation_intensity * 0.3:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Solution refinement with diverse elite features\n    elite_solutions = [sol for sol, _ in archive if np.random.rand() < 0.4]\n    if elite_solutions:\n        elite_solution = elite_solutions[np.random.randint(len(elite_solutions))]\n        combined_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n        np.random.shuffle(combined_items)\n\n        final_solution = np.zeros_like(new_solution)\n        current_weight = 0\n        for idx in combined_items:\n            if weight_lst[idx] <= (capacity - current_weight):\n                final_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        new_solution = final_solution\n\n    return new_solution\n\n",
          "score": [
               -17.882512472707667,
               -19.060916801400516
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Centric Adaptive Exploration with Dynamic Constraint Handling (OCAE-DCH)\", employs a three-stage approach that first identifies the most promising solution through a novel objective-centric selection mechanism that dynamically balances between the two objectives based on their current relative importance, then performs a constraint-aware neighborhood exploration that systematically evaluates potential item swaps while maintaining feasibility through a dynamic capacity threshold adjustment mechanism, and finally applies a solution refinement step that combines features from diverse elite solutions while systematically exploring the neighborhood through a novel adaptive perturbation mechanism that alternates between objective-centric and capacity-focused operations, ensuring both high-quality and diverse solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    min_obj = np.min(objectives, axis=0)\n\n    # Calculate objective importance weights\n    obj_importance = (max_obj - objectives) / (max_obj - min_obj + 1e-10)\n    obj_weights = np.random.dirichlet([1, 1]) if np.random.rand() < 0.5 else obj_importance.mean(axis=0)\n\n    # Select solution with highest weighted score\n    weighted_scores = np.dot(objectives, obj_weights)\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Constraint-aware neighborhood exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate dynamic capacity threshold\n    capacity_threshold = remaining_capacity * (0.5 + 0.5 * np.random.rand())\n\n    # Evaluate potential swaps\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    for i in in_items:\n        for j in out_items:\n            weight_diff = weight_lst[j] - weight_lst[i]\n            if abs(weight_diff) <= capacity_threshold:\n                # Calculate objective improvements\n                value1_diff = value1_lst[j] - value1_lst[i]\n                value2_diff = value2_lst[j] - value2_lst[i]\n\n                # Accept swap if beneficial for at least one objective\n                if (value1_diff > 0 or value2_diff > 0) and np.random.rand() < 0.6:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight += weight_diff\n                    remaining_capacity = capacity - current_weight\n                    capacity_threshold = remaining_capacity * (0.5 + 0.5 * np.random.rand())\n                    break\n\n    # Phase 3: Adaptive perturbation with elite features\n    elite_solutions = [sol for sol, _ in archive if np.random.rand() < 0.3]\n    if elite_solutions:\n        elite_solution = elite_solutions[np.random.randint(len(elite_solutions))]\n\n        # Combine features from elite solution\n        combined_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n        np.random.shuffle(combined_items)\n\n        final_solution = np.zeros_like(new_solution)\n        current_weight = 0\n        for idx in combined_items:\n            if weight_lst[idx] <= (capacity - current_weight):\n                final_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        new_solution = final_solution\n\n    return new_solution\n\n",
          "score": [
               -18.647553129844333,
               -18.825095712577152
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Multi-Objective Adaptive Diversification with Hybrid Objective-Guided Exploration (MO-AD-HOGE)\" employs a four-stage approach that first identifies solutions with high diversity in their objective contributions through a novel adaptive clustering mechanism, then performs a hybrid neighborhood exploration that dynamically balances between objective improvements and solution diversification using a probabilistic item swapping mechanism that incorporates both objective-specific and capacity-aware criteria, and finally applies a solution refinement step that combines features from diverse elite solutions while systematically exploring the neighborhood through a novel adaptive perturbation mechanism that alternates between objective-centric and capacity-focused operations, ensuring both high-quality and diverse solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective value\n    objectives = np.array([obj for _, obj in archive])\n    combined_scores = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-specific item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-specific efficiencies\n    value1_efficiency = value1_lst / (weight_lst + 1e-10)\n    value2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by efficiency for each objective\n    sorted_items1 = np.argsort(-value1_efficiency)\n    sorted_items2 = np.argsort(-value2_efficiency)\n\n    # Perform objective-specific replacements\n    for i in sorted_items1:\n        if new_solution[i] == 1:\n            # Try to replace with best value2 item\n            for j in sorted_items2:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if value2_lst[j] > value2_lst[i]:\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Capacity-aware perturbation\n    perturbation_prob = 0.3\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_prob:\n            if new_solution[idx] == 1 and np.random.rand() < 0.5:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Solution merging with random elite\n    if len(archive) > 1:\n        elite_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n        elite_solution = archive[elite_idx][0]\n\n        # Create merged solution\n        merged_solution = np.zeros_like(new_solution)\n        current_weight = 0\n\n        # Add items from current solution\n        for idx in np.where(new_solution == 1)[0]:\n            if weight_lst[idx] <= (capacity - current_weight):\n                merged_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Add items from elite solution if not already added\n        for idx in np.where(elite_solution == 1)[0]:\n            if merged_solution[idx] == 0 and weight_lst[idx] <= (capacity - current_weight):\n                merged_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        new_solution = merged_solution\n\n    return new_solution\n\n",
          "score": [
               -17.28156934092503,
               -19.51937221900962
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Centric Dynamic Perturbation with Adaptive Capacity Exploration (OC-DPACE)\", employs a three-stage approach that first selects the most promising solution based on a dynamic objective-centric scoring system that balances both objectives with adaptive weights, then performs a novel dynamic perturbation mechanism that systematically explores the neighborhood by strategically flipping items based on their contribution to each objective while maintaining capacity constraints, and finally applies an adaptive capacity exploration phase that dynamically adjusts the solution by considering both objective improvements and capacity utilization through a hybrid probabilistic selection mechanism that alternates between objective-specific and capacity-aware operations, ensuring both high-quality and feasible solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select the most promising solution based on dynamic objective-centric scoring\n    scores = []\n    for sol, (obj1, obj2) in archive:\n        weight = np.sum(weight_lst[sol == 1])\n        norm_obj1 = obj1 / (np.sum(value1_lst) + 1e-10)\n        norm_obj2 = obj2 / (np.sum(value2_lst) + 1e-10)\n        capacity_util = weight / capacity\n        score = 0.6 * (norm_obj1 + norm_obj2) - 0.4 * capacity_util\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Dynamic perturbation mechanism with objective-centric flipping\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-centric probabilities\n    obj1_contrib = value1_lst / (weight_lst + 1e-10)\n    obj2_contrib = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items based on their contribution to each objective\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            if np.random.rand() < 0.3:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                remaining_capacity += weight_lst[i]\n        else:\n            if weight_lst[i] <= remaining_capacity:\n                flip_prob = 0.2 * (obj1_contrib[i] / (np.max(obj1_contrib) + 1e-10)) + 0.2 * (obj2_contrib[i] / (np.max(obj2_contrib) + 1e-10))\n                if np.random.rand() < flip_prob:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    remaining_capacity -= weight_lst[i]\n\n    # Phase 3: Adaptive capacity exploration with hybrid selection\n    if np.random.rand() < 0.5:\n        # Objective-centric selection\n        obj_weights = np.random.dirichlet([1, 1, 1])[:2]\n        weighted_values = obj_weights[0] * value1_lst + obj_weights[1] * value2_lst\n        value_efficiency = weighted_values / (weight_lst + 1e-10)\n        sorted_items = np.argsort(-value_efficiency)\n\n        for idx in sorted_items:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                if np.random.rand() < 0.3:\n                    break\n    else:\n        # Capacity-aware selection\n        sorted_items = np.argsort(weight_lst)\n        for idx in sorted_items:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                if np.random.rand() < 0.3:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -18.917261852891336,
               -18.723502685084632
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Objective-Driven Hybrid Exploration with Dynamic Perturbation and Capacity-Aware Refinement (A-ODEH-DPCR)\", builds upon the adaptive objective analysis from the first algorithm and the hybrid exploration strategy from the second, but introduces a novel three-stage process: 1) it first identifies solutions with high potential by dynamically weighting objectives and prioritizing items with high value-to-weight ratios, 2) it then applies a hybrid perturbation mechanism that alternates between objective-specific removals and capacity-aware additions, with intensity adjusted based on solution quality, and 3) it finally performs an adaptive refinement phase that selectively swaps items based on their marginal contributions to both objectives, while maintaining feasibility through probabilistic acceptance criteria that balance exploration and exploitation. This approach systematically explores the solution space while prioritizing diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic objective weighting and solution selection\n    objectives = np.array([obj for _, obj in archive])\n    objective_weights = np.random.uniform(0.3, 0.7, size=2)\n    objective_weights /= np.sum(objective_weights)\n    combined_values = objectives[:, 0] * objective_weights[0] + objectives[:, 1] * objective_weights[1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Phase 2: Hybrid perturbation with adaptive intensity\n    value_to_weight_ratio = (value1_lst * objective_weights[0] + value2_lst * objective_weights[1]) / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-value_to_weight_ratio)\n\n    # Determine perturbation intensity\n    max_possible_value = np.sum(value1_lst * objective_weights[0] + value2_lst * objective_weights[1])\n    current_value = combined_values[selected_idx]\n    perturbation_intensity = min(0.7, 1.0 - current_value / max_possible_value)\n\n    # Remove low-value items with probability\n    for idx in sorted_indices[len(sorted_indices)//2:]:\n        if new_solution[idx] == 1 and np.random.rand() < perturbation_intensity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n\n    # Add high-value items with probabilistic acceptance\n    out_items = np.where(new_solution == 0)[0]\n    sorted_out_items = np.argsort(-value_to_weight_ratio[out_items])\n\n    for idx in out_items[sorted_out_items[:len(sorted_out_items)//2]]:\n        if weight_lst[idx] <= remaining_capacity and np.random.rand() < (1 - perturbation_intensity):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 3: Adaptive refinement with marginal contribution analysis\n    if np.random.rand() < 0.7:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        # Calculate marginal contributions\n        in_marginal = value_to_weight_ratio[in_items]\n        out_marginal = value_to_weight_ratio[out_items]\n\n        # Sort items by marginal contribution\n        in_sorted = in_items[np.argsort(in_marginal)]\n        out_sorted = out_items[np.argsort(-out_marginal)]\n\n        # Perform selective swaps\n        for i in in_sorted[:len(in_sorted)//2]:\n            for j in out_sorted[:len(out_sorted)//2]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity and np.random.rand() < 0.9:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.159914218470085,
               -18.65742086345796
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Dynamic Objective-Aligned Solution Evolution with Adaptive Multi-Objective Perturbation (DOASE-AMP)\", first identifies the most balanced solution in the archive by evaluating both objectives through a novel trade-off metric that combines their normalized values with a dynamic weighting factor, then applies a hybrid search strategy that alternates between objective-specific perturbations and capacity-constrained swaps, where items are prioritized based on their adaptive contributions to both objectives, while dynamically adjusting the exploration intensity based on the solution's proximity to the Pareto front and the archive's diversity, ensuring a balance between exploitation of high-value items and exploration of diverse solution spaces to generate high-quality neighbors across multiple objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select solution with most balanced objectives\n    objectives = np.array([(v1, v2) for _, (v1, v2) in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-10)\n    balance_scores = 1 - np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Dynamic objective-aligned perturbation\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate adaptive weights based on objective balance\n    v1_total, v2_total = objectives[selected_idx]\n    alpha = np.random.uniform(0.3, 0.7) if v1_total > v2_total else np.random.uniform(0.7, 0.3)\n    adaptive_values = alpha * value1_lst + (1 - alpha) * value2_lst\n    value_ratios = adaptive_values / (weight_lst + 1e-10)\n\n    # Step 3: Multi-stage perturbation\n    # Phase 1: Remove items with low adaptive value\n    in_items = np.where(new_solution == 1)[0]\n    sorted_in = in_items[np.argsort(value_ratios[in_items])]\n    for idx in sorted_in[:len(sorted_in)//2]:\n        if np.random.rand() < 0.4:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n\n    # Phase 2: Add high-value items\n    out_items = np.where(new_solution == 0)[0]\n    sorted_out = out_items[np.argsort(-value_ratios[out_items])]\n    for idx in sorted_out[:len(sorted_out)//2]:\n        if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.6:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Step 4: Adaptive swaps based on objective balance\n    if np.random.rand() < 0.5:\n        remove_candidates = np.where(new_solution == 1)[0]\n        add_candidates = np.where(new_solution == 0)[0]\n\n        remove_candidates = remove_candidates[np.argsort(value_ratios[remove_candidates])]\n        add_candidates = add_candidates[np.argsort(-value_ratios[add_candidates])]\n\n        for i in remove_candidates[:len(remove_candidates)//2]:\n            for j in add_candidates[:len(add_candidates)//2]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity and np.random.rand() < 0.7:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.057830218367492,
               -18.674432122460587
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Objective-Centric Exploration with Dynamic Pareto-Adaptive Perturbation (A-OCE-DPAP)\", first identifies solutions in the archive with the highest combined objective values while maintaining feasibility, then applies a novel hybrid search strategy that combines Pareto-adaptive perturbation with dynamic objective-centric exploration, where items are prioritized based on their adaptive contributions to both objectives through a multi-stage perturbation mechanism that alternates between objective-specific mutations and capacity-aware item swaps, while dynamically adjusting the exploration intensity based on the solution's proximity to the Pareto front, ensuring a balance between exploitation of high-value items and exploration of diverse solution spaces to generate high-quality neighbors across multiple objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective values\n    objectives = np.array([obj for _, obj in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Pareto-adaptive perturbation\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate Pareto-adaptive weights\n    pareto_weights = np.random.uniform(0.3, 0.7)\n    adaptive_values = pareto_weights * value1_lst + (1 - pareto_weights) * value2_lst\n    value_ratios = adaptive_values / (weight_lst + 1e-10)\n\n    # Sort items by adaptive value ratio\n    sorted_items = np.argsort(-value_ratios)\n\n    # Dynamic perturbation intensity\n    perturbation_intensity = min(0.5, 1.0 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.sum(value1_lst) + np.sum(value2_lst)))\n\n    # Remove low-value items with probability based on intensity\n    for idx in sorted_items[len(sorted_items)//2:]:\n        if new_solution[idx] == 1 and np.random.rand() < perturbation_intensity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n\n    # Phase 3: Objective-centric exploration\n    out_items = np.where(new_solution == 0)[0]\n    sorted_out_items = np.argsort(-value_ratios[out_items])\n\n    # Add high-value items with probability based on intensity\n    for idx in out_items[sorted_out_items[:len(sorted_out_items)//2]]:\n        if weight_lst[idx] <= remaining_capacity and np.random.rand() < (1 - perturbation_intensity):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Dynamic capacity-aware swaps\n    if np.random.rand() < 0.5:  # Higher probability for swaps\n        remove_candidates = np.where(new_solution == 1)[0]\n        add_candidates = np.where(new_solution == 0)[0]\n\n        # Sort candidates by value ratio\n        remove_candidates = remove_candidates[np.argsort(value_ratios[remove_candidates])]\n        add_candidates = add_candidates[np.argsort(-value_ratios[add_candidates])]\n\n        # Perform swaps with adaptive probability\n        for i in remove_candidates[:len(remove_candidates)//2]:\n            for j in add_candidates[:len(add_candidates)//2]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity and np.random.rand() < 0.7:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.28343212616835,
               -18.581111593129386
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Objective Exploration with Dynamic Hybrid Perturbation (A-MOEDHP)\", combines the strengths of adaptive objective analysis and hybrid neighborhood exploration from the provided algorithms with a novel two-stage perturbation mechanism. It first identifies solutions with high potential by analyzing both objectives through dynamic weighting, then applies a hybrid search strategy that alternates between objective-specific perturbations and capacity-aware swaps, dynamically adjusting the exploration intensity based on the solution's proximity to the Pareto front. This approach prioritizes items with high value-to-weight ratios while systematically exploring the neighborhood through probabilistic acceptance criteria, ensuring diverse and high-quality solutions across both objectives while maintaining feasibility.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective values\n    objectives = np.array([obj for _, obj in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Phase 2: Dynamic objective weighting and perturbation\n    objective_weights = np.random.uniform(0.4, 0.6, size=2)\n    objective_weights /= np.sum(objective_weights)\n    combined_values = objective_weights[0] * value1_lst + objective_weights[1] * value2_lst\n    value_to_weight_ratio = combined_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-value_to_weight_ratio)\n\n    # Determine perturbation intensity based on solution quality\n    max_possible_value = np.sum(value1_lst) + np.sum(value2_lst)\n    current_value = objectives[selected_idx, 0] + objectives[selected_idx, 1]\n    perturbation_intensity = min(0.6, 1.0 - current_value / max_possible_value)\n\n    # Remove low-value items with probability based on intensity\n    for idx in sorted_indices[len(sorted_indices)//2:]:\n        if new_solution[idx] == 1 and np.random.rand() < perturbation_intensity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n\n    # Phase 3: Add high-value items with probabilistic acceptance\n    out_items = np.where(new_solution == 0)[0]\n    sorted_out_items = np.argsort(-value_to_weight_ratio[out_items])\n\n    for idx in out_items[sorted_out_items[:len(sorted_out_items)//2]]:\n        if weight_lst[idx] <= remaining_capacity and np.random.rand() < (1 - perturbation_intensity):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Capacity-aware swaps with adaptive probability\n    if np.random.rand() < 0.6:  # Higher probability for swaps\n        remove_candidates = np.where(new_solution == 1)[0]\n        add_candidates = np.where(new_solution == 0)[0]\n\n        # Sort candidates by value ratio\n        remove_candidates = remove_candidates[np.argsort(value_to_weight_ratio[remove_candidates])]\n        add_candidates = add_candidates[np.argsort(-value_to_weight_ratio[add_candidates])]\n\n        # Perform swaps with adaptive probability\n        for i in remove_candidates[:len(remove_candidates)//2]:\n            for j in add_candidates[:len(add_candidates)//2]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity and np.random.rand() < 0.8:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.280714416697045,
               -18.597665007027707
          ]
     }
]