[
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective value\n    objectives = np.array([obj for _, obj in archive])\n    combined_scores = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-specific item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-specific efficiencies\n    value1_efficiency = value1_lst / (weight_lst + 1e-10)\n    value2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by efficiency for each objective\n    sorted_items1 = np.argsort(-value1_efficiency)\n    sorted_items2 = np.argsort(-value2_efficiency)\n\n    # Perform objective-specific replacements\n    for i in sorted_items1:\n        if new_solution[i] == 1:\n            # Try to replace with best value2 item\n            for j in sorted_items2:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if value2_lst[j] > value2_lst[i]:\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Capacity-aware perturbation\n    perturbation_prob = 0.3\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_prob:\n            if new_solution[idx] == 1 and np.random.rand() < 0.5:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Solution merging with random elite\n    if len(archive) > 1:\n        elite_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n        elite_solution = archive[elite_idx][0]\n\n        # Create merged solution\n        merged_solution = np.zeros_like(new_solution)\n        current_weight = 0\n\n        # Add items from current solution\n        for idx in np.where(new_solution == 1)[0]:\n            if weight_lst[idx] <= (capacity - current_weight):\n                merged_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Add items from elite solution if not already added\n        for idx in np.where(elite_solution == 1)[0]:\n            if merged_solution[idx] == 0 and weight_lst[idx] <= (capacity - current_weight):\n                merged_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        new_solution = merged_solution\n\n    return new_solution\n\n",
          "score": [
               -17.2550542197848,
               -19.57503134882105
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Centric Adaptive Hybrid Exploration with Dynamic Perturbation and Elite Fusion (OCA-HEDEPF)\", combines a novel multi-objective selection mechanism that prioritizes solutions with balanced objective contributions through a dynamic weighting scheme, with an adaptive neighborhood exploration strategy that alternates between objective-specific item replacements and capacity-aware perturbations, while incorporating a solution refinement phase that fuses features from diverse elite solutions through a probabilistic item selection mechanism that balances objective improvements with solution diversity, all while systematically exploring the solution space through a novel adaptive perturbation schedule that adjusts its intensity based on the current solution's proximity to the Pareto front and its objective-centric efficiency, ensuring both high-quality and diverse solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = 1 - np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-centric item replacement with dynamic weights\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate dynamic objective weights\n    obj1_weight = 0.5 + 0.5 * (objectives[selected_idx, 0] / (objectives[selected_idx, 0] + objectives[selected_idx, 1] + 1e-10))\n    obj2_weight = 1 - obj1_weight\n\n    # Calculate combined efficiency scores\n    combined_efficiency = (obj1_weight * value1_lst + obj2_weight * value2_lst) / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-combined_efficiency)\n\n    # Perform adaptive item replacements\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            # Find best replacement item\n            best_replacement = -1\n            max_gain = 0\n            for j in sorted_items:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    gain = (obj1_weight * (value1_lst[j] - value1_lst[i]) +\n                            obj2_weight * (value2_lst[j] - value2_lst[i]))\n                    if gain > max_gain:\n                        max_gain = gain\n                        best_replacement = j\n\n            if best_replacement != -1 and max_gain > 0:\n                new_solution[i] = 0\n                new_solution[best_replacement] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement]\n                remaining_capacity = capacity - current_weight\n\n    # Phase 3: Adaptive perturbation with dynamic intensity\n    perturbation_intensity = 0.3 + 0.4 * (1 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) /\n                                        (objectives.max(axis=0).sum() + 1e-10))\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.6:  # Higher probability to remove\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.3:  # Lower probability to add\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution fusion with probabilistic selection\n    if len(archive) > 1:\n        # Select elite solutions based on their diversity\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    fusion_prob = 0.5 + 0.5 * (combined_efficiency[idx] / (combined_efficiency.max() + 1e-10))\n                    if np.random.rand() < fusion_prob:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -20.045799595455243,
               -17.134883582342496
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Diversity-Preserving Adaptive Multi-Objective Greedy Search (DAMOGS)\", employs a unique combination of objective-driven greedy selection with diversity-preserving perturbations, where it first identifies the most promising solution in the archive through a hybrid objective scoring mechanism that balances individual objective values with their relative contributions to the Pareto front, then systematically explores the solution space by iteratively applying a novel adaptive greedy replacement strategy that prioritizes items with complementary objective profiles while maintaining a strict capacity constraint, followed by a diversity-enhancing perturbation phase that selectively introduces or removes items based on their potential to create non-dominated solutions in the objective space, and finally incorporates a solution refinement step that merges features from multiple elite solutions through a probabilistic item selection mechanism that prioritizes items with high objective efficiency and low redundancy, all while dynamically adjusting the exploration intensity based on the current solution's proximity to the identified Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with hybrid objective scoring\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    norm_obj = objectives / (max_obj + 1e-10)\n    hybrid_scores = 0.6 * norm_obj[:, 0] + 0.4 * norm_obj[:, 1] + 0.2 * (norm_obj[:, 0] * norm_obj[:, 1])\n    selected_idx = np.argmax(hybrid_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Adaptive greedy replacement with complementarity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate complementarity scores\n    comp_scores = value1_lst * value2_lst / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-comp_scores)\n\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            # Find best complementary item to replace\n            for j in sorted_items:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if (value1_lst[j] > value1_lst[i] and value2_lst[j] >= value2_lst[i]) or \\\n                       (value1_lst[j] >= value1_lst[i] and value2_lst[j] > value2_lst[i]):\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Diversity-preserving perturbation\n    diversity_factor = 0.3\n    for idx in range(len(new_solution)):\n        if np.random.rand() < diversity_factor:\n            if new_solution[idx] == 1 and np.random.rand() < 0.7:\n                # Remove item with high probability\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                # Add item with lower probability\n                if np.random.rand() < 0.3:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution merging with probabilistic selection\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    if np.random.rand() < 0.5:  # Moderate probability to accept from elite\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -19.36046321062825,
               -18.26125506516535
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Objective Solution Evolution (AMOSE)\", integrates a dynamic solution selection mechanism that prioritizes under-represented objective regions with a hybrid neighborhood generation strategy that combines greedy objective-specific improvements with probabilistic capacity-aware perturbations, while incorporating an elite solution fusion phase that uses a novel diversity-preserving crossover operator to merge solution features from multiple high-quality solutions, all while maintaining feasibility through an adaptive capacity management system that dynamically adjusts perturbation intensity based on the current solution's objective trade-off characteristics.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective value\n    objectives = np.array([obj for _, obj in archive])\n    combined_scores = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-driven neighborhood exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-specific efficiencies\n    value1_efficiency = value1_lst / (weight_lst + 1e-10)\n    value2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by efficiency for each objective\n    sorted_items1 = np.argsort(-value1_efficiency)\n    sorted_items2 = np.argsort(-value2_efficiency)\n\n    # Perform adaptive objective-driven swaps\n    for i in sorted_items1:\n        if new_solution[i] == 1 and np.random.rand() < 0.5:\n            # Try to replace with best value2 item\n            for j in sorted_items2:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if value2_lst[j] > value2_lst[i]:\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Capacity-aware perturbation with adaptive intensity\n    perturbation_intensity = 0.3 + 0.2 * (1 - (objectives[selected_idx][0] + objectives[selected_idx][1]) / np.sum(objectives))\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.6:  # Higher probability to remove\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.4:  # Lower probability to add\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution fusion with diversity preservation\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    if np.random.rand() < 0.6:  # Higher probability to accept from elite\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -17.967428968213934,
               -19.117728840818664
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Centric Adaptive Exploration with Dynamic Constraint Handling (OCAE-DCH)\", employs a three-stage approach that first identifies the most promising solution through a novel objective-centric selection mechanism that dynamically balances between the two objectives based on their current relative importance, then performs a constraint-aware neighborhood exploration that systematically evaluates potential item swaps while maintaining feasibility through a dynamic capacity threshold adjustment mechanism, and finally applies a solution refinement step that combines features from diverse elite solutions while systematically exploring the neighborhood through a novel adaptive perturbation mechanism that alternates between objective-centric and capacity-focused operations, ensuring both high-quality and diverse solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    min_obj = np.min(objectives, axis=0)\n\n    # Calculate objective importance weights\n    obj_importance = (max_obj - objectives) / (max_obj - min_obj + 1e-10)\n    obj_weights = np.random.dirichlet([1, 1]) if np.random.rand() < 0.5 else obj_importance.mean(axis=0)\n\n    # Select solution with highest weighted score\n    weighted_scores = np.dot(objectives, obj_weights)\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Constraint-aware neighborhood exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate dynamic capacity threshold\n    capacity_threshold = remaining_capacity * (0.5 + 0.5 * np.random.rand())\n\n    # Evaluate potential swaps\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    for i in in_items:\n        for j in out_items:\n            weight_diff = weight_lst[j] - weight_lst[i]\n            if abs(weight_diff) <= capacity_threshold:\n                # Calculate objective improvements\n                value1_diff = value1_lst[j] - value1_lst[i]\n                value2_diff = value2_lst[j] - value2_lst[i]\n\n                # Accept swap if beneficial for at least one objective\n                if (value1_diff > 0 or value2_diff > 0) and np.random.rand() < 0.6:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight += weight_diff\n                    remaining_capacity = capacity - current_weight\n                    capacity_threshold = remaining_capacity * (0.5 + 0.5 * np.random.rand())\n                    break\n\n    # Phase 3: Adaptive perturbation with elite features\n    elite_solutions = [sol for sol, _ in archive if np.random.rand() < 0.3]\n    if elite_solutions:\n        elite_solution = elite_solutions[np.random.randint(len(elite_solutions))]\n\n        # Combine features from elite solution\n        combined_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n        np.random.shuffle(combined_items)\n\n        final_solution = np.zeros_like(new_solution)\n        current_weight = 0\n        for idx in combined_items:\n            if weight_lst[idx] <= (capacity - current_weight):\n                final_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        new_solution = final_solution\n\n    return new_solution\n\n",
          "score": [
               -18.647553129844333,
               -18.825095712577152
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Driven Hybrid Clustering and Adaptive Neighborhood Exploration (OH-CANE)\", combines a novel multi-objective clustering technique that identifies solution regions with complementary objective contributions with a dynamic neighborhood exploration strategy that alternates between objective-specific item swaps and capacity-aware perturbations, while incorporating a solution refinement phase that merges features from diverse elite solutions through a probabilistic item selection mechanism that balances objective improvements with solution diversity, all while systematically exploring the solution space through a novel adaptive perturbation schedule that adjusts its intensity based on the current solution's proximity to the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective value\n    objectives = np.array([obj for _, obj in archive])\n    combined_scores = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-driven clustering and neighborhood exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-specific efficiencies\n    value1_efficiency = value1_lst / (weight_lst + 1e-10)\n    value2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by efficiency for each objective\n    sorted_items1 = np.argsort(-value1_efficiency)\n    sorted_items2 = np.argsort(-value2_efficiency)\n\n    # Perform adaptive objective-driven swaps\n    swap_prob = 0.5\n    for i in sorted_items1:\n        if new_solution[i] == 1 and np.random.rand() < swap_prob:\n            # Try to replace with best value2 item\n            for j in sorted_items2:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if value2_lst[j] > value2_lst[i]:\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Adaptive perturbation with capacity awareness\n    perturbation_intensity = 0.4\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.6:  # Higher probability to remove\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.4:  # Lower probability to add\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution merging with probabilistic selection\n    if len(archive) > 1:\n        # Select elite solutions based on their diversity\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(3, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    if np.random.rand() < 0.7:  # Higher probability to accept from elite\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -17.878808762942704,
               -19.39905387664975
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Multi-Objective Adaptive Diversification with Hybrid Objective-Guided Exploration (MO-AD-HOGE)\" employs a four-stage approach that first identifies solutions with high diversity in their objective contributions through a novel adaptive clustering mechanism, then performs a hybrid neighborhood exploration that dynamically balances between objective improvements and solution diversification using a probabilistic item swapping mechanism that incorporates both objective-specific and capacity-aware criteria, and finally applies a solution refinement step that combines features from diverse elite solutions while systematically exploring the neighborhood through a novel adaptive perturbation mechanism that alternates between objective-centric and capacity-focused operations, ensuring both high-quality and diverse solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective value\n    objectives = np.array([obj for _, obj in archive])\n    combined_scores = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-specific item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-specific efficiencies\n    value1_efficiency = value1_lst / (weight_lst + 1e-10)\n    value2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by efficiency for each objective\n    sorted_items1 = np.argsort(-value1_efficiency)\n    sorted_items2 = np.argsort(-value2_efficiency)\n\n    # Perform objective-specific replacements\n    for i in sorted_items1:\n        if new_solution[i] == 1:\n            # Try to replace with best value2 item\n            for j in sorted_items2:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if value2_lst[j] > value2_lst[i]:\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Capacity-aware perturbation\n    perturbation_prob = 0.3\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_prob:\n            if new_solution[idx] == 1 and np.random.rand() < 0.5:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Solution merging with random elite\n    if len(archive) > 1:\n        elite_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n        elite_solution = archive[elite_idx][0]\n\n        # Create merged solution\n        merged_solution = np.zeros_like(new_solution)\n        current_weight = 0\n\n        # Add items from current solution\n        for idx in np.where(new_solution == 1)[0]:\n            if weight_lst[idx] <= (capacity - current_weight):\n                merged_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Add items from elite solution if not already added\n        for idx in np.where(elite_solution == 1)[0]:\n            if merged_solution[idx] == 0 and weight_lst[idx] <= (capacity - current_weight):\n                merged_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        new_solution = merged_solution\n\n    return new_solution\n\n",
          "score": [
               -17.28156934092503,
               -19.51937221900962
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Centric Dynamic Perturbation with Adaptive Capacity Exploration (OC-DPACE)\", employs a three-stage approach that first selects the most promising solution based on a dynamic objective-centric scoring system that balances both objectives with adaptive weights, then performs a novel dynamic perturbation mechanism that systematically explores the neighborhood by strategically flipping items based on their contribution to each objective while maintaining capacity constraints, and finally applies an adaptive capacity exploration phase that dynamically adjusts the solution by considering both objective improvements and capacity utilization through a hybrid probabilistic selection mechanism that alternates between objective-specific and capacity-aware operations, ensuring both high-quality and feasible solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select the most promising solution based on dynamic objective-centric scoring\n    scores = []\n    for sol, (obj1, obj2) in archive:\n        weight = np.sum(weight_lst[sol == 1])\n        norm_obj1 = obj1 / (np.sum(value1_lst) + 1e-10)\n        norm_obj2 = obj2 / (np.sum(value2_lst) + 1e-10)\n        capacity_util = weight / capacity\n        score = 0.6 * (norm_obj1 + norm_obj2) - 0.4 * capacity_util\n        scores.append(score)\n\n    selected_idx = np.argmax(scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Dynamic perturbation mechanism with objective-centric flipping\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-centric probabilities\n    obj1_contrib = value1_lst / (weight_lst + 1e-10)\n    obj2_contrib = value2_lst / (weight_lst + 1e-10)\n\n    # Flip items based on their contribution to each objective\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            if np.random.rand() < 0.3:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                remaining_capacity += weight_lst[i]\n        else:\n            if weight_lst[i] <= remaining_capacity:\n                flip_prob = 0.2 * (obj1_contrib[i] / (np.max(obj1_contrib) + 1e-10)) + 0.2 * (obj2_contrib[i] / (np.max(obj2_contrib) + 1e-10))\n                if np.random.rand() < flip_prob:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    remaining_capacity -= weight_lst[i]\n\n    # Phase 3: Adaptive capacity exploration with hybrid selection\n    if np.random.rand() < 0.5:\n        # Objective-centric selection\n        obj_weights = np.random.dirichlet([1, 1, 1])[:2]\n        weighted_values = obj_weights[0] * value1_lst + obj_weights[1] * value2_lst\n        value_efficiency = weighted_values / (weight_lst + 1e-10)\n        sorted_items = np.argsort(-value_efficiency)\n\n        for idx in sorted_items:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                if np.random.rand() < 0.3:\n                    break\n    else:\n        # Capacity-aware selection\n        sorted_items = np.argsort(weight_lst)\n        for idx in sorted_items:\n            if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n                if np.random.rand() < 0.3:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -18.917261852891336,
               -18.723502685084632
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Objective-Driven Hybrid Exploration with Dynamic Perturbation and Capacity-Aware Refinement (A-ODEH-DPCR)\", builds upon the adaptive objective analysis from the first algorithm and the hybrid exploration strategy from the second, but introduces a novel three-stage process: 1) it first identifies solutions with high potential by dynamically weighting objectives and prioritizing items with high value-to-weight ratios, 2) it then applies a hybrid perturbation mechanism that alternates between objective-specific removals and capacity-aware additions, with intensity adjusted based on solution quality, and 3) it finally performs an adaptive refinement phase that selectively swaps items based on their marginal contributions to both objectives, while maintaining feasibility through probabilistic acceptance criteria that balance exploration and exploitation. This approach systematically explores the solution space while prioritizing diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic objective weighting and solution selection\n    objectives = np.array([obj for _, obj in archive])\n    objective_weights = np.random.uniform(0.3, 0.7, size=2)\n    objective_weights /= np.sum(objective_weights)\n    combined_values = objectives[:, 0] * objective_weights[0] + objectives[:, 1] * objective_weights[1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Phase 2: Hybrid perturbation with adaptive intensity\n    value_to_weight_ratio = (value1_lst * objective_weights[0] + value2_lst * objective_weights[1]) / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-value_to_weight_ratio)\n\n    # Determine perturbation intensity\n    max_possible_value = np.sum(value1_lst * objective_weights[0] + value2_lst * objective_weights[1])\n    current_value = combined_values[selected_idx]\n    perturbation_intensity = min(0.7, 1.0 - current_value / max_possible_value)\n\n    # Remove low-value items with probability\n    for idx in sorted_indices[len(sorted_indices)//2:]:\n        if new_solution[idx] == 1 and np.random.rand() < perturbation_intensity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n\n    # Add high-value items with probabilistic acceptance\n    out_items = np.where(new_solution == 0)[0]\n    sorted_out_items = np.argsort(-value_to_weight_ratio[out_items])\n\n    for idx in out_items[sorted_out_items[:len(sorted_out_items)//2]]:\n        if weight_lst[idx] <= remaining_capacity and np.random.rand() < (1 - perturbation_intensity):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 3: Adaptive refinement with marginal contribution analysis\n    if np.random.rand() < 0.7:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        # Calculate marginal contributions\n        in_marginal = value_to_weight_ratio[in_items]\n        out_marginal = value_to_weight_ratio[out_items]\n\n        # Sort items by marginal contribution\n        in_sorted = in_items[np.argsort(in_marginal)]\n        out_sorted = out_items[np.argsort(-out_marginal)]\n\n        # Perform selective swaps\n        for i in in_sorted[:len(in_sorted)//2]:\n            for j in out_sorted[:len(out_sorted)//2]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity and np.random.rand() < 0.9:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.159914218470085,
               -18.65742086345796
          ]
     },
     {
          "algorithm": "{The proposed algorithm integrates a hybrid exploration-exploitation strategy with dynamic objective prioritization, where it first identifies solutions with high potential for improvement by analyzing their objective contributions and neighborhood diversity, then applies a multi-stage local search that combines probabilistic item selection based on adaptive objective weights, a guided item replacement mechanism that strategically enhances both objectives while maintaining feasibility, and a solution refinement phase that leverages both the base solution and a candidate solution generated through a diversity-aware construction heuristic to systematically explore the neighborhood while dynamically adjusting the exploration-exploitation balance through temperature-based acceptance criteria and penalty-based feasibility checks.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    base_idx = np.argmax(np.max(objectives, axis=0) - np.min(objectives, axis=0))\n    base_solution = archive[base_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Generate candidate solution with dynamic prioritization\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    beta = np.random.uniform(0.4, 0.6)  # Dynamic prioritization factor\n    priority_scores = beta * value1_lst + (1 - beta) * value2_lst\n    priority_scores /= (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-priority_scores)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Hybrid neighborhood exploration\n    new_solution = base_solution.copy()\n    temperature = 0.6\n    for _ in range(4):\n        # Calculate adaptive mutation scores\n        marginal1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n        marginal2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n        weight_impact = weight_lst * (1 - 2 * new_solution)\n\n        # Combine objectives with temperature-based acceptance\n        scores = (marginal1 + marginal2) / (1 + abs(weight_impact))\n        temp_weight = current_weight + weight_impact\n        scores[temp_weight > capacity] = -np.inf\n\n        if np.all(scores <= -np.inf):\n            break\n\n        # Apply temperature-based selection\n        probs = np.exp(scores / temperature)\n        probs /= np.sum(probs)\n        selected_item = np.random.choice(len(scores), p=probs)\n\n        # Update solution and temperature\n        new_solution[selected_item] = 1 - new_solution[selected_item]\n        current_weight += weight_impact[selected_item]\n        temperature *= 0.85\n\n    # Step 4: Solution refinement with candidate merging\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -19.295790774938155,
               -18.457964896102936
          ]
     }
]