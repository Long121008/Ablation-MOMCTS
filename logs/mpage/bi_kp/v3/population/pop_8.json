[
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (here, randomly from the archive)\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n\n    # Random flip some bits (exploration)\n    flip_indices = np.random.choice(len(base_solution), size=np.random.randint(1, min(5, len(base_solution))), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Greedy improvement step (exploitation)\n    best_improvement = 0\n    best_idx = -1\n    best_action = None  # 'add' or 'remove'\n\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            # Evaluate removal\n            delta_weight = -weight_lst[idx]\n            delta_value1 = -value1_lst[idx]\n            delta_value2 = -value2_lst[idx]\n            if current_weight + delta_weight >= 0:\n                # Use a weighted sum of the two objectives for improvement\n                improvement = 0.5 * delta_value1 + 0.5 * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'remove'\n        else:\n            # Evaluate addition\n            delta_weight = weight_lst[idx]\n            delta_value1 = value1_lst[idx]\n            delta_value2 = value2_lst[idx]\n            if current_weight + delta_weight <= capacity:\n                improvement = 0.5 * delta_value1 + 0.5 * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'add'\n\n    if best_idx != -1:\n        if best_action == 'remove':\n            new_solution[best_idx] = 0\n        else:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.85684229040964,
               -18.702342658375688
          ]
     },
     {
          "algorithm": "{The proposed heuristic function 'select_neighbor' employs a novel adaptive neighborhood exploration strategy that dynamically balances between local improvement and global diversification by combining a probabilistic selection mechanism with a value-weighted mutation operator. It first evaluates each solution in the archive based on its current objective values and potential marginal improvements, then selects a base solution with a probability weighted by both its objective quality and the diversity of its neighborhood. The algorithm then applies a hybrid local search operator that performs a series of controlled mutations, where each mutation is guided by a weighted combination of the item's marginal contributions to both objectives, while respecting the capacity constraint through a penalty-based feasibility check. To enhance exploration, the operator incorporates a temperature-based acceptance criterion that allows occasional uphill moves, gradually cooling down to focus on exploitation. The function returns the new neighbor solution after validating its feasibility and ensuring significant improvement in at least one of the objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a base solution with adaptive probability\n    scores = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            scores.append(0.0)\n        else:\n            # Score based on normalized objective values and marginal potential\n            norm_v1 = v1 / (np.sum(value1_lst) + 1e-6)\n            norm_v2 = v2 / (np.sum(value2_lst) + 1e-6)\n            marginal1 = np.sum(value1_lst * (1 - sol))\n            marginal2 = np.sum(value2_lst * (1 - sol))\n            score = (norm_v1 + norm_v2) * (marginal1 + marginal2)\n            scores.append(score)\n\n    if all(s == 0 for s in scores):\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        probs = np.array(scores) / np.sum(scores)\n        selected_idx = np.random.choice(len(archive), p=probs)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Adaptive mutation operator\n    temperature = 0.5  # Initial temperature for simulated annealing\n    for _ in range(3):  # Number of mutation steps\n        # Calculate value-weighted mutation probabilities\n        marginal1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n        marginal2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n        weight_impact = weight_lst * (1 - 2 * new_solution)\n\n        # Combine objectives with temperature-based acceptance\n        scores = (marginal1 + marginal2) / (1 + abs(weight_impact))\n        temp_weight = current_weight + weight_impact\n        scores[temp_weight > capacity] = -np.inf\n\n        if np.all(scores <= -np.inf):\n            break\n\n        # Apply temperature-based selection\n        probs = np.exp(scores / temperature)\n        probs /= np.sum(probs)\n        selected_item = np.random.choice(len(scores), p=probs)\n\n        # Update solution and temperature\n        new_solution[selected_item] = 1 - new_solution[selected_item]\n        current_weight += weight_impact[selected_item]\n        temperature *= 0.9  # Cool down\n\n    return new_solution\n\n",
          "score": [
               -18.906346342175787,
               -18.508733039037597
          ]
     },
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a base solution with adaptive probability\n    scores = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            scores.append(0.0)\n        else:\n            # Score based on normalized objective values and marginal potential\n            norm_v1 = v1 / (np.sum(value1_lst) + 1e-6)\n            norm_v2 = v2 / (np.sum(value2_lst) + 1e-6)\n            marginal1 = np.sum(value1_lst * (1 - sol))\n            marginal2 = np.sum(value2_lst * (1 - sol))\n            score = (norm_v1 + norm_v2) * (marginal1 + marginal2)\n            scores.append(score)\n\n    if all(s == 0 for s in scores):\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        probs = np.array(scores) / np.sum(scores)\n        selected_idx = np.random.choice(len(archive), p=probs)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Adaptive mutation operator\n    temperature = 0.5  # Initial temperature for simulated annealing\n    for _ in range(3):  # Number of mutation steps\n        # Calculate value-weighted mutation probabilities\n        marginal1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n        marginal2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n        weight_impact = weight_lst * (1 - 2 * new_solution)\n\n        # Combine objectives with temperature-based acceptance\n        scores = (marginal1 + marginal2) / (1 + abs(weight_impact))\n        temp_weight = current_weight + weight_impact\n        scores[temp_weight > capacity] = -np.inf\n\n        if np.all(scores <= -np.inf):\n            break\n\n        # Apply temperature-based selection\n        probs = np.exp(scores / temperature)\n        probs /= np.sum(probs)\n        selected_item = np.random.choice(len(scores), p=probs)\n\n        # Update solution and temperature\n        new_solution[selected_item] = 1 - new_solution[selected_item]\n        current_weight += weight_impact[selected_item]\n        temperature *= 0.9  # Cool down\n\n    return new_solution\n\n",
          "score": [
               -18.94795354824474,
               -18.492846467693816
          ]
     },
     {
          "algorithm": "{The proposed heuristic function 'select_neighbor' employs a novel adaptive neighborhood exploration strategy that dynamically balances between local improvement and global diversification by combining a probabilistic selection mechanism with a value-weighted mutation operator. It first evaluates each solution in the archive based on its current objective values and potential marginal improvements, then selects a base solution with a probability weighted by both its objective quality and the diversity of its neighborhood. The algorithm then applies a hybrid local search operator that performs a series of controlled mutations, where each mutation is guided by a weighted combination of the item's marginal contributions to both objectives, while respecting the capacity constraint through a penalty-based feasibility check. To enhance exploration, the operator incorporates a temperature-based acceptance criterion that allows occasional uphill moves, gradually cooling down to focus on exploitation. The function returns the new neighbor solution after validating its feasibility and ensuring significant improvement in at least one of the objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a base solution with adaptive probability\n    scores = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            scores.append(0.0)\n        else:\n            # Score based on normalized objective values and marginal potential\n            norm_v1 = v1 / (np.sum(value1_lst) + 1e-6)\n            norm_v2 = v2 / (np.sum(value2_lst) + 1e-6)\n            marginal1 = np.sum(value1_lst * (1 - sol))\n            marginal2 = np.sum(value2_lst * (1 - sol))\n            score = (norm_v1 + norm_v2) * (marginal1 + marginal2)\n            scores.append(score)\n\n    if all(s == 0 for s in scores):\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        probs = np.array(scores) / np.sum(scores)\n        selected_idx = np.random.choice(len(archive), p=probs)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Adaptive mutation operator\n    temperature = 0.5  # Initial temperature for simulated annealing\n    for _ in range(3):  # Number of mutation steps\n        # Calculate value-weighted mutation probabilities\n        marginal1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n        marginal2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n        weight_impact = weight_lst * (1 - 2 * new_solution)\n\n        # Combine objectives with temperature-based acceptance\n        scores = (marginal1 + marginal2) / (1 + abs(weight_impact))\n        temp_weight = current_weight + weight_impact\n        scores[temp_weight > capacity] = -np.inf\n\n        if np.all(scores <= -np.inf):\n            break\n\n        # Apply temperature-based selection\n        probs = np.exp(scores / temperature)\n        probs /= np.sum(probs)\n        selected_item = np.random.choice(len(scores), p=probs)\n\n        # Update solution and temperature\n        new_solution[selected_item] = 1 - new_solution[selected_item]\n        current_weight += weight_impact[selected_item]\n        temperature *= 0.9  # Cool down\n\n    return new_solution\n\n",
          "score": [
               -18.755373298520603,
               -18.642659644232722
          ]
     },
     {
          "algorithm": "{The new algorithm employs a hybrid approach that first identifies the solution with the highest potential for multi-objective improvement by analyzing the trade-off between objectives and solution structure, then applies a novel adaptive local search that dynamically balances exploration and exploitation through a three-phase process: first, it performs a probabilistic item selection based on both objective values and weights while maintaining feasibility, second, it applies a guided mutation phase that strategically replaces items to improve both objectives, and third, it incorporates a solution recombination step that merges features from the selected base solution and a randomly generated candidate solution, all while systematically exploring the neighborhood while respecting capacity constraints. The entire process is guided by adaptive parameters that adjust based on the current solution quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Phase 1: Select the solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = np.argmax(np.sum(objectives, axis=1) / (np.sum(weight_lst[archive[0][0] == 1]) + 1e-10))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Probabilistic item selection with feasibility check\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - total_weight\n\n    # Calculate selection probabilities based on normalized values and weights\n    combined_values = value1_lst + value2_lst\n    normalized_scores = combined_values / (weight_lst + 1e-10)\n    selection_probs = normalized_scores / (np.sum(normalized_scores) + 1e-10)\n\n    # Select items to add or remove based on probabilities\n    for i in range(len(new_solution)):\n        if np.random.rand() < selection_probs[i]:\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n            else:\n                if weight_lst[i] <= remaining_capacity:\n                    new_solution[i] = 1\n                    total_weight += weight_lst[i]\n                    remaining_capacity -= weight_lst[i]\n\n    # Phase 3: Guided item replacement\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            for j in range(len(new_solution)):\n                if new_solution[j] == 0 and weight_lst[j] <= (capacity - total_weight + weight_lst[i]):\n                    if (value1_lst[j] + value2_lst[j]) > (value1_lst[i] + value2_lst[i]):\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        total_weight = total_weight - weight_lst[i] + weight_lst[j]\n                        break\n\n    # Phase 4: Solution recombination with random candidate\n    candidate_solution = np.zeros_like(new_solution)\n    candidate_weight = 0\n    for i in range(len(new_solution)):\n        if np.random.rand() < 0.3:\n            if weight_lst[i] <= (capacity - candidate_weight):\n                candidate_solution[i] = 1\n                candidate_weight += weight_lst[i]\n\n    # Combine solutions by taking items that are in either solution\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -18.784911436192832,
               -18.50466472466423
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Objective Neighborhood Exploration with Dynamic Objective Balancing (AMONE-DOB)\", first selects a solution from the archive that exhibits high diversity in objective contributions and then applies a hybrid search strategy that combines adaptive objective weighting with a novel neighborhood exploration mechanism. This mechanism dynamically balances the exploration of both objectives through a three-stage process: first, it identifies critical items using a probabilistic selection based on their adaptive weighted contributions to both objectives while maintaining feasibility, second, it performs a guided item replacement phase that strategically swaps items between objectives to improve both values, and third, it incorporates a solution refinement step that merges features from the selected base solution and a randomly generated candidate solution while systematically exploring the neighborhood while respecting capacity constraints. The entire process is guided by adaptive parameters that adjust based on the current solution quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = np.argmax(np.std(objectives, axis=0))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate candidate solution using adaptive objective weighting\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    alpha = np.random.uniform(0.3, 0.7)  # Dynamic objective balance factor\n    weighted_values = alpha * value1_lst + (1 - alpha) * value2_lst\n    weights = weighted_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-weights)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Adaptive neighborhood exploration\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Critical item identification and replacement\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and np.random.rand() < 0.3:\n            # Find replacement items that improve both objectives\n            potential_replacements = []\n            for j in range(len(new_solution)):\n                if new_solution[j] == 0 and weight_lst[j] <= current_weight + weight_lst[j] - weight_lst[i]:\n                    value_diff1 = value1_lst[j] - value1_lst[i]\n                    value_diff2 = value2_lst[j] - value2_lst[i]\n                    if value_diff1 > 0 or value_diff2 > 0:\n                        potential_replacements.append((j, value_diff1 + value_diff2))\n\n            if potential_replacements:\n                best_replacement = max(potential_replacements, key=lambda x: x[1])\n                new_solution[i] = 0\n                new_solution[best_replacement[0]] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement[0]]\n\n    # Solution refinement with candidate merging\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -18.855531225769518,
               -18.46771687324549
          ]
     },
     {
          "algorithm": "{The proposed heuristic function 'select_neighbor' first identifies promising solutions in the archive by evaluating their potential for improvement through a novel local search strategy that combines random selection with a weighted exploration of solution quality and diversity, favoring those with higher marginal gains in either objective while avoiding redundant searches. It then applies a hybrid local search operator that strategically flips a subset of items based on a dynamic trade-off between value improvements and weight feasibility, ensuring feasibility by prioritizing items with the highest value-weight ratios and penalizing solutions that exceed capacity. The operator also incorporates a probabilistic component to escape local optima, flipping items with a chance proportional to their marginal contribution, while maintaining a balance between exploration and exploitation. The function returns the new neighbor solution after validating its feasibility and objective improvements.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with weighted randomness based on solution quality and diversity\n    scores = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            scores.append(0.0)  # Discourage infeasible solutions\n        else:\n            # Score based on marginal improvement potential\n            marginal1 = np.sum(value1_lst * (1 - sol))\n            marginal2 = np.sum(value2_lst * (1 - sol))\n            score = marginal1 + marginal2\n            scores.append(score)\n\n    if all(s == 0 for s in scores):\n        # All solutions are infeasible, select randomly\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select with probability proportional to score\n        probs = np.array(scores) / np.sum(scores)\n        selected_idx = np.random.choice(len(archive), p=probs)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search operator\n    for _ in range(3):  # Number of flips per iteration\n        # Calculate marginal gains for each item\n        marginal1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n        marginal2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n\n        # Calculate weight impact\n        weight_impact = weight_lst * (1 - 2 * new_solution)\n\n        # Calculate scores combining both objectives and feasibility\n        scores = (marginal1 + marginal2) / (1 + abs(weight_impact))\n\n        # Penalize solutions that would exceed capacity\n        temp_weight = current_weight + weight_impact\n        scores[temp_weight > capacity] = -np.inf\n\n        # Select item to flip with probability proportional to score\n        if np.all(scores <= -np.inf):\n            break  # No feasible moves\n\n        probs = np.exp(scores - np.max(scores))  # Softmax for numerical stability\n        probs /= np.sum(probs)\n\n        selected_item = np.random.choice(len(scores), p=probs)\n        new_solution[selected_item] = 1 - new_solution[selected_item]\n        current_weight += weight_impact[selected_item]\n\n    return new_solution\n\n",
          "score": [
               -18.78125726298865,
               -18.394552497017067
          ]
     },
     {
          "algorithm": "{The proposed algorithm, named \"Adaptive Multi-Objective Path Relinking (AMOPR)\", first identifies the most promising solution in the archive by evaluating the combined objective values and dominance relationships, then constructs a path between this solution and a randomly selected elite solution from the archive, adaptively combining their features through a novel \"path relinking\" strategy that prioritizes items with high marginal gains in both objectives while ensuring feasibility, and finally refines the resulting solution using a dynamic \"value-weighted\" perturbation operator that adjusts the perturbation intensity based on the current solution's proximity to the Pareto front, thus balancing exploration and exploitation to generate high-quality neighbors across multiple objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the most promising solution (highest combined objective values)\n    selected_idx = np.argmax([obj[0] + obj[1] for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Randomly select an elite solution from the archive\n    elite_idx = np.random.choice(len(archive))\n    elite_solution = archive[elite_idx][0].copy()\n\n    # Path relinking: construct a path between base and elite solutions\n    # Identify differing items between base and elite solutions\n    differing_items = np.where(base_solution != elite_solution)[0]\n\n    if len(differing_items) > 0:\n        # Randomly select a subset of differing items to relink\n        relink_items = np.random.choice(differing_items, size=min(3, len(differing_items)), replace=False)\n\n        # Calculate marginal gains for relinking items\n        marginal_gains = []\n        for i in relink_items:\n            if base_solution[i] == 0 and elite_solution[i] == 1:\n                # Item in elite but not in base: calculate gain if added\n                if np.sum(weight_lst * new_solution) + weight_lst[i] <= capacity:\n                    gain1 = value1_lst[i]\n                    gain2 = value2_lst[i]\n                    marginal_gains.append((gain1 + gain2, i, 1))  # 1 means add item\n            elif base_solution[i] == 1 and elite_solution[i] == 0:\n                # Item in base but not in elite: calculate gain if removed\n                if np.sum(weight_lst * new_solution) - weight_lst[i] >= 0:\n                    gain1 = -value1_lst[i]\n                    gain2 = -value2_lst[i]\n                    marginal_gains.append((gain1 + gain2, i, 0))  # 0 means remove item\n\n        # Sort by marginal gains (descending)\n        marginal_gains.sort(reverse=True, key=lambda x: x[0])\n\n        # Apply the best marginal gain moves\n        current_weight = np.sum(weight_lst * new_solution)\n        for _, i, action in marginal_gains:\n            if action == 1 and new_solution[i] == 0:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n            elif action == 0 and new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Dynamic perturbation: adjust based on solution's position in objective space\n    # Calculate the solution's dominance count\n    dominance_count = 0\n    for _, obj in archive:\n        if (obj[0] > archive[selected_idx][1][0] and obj[1] >= archive[selected_idx][1][1]) or \\\n           (obj[0] >= archive[selected_idx][1][0] and obj[1] > archive[selected_idx][1][1]):\n            dominance_count += 1\n\n    # More perturbation if the solution is non-dominated (higher quality)\n    perturbation_intensity = 0.1 if dominance_count == 0 else 0.3\n\n    # Apply perturbation\n    for i in range(len(new_solution)):\n        if np.random.random() < perturbation_intensity:\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n            else:\n                if np.sum(weight_lst * new_solution) + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.69134593850977,
               -18.079555253041722
          ]
     },
     {
          "algorithm": "{The new algorithm builds upon the common backbone of selecting promising solutions from the archive and applying intelligent local search, but introduces a novel approach that combines Pareto-frontier analysis with a dynamic value-weighted mutation strategy. It first identifies the most diverse non-dominated solutions in the archive, then applies a multi-stage local search that alternates between objective-specific mutations and capacity-preserving item swaps, while dynamically adjusting mutation probabilities based on both objective values and their relative importance in the current solution space. The algorithm also incorporates a guided diversification step that strategically reintroduces items based on their marginal contribution to both objectives, while maintaining feasibility through a probabilistic capacity-aware adjustment mechanism.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Identify diverse non-dominated solutions\n    objectives = np.array([obj for _, obj in archive])\n    solutions = np.array([sol for sol, _ in archive])\n\n    # Find Pareto frontier\n    pareto_indices = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and objectives[j, 0] >= objectives[i, 0] and objectives[j, 1] >= objectives[i, 1]:\n                if objectives[j, 0] > objectives[i, 0] or objectives[j, 1] > objectives[i, 1]:\n                    dominated = True\n                    break\n        if not dominated:\n            pareto_indices.append(i)\n\n    if not pareto_indices:\n        pareto_indices = list(range(len(archive)))\n\n    # Calculate diversity scores for Pareto solutions\n    diversity_scores = np.zeros(len(pareto_indices))\n    for i in range(len(pareto_indices)):\n        min_dist = np.inf\n        for j in range(len(pareto_indices)):\n            if i != j:\n                dist = np.sqrt((objectives[pareto_indices[i], 0] - objectives[pareto_indices[j], 0])**2 +\n                              (objectives[pareto_indices[i], 1] - objectives[pareto_indices[j], 1])**2)\n                if dist < min_dist:\n                    min_dist = dist\n        diversity_scores[i] = min_dist\n\n    # Select the most diverse Pareto solution\n    selected_idx = pareto_indices[np.argmax(diversity_scores)]\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Dynamic value-weighted mutation\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate value weights for each objective\n    total_value1 = objectives[selected_idx, 0]\n    total_value2 = objectives[selected_idx, 1]\n\n    # Normalize value weights\n    if total_value1 + total_value2 > 0:\n        value_weight1 = total_value1 / (total_value1 + total_value2)\n        value_weight2 = total_value2 / (total_value1 + total_value2)\n    else:\n        value_weight1 = 0.5\n        value_weight2 = 0.5\n\n    # Calculate mutation probabilities based on value weights\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    # Calculate marginal contributions for in-items\n    marginal_contrib1 = np.zeros(len(in_items))\n    marginal_contrib2 = np.zeros(len(in_items))\n    for i, idx in enumerate(in_items):\n        marginal_contrib1[i] = value1_lst[idx] / (total_value1 + 1e-10)\n        marginal_contrib2[i] = value2_lst[idx] / (total_value2 + 1e-10)\n\n    # Calculate mutation probabilities\n    mutation_probs = np.zeros(len(new_solution))\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Higher probability to remove items with low marginal contribution\n            pos = np.where(in_items == i)[0][0]\n            mutation_probs[i] = 0.1 * (1 - value_weight1 * marginal_contrib1[pos] - value_weight2 * marginal_contrib2[pos])\n        else:\n            # Higher probability to add items with high value-to-weight ratio\n            if weight_lst[i] <= remaining_capacity:\n                value_ratio = (value_weight1 * value1_lst[i] + value_weight2 * value2_lst[i]) / (weight_lst[i] + 1e-10)\n                mutation_probs[i] = 0.5 * value_ratio\n\n    # Normalize mutation probabilities\n    mutation_probs = mutation_probs / (np.sum(mutation_probs) + 1e-10)\n\n    # Apply mutations\n    num_mutations = min(3, len(new_solution) // 4)\n    for _ in range(num_mutations):\n        if np.sum(mutation_probs) > 0:\n            item_idx = np.random.choice(len(new_solution), p=mutation_probs)\n\n            if new_solution[item_idx] == 1:\n                # Remove item\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n                remaining_capacity += weight_lst[item_idx]\n            else:\n                # Add item if it fits\n                if weight_lst[item_idx] <= remaining_capacity:\n                    new_solution[item_idx] = 1\n                    current_weight += weight_lst[item_idx]\n                    remaining_capacity -= weight_lst[item_idx]\n\n    # Phase 3: Guided diversification\n    if np.random.rand() < 0.3:  # 30% chance for diversification\n        # Calculate value-to-weight ratios for out-items\n        value_ratios = (value_weight1 * value1_lst + value_weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Select top 20% out-items by value-to-weight ratio\n        num_candidates = max(1, len(out_items) // 5)\n        top_candidates = np.argsort(value_ratios[out_items])[-num_candidates:]\n\n        for idx in out_items[top_candidates]:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -18.683702084350653,
               -18.368473124799703
          ]
     },
     {
          "algorithm": "{The proposed algorithm, named \"Dual-Objective Guided Evolutionary Exploration (DOGEE)\", first identifies solutions in the archive that exhibit high variance in their objective contributions, then applies a novel hybrid search strategy that combines objective-specific greedy selection with probabilistic item swapping, where items are prioritized based on their adaptive weighted contributions to both objectives while maintaining feasibility, and finally refines the solution through an evolutionary perturbation mechanism that dynamically adjusts the exploration intensity based on the solution's proximity to the Pareto front, ensuring a balance between exploitation of high-value items and exploration of diverse solution spaces to generate high-quality neighbors across multiple objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest objective variance\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = np.argmax(np.var(objectives, axis=0))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate candidate solution using weighted random walk\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    weights = np.random.rand(len(base_solution)) * (value1_lst + value2_lst) / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-weights)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Dual-objective guided evolutionary exploration\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Objective-specific greedy selection\n    for obj_idx in range(2):\n        if obj_idx == 0:\n            values = value1_lst\n        else:\n            values = value2_lst\n\n        # Find best items to add\n        add_indices = np.where(candidate_solution == 1)[0]\n        add_indices = add_indices[np.argsort(-values[add_indices])]\n\n        for i in add_indices:\n            if new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n\n        # Find worst items to remove\n        remove_indices = np.where(new_solution == 1)[0]\n        remove_indices = remove_indices[np.argsort(values[remove_indices])]\n\n        for i in remove_indices:\n            if np.random.rand() < 0.2:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n\n    # Probabilistic item swapping\n    for i in range(len(new_solution)):\n        if np.random.rand() < 0.1:\n            if new_solution[i] == 1:\n                # Try to swap with a candidate item\n                for j in np.where(candidate_solution == 1)[0]:\n                    if new_solution[j] == 0 and abs(weight_lst[i] - weight_lst[j]) <= current_weight - capacity:\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        break\n            else:\n                # Try to add a candidate item\n                if current_weight + weight_lst[i] <= capacity and candidate_solution[i] == 1:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    return new_solution\n\n",
          "score": [
               -17.556313346201502,
               -18.33406906997127
          ]
     }
]