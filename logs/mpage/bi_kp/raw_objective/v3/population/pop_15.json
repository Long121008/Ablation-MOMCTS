[
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (here, randomly from the archive)\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n\n    # Random flip some bits (exploration)\n    flip_indices = np.random.choice(len(base_solution), size=np.random.randint(1, min(5, len(base_solution))), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Greedy improvement step (exploitation)\n    best_improvement = 0\n    best_idx = -1\n    best_action = None  # 'add' or 'remove'\n\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            # Evaluate removal\n            delta_weight = -weight_lst[idx]\n            delta_value1 = -value1_lst[idx]\n            delta_value2 = -value2_lst[idx]\n            if current_weight + delta_weight >= 0:\n                # Use a weighted sum of the two objectives for improvement\n                improvement = 0.5 * delta_value1 + 0.5 * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'remove'\n        else:\n            # Evaluate addition\n            delta_weight = weight_lst[idx]\n            delta_value1 = value1_lst[idx]\n            delta_value2 = value2_lst[idx]\n            if current_weight + delta_weight <= capacity:\n                improvement = 0.5 * delta_value1 + 0.5 * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'add'\n\n    if best_idx != -1:\n        if best_action == 'remove':\n            new_solution[best_idx] = 0\n        else:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.85684229040964,
               -18.702342658375688
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Balanced Adaptive Path Exploration with Dynamic Trade-off Navigation (O-BAPE-DTN)\", first identifies a solution from the archive that shows balanced contributions to both objectives and then applies a hybrid search strategy that combines adaptive path exploration with a novel neighborhood navigation mechanism. This mechanism dynamically navigates the trade-off space by first constructing a solution path using a probabilistic selection of items based on their balanced contributions to both objectives, then performs a guided path refinement phase that systematically explores alternative paths while respecting capacity constraints, followed by a solution diversification step that strategically reallocates items along the path to improve both objectives, and finally applies a path optimization step that uses a weighted sum of both objectives to further refine the solution path. The entire process is guided by adaptive parameters that adjust based on the current path quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with balanced contributions to both objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    balance_scores = 1 - np.abs(normalized_objectives[:, 0] - normalized_objectives[:, 1])\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate initial path solution\n    path_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    beta = np.random.uniform(0.3, 0.7)  # Dynamic trade-off factor\n    balanced_values = (1 - beta) * value1_lst + beta * value2_lst\n    weights = balanced_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-weights)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and path_solution[idx] == 0:\n            path_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Path refinement with alternative exploration\n    path_items = np.where(path_solution == 1)[0]\n    np.random.shuffle(path_items)\n\n    # Explore alternative paths while respecting capacity\n    for idx in path_items:\n        if np.random.rand() < 0.5 and new_solution[idx] == 0:\n            if weight_lst[idx] <= (capacity - current_weight):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            else:\n                # Try to replace an existing item\n                for j in range(len(new_solution)):\n                    if new_solution[j] == 1 and weight_lst[idx] <= current_weight + weight_lst[idx] - weight_lst[j]:\n                        new_solution[j] = 0\n                        new_solution[idx] = 1\n                        current_weight = current_weight - weight_lst[j] + weight_lst[idx]\n                        break\n\n    # Solution diversification with path reallocation\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and np.random.rand() < 0.3:\n            # Find alternative items along the path\n            potential_replacements = []\n            for j in range(len(new_solution)):\n                if new_solution[j] == 0 and path_solution[j] == 1 and weight_lst[j] <= current_weight + weight_lst[j] - weight_lst[i]:\n                    value_diff1 = value1_lst[j] - value1_lst[i]\n                    value_diff2 = value2_lst[j] - value2_lst[i]\n                    if value_diff1 > 0 or value_diff2 > 0:\n                        potential_replacements.append((j, value_diff1 + value_diff2))\n\n            if potential_replacements:\n                best_replacement = max(potential_replacements, key=lambda x: x[1])\n                new_solution[i] = 0\n                new_solution[best_replacement[0]] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement[0]]\n\n    # Path optimization with weighted objective improvement\n    gamma = np.random.uniform(0.2, 0.8)  # Dynamic objective weighting factor\n    best_improvement = 0\n    best_idx = -1\n    best_action = None\n\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            # Evaluate removal\n            delta_weight = -weight_lst[idx]\n            delta_value1 = -value1_lst[idx]\n            delta_value2 = -value2_lst[idx]\n            if current_weight + delta_weight >= 0:\n                improvement = gamma * delta_value1 + (1 - gamma) * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'remove'\n        else:\n            # Evaluate addition if it's part of the path\n            if path_solution[idx] == 1 and current_weight + weight_lst[idx] <= capacity:\n                delta_weight = weight_lst[idx]\n                delta_value1 = value1_lst[idx]\n                delta_value2 = value2_lst[idx]\n                improvement = gamma * delta_value1 + (1 - gamma) * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'add'\n\n    if best_idx != -1:\n        if best_action == 'remove':\n            new_solution[best_idx] = 0\n        else:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.961259023056908,
               -18.701306800405522
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Objective-Centric Exploration with Dynamic Pareto-Adaptive Perturbation (A-OCE-DPAP)\", first identifies solutions in the archive with the highest combined objective values while maintaining feasibility, then applies a novel hybrid search strategy that combines Pareto-adaptive perturbation with dynamic objective-centric exploration, where items are prioritized based on their adaptive contributions to both objectives through a multi-stage perturbation mechanism that alternates between objective-specific mutations and capacity-aware item swaps, while dynamically adjusting the exploration intensity based on the solution's proximity to the Pareto front, ensuring a balance between exploitation of high-value items and exploration of diverse solution spaces to generate high-quality neighbors across multiple objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective values\n    objectives = np.array([obj for _, obj in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Pareto-adaptive perturbation\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate Pareto-adaptive weights\n    pareto_weights = np.random.uniform(0.3, 0.7)\n    adaptive_values = pareto_weights * value1_lst + (1 - pareto_weights) * value2_lst\n    value_ratios = adaptive_values / (weight_lst + 1e-10)\n\n    # Sort items by adaptive value ratio\n    sorted_items = np.argsort(-value_ratios)\n\n    # Dynamic perturbation intensity\n    perturbation_intensity = min(0.5, 1.0 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.sum(value1_lst) + np.sum(value2_lst)))\n\n    # Remove low-value items with probability based on intensity\n    for idx in sorted_items[len(sorted_items)//2:]:\n        if new_solution[idx] == 1 and np.random.rand() < perturbation_intensity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n\n    # Phase 3: Objective-centric exploration\n    out_items = np.where(new_solution == 0)[0]\n    sorted_out_items = np.argsort(-value_ratios[out_items])\n\n    # Add high-value items with probability based on intensity\n    for idx in out_items[sorted_out_items[:len(sorted_out_items)//2]]:\n        if weight_lst[idx] <= remaining_capacity and np.random.rand() < (1 - perturbation_intensity):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Dynamic capacity-aware swaps\n    if np.random.rand() < 0.5:  # Higher probability for swaps\n        remove_candidates = np.where(new_solution == 1)[0]\n        add_candidates = np.where(new_solution == 0)[0]\n\n        # Sort candidates by value ratio\n        remove_candidates = remove_candidates[np.argsort(value_ratios[remove_candidates])]\n        add_candidates = add_candidates[np.argsort(-value_ratios[add_candidates])]\n\n        # Perform swaps with adaptive probability\n        for i in remove_candidates[:len(remove_candidates)//2]:\n            for j in add_candidates[:len(add_candidates)//2]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity and np.random.rand() < 0.7:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.28343212616835,
               -18.581111593129386
          ]
     },
     {
          "algorithm": "{The proposed algorithm integrates a hybrid exploration-exploitation strategy with dynamic objective prioritization, where it first identifies solutions with high potential for improvement by analyzing their objective contributions and neighborhood diversity, then applies a multi-stage local search that combines probabilistic item selection based on adaptive objective weights, a guided item replacement mechanism that strategically enhances both objectives while maintaining feasibility, and a solution refinement phase that leverages both the base solution and a candidate solution generated through a diversity-aware construction heuristic to systematically explore the neighborhood while dynamically adjusting the exploration-exploitation balance through temperature-based acceptance criteria and penalty-based feasibility checks.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    base_idx = np.argmax(np.max(objectives, axis=0) - np.min(objectives, axis=0))\n    base_solution = archive[base_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Generate candidate solution with dynamic prioritization\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    beta = np.random.uniform(0.4, 0.6)  # Dynamic prioritization factor\n    priority_scores = beta * value1_lst + (1 - beta) * value2_lst\n    priority_scores /= (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-priority_scores)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Hybrid neighborhood exploration\n    new_solution = base_solution.copy()\n    temperature = 0.6\n    for _ in range(4):\n        # Calculate adaptive mutation scores\n        marginal1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n        marginal2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n        weight_impact = weight_lst * (1 - 2 * new_solution)\n\n        # Combine objectives with temperature-based acceptance\n        scores = (marginal1 + marginal2) / (1 + abs(weight_impact))\n        temp_weight = current_weight + weight_impact\n        scores[temp_weight > capacity] = -np.inf\n\n        if np.all(scores <= -np.inf):\n            break\n\n        # Apply temperature-based selection\n        probs = np.exp(scores / temperature)\n        probs /= np.sum(probs)\n        selected_item = np.random.choice(len(scores), p=probs)\n\n        # Update solution and temperature\n        new_solution[selected_item] = 1 - new_solution[selected_item]\n        current_weight += weight_impact[selected_item]\n        temperature *= 0.85\n\n    # Step 4: Solution refinement with candidate merging\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -19.295790774938155,
               -18.457964896102936
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Objective Exploration with Dynamic Hybrid Perturbation (A-MOEDHP)\", combines the strengths of adaptive objective analysis and hybrid neighborhood exploration from the provided algorithms with a novel two-stage perturbation mechanism. It first identifies solutions with high potential by analyzing both objectives through dynamic weighting, then applies a hybrid search strategy that alternates between objective-specific perturbations and capacity-aware swaps, dynamically adjusting the exploration intensity based on the solution's proximity to the Pareto front. This approach prioritizes items with high value-to-weight ratios while systematically exploring the neighborhood through probabilistic acceptance criteria, ensuring diverse and high-quality solutions across both objectives while maintaining feasibility.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective values\n    objectives = np.array([obj for _, obj in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Phase 2: Dynamic objective weighting and perturbation\n    objective_weights = np.random.uniform(0.4, 0.6, size=2)\n    objective_weights /= np.sum(objective_weights)\n    combined_values = objective_weights[0] * value1_lst + objective_weights[1] * value2_lst\n    value_to_weight_ratio = combined_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-value_to_weight_ratio)\n\n    # Determine perturbation intensity based on solution quality\n    max_possible_value = np.sum(value1_lst) + np.sum(value2_lst)\n    current_value = objectives[selected_idx, 0] + objectives[selected_idx, 1]\n    perturbation_intensity = min(0.6, 1.0 - current_value / max_possible_value)\n\n    # Remove low-value items with probability based on intensity\n    for idx in sorted_indices[len(sorted_indices)//2:]:\n        if new_solution[idx] == 1 and np.random.rand() < perturbation_intensity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n\n    # Phase 3: Add high-value items with probabilistic acceptance\n    out_items = np.where(new_solution == 0)[0]\n    sorted_out_items = np.argsort(-value_to_weight_ratio[out_items])\n\n    for idx in out_items[sorted_out_items[:len(sorted_out_items)//2]]:\n        if weight_lst[idx] <= remaining_capacity and np.random.rand() < (1 - perturbation_intensity):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Capacity-aware swaps with adaptive probability\n    if np.random.rand() < 0.6:  # Higher probability for swaps\n        remove_candidates = np.where(new_solution == 1)[0]\n        add_candidates = np.where(new_solution == 0)[0]\n\n        # Sort candidates by value ratio\n        remove_candidates = remove_candidates[np.argsort(value_to_weight_ratio[remove_candidates])]\n        add_candidates = add_candidates[np.argsort(-value_to_weight_ratio[add_candidates])]\n\n        # Perform swaps with adaptive probability\n        for i in remove_candidates[:len(remove_candidates)//2]:\n            for j in add_candidates[:len(add_candidates)//2]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity and np.random.rand() < 0.8:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.280714416697045,
               -18.597665007027707
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Dynamic Objective-Aligned Solution Evolution with Adaptive Multi-Objective Perturbation (DOASE-AMP)\", first identifies the most balanced solution in the archive by evaluating both objectives through a novel trade-off metric that combines their normalized values with a dynamic weighting factor, then applies a hybrid search strategy that alternates between objective-specific perturbations and capacity-constrained swaps, where items are prioritized based on their adaptive contributions to both objectives, while dynamically adjusting the exploration intensity based on the solution's proximity to the Pareto front and the archive's diversity, ensuring a balance between exploitation of high-value items and exploration of diverse solution spaces to generate high-quality neighbors across multiple objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select solution with most balanced objectives\n    objectives = np.array([(v1, v2) for _, (v1, v2) in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-10)\n    balance_scores = 1 - np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Dynamic objective-aligned perturbation\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate adaptive weights based on objective balance\n    v1_total, v2_total = objectives[selected_idx]\n    alpha = np.random.uniform(0.3, 0.7) if v1_total > v2_total else np.random.uniform(0.7, 0.3)\n    adaptive_values = alpha * value1_lst + (1 - alpha) * value2_lst\n    value_ratios = adaptive_values / (weight_lst + 1e-10)\n\n    # Step 3: Multi-stage perturbation\n    # Phase 1: Remove items with low adaptive value\n    in_items = np.where(new_solution == 1)[0]\n    sorted_in = in_items[np.argsort(value_ratios[in_items])]\n    for idx in sorted_in[:len(sorted_in)//2]:\n        if np.random.rand() < 0.4:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n\n    # Phase 2: Add high-value items\n    out_items = np.where(new_solution == 0)[0]\n    sorted_out = out_items[np.argsort(-value_ratios[out_items])]\n    for idx in sorted_out[:len(sorted_out)//2]:\n        if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.6:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Step 4: Adaptive swaps based on objective balance\n    if np.random.rand() < 0.5:\n        remove_candidates = np.where(new_solution == 1)[0]\n        add_candidates = np.where(new_solution == 0)[0]\n\n        remove_candidates = remove_candidates[np.argsort(value_ratios[remove_candidates])]\n        add_candidates = add_candidates[np.argsort(-value_ratios[add_candidates])]\n\n        for i in remove_candidates[:len(remove_candidates)//2]:\n            for j in add_candidates[:len(add_candidates)//2]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity and np.random.rand() < 0.7:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.057830218367492,
               -18.674432122460587
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Multi-Objective Adaptive Diversification with Hybrid Objective-Guided Exploration (MO-AD-HOGE)\", employs a four-stage approach that first identifies solutions with high diversity in their objective contributions through a novel adaptive clustering mechanism, then performs a hybrid neighborhood exploration that dynamically balances between objective improvements and solution diversification using a probabilistic item swapping mechanism that incorporates both objective-specific and capacity-aware criteria, and finally applies a solution refinement step that combines features from diverse elite solutions while systematically exploring the neighborhood through a novel adaptive perturbation mechanism that alternates between objective-centric and capacity-focused operations, ensuring both high-quality and diverse solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select diverse solution through adaptive clustering\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n\n    # Calculate diversity scores\n    diversity_scores = np.zeros(len(archive))\n    for i in range(len(archive)):\n        distances = np.sqrt(np.sum((normalized_obj - normalized_obj[i])**2, axis=1))\n        diversity_scores[i] = np.mean(distances)\n\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Hybrid objective-guided exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate adaptive objective weights\n    obj_weights = np.random.dirichlet([1, 1, 1])[:2]\n    weighted_values = obj_weights[0] * value1_lst + obj_weights[1] * value2_lst\n    value_efficiency = weighted_values / (weight_lst + 1e-10)\n\n    # Sort items by efficiency\n    sorted_items = np.argsort(-value_efficiency)\n\n    # Probabilistic item swapping with capacity check\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    for i in in_items:\n        for j in out_items:\n            if weight_lst[j] <= remaining_capacity + weight_lst[i] and np.random.rand() < 0.5:\n                if (value1_lst[j] > value1_lst[i] or value2_lst[j] > value2_lst[i]) and np.random.rand() < 0.7:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    remaining_capacity = capacity - current_weight\n                    break\n\n    # Phase 3: Adaptive perturbation mechanism\n    perturbation_intensity = min(0.7, 1.0 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.sum(value1_lst) + np.sum(value2_lst)))\n\n    for idx in sorted_items:\n        if new_solution[idx] == 1 and np.random.rand() < perturbation_intensity * 0.5:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n        elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity and np.random.rand() < perturbation_intensity * 0.3:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Solution refinement with diverse elite features\n    elite_solutions = [sol for sol, _ in archive if np.random.rand() < 0.4]\n    if elite_solutions:\n        elite_solution = elite_solutions[np.random.randint(len(elite_solutions))]\n        combined_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n        np.random.shuffle(combined_items)\n\n        final_solution = np.zeros_like(new_solution)\n        current_weight = 0\n        for idx in combined_items:\n            if weight_lst[idx] <= (capacity - current_weight):\n                final_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        new_solution = final_solution\n\n    return new_solution\n\n",
          "score": [
               -17.882512472707667,
               -19.060916801400516
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Objective-Driven Hybrid Exploration with Dynamic Perturbation and Capacity-Aware Refinement (A-ODEH-DPCR)\", builds upon the adaptive objective analysis from the first algorithm and the hybrid exploration strategy from the second, but introduces a novel three-stage process: 1) it first identifies solutions with high potential by dynamically weighting objectives and prioritizing items with high value-to-weight ratios, 2) it then applies a hybrid perturbation mechanism that alternates between objective-specific removals and capacity-aware additions, with intensity adjusted based on solution quality, and 3) it finally performs an adaptive refinement phase that selectively swaps items based on their marginal contributions to both objectives, while maintaining feasibility through probabilistic acceptance criteria that balance exploration and exploitation. This approach systematically explores the solution space while prioritizing diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic objective weighting and solution selection\n    objectives = np.array([obj for _, obj in archive])\n    objective_weights = np.random.uniform(0.3, 0.7, size=2)\n    objective_weights /= np.sum(objective_weights)\n    combined_values = objectives[:, 0] * objective_weights[0] + objectives[:, 1] * objective_weights[1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate current state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Phase 2: Hybrid perturbation with adaptive intensity\n    value_to_weight_ratio = (value1_lst * objective_weights[0] + value2_lst * objective_weights[1]) / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-value_to_weight_ratio)\n\n    # Determine perturbation intensity\n    max_possible_value = np.sum(value1_lst * objective_weights[0] + value2_lst * objective_weights[1])\n    current_value = combined_values[selected_idx]\n    perturbation_intensity = min(0.7, 1.0 - current_value / max_possible_value)\n\n    # Remove low-value items with probability\n    for idx in sorted_indices[len(sorted_indices)//2:]:\n        if new_solution[idx] == 1 and np.random.rand() < perturbation_intensity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n\n    # Add high-value items with probabilistic acceptance\n    out_items = np.where(new_solution == 0)[0]\n    sorted_out_items = np.argsort(-value_to_weight_ratio[out_items])\n\n    for idx in out_items[sorted_out_items[:len(sorted_out_items)//2]]:\n        if weight_lst[idx] <= remaining_capacity and np.random.rand() < (1 - perturbation_intensity):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 3: Adaptive refinement with marginal contribution analysis\n    if np.random.rand() < 0.7:\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        # Calculate marginal contributions\n        in_marginal = value_to_weight_ratio[in_items]\n        out_marginal = value_to_weight_ratio[out_items]\n\n        # Sort items by marginal contribution\n        in_sorted = in_items[np.argsort(in_marginal)]\n        out_sorted = out_items[np.argsort(-out_marginal)]\n\n        # Perform selective swaps\n        for i in in_sorted[:len(in_sorted)//2]:\n            for j in out_sorted[:len(out_sorted)//2]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity and np.random.rand() < 0.9:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.159914218470085,
               -18.65742086345796
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Objective Neighborhood Exploration with Dynamic Objective Balancing (AMONE-DOB)\", first selects a solution from the archive that exhibits high diversity in objective contributions and then applies a hybrid search strategy that combines adaptive objective weighting with a novel neighborhood exploration mechanism. This mechanism dynamically balances the exploration of both objectives through a three-stage process: first, it identifies critical items using a probabilistic selection based on their adaptive weighted contributions to both objectives while maintaining feasibility, second, it performs a guided item replacement phase that strategically swaps items between objectives to improve both values, and third, it incorporates a solution refinement step that merges features from the selected base solution and a randomly generated candidate solution while systematically exploring the neighborhood while respecting capacity constraints. The entire process is guided by adaptive parameters that adjust based on the current solution quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = np.argmax(np.std(objectives, axis=0))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate candidate solution using adaptive objective weighting\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    alpha = np.random.uniform(0.3, 0.7)  # Dynamic objective balance factor\n    weighted_values = alpha * value1_lst + (1 - alpha) * value2_lst\n    weights = weighted_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-weights)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Adaptive neighborhood exploration\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Critical item identification and replacement\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and np.random.rand() < 0.3:\n            # Find replacement items that improve both objectives\n            potential_replacements = []\n            for j in range(len(new_solution)):\n                if new_solution[j] == 0 and weight_lst[j] <= current_weight + weight_lst[j] - weight_lst[i]:\n                    value_diff1 = value1_lst[j] - value1_lst[i]\n                    value_diff2 = value2_lst[j] - value2_lst[i]\n                    if value_diff1 > 0 or value_diff2 > 0:\n                        potential_replacements.append((j, value_diff1 + value_diff2))\n\n            if potential_replacements:\n                best_replacement = max(potential_replacements, key=lambda x: x[1])\n                new_solution[i] = 0\n                new_solution[best_replacement[0]] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement[0]]\n\n    # Solution refinement with candidate merging\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -18.76309843274899,
               -18.686923793127768
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Multi-Objective Adaptive Greedy Perturbation with Dynamic Objective-Weighted Exploration (MO-AGPE-DOWE)\", combines a three-phase approach that first identifies solutions with the highest combined objective values while maintaining feasibility, then applies a novel hybrid search strategy that integrates adaptive greedy perturbation with dynamic objective-weighted exploration, where items are prioritized based on their adaptive contributions to both objectives through a multi-stage perturbation mechanism that alternates between objective-specific greedy selections and capacity-aware item swaps, while dynamically adjusting the exploration intensity based on the solution's proximity to the Pareto front, ensuring a balance between exploitation of high-value items and exploration of diverse solution spaces to generate high-quality neighbors across multiple objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective values\n    objectives = np.array([obj for _, obj in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Adaptive greedy perturbation\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate dynamic objective weights\n    obj_weights = np.random.uniform(0.2, 0.8)\n    weighted_values = obj_weights * value1_lst + (1 - obj_weights) * value2_lst\n    value_efficiency = weighted_values / (weight_lst + 1e-10)\n\n    # Sort items by efficiency\n    sorted_items = np.argsort(-value_efficiency)\n\n    # Dynamic perturbation intensity\n    perturbation_intensity = min(0.6, 1.0 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.sum(value1_lst) + np.sum(value2_lst)))\n\n    # Remove low-efficiency items with probability\n    for idx in sorted_items[len(sorted_items)//2:]:\n        if new_solution[idx] == 1 and np.random.rand() < perturbation_intensity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n\n    # Phase 3: Objective-weighted exploration\n    out_items = np.where(new_solution == 0)[0]\n    sorted_out_items = np.argsort(-value_efficiency[out_items])\n\n    # Add high-efficiency items with probability\n    for idx in out_items[sorted_out_items[:len(sorted_out_items)//2]]:\n        if weight_lst[idx] <= remaining_capacity and np.random.rand() < (1 - perturbation_intensity):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Dynamic capacity-aware swaps\n    if np.random.rand() < 0.6:  # Higher probability for swaps\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        # Sort items by efficiency\n        in_items_sorted = in_items[np.argsort(value_efficiency[in_items])]\n        out_items_sorted = out_items[np.argsort(-value_efficiency[out_items])]\n\n        # Perform swaps with adaptive probability\n        for i in in_items_sorted[:len(in_items_sorted)//2]:\n            for j in out_items_sorted[:len(out_items_sorted)//2]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity and np.random.rand() < 0.8:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.280056997312094,
               -18.566488163466985
          ]
     }
]