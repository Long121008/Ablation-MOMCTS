[
     {
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Objective Knapsack Exploration via Dynamic Objective Fusion and Balanced Perturbation (AMKE-DOFBP)\", employs a novel two-phase selection mechanism that first identifies the most under-represented objective in the archive through a dynamic objective dominance analysis, then uses this information to guide a hybrid neighborhood exploration strategy that combines objective-specific item swaps with capacity-aware perturbations, while incorporating a solution refinement phase that fuses features from diverse elite solutions through a probabilistic item selection mechanism that balances objective improvements with solution diversity, all while systematically exploring the solution space through a novel adaptive perturbation schedule that adjusts its intensity based on the current solution's objective-centric efficiency and its proximity to the Pareto front, ensuring both high-quality and diverse solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic objective dominance analysis\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n\n    # Identify the most under-represented objective\n    obj_dominance = np.mean(normalized_obj > 0.5, axis=0)\n    target_obj = np.argmin(obj_dominance)\n\n    # Select base solution with the highest value in the target objective\n    if target_obj == 0:\n        selected_idx = np.argmax(objectives[:, 0])\n    else:\n        selected_idx = np.argmax(objectives[:, 1])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Hybrid neighborhood exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-specific efficiency scores\n    obj1_efficiency = value1_lst / (weight_lst + 1e-10)\n    obj2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Perform objective-specific item swaps\n    if target_obj == 0:\n        sorted_items = np.argsort(-obj1_efficiency)\n    else:\n        sorted_items = np.argsort(-obj2_efficiency)\n\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            # Find best replacement item based on the other objective\n            if target_obj == 0:\n                best_replacement = np.argmax(obj2_efficiency * (new_solution == 0) * (weight_lst <= remaining_capacity + weight_lst[i]))\n            else:\n                best_replacement = np.argmax(obj1_efficiency * (new_solution == 0) * (weight_lst <= remaining_capacity + weight_lst[i]))\n\n            if new_solution[best_replacement] == 0 and weight_lst[best_replacement] <= remaining_capacity + weight_lst[i]:\n                new_solution[i] = 0\n                new_solution[best_replacement] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement]\n                remaining_capacity = capacity - current_weight\n\n    # Phase 3: Balanced perturbation with dynamic intensity\n    perturbation_intensity = 0.2 + 0.6 * (1 - (objectives[selected_idx, target_obj] / (objectives[:, target_obj].max() + 1e-10)))\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.5:  # Equal probability to remove\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.4:  # Higher probability to add\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution fusion with probabilistic selection\n    if len(archive) > 1:\n        # Select elite solutions based on the other objective\n        if target_obj == 0:\n            elite_indices = np.argsort(-objectives[:, 1])[:min(2, len(archive)-1)]\n        else:\n            elite_indices = np.argsort(-objectives[:, 0])[:min(2, len(archive)-1)]\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    if target_obj == 0:\n                        fusion_prob = 0.4 + 0.6 * (obj1_efficiency[idx] / (obj1_efficiency.max() + 1e-10))\n                    else:\n                        fusion_prob = 0.4 + 0.6 * (obj2_efficiency[idx] / (obj2_efficiency.max() + 1e-10))\n                    if np.random.rand() < fusion_prob:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -16.82051137132889,
               -19.75935988528277
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Centric Adaptive Hybrid Exploration with Dynamic Perturbation and Elite Fusion (OCA-HEDEPF)\", combines a novel multi-objective selection mechanism that prioritizes solutions with balanced objective contributions through a dynamic weighting scheme, with an adaptive neighborhood exploration strategy that alternates between objective-specific item replacements and capacity-aware perturbations, while incorporating a solution refinement phase that fuses features from diverse elite solutions through a probabilistic item selection mechanism that balances objective improvements with solution diversity, all while systematically exploring the solution space through a novel adaptive perturbation schedule that adjusts its intensity based on the current solution's proximity to the Pareto front and its objective-centric efficiency, ensuring both high-quality and diverse solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = 1 - np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-centric item replacement with dynamic weights\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate dynamic objective weights\n    obj1_weight = 0.5 + 0.5 * (objectives[selected_idx, 0] / (objectives[selected_idx, 0] + objectives[selected_idx, 1] + 1e-10))\n    obj2_weight = 1 - obj1_weight\n\n    # Calculate combined efficiency scores\n    combined_efficiency = (obj1_weight * value1_lst + obj2_weight * value2_lst) / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-combined_efficiency)\n\n    # Perform adaptive item replacements\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            # Find best replacement item\n            best_replacement = -1\n            max_gain = 0\n            for j in sorted_items:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    gain = (obj1_weight * (value1_lst[j] - value1_lst[i]) +\n                            obj2_weight * (value2_lst[j] - value2_lst[i]))\n                    if gain > max_gain:\n                        max_gain = gain\n                        best_replacement = j\n\n            if best_replacement != -1 and max_gain > 0:\n                new_solution[i] = 0\n                new_solution[best_replacement] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement]\n                remaining_capacity = capacity - current_weight\n\n    # Phase 3: Adaptive perturbation with dynamic intensity\n    perturbation_intensity = 0.3 + 0.4 * (1 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) /\n                                        (objectives.max(axis=0).sum() + 1e-10))\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.6:  # Higher probability to remove\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.3:  # Lower probability to add\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution fusion with probabilistic selection\n    if len(archive) > 1:\n        # Select elite solutions based on their diversity\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    fusion_prob = 0.5 + 0.5 * (combined_efficiency[idx] / (combined_efficiency.max() + 1e-10))\n                    if np.random.rand() < fusion_prob:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -20.045799595455243,
               -17.134883582342496
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Diversity-Preserving Adaptive Multi-Objective Greedy Search (DAMOGS)\", employs a unique combination of objective-driven greedy selection with diversity-preserving perturbations, where it first identifies the most promising solution in the archive through a hybrid objective scoring mechanism that balances individual objective values with their relative contributions to the Pareto front, then systematically explores the solution space by iteratively applying a novel adaptive greedy replacement strategy that prioritizes items with complementary objective profiles while maintaining a strict capacity constraint, followed by a diversity-enhancing perturbation phase that selectively introduces or removes items based on their potential to create non-dominated solutions in the objective space, and finally incorporates a solution refinement step that merges features from multiple elite solutions through a probabilistic item selection mechanism that prioritizes items with high objective efficiency and low redundancy, all while dynamically adjusting the exploration intensity based on the current solution's proximity to the identified Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with hybrid objective scoring\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    norm_obj = objectives / (max_obj + 1e-10)\n    hybrid_scores = 0.6 * norm_obj[:, 0] + 0.4 * norm_obj[:, 1] + 0.2 * (norm_obj[:, 0] * norm_obj[:, 1])\n    selected_idx = np.argmax(hybrid_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Adaptive greedy replacement with complementarity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate complementarity scores\n    comp_scores = value1_lst * value2_lst / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-comp_scores)\n\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            # Find best complementary item to replace\n            for j in sorted_items:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if (value1_lst[j] > value1_lst[i] and value2_lst[j] >= value2_lst[i]) or \\\n                       (value1_lst[j] >= value1_lst[i] and value2_lst[j] > value2_lst[i]):\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Diversity-preserving perturbation\n    diversity_factor = 0.3\n    for idx in range(len(new_solution)):\n        if np.random.rand() < diversity_factor:\n            if new_solution[idx] == 1 and np.random.rand() < 0.7:\n                # Remove item with high probability\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                # Add item with lower probability\n                if np.random.rand() < 0.3:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution merging with probabilistic selection\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    if np.random.rand() < 0.5:  # Moderate probability to accept from elite\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -19.36046321062825,
               -18.26125506516535
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Multi-Objective Adaptive Diversification with Hybrid Objective-Guided Exploration (MO-AD-HOGE)\" employs a four-stage approach that first identifies solutions with high diversity in their objective contributions through a novel adaptive clustering mechanism, then performs a hybrid neighborhood exploration that dynamically balances between objective improvements and solution diversification using a probabilistic item swapping mechanism that incorporates both objective-specific and capacity-aware criteria, and finally applies a solution refinement step that combines features from diverse elite solutions while systematically exploring the neighborhood through a novel adaptive perturbation mechanism that alternates between objective-centric and capacity-focused operations, ensuring both high-quality and diverse solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective value\n    objectives = np.array([obj for _, obj in archive])\n    combined_scores = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-specific item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-specific efficiencies\n    value1_efficiency = value1_lst / (weight_lst + 1e-10)\n    value2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by efficiency for each objective\n    sorted_items1 = np.argsort(-value1_efficiency)\n    sorted_items2 = np.argsort(-value2_efficiency)\n\n    # Perform objective-specific replacements\n    for i in sorted_items1:\n        if new_solution[i] == 1:\n            # Try to replace with best value2 item\n            for j in sorted_items2:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if value2_lst[j] > value2_lst[i]:\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Capacity-aware perturbation\n    perturbation_prob = 0.3\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_prob:\n            if new_solution[idx] == 1 and np.random.rand() < 0.5:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Solution merging with random elite\n    if len(archive) > 1:\n        elite_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n        elite_solution = archive[elite_idx][0]\n\n        # Create merged solution\n        merged_solution = np.zeros_like(new_solution)\n        current_weight = 0\n\n        # Add items from current solution\n        for idx in np.where(new_solution == 1)[0]:\n            if weight_lst[idx] <= (capacity - current_weight):\n                merged_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Add items from elite solution if not already added\n        for idx in np.where(elite_solution == 1)[0]:\n            if merged_solution[idx] == 0 and weight_lst[idx] <= (capacity - current_weight):\n                merged_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        new_solution = merged_solution\n\n    return new_solution\n\n",
          "score": [
               -17.28156934092503,
               -19.51937221900962
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Aware Hybrid Evolutionary Neighborhood Exploration (OAHENE)\", combines a novel multi-objective solution selection mechanism that dynamically prioritizes solutions based on their objective trade-off characteristics with a hybrid neighborhood generation strategy that integrates objective-specific item swaps with capacity-aware perturbations, while incorporating a solution refinement phase that merges features from diverse elite solutions through a probabilistic item selection mechanism that balances objective improvements with solution diversity, all while systematically exploring the solution space through an adaptive perturbation schedule that adjusts its intensity based on the current solution's proximity to the Pareto front and its objective trade-off characteristics.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with balanced objective trade-off\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-10)\n    tradeoff_scores = np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    selected_idx = np.argmin(tradeoff_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-specific item swaps with capacity check\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-specific efficiencies\n    value1_efficiency = value1_lst / (weight_lst + 1e-10)\n    value2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by efficiency for each objective\n    sorted_items1 = np.argsort(-value1_efficiency)\n    sorted_items2 = np.argsort(-value2_efficiency)\n\n    # Perform alternating objective-driven swaps\n    for i in sorted_items1:\n        if new_solution[i] == 1 and np.random.rand() < 0.4:\n            # Try to replace with best value2 item\n            for j in sorted_items2:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if value2_lst[j] > value2_lst[i]:\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Adaptive capacity-aware perturbations\n    perturbation_intensity = 0.2 + 0.3 * (1 - (objectives[selected_idx][0] * objectives[selected_idx][1]) / (np.sum(objectives[:, 0]) * np.sum(objectives[:, 1])))\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.5:  # Moderate probability to remove\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.3:  # Lower probability to add\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution merging with trade-off aware selection\n    if len(archive) > 1:\n        # Select elite solutions based on their trade-off characteristics\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            elite_obj = objectives[elite_idx]\n            tradeoff_factor = np.abs(elite_obj[0] - elite_obj[1]) / (elite_obj[0] + elite_obj[1] + 1e-10)\n\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    if np.random.rand() < 0.5 * (1 + tradeoff_factor):  # Adjust probability based on trade-off\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -18.127465841390276,
               -19.150760708085386
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Centric Adaptive Exploration with Dynamic Constraint Handling (OCAE-DCH)\", employs a three-stage approach that first identifies the most promising solution through a novel objective-centric selection mechanism that dynamically balances between the two objectives based on their current relative importance, then performs a constraint-aware neighborhood exploration that systematically evaluates potential item swaps while maintaining feasibility through a dynamic capacity threshold adjustment mechanism, and finally applies a solution refinement step that combines features from diverse elite solutions while systematically exploring the neighborhood through a novel adaptive perturbation mechanism that alternates between objective-centric and capacity-focused operations, ensuring both high-quality and diverse solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    min_obj = np.min(objectives, axis=0)\n\n    # Calculate objective importance weights\n    obj_importance = (max_obj - objectives) / (max_obj - min_obj + 1e-10)\n    obj_weights = np.random.dirichlet([1, 1]) if np.random.rand() < 0.5 else obj_importance.mean(axis=0)\n\n    # Select solution with highest weighted score\n    weighted_scores = np.dot(objectives, obj_weights)\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Constraint-aware neighborhood exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate dynamic capacity threshold\n    capacity_threshold = remaining_capacity * (0.5 + 0.5 * np.random.rand())\n\n    # Evaluate potential swaps\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    for i in in_items:\n        for j in out_items:\n            weight_diff = weight_lst[j] - weight_lst[i]\n            if abs(weight_diff) <= capacity_threshold:\n                # Calculate objective improvements\n                value1_diff = value1_lst[j] - value1_lst[i]\n                value2_diff = value2_lst[j] - value2_lst[i]\n\n                # Accept swap if beneficial for at least one objective\n                if (value1_diff > 0 or value2_diff > 0) and np.random.rand() < 0.6:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight += weight_diff\n                    remaining_capacity = capacity - current_weight\n                    capacity_threshold = remaining_capacity * (0.5 + 0.5 * np.random.rand())\n                    break\n\n    # Phase 3: Adaptive perturbation with elite features\n    elite_solutions = [sol for sol, _ in archive if np.random.rand() < 0.3]\n    if elite_solutions:\n        elite_solution = elite_solutions[np.random.randint(len(elite_solutions))]\n\n        # Combine features from elite solution\n        combined_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n        np.random.shuffle(combined_items)\n\n        final_solution = np.zeros_like(new_solution)\n        current_weight = 0\n        for idx in combined_items:\n            if weight_lst[idx] <= (capacity - current_weight):\n                final_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        new_solution = final_solution\n\n    return new_solution\n\n",
          "score": [
               -18.647553129844333,
               -18.825095712577152
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Balanced Adaptive Hybrid Exploration with Dynamic Perturbation and Elite Fusion (OBA-HEDEPF)\", combines a novel multi-objective selection mechanism that prioritizes solutions with balanced objective contributions through a dynamic weighting scheme, with an adaptive neighborhood exploration strategy that alternates between objective-specific item replacements and capacity-aware perturbations, while incorporating a solution refinement phase that fuses features from diverse elite solutions through a probabilistic item selection mechanism that balances objective improvements with solution diversity, all while systematically exploring the solution space through a novel adaptive perturbation schedule that adjusts its intensity based on the current solution's proximity to the Pareto front and its objective-centric efficiency, ensuring both high-quality and diverse solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = 1 - np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-centric item replacement with dynamic weights\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate dynamic objective weights\n    obj1_weight = 0.5 + 0.5 * (objectives[selected_idx, 0] / (objectives[selected_idx, 0] + objectives[selected_idx, 1] + 1e-10))\n    obj2_weight = 1 - obj1_weight\n\n    # Calculate combined efficiency scores\n    combined_efficiency = (obj1_weight * value1_lst + obj2_weight * value2_lst) / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-combined_efficiency)\n\n    # Perform adaptive item replacements\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            # Find best replacement item\n            best_replacement = -1\n            max_gain = 0\n            for j in sorted_items:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    gain = (obj1_weight * (value1_lst[j] - value1_lst[i]) +\n                            obj2_weight * (value2_lst[j] - value2_lst[i]))\n                    if gain > max_gain:\n                        max_gain = gain\n                        best_replacement = j\n\n            if best_replacement != -1 and max_gain > 0:\n                new_solution[i] = 0\n                new_solution[best_replacement] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement]\n                remaining_capacity = capacity - current_weight\n\n    # Phase 3: Adaptive perturbation with dynamic intensity\n    perturbation_intensity = 0.3 + 0.4 * (1 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) /\n                                        (objectives.max(axis=0).sum() + 1e-10))\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.6:  # Higher probability to remove\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.3:  # Lower probability to add\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution fusion with probabilistic selection\n    if len(archive) > 1:\n        # Select elite solutions based on their diversity\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    fusion_prob = 0.5 + 0.5 * (combined_efficiency[idx] / (combined_efficiency.max() + 1e-10))\n                    if np.random.rand() < fusion_prob:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -19.868069155191158,
               -17.671918851578514
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Driven Hybrid Clustering and Adaptive Neighborhood Exploration (OH-CANE)\", combines a novel multi-objective clustering technique that identifies solution regions with complementary objective contributions with a dynamic neighborhood exploration strategy that alternates between objective-specific item swaps and capacity-aware perturbations, while incorporating a solution refinement phase that merges features from diverse elite solutions through a probabilistic item selection mechanism that balances objective improvements with solution diversity, all while systematically exploring the solution space through a novel adaptive perturbation schedule that adjusts its intensity based on the current solution's proximity to the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective value\n    objectives = np.array([obj for _, obj in archive])\n    combined_scores = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-driven clustering and neighborhood exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-specific efficiencies\n    value1_efficiency = value1_lst / (weight_lst + 1e-10)\n    value2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by efficiency for each objective\n    sorted_items1 = np.argsort(-value1_efficiency)\n    sorted_items2 = np.argsort(-value2_efficiency)\n\n    # Perform adaptive objective-driven swaps\n    swap_prob = 0.5\n    for i in sorted_items1:\n        if new_solution[i] == 1 and np.random.rand() < swap_prob:\n            # Try to replace with best value2 item\n            for j in sorted_items2:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if value2_lst[j] > value2_lst[i]:\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Adaptive perturbation with capacity awareness\n    perturbation_intensity = 0.4\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.6:  # Higher probability to remove\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.4:  # Lower probability to add\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution merging with probabilistic selection\n    if len(archive) > 1:\n        # Select elite solutions based on their diversity\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(3, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    if np.random.rand() < 0.7:  # Higher probability to accept from elite\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -17.878808762942704,
               -19.39905387664975
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Dual-Objective Harmony Search with Adaptive Constraint Navigation and Elite Fusion (DOHS-ACNEF)\", combines elements from the provided algorithms by incorporating a harmony search-inspired approach that dynamically balances between objective-centric and capacity-aware operations, with adaptive constraint handling through probabilistic item selection and removal that maintains feasibility, while systematically incorporating features from elite solutions through a novel fusion mechanism that alternates between objective-specific and capacity-focused operations, all while employing a dynamic neighborhood exploration strategy that adapts to the current solution's quality and diversity in the archive.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dual-Objective Harmony Selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n\n    # Calculate harmony weights based on objective diversity and quality\n    quality_weights = 1 - np.std(normalized_obj, axis=0)\n    diversity_weights = np.mean(normalized_obj, axis=0)\n    combined_weights = 0.6 * quality_weights + 0.4 * diversity_weights\n    combined_weights /= np.sum(combined_weights)\n\n    # Select solution with highest combined score\n    weighted_scores = np.dot(normalized_obj, combined_weights)\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate initial state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Phase 2: Adaptive Constraint Navigation\n    # Determine operation mode (objective-focused or capacity-focused)\n    if np.random.rand() < 0.7:\n        # Objective-focused operation\n        if np.random.rand() < 0.5:\n            # Value-to-weight ratio based removal\n            in_items = np.where(new_solution == 1)[0]\n            value_ratio = (value1_lst[in_items] + value2_lst[in_items]) / (weight_lst[in_items] + 1e-10)\n            sorted_items = in_items[np.argsort(value_ratio)]\n            for idx in sorted_items[:len(sorted_items)//2]:\n                if np.random.rand() < 0.5:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n        else:\n            # Probabilistic removal based on objective importance\n            in_items = np.where(new_solution == 1)[0]\n            for idx in in_items:\n                if np.random.rand() < (0.3 + 0.4 * combined_weights[0] + 0.3 * combined_weights[1]):\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n\n        # Add items based on combined objective\n        out_items = np.where(new_solution == 0)[0]\n        combined_ratio = (combined_weights[0] * value1_lst[out_items] + combined_weights[1] * value2_lst[out_items]) / (weight_lst[out_items] + 1e-10)\n        sorted_out = out_items[np.argsort(-combined_ratio)]\n        for idx in sorted_out[:len(sorted_out)//2]:\n            if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.6:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n    else:\n        # Capacity-focused operation\n        # Remove items with low capacity utilization\n        in_items = np.where(new_solution == 1)[0]\n        capacity_util = weight_lst[in_items] / (capacity + 1e-10)\n        sorted_items = in_items[np.argsort(capacity_util)]\n        for idx in sorted_items[:len(sorted_items)//2]:\n            if np.random.rand() < 0.4:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n\n        # Add items that fill capacity gaps\n        out_items = np.where(new_solution == 0)[0]\n        sorted_out = out_items[np.argsort(-weight_lst[out_items])]\n        for idx in sorted_out[:len(sorted_out)//2]:\n            if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.5:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 3: Elite Fusion with Dynamic Perturbation\n    elite_indices = np.random.choice(len(archive), size=min(2, len(archive)), replace=False)\n    for idx in elite_indices:\n        elite_solution = archive[idx][0]\n        # Create hybrid solution by combining features\n        hybrid_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n        np.random.shuffle(hybrid_items)\n\n        temp_solution = np.zeros_like(new_solution)\n        temp_weight = 0\n        for item in hybrid_items:\n            if weight_lst[item] <= (capacity - temp_weight):\n                temp_solution[item] = 1\n                temp_weight += weight_lst[item]\n\n        # Accept if it improves the combined objective\n        temp_obj1 = np.sum(value1_lst[temp_solution == 1])\n        temp_obj2 = np.sum(value2_lst[temp_solution == 1])\n        current_obj1 = np.sum(value1_lst[new_solution == 1])\n        current_obj2 = np.sum(value2_lst[new_solution == 1])\n\n        if (temp_obj1 * combined_weights[0] + temp_obj2 * combined_weights[1]) > \\\n           (current_obj1 * combined_weights[0] + current_obj2 * combined_weights[1]) and \\\n           np.random.rand() < 0.7:\n            new_solution = temp_solution\n            current_weight = temp_weight\n\n    return new_solution\n\n",
          "score": [
               -19.166179777355207,
               -18.641630064749066
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Pareto-Enhanced Adaptive Hybrid Exploration with Multi-Objective Diversification and Dynamic Perturbation (PAHE-MODDP)\", employs a novel multi-objective selection mechanism that prioritizes solutions with balanced objective contributions through a dynamic weighting scheme, combined with an adaptive neighborhood exploration strategy that alternates between objective-specific item replacements and capacity-aware perturbations, while incorporating a solution diversification phase that systematically explores the solution space through a novel adaptive perturbation schedule that adjusts its intensity based on the current solution's proximity to the Pareto front and its objective-centric efficiency, ensuring both high-quality and diverse solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Multi-objective solution selection with dynamic weighting\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = 1 - np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-specific item replacement with dynamic weights\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    obj1_weight = 0.5 + 0.5 * (objectives[selected_idx, 0] / (objectives[selected_idx, 0] + objectives[selected_idx, 1] + 1e-10))\n    obj2_weight = 1 - obj1_weight\n\n    combined_efficiency = (obj1_weight * value1_lst + obj2_weight * value2_lst) / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-combined_efficiency)\n\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            best_replacement = -1\n            max_gain = 0\n            for j in sorted_items:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    gain = (obj1_weight * (value1_lst[j] - value1_lst[i]) +\n                            obj2_weight * (value2_lst[j] - value2_lst[i]))\n                    if gain > max_gain:\n                        max_gain = gain\n                        best_replacement = j\n\n            if best_replacement != -1 and max_gain > 0:\n                new_solution[i] = 0\n                new_solution[best_replacement] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement]\n                remaining_capacity = capacity - current_weight\n\n    # Phase 3: Adaptive perturbation with dynamic intensity and diversification\n    perturbation_intensity = 0.3 + 0.4 * (1 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) /\n                                        (objectives.max(axis=0).sum() + 1e-10))\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.6:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.3:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Solution diversification through elite solution fusion\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    fusion_prob = 0.5 + 0.5 * (combined_efficiency[idx] / (combined_efficiency.max() + 1e-10))\n                    if np.random.rand() < fusion_prob:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -19.885491330575377,
               -17.493786473635225
          ]
     }
]