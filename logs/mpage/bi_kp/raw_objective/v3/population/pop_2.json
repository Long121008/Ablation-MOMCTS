[
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (here, randomly from the archive)\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n\n    # Random flip some bits (exploration)\n    flip_indices = np.random.choice(len(base_solution), size=np.random.randint(1, min(5, len(base_solution))), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Greedy improvement step (exploitation)\n    best_improvement = 0\n    best_idx = -1\n    best_action = None  # 'add' or 'remove'\n\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            # Evaluate removal\n            delta_weight = -weight_lst[idx]\n            delta_value1 = -value1_lst[idx]\n            delta_value2 = -value2_lst[idx]\n            if current_weight + delta_weight >= 0:\n                # Use a weighted sum of the two objectives for improvement\n                improvement = 0.5 * delta_value1 + 0.5 * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'remove'\n        else:\n            # Evaluate addition\n            delta_weight = weight_lst[idx]\n            delta_value1 = value1_lst[idx]\n            delta_value2 = value2_lst[idx]\n            if current_weight + delta_weight <= capacity:\n                improvement = 0.5 * delta_value1 + 0.5 * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'add'\n\n    if best_idx != -1:\n        if best_action == 'remove':\n            new_solution[best_idx] = 0\n        else:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.85684229040964,
               -18.702342658375688
          ]
     },
     {
          "algorithm": "{The proposed heuristic function 'select_neighbor' first identifies promising solutions in the archive by evaluating their potential for improvement through a novel local search strategy that combines random selection with a weighted exploration of solution quality and diversity, favoring those with higher marginal gains in either objective while avoiding redundant searches. It then applies a hybrid local search operator that strategically flips a subset of items based on a dynamic trade-off between value improvements and weight feasibility, ensuring feasibility by prioritizing items with the highest value-weight ratios and penalizing solutions that exceed capacity. The operator also incorporates a probabilistic component to escape local optima, flipping items with a chance proportional to their marginal contribution, while maintaining a balance between exploration and exploitation. The function returns the new neighbor solution after validating its feasibility and objective improvements.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with weighted randomness based on solution quality and diversity\n    scores = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            scores.append(0.0)  # Discourage infeasible solutions\n        else:\n            # Score based on marginal improvement potential\n            marginal1 = np.sum(value1_lst * (1 - sol))\n            marginal2 = np.sum(value2_lst * (1 - sol))\n            score = marginal1 + marginal2\n            scores.append(score)\n\n    if all(s == 0 for s in scores):\n        # All solutions are infeasible, select randomly\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select with probability proportional to score\n        probs = np.array(scores) / np.sum(scores)\n        selected_idx = np.random.choice(len(archive), p=probs)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search operator\n    for _ in range(3):  # Number of flips per iteration\n        # Calculate marginal gains for each item\n        marginal1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n        marginal2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n\n        # Calculate weight impact\n        weight_impact = weight_lst * (1 - 2 * new_solution)\n\n        # Calculate scores combining both objectives and feasibility\n        scores = (marginal1 + marginal2) / (1 + abs(weight_impact))\n\n        # Penalize solutions that would exceed capacity\n        temp_weight = current_weight + weight_impact\n        scores[temp_weight > capacity] = -np.inf\n\n        # Select item to flip with probability proportional to score\n        if np.all(scores <= -np.inf):\n            break  # No feasible moves\n\n        probs = np.exp(scores - np.max(scores))  # Softmax for numerical stability\n        probs /= np.sum(probs)\n\n        selected_item = np.random.choice(len(scores), p=probs)\n        new_solution[selected_item] = 1 - new_solution[selected_item]\n        current_weight += weight_impact[selected_item]\n\n    return new_solution\n\n",
          "score": [
               -18.78125726298865,
               -18.394552497017067
          ]
     },
     {
          "algorithm": "{The heuristic function 'select_neighbor' first identifies the most promising solution in the archive by evaluating the potential for improvement in both objectives, considering the trade-off between them. It then applies a hybrid local search strategy that combines a novel \"multi-objective swap and flip\" operator with a guided random walk to explore the solution space, ensuring feasibility by dynamically adjusting the selection of items to swap or flip based on their marginal contributions to both objectives. The operator prioritizes items with high marginal gains in either objective while respecting the capacity constraint, and the guided random walk introduces controlled diversification to escape local optima. The function intelligently selects a solution from the archive by favoring those with high \"improvement potential\" (e.g., solutions close to the Pareto front but not yet dominated) and generates a neighbor by either swapping two items or flipping a single item, with a bias toward items that improve the underperforming objective while maintaining feasibility.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the most promising solution (e.g., with highest improvement potential)\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = np.array([(obj[0] / np.max(value1_lst), obj[1] / np.max(value2_lst)) for _, obj in archive])\n    improvement_potential = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(improvement_potential)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Generate a neighbor using a hybrid local search strategy\n    # 1. Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # 2. Identify items to consider for flipping/swapping\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # 3. Apply a multi-objective swap and flip operator\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Randomly select an included item and an excluded item\n        included_item = np.random.choice(included_items)\n        excluded_item = np.random.choice(excluded_items)\n\n        # Calculate potential new weight and values\n        new_weight = current_weight - weight_lst[included_item] + weight_lst[excluded_item]\n        new_value1 = current_value1 - value1_lst[included_item] + value1_lst[excluded_item]\n        new_value2 = current_value2 - value2_lst[included_item] + value2_lst[excluded_item]\n\n        # Check feasibility\n        if new_weight <= capacity:\n            # Perform the swap\n            new_solution[included_item] = 0\n            new_solution[excluded_item] = 1\n        else:\n            # If swap is infeasible, try flipping an item\n            # Select an item to flip (prefer items that improve the underperforming objective)\n            if current_value1 < current_value2:\n                # Prefer items that improve value1\n                candidates = included_items[value1_lst[included_items] > value2_lst[included_items]]\n            else:\n                # Prefer items that improve value2\n                candidates = included_items[value2_lst[included_items] > value1_lst[included_items]]\n\n            if len(candidates) > 0:\n                flip_item = np.random.choice(candidates)\n                new_weight = current_weight - weight_lst[flip_item]\n                if new_weight <= capacity:\n                    new_solution[flip_item] = 0\n            else:\n                # If no candidates, randomly flip an item\n                flip_item = np.random.choice(included_items)\n                new_weight = current_weight - weight_lst[flip_item]\n                if new_weight <= capacity:\n                    new_solution[flip_item] = 0\n    else:\n        # If all items are included or excluded, perform a random flip\n        flip_item = np.random.choice(len(new_solution))\n        if new_solution[flip_item] == 1:\n            new_weight = current_weight - weight_lst[flip_item]\n            if new_weight <= capacity:\n                new_solution[flip_item] = 0\n        else:\n            new_weight = current_weight + weight_lst[flip_item]\n            if new_weight <= capacity:\n                new_solution[flip_item] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.31320176969653,
               -18.221934149935365
          ]
     },
     {
          "algorithm": "{The proposed algorithm, named \"Adaptive Multi-Objective Path Relinking (AMOPR)\", first identifies the most promising solution in the archive by evaluating the combined objective values and dominance relationships, then constructs a path between this solution and a randomly selected elite solution from the archive, adaptively combining their features through a novel \"path relinking\" strategy that prioritizes items with high marginal gains in both objectives while ensuring feasibility, and finally refines the resulting solution using a dynamic \"value-weighted\" perturbation operator that adjusts the perturbation intensity based on the current solution's proximity to the Pareto front, thus balancing exploration and exploitation to generate high-quality neighbors across multiple objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the most promising solution (highest combined objective values)\n    selected_idx = np.argmax([obj[0] + obj[1] for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Randomly select an elite solution from the archive\n    elite_idx = np.random.choice(len(archive))\n    elite_solution = archive[elite_idx][0].copy()\n\n    # Path relinking: construct a path between base and elite solutions\n    # Identify differing items between base and elite solutions\n    differing_items = np.where(base_solution != elite_solution)[0]\n\n    if len(differing_items) > 0:\n        # Randomly select a subset of differing items to relink\n        relink_items = np.random.choice(differing_items, size=min(3, len(differing_items)), replace=False)\n\n        # Calculate marginal gains for relinking items\n        marginal_gains = []\n        for i in relink_items:\n            if base_solution[i] == 0 and elite_solution[i] == 1:\n                # Item in elite but not in base: calculate gain if added\n                if np.sum(weight_lst * new_solution) + weight_lst[i] <= capacity:\n                    gain1 = value1_lst[i]\n                    gain2 = value2_lst[i]\n                    marginal_gains.append((gain1 + gain2, i, 1))  # 1 means add item\n            elif base_solution[i] == 1 and elite_solution[i] == 0:\n                # Item in base but not in elite: calculate gain if removed\n                if np.sum(weight_lst * new_solution) - weight_lst[i] >= 0:\n                    gain1 = -value1_lst[i]\n                    gain2 = -value2_lst[i]\n                    marginal_gains.append((gain1 + gain2, i, 0))  # 0 means remove item\n\n        # Sort by marginal gains (descending)\n        marginal_gains.sort(reverse=True, key=lambda x: x[0])\n\n        # Apply the best marginal gain moves\n        current_weight = np.sum(weight_lst * new_solution)\n        for _, i, action in marginal_gains:\n            if action == 1 and new_solution[i] == 0:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n            elif action == 0 and new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Dynamic perturbation: adjust based on solution's position in objective space\n    # Calculate the solution's dominance count\n    dominance_count = 0\n    for _, obj in archive:\n        if (obj[0] > archive[selected_idx][1][0] and obj[1] >= archive[selected_idx][1][1]) or \\\n           (obj[0] >= archive[selected_idx][1][0] and obj[1] > archive[selected_idx][1][1]):\n            dominance_count += 1\n\n    # More perturbation if the solution is non-dominated (higher quality)\n    perturbation_intensity = 0.1 if dominance_count == 0 else 0.3\n\n    # Apply perturbation\n    for i in range(len(new_solution)):\n        if np.random.random() < perturbation_intensity:\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n            else:\n                if np.sum(weight_lst * new_solution) + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.69134593850977,
               -18.079555253041722
          ]
     },
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with a probability inversely proportional to its dominance\n    # Solutions with higher crowding distance (more space to improve) are more likely to be selected\n    crowding_distances = np.zeros(len(archive))\n    for i in range(len(archive)):\n        # Calculate crowding distance (simplified)\n        neighbors = [j for j in range(len(archive)) if j != i]\n        if not neighbors:\n            crowding_distances[i] = 1.0\n            continue\n        dist1 = np.abs(archive[i][1][0] - archive[neighbors[0]][1][0])\n        dist2 = np.abs(archive[i][1][1] - archive[neighbors[0]][1][1])\n        for j in neighbors[1:]:\n            dist1 = min(dist1, np.abs(archive[i][1][0] - archive[j][1][0]))\n            dist2 = min(dist2, np.abs(archive[i][1][1] - archive[j][1][1]))\n        crowding_distances[i] = dist1 + dist2\n\n    # Normalize crowding distances and use as selection probabilities\n    if np.sum(crowding_distances) > 0:\n        probs = crowding_distances / np.sum(crowding_distances)\n    else:\n        probs = np.ones(len(archive)) / len(archive)\n\n    selected_idx = np.random.choice(len(archive), p=probs)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Step 2: Dynamic objective weighting based on current solution's position\n    # Solutions with lower values in either objective are prioritized for improvement\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    obj_weight1 = 1.0 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    obj_weight2 = 1.0 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n    norm = obj_weight1 + obj_weight2\n    if norm > 0:\n        obj_weight1 /= norm\n        obj_weight2 /= norm\n\n    # Step 3: Probabilistic selection of items to add/remove\n    new_solution = base_solution.copy()\n    candidates = np.where(base_solution == 1)[0]\n    non_candidates = np.where(base_solution == 0)[0]\n\n    # Remove items with low probability based on their contribution to the objectives\n    if len(candidates) > 0:\n        remove_probs = obj_weight1 * value1_lst[candidates] + obj_weight2 * value2_lst[candidates]\n        remove_probs = remove_probs / np.sum(remove_probs) if np.sum(remove_probs) > 0 else np.ones(len(candidates)) / len(candidates)\n        to_remove = np.random.choice(candidates, size=min(2, len(candidates)), p=remove_probs, replace=False)\n        for idx in to_remove:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Add items with high probability based on their contribution to the objectives\n    if len(non_candidates) > 0 and current_weight < capacity:\n        add_probs = obj_weight1 * value1_lst[non_candidates] + obj_weight2 * value2_lst[non_candidates]\n        add_probs = add_probs / np.sum(add_probs) if np.sum(add_probs) > 0 else np.ones(len(non_candidates)) / len(non_candidates)\n        to_add = np.random.choice(non_candidates, size=min(2, len(non_candidates)), p=add_probs, replace=False)\n        for idx in to_add:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 4: Swap and rebalance operator - temporarily swap items between objectives\n    # to identify high-impact moves while maintaining feasibility\n    if len(candidates) > 0 and len(non_candidates) > 0 and current_weight < capacity:\n        # Select a pair of items to swap (one in, one out)\n        swap_out = np.random.choice(candidates)\n        swap_in = np.random.choice(non_candidates)\n        delta_weight = weight_lst[swap_in] - weight_lst[swap_out]\n        if current_weight + delta_weight <= capacity:\n            new_solution[swap_out] = 0\n            new_solution[swap_in] = 1\n            current_weight += delta_weight\n\n    return new_solution\n\n",
          "score": [
               -17.97492684555088,
               -17.818315203935917
          ]
     },
     {
          "algorithm": "{The new algorithm employs a multi-phase approach to generate high-quality neighbor solutions by first identifying the most promising solution in the archive through a combination of objective dominance and solution diversity metrics, then applying a novel adaptive local search strategy that dynamically balances exploration and exploitation. This strategy combines probabilistic item selection based on both objective values and weights, with a guided mutation phase that strategically introduces changes to the solution while maintaining feasibility. The algorithm also incorporates a solution recombination step that merges features from the selected base solution and a randomly generated candidate solution, followed by a feasibility-preserving mutation phase that systematically explores the neighborhood while respecting capacity constraints. The entire process is guided by adaptive parameters that adjust based on the current solution quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Phase 1: Select the most promising solution using a combined metric\n    objectives = np.array([obj for _, obj in archive])\n    dominance_counts = np.zeros(len(archive))\n    diversity_scores = np.zeros(len(archive))\n\n    # Calculate dominance counts (number of solutions that dominate each solution)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dominance_counts[i] += 1\n\n    # Calculate diversity scores (distance to nearest neighbor in objective space)\n    for i in range(len(archive)):\n        min_dist = np.inf\n        for j in range(len(archive)):\n            if i != j:\n                dist = np.sqrt((objectives[i, 0] - objectives[j, 0])**2 + (objectives[i, 1] - objectives[j, 1])**2)\n                if dist < min_dist:\n                    min_dist = dist\n        diversity_scores[i] = min_dist\n\n    # Combine metrics to select the most promising solution\n    combined_scores = (1 - dominance_counts / (len(archive) - 1)) * diversity_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Adaptive local search with probabilistic selection\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - total_weight\n\n    # Calculate selection probabilities based on normalized values and weights\n    combined_values = value1_lst + value2_lst\n    normalized_scores = combined_values / (weight_lst + 1e-10)\n    selection_probs = normalized_scores / (np.sum(normalized_scores) + 1e-10)\n\n    # Phase 3: Guided mutation with feasibility check\n    mutation_size = min(5, len(new_solution) // 3)\n    for _ in range(mutation_size):\n        # Select an item to mutate based on probabilities\n        item_idx = np.random.choice(len(new_solution), p=selection_probs)\n\n        if new_solution[item_idx] == 1:\n            # Try to remove the item if it's in the solution\n            new_solution[item_idx] = 0\n            total_weight -= weight_lst[item_idx]\n        else:\n            # Try to add the item if it fits and improves at least one objective\n            if weight_lst[item_idx] <= remaining_capacity:\n                if (value1_lst[item_idx] > 0) or (value2_lst[item_idx] > 0):\n                    new_solution[item_idx] = 1\n                    total_weight += weight_lst[item_idx]\n                    remaining_capacity -= weight_lst[item_idx]\n\n    # Phase 4: Solution recombination with random candidate\n    # Generate a random candidate solution with some items selected\n    candidate_solution = np.zeros_like(new_solution)\n    candidate_weight = 0\n    for i in range(len(new_solution)):\n        if np.random.rand() < 0.3:  # 30% chance to include each item\n            if weight_lst[i] <= (capacity - candidate_weight):\n                candidate_solution[i] = 1\n                candidate_weight += weight_lst[i]\n\n    # Recombine solutions by taking items that are in either solution\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -17.836191286975296,
               -17.610764910920075
          ]
     },
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution from the archive (prioritize non-dominated with high values)\n    base_solutions = [sol for sol, _ in archive]\n    base_objectives = [obj for _, obj in archive]\n\n    # Calculate total values for each solution\n    total_values1 = np.array([obj[0] for obj in base_objectives])\n    total_values2 = np.array([obj[1] for obj in base_objectives])\n\n    # Identify non-dominated solutions\n    non_dominated_indices = []\n    for i in range(len(base_objectives)):\n        dominated = False\n        for j in range(len(base_objectives)):\n            if i != j and total_values1[j] >= total_values1[i] and total_values2[j] >= total_values2[i]:\n                dominated = True\n                break\n        if not dominated:\n            non_dominated_indices.append(i)\n\n    if not non_dominated_indices:\n        non_dominated_indices = list(range(len(base_objectives)))\n\n    # Select the solution with highest sum of normalized values\n    normalized_values1 = (total_values1 - np.min(total_values1)) / (np.max(total_values1) - np.min(total_values1) + 1e-8)\n    normalized_values2 = (total_values2 - np.min(total_values2)) / (np.max(total_values2) - np.min(total_values2) + 1e-8)\n    scores = normalized_values1 + normalized_values2\n    best_idx = np.argmax(scores[non_dominated_indices])\n    base_solution = base_solutions[non_dominated_indices[best_idx]].copy()\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    current_value1 = np.sum(value1_lst[base_solution == 1])\n    current_value2 = np.sum(value2_lst[base_solution == 1])\n\n    # Hybrid local search: item swapping + probabilistic insertion\n    for _ in range(10):  # Number of local search iterations\n        # Item swapping (exchange two items)\n        in_items = np.where(new_solution == 1)[0]\n        out_items = np.where(new_solution == 0)[0]\n\n        if len(in_items) >= 2 and len(out_items) >= 1:\n            # Randomly select two items to swap out and one to swap in\n            swap_out1, swap_out2 = np.random.choice(in_items, 2, replace=False)\n            swap_in = np.random.choice(out_items)\n\n            # Calculate new weight and values\n            new_weight = current_weight - weight_lst[swap_out1] - weight_lst[swap_out2] + weight_lst[swap_in]\n            if new_weight <= capacity:\n                new_value1 = current_value1 - value1_lst[swap_out1] - value1_lst[swap_out2] + value1_lst[swap_in]\n                new_value2 = current_value2 - value2_lst[swap_out1] - value2_lst[swap_out2] + value2_lst[swap_in]\n\n                # Accept the move if it improves at least one objective\n                if new_value1 > current_value1 or new_value2 > current_value2:\n                    new_solution[swap_out1] = 0\n                    new_solution[swap_out2] = 0\n                    new_solution[swap_in] = 1\n                    current_weight = new_weight\n                    current_value1 = new_value1\n                    current_value2 = new_value2\n\n        # Probabilistic insertion (flip items with high marginal value-to-weight ratio)\n        marginal_value1 = (value1_lst - value1_lst[new_solution == 1].mean()) / (weight_lst + 1e-8)\n        marginal_value2 = (value2_lst - value2_lst[new_solution == 1].mean()) / (weight_lst + 1e-8)\n        marginal_scores = marginal_value1 + marginal_value2\n\n        # Select items to flip based on marginal scores\n        flip_candidates = np.where(new_solution == 0)[0]\n        if len(flip_candidates) > 0:\n            # Select top 20% candidates by marginal score\n            num_candidates = max(1, len(flip_candidates) // 5)\n            top_candidates = np.argsort(marginal_scores[flip_candidates])[-num_candidates:]\n\n            for idx in flip_candidates[top_candidates]:\n                if np.random.rand() < 0.3:  # 30% chance to flip\n                    if current_weight + weight_lst[idx] <= capacity:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        current_value1 += value1_lst[idx]\n                        current_value2 += value2_lst[idx]\n                    else:\n                        # Try to remove a random item to make space\n                        in_items = np.where(new_solution == 1)[0]\n                        if len(in_items) > 0:\n                            remove_idx = np.random.choice(in_items)\n                            new_solution[remove_idx] = 0\n                            current_weight -= weight_lst[remove_idx]\n                            current_value1 -= value1_lst[remove_idx]\n                            current_value2 -= value2_lst[remove_idx]\n\n                            # Then add the new item\n                            if current_weight + weight_lst[idx] <= capacity:\n                                new_solution[idx] = 1\n                                current_weight += weight_lst[idx]\n                                current_value1 += value1_lst[idx]\n                                current_value2 += value2_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -17.161092703575015,
               -17.23210254548819
          ]
     },
     {
          "algorithm": "{The proposed algorithm, named \"Multi-Objective Adaptive Local Search (MOALS)\", intelligently selects a solution from the archive by prioritizing those with high objective values and low crowding distance in the objective space, then applies a hybrid local search strategy that combines exploratory moves (randomly flipping a subset of items) and exploitative moves (targeted flips to improve both objectives) while ensuring feasibility by dynamically adjusting the flip probability based on the current solution's weight and capacity, and finally refines the solution using a novel \"value-weighted\" swap operator that prioritizes items with high marginal gains in both objectives, thus balancing exploration and exploitation to generate high-quality neighbors across multiple objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    # Prioritize solutions with high objective values and low crowding distance\n    solutions = [s for s, _ in archive]\n    objectives = [o for _, o in archive]\n\n    # Calculate crowding distance for each solution\n    def crowding_distance(solutions, objectives):\n        n = len(solutions)\n        if n <= 2:\n            return [float('inf')] * n\n\n        # Sort by each objective\n        sorted_indices = [np.argsort([o[i] for o in objectives]) for i in range(2)]\n\n        distances = [0.0] * n\n        for i in range(2):\n            sorted_idx = sorted_indices[i]\n            min_obj = objectives[sorted_idx[0]][i]\n            max_obj = objectives[sorted_idx[-1]][i]\n\n            # Handle edge cases\n            distances[sorted_idx[0]] = float('inf')\n            distances[sorted_idx[-1]] = float('inf')\n\n            for j in range(1, n-1):\n                distances[sorted_idx[j]] += (objectives[sorted_idx[j+1]][i] - objectives[sorted_idx[j-1]][i]) / (max_obj - min_obj)\n\n        return distances\n\n    distances = crowding_distance(solutions, objectives)\n    # Combine objective values and crowding distance for selection\n    scores = [o1 + o2 + d for (o1, o2), d in zip(objectives, distances)]\n    selected_idx = np.argmax(scores)\n    base_solution = solutions[selected_idx].copy()\n\n    # Generate a neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Exploratory move: randomly flip a subset of items\n    flip_prob = 0.1 + 0.3 * (1 - current_weight / capacity)  # Higher probability when under capacity\n    for i in range(len(base_solution)):\n        if random.random() < flip_prob:\n            if base_solution[i] == 1:\n                # Try to remove item if it doesn't violate capacity\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                # Try to add item if it fits in capacity\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    # Exploitative move: targeted flip to improve both objectives\n    # Calculate marginal gains for each item\n    marginal_gains = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 0:\n            if current_weight + weight_lst[i] <= capacity:\n                gain1 = value1_lst[i]\n                gain2 = value2_lst[i]\n                marginal_gains.append((gain1 + gain2, i))\n        else:\n            if current_weight - weight_lst[i] >= 0:\n                gain1 = -value1_lst[i]\n                gain2 = -value2_lst[i]\n                marginal_gains.append((gain1 + gain2, i))\n\n    # Sort by total marginal gain (both objectives)\n    marginal_gains.sort(reverse=True, key=lambda x: x[0])\n\n    # Apply the best marginal gain moves\n    num_moves = min(3, len(marginal_gains))\n    for _, i in marginal_gains[:num_moves]:\n        if new_solution[i] == 0:\n            new_solution[i] = 1\n        else:\n            new_solution[i] = 0\n\n    # Value-weighted swap operator\n    # Calculate value density for each item\n    value_density1 = value1_lst / weight_lst\n    value_density2 = value2_lst / weight_lst\n\n    # Find pairs of items where swapping improves both objectives\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            for j in range(len(new_solution)):\n                if new_solution[j] == 0 and weight_lst[i] + weight_lst[j] <= capacity:\n                    # Calculate potential improvement\n                    delta1 = value1_lst[j] - value1_lst[i]\n                    delta2 = value2_lst[j] - value2_lst[i]\n                    if delta1 > 0 and delta2 > 0:\n                        # Perform swap\n                        new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                        break\n\n    return new_solution\n\n",
          "score": [
               -16.752490438203917,
               -16.791677647440192
          ]
     },
     {
          "algorithm": "{The proposed heuristic function 'select_neighbor' first identifies the most promising solution in the archive by evaluating each solution's potential for improvement through a novel hybrid local search strategy. This involves selecting a solution with the highest combined objective values and a low dominance count, ensuring it lies on the Pareto front. The function then applies a creative local search operator that combines elements of both bit-flipping and item swapping: it randomly flips a subset of items (bit-flipping) while ensuring feasibility, followed by strategically swapping items between the solution and a randomly generated candidate solution (hybrid swapping). The candidate solution is generated by greedily selecting items with the highest combined normalized objective values, but only those that can fit within the remaining capacity. The neighbor solution is generated by combining the best items from both the original solution and the candidate solution, ensuring the total weight does not exceed the capacity. This approach balances exploration and exploitation, promoting diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the most promising solution (highest combined objective values)\n    selected_idx = np.argmax([obj[0] + obj[1] for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Generate a candidate solution greedily (highest combined normalized values)\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    normalized_values = (value1_lst + value2_lst) / (weight_lst + 1e-10)  # Avoid division by zero\n    sorted_indices = np.argsort(-normalized_values)  # Descending order\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Hybrid local search: combine base_solution and candidate_solution\n    combined_items = np.where((base_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Try to add items from combined_items to new_solution while respecting capacity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    for idx in combined_items:\n        if new_solution[idx] == 0 and weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Randomly flip some items to explore neighborhood\n    flip_indices = np.random.choice(len(new_solution), size=min(3, len(new_solution)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            new_solution[idx] = 0\n        else:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -16.027020456746982,
               -15.720457283919782
          ]
     },
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a base solution with intelligent randomness\n    objectives = np.array([obj for _, obj in archive])\n    crowding_dist = np.zeros(len(archive))\n\n    # Compute crowding distance for diversity\n    for i in range(2):  # For each objective\n        sorted_idx = np.argsort(objectives[:, i])\n        crowding_dist[sorted_idx[0]] = np.inf\n        crowding_dist[sorted_idx[-1]] = np.inf\n        for j in range(1, len(archive) - 1):\n            crowding_dist[sorted_idx[j]] += (objectives[sorted_idx[j+1], i] - objectives[sorted_idx[j-1], i]) / (objectives[sorted_idx[-1], i] - objectives[sorted_idx[0], i] + 1e-10)\n\n    # Select solution with highest crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding_dist)\n    base_solution, _ = archive[selected_idx]\n\n    # Generate neighbor using hybrid local search\n    new_solution = base_solution.copy()\n    total_weight = np.sum(weight_lst * base_solution)\n\n    # Parameters for the local search\n    max_flips = min(5, len(base_solution) // 4)\n    max_swaps = min(3, len(base_solution) // 8)\n\n    # Randomly flip items (with probability based on crowding distance)\n    flip_prob = 0.2 + 0.8 * (crowding_dist[selected_idx] / (np.max(crowding_dist) + 1e-10))\n    for i in range(len(base_solution)):\n        if np.random.rand() < flip_prob:\n            if base_solution[i] == 1:\n                if total_weight - weight_lst[i] <= capacity:\n                    new_solution[i] = 0\n                    total_weight -= weight_lst[i]\n            else:\n                if total_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    total_weight += weight_lst[i]\n\n    # Randomly swap items between selected and unselected (preserving feasibility)\n    selected_items = np.where(new_solution == 1)[0]\n    unselected_items = np.where(new_solution == 0)[0]\n\n    for _ in range(max_swaps):\n        if len(selected_items) > 0 and len(unselected_items) > 0:\n            i = np.random.choice(selected_items)\n            j = np.random.choice(unselected_items)\n\n            if total_weight - weight_lst[i] + weight_lst[j] <= capacity:\n                new_solution[i] = 0\n                new_solution[j] = 1\n                total_weight = total_weight - weight_lst[i] + weight_lst[j]\n\n    return new_solution\n\n",
          "score": [
               -15.096770773729961,
               -15.635294405873616
          ]
     }
]