[
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (here, randomly from the archive)\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n\n    # Random flip some bits (exploration)\n    flip_indices = np.random.choice(len(base_solution), size=np.random.randint(1, min(5, len(base_solution))), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Greedy improvement step (exploitation)\n    best_improvement = 0\n    best_idx = -1\n    best_action = None  # 'add' or 'remove'\n\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            # Evaluate removal\n            delta_weight = -weight_lst[idx]\n            delta_value1 = -value1_lst[idx]\n            delta_value2 = -value2_lst[idx]\n            if current_weight + delta_weight >= 0:\n                # Use a weighted sum of the two objectives for improvement\n                improvement = 0.5 * delta_value1 + 0.5 * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'remove'\n        else:\n            # Evaluate addition\n            delta_weight = weight_lst[idx]\n            delta_value1 = value1_lst[idx]\n            delta_value2 = value2_lst[idx]\n            if current_weight + delta_weight <= capacity:\n                improvement = 0.5 * delta_value1 + 0.5 * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'add'\n\n    if best_idx != -1:\n        if best_action == 'remove':\n            new_solution[best_idx] = 0\n        else:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.85684229040964,
               -18.702342658375688
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Balanced Adaptive Path Exploration with Dynamic Trade-off Navigation (O-BAPE-DTN)\", first identifies a solution from the archive that shows balanced contributions to both objectives and then applies a hybrid search strategy that combines adaptive path exploration with a novel neighborhood navigation mechanism. This mechanism dynamically navigates the trade-off space by first constructing a solution path using a probabilistic selection of items based on their balanced contributions to both objectives, then performs a guided path refinement phase that systematically explores alternative paths while respecting capacity constraints, followed by a solution diversification step that strategically reallocates items along the path to improve both objectives, and finally applies a path optimization step that uses a weighted sum of both objectives to further refine the solution path. The entire process is guided by adaptive parameters that adjust based on the current path quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with balanced contributions to both objectives\n    objectives = np.array([obj for _, obj in archive])\n    normalized_objectives = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n    balance_scores = 1 - np.abs(normalized_objectives[:, 0] - normalized_objectives[:, 1])\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate initial path solution\n    path_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    beta = np.random.uniform(0.3, 0.7)  # Dynamic trade-off factor\n    balanced_values = (1 - beta) * value1_lst + beta * value2_lst\n    weights = balanced_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-weights)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and path_solution[idx] == 0:\n            path_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Path refinement with alternative exploration\n    path_items = np.where(path_solution == 1)[0]\n    np.random.shuffle(path_items)\n\n    # Explore alternative paths while respecting capacity\n    for idx in path_items:\n        if np.random.rand() < 0.5 and new_solution[idx] == 0:\n            if weight_lst[idx] <= (capacity - current_weight):\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n            else:\n                # Try to replace an existing item\n                for j in range(len(new_solution)):\n                    if new_solution[j] == 1 and weight_lst[idx] <= current_weight + weight_lst[idx] - weight_lst[j]:\n                        new_solution[j] = 0\n                        new_solution[idx] = 1\n                        current_weight = current_weight - weight_lst[j] + weight_lst[idx]\n                        break\n\n    # Solution diversification with path reallocation\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and np.random.rand() < 0.3:\n            # Find alternative items along the path\n            potential_replacements = []\n            for j in range(len(new_solution)):\n                if new_solution[j] == 0 and path_solution[j] == 1 and weight_lst[j] <= current_weight + weight_lst[j] - weight_lst[i]:\n                    value_diff1 = value1_lst[j] - value1_lst[i]\n                    value_diff2 = value2_lst[j] - value2_lst[i]\n                    if value_diff1 > 0 or value_diff2 > 0:\n                        potential_replacements.append((j, value_diff1 + value_diff2))\n\n            if potential_replacements:\n                best_replacement = max(potential_replacements, key=lambda x: x[1])\n                new_solution[i] = 0\n                new_solution[best_replacement[0]] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement[0]]\n\n    # Path optimization with weighted objective improvement\n    gamma = np.random.uniform(0.2, 0.8)  # Dynamic objective weighting factor\n    best_improvement = 0\n    best_idx = -1\n    best_action = None\n\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            # Evaluate removal\n            delta_weight = -weight_lst[idx]\n            delta_value1 = -value1_lst[idx]\n            delta_value2 = -value2_lst[idx]\n            if current_weight + delta_weight >= 0:\n                improvement = gamma * delta_value1 + (1 - gamma) * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'remove'\n        else:\n            # Evaluate addition if it's part of the path\n            if path_solution[idx] == 1 and current_weight + weight_lst[idx] <= capacity:\n                delta_weight = weight_lst[idx]\n                delta_value1 = value1_lst[idx]\n                delta_value2 = value2_lst[idx]\n                improvement = gamma * delta_value1 + (1 - gamma) * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'add'\n\n    if best_idx != -1:\n        if best_action == 'remove':\n            new_solution[best_idx] = 0\n        else:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.961259023056908,
               -18.701306800405522
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Objective-Centric Exploration with Dynamic Pareto-Adaptive Perturbation (A-OCE-DPAP)\", first identifies solutions in the archive with the highest combined objective values while maintaining feasibility, then applies a novel hybrid search strategy that combines Pareto-adaptive perturbation with dynamic objective-centric exploration, where items are prioritized based on their adaptive contributions to both objectives through a multi-stage perturbation mechanism that alternates between objective-specific mutations and capacity-aware item swaps, while dynamically adjusting the exploration intensity based on the solution's proximity to the Pareto front, ensuring a balance between exploitation of high-value items and exploration of diverse solution spaces to generate high-quality neighbors across multiple objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective values\n    objectives = np.array([obj for _, obj in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Pareto-adaptive perturbation\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate Pareto-adaptive weights\n    pareto_weights = np.random.uniform(0.3, 0.7)\n    adaptive_values = pareto_weights * value1_lst + (1 - pareto_weights) * value2_lst\n    value_ratios = adaptive_values / (weight_lst + 1e-10)\n\n    # Sort items by adaptive value ratio\n    sorted_items = np.argsort(-value_ratios)\n\n    # Dynamic perturbation intensity\n    perturbation_intensity = min(0.5, 1.0 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) / (np.sum(value1_lst) + np.sum(value2_lst)))\n\n    # Remove low-value items with probability based on intensity\n    for idx in sorted_items[len(sorted_items)//2:]:\n        if new_solution[idx] == 1 and np.random.rand() < perturbation_intensity:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n\n    # Phase 3: Objective-centric exploration\n    out_items = np.where(new_solution == 0)[0]\n    sorted_out_items = np.argsort(-value_ratios[out_items])\n\n    # Add high-value items with probability based on intensity\n    for idx in out_items[sorted_out_items[:len(sorted_out_items)//2]]:\n        if weight_lst[idx] <= remaining_capacity and np.random.rand() < (1 - perturbation_intensity):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Dynamic capacity-aware swaps\n    if np.random.rand() < 0.5:  # Higher probability for swaps\n        remove_candidates = np.where(new_solution == 1)[0]\n        add_candidates = np.where(new_solution == 0)[0]\n\n        # Sort candidates by value ratio\n        remove_candidates = remove_candidates[np.argsort(value_ratios[remove_candidates])]\n        add_candidates = add_candidates[np.argsort(-value_ratios[add_candidates])]\n\n        # Perform swaps with adaptive probability\n        for i in remove_candidates[:len(remove_candidates)//2]:\n            for j in add_candidates[:len(add_candidates)//2]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity and np.random.rand() < 0.7:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.28343212616835,
               -18.581111593129386
          ]
     },
     {
          "algorithm": "{The proposed algorithm integrates a hybrid exploration-exploitation strategy with dynamic objective prioritization, where it first identifies solutions with high potential for improvement by analyzing their objective contributions and neighborhood diversity, then applies a multi-stage local search that combines probabilistic item selection based on adaptive objective weights, a guided item replacement mechanism that strategically enhances both objectives while maintaining feasibility, and a solution refinement phase that leverages both the base solution and a candidate solution generated through a diversity-aware construction heuristic to systematically explore the neighborhood while dynamically adjusting the exploration-exploitation balance through temperature-based acceptance criteria and penalty-based feasibility checks.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select solution with highest potential improvement\n    objectives = np.array([obj for _, obj in archive])\n    base_idx = np.argmax(np.max(objectives, axis=0) - np.min(objectives, axis=0))\n    base_solution = archive[base_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Generate candidate solution with dynamic prioritization\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    beta = np.random.uniform(0.4, 0.6)  # Dynamic prioritization factor\n    priority_scores = beta * value1_lst + (1 - beta) * value2_lst\n    priority_scores /= (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-priority_scores)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Hybrid neighborhood exploration\n    new_solution = base_solution.copy()\n    temperature = 0.6\n    for _ in range(4):\n        # Calculate adaptive mutation scores\n        marginal1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n        marginal2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n        weight_impact = weight_lst * (1 - 2 * new_solution)\n\n        # Combine objectives with temperature-based acceptance\n        scores = (marginal1 + marginal2) / (1 + abs(weight_impact))\n        temp_weight = current_weight + weight_impact\n        scores[temp_weight > capacity] = -np.inf\n\n        if np.all(scores <= -np.inf):\n            break\n\n        # Apply temperature-based selection\n        probs = np.exp(scores / temperature)\n        probs /= np.sum(probs)\n        selected_item = np.random.choice(len(scores), p=probs)\n\n        # Update solution and temperature\n        new_solution[selected_item] = 1 - new_solution[selected_item]\n        current_weight += weight_impact[selected_item]\n        temperature *= 0.85\n\n    # Step 4: Solution refinement with candidate merging\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -19.295790774938155,
               -18.457964896102936
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Objective Neighborhood Exploration with Dynamic Objective Balancing (AMONE-DOB)\", first selects a solution from the archive that exhibits high diversity in objective contributions and then applies a hybrid search strategy that combines adaptive objective weighting with a novel neighborhood exploration mechanism. This mechanism dynamically balances the exploration of both objectives through a three-stage process: first, it identifies critical items using a probabilistic selection based on their adaptive weighted contributions to both objectives while maintaining feasibility, second, it performs a guided item replacement phase that strategically swaps items between objectives to improve both values, and third, it incorporates a solution refinement step that merges features from the selected base solution and a randomly generated candidate solution while systematically exploring the neighborhood while respecting capacity constraints. The entire process is guided by adaptive parameters that adjust based on the current solution quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = np.argmax(np.std(objectives, axis=0))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate candidate solution using adaptive objective weighting\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    alpha = np.random.uniform(0.3, 0.7)  # Dynamic objective balance factor\n    weighted_values = alpha * value1_lst + (1 - alpha) * value2_lst\n    weights = weighted_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-weights)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Adaptive neighborhood exploration\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Critical item identification and replacement\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and np.random.rand() < 0.3:\n            # Find replacement items that improve both objectives\n            potential_replacements = []\n            for j in range(len(new_solution)):\n                if new_solution[j] == 0 and weight_lst[j] <= current_weight + weight_lst[j] - weight_lst[i]:\n                    value_diff1 = value1_lst[j] - value1_lst[i]\n                    value_diff2 = value2_lst[j] - value2_lst[i]\n                    if value_diff1 > 0 or value_diff2 > 0:\n                        potential_replacements.append((j, value_diff1 + value_diff2))\n\n            if potential_replacements:\n                best_replacement = max(potential_replacements, key=lambda x: x[1])\n                new_solution[i] = 0\n                new_solution[best_replacement[0]] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement[0]]\n\n    # Solution refinement with candidate merging\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -18.76309843274899,
               -18.686923793127768
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Dimensional Solution Exploration with Dynamic Objective Fusion (AMSE-DOF)\", first identifies the solution in the archive with the highest combined objective value while considering the trade-off between both objectives, then applies a hybrid search strategy that combines adaptive objective fusion with a novel neighborhood exploration mechanism. This mechanism dynamically balances the exploration of both objectives through a four-stage process: first, it performs a probabilistic selection of items based on their adaptive fusion of both objectives while maintaining feasibility, second, it conducts a guided item replacement phase that strategically swaps items between objectives to improve both values, third, it incorporates a solution refinement step that merges features from the selected base solution and a randomly generated candidate solution while systematically exploring the neighborhood while respecting capacity constraints, and fourth, it applies a dynamic objective fusion adjustment phase that adapts the weighting of the objectives based on the current solution's performance and the archive's diversity. The entire process is guided by adaptive parameters that adjust based on the current solution quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select solution with highest combined objective value considering trade-off\n    objectives = np.array([(v1 + v2) / (1 + abs(v1 - v2)) for _, (v1, v2) in archive])\n    selected_idx = np.argmax(objectives)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Generate candidate solution using adaptive objective fusion\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    beta = np.random.uniform(0.4, 0.6)  # Dynamic fusion factor\n    fused_values = beta * value1_lst + (1 - beta) * value2_lst\n    weights = fused_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-weights)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Adaptive neighborhood exploration with guided item replacement\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Identify critical items and potential replacements\n    critical_items = np.where(new_solution == 1)[0]\n    for i in critical_items:\n        if np.random.rand() < 0.4:\n            # Find replacement items that improve both objectives\n            potential_replacements = []\n            for j in range(len(new_solution)):\n                if new_solution[j] == 0 and weight_lst[j] <= current_weight + weight_lst[j] - weight_lst[i]:\n                    value_diff1 = value1_lst[j] - value1_lst[i]\n                    value_diff2 = value2_lst[j] - value2_lst[i]\n                    if value_diff1 > 0 and value_diff2 > 0:\n                        potential_replacements.append((j, value_diff1 + value_diff2))\n\n            if potential_replacements:\n                best_replacement = max(potential_replacements, key=lambda x: x[1])\n                new_solution[i] = 0\n                new_solution[best_replacement[0]] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement[0]]\n\n    # Step 4: Solution refinement with candidate merging and dynamic fusion adjustment\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic fusion adjustment based on current solution performance\n    current_v1 = np.sum(value1_lst[new_solution == 1])\n    current_v2 = np.sum(value2_lst[new_solution == 1])\n    if abs(current_v1 - current_v2) > np.mean([v1 - v2 for _, (v1, v2) in archive]):\n        beta = np.random.uniform(0.3, 0.7)  # Adjust fusion factor if objectives are imbalanced\n\n    return new_solution\n\n",
          "score": [
               -18.84941872503954,
               -18.662616742622543
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Driven Adaptive Neighborhood Evolution with Dynamic Feasibility Preservation (O-DANE-DFP)\", combines a multi-phase approach that first identifies critical items using an adaptive objective-driven selection mechanism, followed by a probabilistic neighborhood exploration phase that dynamically balances between objective improvements and feasibility preservation, and concludes with a solution consolidation step that merges features from the base solution and a greedily constructed candidate solution while systematically exploring the neighborhood while respecting capacity constraints. This approach leverages adaptive objective weighting to prioritize items that show the most potential for improvement across both objectives, while maintaining feasibility through dynamic capacity checks and probabilistic acceptance criteria that balance exploration and exploitation.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest combined objective value\n    objectives = np.array([obj for _, obj in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate candidate solution using adaptive objective-driven selection\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    objective_ratio = np.random.uniform(0.4, 0.6)  # Dynamic objective balance factor\n    combined_values = objective_ratio * value1_lst + (1 - objective_ratio) * value2_lst\n    value_to_weight_ratio = combined_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-value_to_weight_ratio)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Probabilistic neighborhood exploration with dynamic feasibility preservation\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Identify critical items and explore replacements\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and np.random.rand() < 0.4:\n            # Find items that can improve at least one objective while preserving feasibility\n            potential_replacements = []\n            for j in range(len(new_solution)):\n                if new_solution[j] == 0 and weight_lst[j] <= capacity:\n                    weight_diff = weight_lst[j] - weight_lst[i]\n                    if current_weight + weight_diff <= capacity:\n                        value_diff1 = value1_lst[j] - value1_lst[i]\n                        value_diff2 = value2_lst[j] - value2_lst[i]\n                        if (value_diff1 > 0 or value_diff2 > 0) and np.random.rand() < 0.6:  # Probabilistic acceptance\n                            potential_replacements.append((j, value_diff1 + value_diff2))\n\n            if potential_replacements:\n                best_replacement = max(potential_replacements, key=lambda x: x[1])\n                new_solution[i] = 0\n                new_solution[best_replacement[0]] = 1\n                current_weight += weight_lst[best_replacement[0]] - weight_lst[i]\n\n    # Solution consolidation with candidate merging\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    final_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            final_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return final_solution\n\n",
          "score": [
               -19.220895827039115,
               -18.517466624844758
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Dual-Objective Adaptive Exploration with Hybrid Feasibility Guided Search (D-OA-EHGS)\", employs a three-stage approach that first identifies high-potential items through an adaptive objective-centric analysis, then performs a hybrid neighborhood exploration that dynamically balances between objective improvements and feasibility preservation using a novel probabilistic swapping mechanism, and finally applies a solution refinement step that combines features from multiple elite solutions while systematically exploring the neighborhood while respecting capacity constraints. This approach leverages adaptive objective weighting to prioritize items that show the most potential for improvement across both objectives, while maintaining feasibility through dynamic capacity checks and a guided probabilistic acceptance criteria that balances exploration and exploitation, and incorporates a novel dual-objective fusion mechanism that dynamically adjusts the exploration focus based on the current solution quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest combined objective value\n    objectives = np.array([obj for _, obj in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Adaptive objective-centric analysis\n    objective_weights = np.random.uniform(0.3, 0.7, size=2)\n    objective_weights /= np.sum(objective_weights)\n    combined_values = objective_weights[0] * value1_lst + objective_weights[1] * value2_lst\n    value_to_weight_ratio = combined_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-value_to_weight_ratio)\n\n    # Hybrid neighborhood exploration with probabilistic swapping\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and np.random.rand() < 0.5:\n            # Find items that can improve at least one objective while preserving feasibility\n            potential_replacements = []\n            for j in sorted_indices:\n                if new_solution[j] == 0 and weight_lst[j] <= capacity:\n                    weight_diff = weight_lst[j] - weight_lst[i]\n                    if current_weight + weight_diff <= capacity:\n                        value_diff1 = value1_lst[j] - value1_lst[i]\n                        value_diff2 = value2_lst[j] - value2_lst[i]\n                        if (value_diff1 > 0 or value_diff2 > 0) and np.random.rand() < 0.7:\n                            potential_replacements.append((j, value_diff1 + value_diff2))\n\n            if potential_replacements:\n                best_replacement = max(potential_replacements, key=lambda x: x[1])\n                new_solution[i] = 0\n                new_solution[best_replacement[0]] = 1\n                current_weight += weight_lst[best_replacement[0]] - weight_lst[i]\n\n    # Solution refinement with elite feature combination\n    elite_solutions = [sol for sol, _ in archive if np.random.rand() < 0.3]\n    if elite_solutions:\n        elite_solution = elite_solutions[np.random.randint(len(elite_solutions))]\n        combined_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n        np.random.shuffle(combined_items)\n\n        # Rebuild solution with combined items while respecting capacity\n        final_solution = np.zeros_like(new_solution)\n        current_weight = 0\n        for idx in combined_items:\n            if weight_lst[idx] <= (capacity - current_weight):\n                final_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        new_solution = final_solution\n\n    return new_solution\n\n",
          "score": [
               -19.13629683829494,
               -18.573566827102255
          ]
     },
     {
          "algorithm": "{The proposed heuristic function 'select_neighbor' employs a novel hybrid local search strategy that combines adaptive neighborhood exploration with a probabilistic selection mechanism and a value-weighted mutation operator, while dynamically balancing exploration and exploitation through a temperature-based acceptance criterion and a penalty-based feasibility check. It first evaluates each solution in the archive based on its current objective values and potential marginal improvements, then selects a base solution with a probability weighted by both its objective quality and the diversity of its neighborhood. The algorithm then applies a hybrid local search operator that performs a series of controlled mutations, where each mutation is guided by a weighted combination of the item's marginal contributions to both objectives, while respecting the capacity constraint through a penalty-based feasibility check. To enhance exploration, the operator incorporates a temperature-based acceptance criterion that allows occasional uphill moves, gradually cooling down to focus on exploitation. The function returns the new neighbor solution after validating its feasibility and ensuring significant improvement in at least one of the objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a base solution with adaptive probability\n    scores = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            scores.append(0.0)\n        else:\n            # Score based on normalized objective values and marginal potential\n            norm_v1 = v1 / (np.sum(value1_lst) + 1e-6)\n            norm_v2 = v2 / (np.sum(value2_lst) + 1e-6)\n            marginal1 = np.sum(value1_lst * (1 - sol))\n            marginal2 = np.sum(value2_lst * (1 - sol))\n            score = (norm_v1 + norm_v2) * (marginal1 + marginal2)\n            scores.append(score)\n\n    if all(s == 0 for s in scores):\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        probs = np.array(scores) / np.sum(scores)\n        selected_idx = np.random.choice(len(archive), p=probs)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Hybrid local search with dynamic mutation\n    temperature = 0.5  # Initial temperature for simulated annealing\n    for _ in range(3):  # Number of mutation steps\n        # Calculate value-weighted mutation probabilities\n        marginal1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n        marginal2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n        weight_impact = weight_lst * (1 - 2 * new_solution)\n\n        # Combine objectives with temperature-based acceptance\n        scores = (marginal1 + marginal2) / (1 + abs(weight_impact))\n        temp_weight = current_weight + weight_impact\n        scores[temp_weight > capacity] = -np.inf\n\n        if np.all(scores <= -np.inf):\n            break\n\n        # Apply temperature-based selection\n        probs = np.exp(scores / temperature)\n        probs /= np.sum(probs)\n        selected_item = np.random.choice(len(scores), p=probs)\n\n        # Update solution and temperature\n        new_solution[selected_item] = 1 - new_solution[selected_item]\n        current_weight += weight_impact[selected_item]\n        temperature *= 0.9  # Cool down\n\n    return new_solution\n\n",
          "score": [
               -18.700457988079812,
               -18.666882570015645
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Objective Evolutionary Perturbation (AMEP)\", first identifies solutions in the archive with the highest combined objective values while maintaining feasibility, then applies a novel hybrid search strategy that combines Pareto-optimal boundary exploration with dynamic value-weighted item selection, where items are prioritized based on their adaptive contributions to both objectives through a multi-stage perturbation mechanism that alternates between objective-specific mutations and capacity-aware item swaps, while dynamically adjusting the exploration intensity based on the solution's proximity to the Pareto front, ensuring a balance between exploitation of high-value items and exploration of diverse solution spaces to generate high-quality neighbors across multiple objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective values\n    objectives = np.array([obj for _, obj in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Pareto-optimal boundary exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate Pareto-optimal boundary\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    # Calculate value ratios for in-items\n    value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n    in_value_ratios = value_ratios[in_items]\n\n    # Sort in-items by value ratio (descending)\n    sorted_in_items = in_items[np.argsort(-in_value_ratios)]\n\n    # Remove low-value items first\n    for idx in sorted_in_items[len(sorted_in_items)//2:]:\n        if np.random.rand() < 0.3:  # 30% chance to remove\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n\n    # Phase 3: Dynamic value-weighted item selection\n    # Calculate value weights for each objective\n    total_value1 = objectives[selected_idx, 0]\n    total_value2 = objectives[selected_idx, 1]\n\n    # Normalize value weights\n    if total_value1 + total_value2 > 0:\n        value_weight1 = total_value1 / (total_value1 + total_value2)\n        value_weight2 = total_value2 / (total_value1 + total_value2)\n    else:\n        value_weight1 = 0.5\n        value_weight2 = 0.5\n\n    # Calculate weighted value ratios for out-items\n    weighted_ratios = (value_weight1 * value1_lst + value_weight2 * value2_lst) / (weight_lst + 1e-10)\n    out_weighted_ratios = weighted_ratios[out_items]\n\n    # Sort out-items by weighted ratio (descending)\n    sorted_out_items = out_items[np.argsort(-out_weighted_ratios)]\n\n    # Add high-value items first\n    for idx in sorted_out_items[:len(sorted_out_items)//2]:\n        if weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Capacity-aware item swaps\n    if np.random.rand() < 0.4:  # 40% chance for swaps\n        # Find items to remove\n        remove_candidates = np.where(new_solution == 1)[0]\n        remove_candidates = remove_candidates[np.argsort(value_ratios[remove_candidates])]\n\n        # Find items to add\n        add_candidates = np.where(new_solution == 0)[0]\n        add_candidates = add_candidates[np.argsort(-weighted_ratios[add_candidates])]\n\n        # Perform swaps\n        for i in remove_candidates[:len(remove_candidates)//2]:\n            for j in add_candidates[:len(add_candidates)//2]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.09405106960521,
               -18.51365665271757
          ]
     }
]