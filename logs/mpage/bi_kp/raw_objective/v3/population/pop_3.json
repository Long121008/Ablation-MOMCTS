[
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (here, randomly from the archive)\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n\n    # Random flip some bits (exploration)\n    flip_indices = np.random.choice(len(base_solution), size=np.random.randint(1, min(5, len(base_solution))), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Greedy improvement step (exploitation)\n    best_improvement = 0\n    best_idx = -1\n    best_action = None  # 'add' or 'remove'\n\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            # Evaluate removal\n            delta_weight = -weight_lst[idx]\n            delta_value1 = -value1_lst[idx]\n            delta_value2 = -value2_lst[idx]\n            if current_weight + delta_weight >= 0:\n                # Use a weighted sum of the two objectives for improvement\n                improvement = 0.5 * delta_value1 + 0.5 * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'remove'\n        else:\n            # Evaluate addition\n            delta_weight = weight_lst[idx]\n            delta_value1 = value1_lst[idx]\n            delta_value2 = value2_lst[idx]\n            if current_weight + delta_weight <= capacity:\n                improvement = 0.5 * delta_value1 + 0.5 * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'add'\n\n    if best_idx != -1:\n        if best_action == 'remove':\n            new_solution[best_idx] = 0\n        else:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.85684229040964,
               -18.702342658375688
          ]
     },
     {
          "algorithm": "{The proposed heuristic function 'select_neighbor' first identifies promising solutions in the archive by evaluating their potential for improvement through a novel local search strategy that combines random selection with a weighted exploration of solution quality and diversity, favoring those with higher marginal gains in either objective while avoiding redundant searches. It then applies a hybrid local search operator that strategically flips a subset of items based on a dynamic trade-off between value improvements and weight feasibility, ensuring feasibility by prioritizing items with the highest value-weight ratios and penalizing solutions that exceed capacity. The operator also incorporates a probabilistic component to escape local optima, flipping items with a chance proportional to their marginal contribution, while maintaining a balance between exploration and exploitation. The function returns the new neighbor solution after validating its feasibility and objective improvements.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with weighted randomness based on solution quality and diversity\n    scores = []\n    for sol, _ in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            scores.append(0.0)  # Discourage infeasible solutions\n        else:\n            # Score based on marginal improvement potential\n            marginal1 = np.sum(value1_lst * (1 - sol))\n            marginal2 = np.sum(value2_lst * (1 - sol))\n            score = marginal1 + marginal2\n            scores.append(score)\n\n    if all(s == 0 for s in scores):\n        # All solutions are infeasible, select randomly\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        # Select with probability proportional to score\n        probs = np.array(scores) / np.sum(scores)\n        selected_idx = np.random.choice(len(archive), p=probs)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search operator\n    for _ in range(3):  # Number of flips per iteration\n        # Calculate marginal gains for each item\n        marginal1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n        marginal2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n\n        # Calculate weight impact\n        weight_impact = weight_lst * (1 - 2 * new_solution)\n\n        # Calculate scores combining both objectives and feasibility\n        scores = (marginal1 + marginal2) / (1 + abs(weight_impact))\n\n        # Penalize solutions that would exceed capacity\n        temp_weight = current_weight + weight_impact\n        scores[temp_weight > capacity] = -np.inf\n\n        # Select item to flip with probability proportional to score\n        if np.all(scores <= -np.inf):\n            break  # No feasible moves\n\n        probs = np.exp(scores - np.max(scores))  # Softmax for numerical stability\n        probs /= np.sum(probs)\n\n        selected_item = np.random.choice(len(scores), p=probs)\n        new_solution[selected_item] = 1 - new_solution[selected_item]\n        current_weight += weight_impact[selected_item]\n\n    return new_solution\n\n",
          "score": [
               -18.78125726298865,
               -18.394552497017067
          ]
     },
     {
          "algorithm": "{The proposed algorithm, named \"Adaptive Multi-Objective Path Relinking (AMOPR)\", first identifies the most promising solution in the archive by evaluating the combined objective values and dominance relationships, then constructs a path between this solution and a randomly selected elite solution from the archive, adaptively combining their features through a novel \"path relinking\" strategy that prioritizes items with high marginal gains in both objectives while ensuring feasibility, and finally refines the resulting solution using a dynamic \"value-weighted\" perturbation operator that adjusts the perturbation intensity based on the current solution's proximity to the Pareto front, thus balancing exploration and exploitation to generate high-quality neighbors across multiple objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the most promising solution (highest combined objective values)\n    selected_idx = np.argmax([obj[0] + obj[1] for _, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Randomly select an elite solution from the archive\n    elite_idx = np.random.choice(len(archive))\n    elite_solution = archive[elite_idx][0].copy()\n\n    # Path relinking: construct a path between base and elite solutions\n    # Identify differing items between base and elite solutions\n    differing_items = np.where(base_solution != elite_solution)[0]\n\n    if len(differing_items) > 0:\n        # Randomly select a subset of differing items to relink\n        relink_items = np.random.choice(differing_items, size=min(3, len(differing_items)), replace=False)\n\n        # Calculate marginal gains for relinking items\n        marginal_gains = []\n        for i in relink_items:\n            if base_solution[i] == 0 and elite_solution[i] == 1:\n                # Item in elite but not in base: calculate gain if added\n                if np.sum(weight_lst * new_solution) + weight_lst[i] <= capacity:\n                    gain1 = value1_lst[i]\n                    gain2 = value2_lst[i]\n                    marginal_gains.append((gain1 + gain2, i, 1))  # 1 means add item\n            elif base_solution[i] == 1 and elite_solution[i] == 0:\n                # Item in base but not in elite: calculate gain if removed\n                if np.sum(weight_lst * new_solution) - weight_lst[i] >= 0:\n                    gain1 = -value1_lst[i]\n                    gain2 = -value2_lst[i]\n                    marginal_gains.append((gain1 + gain2, i, 0))  # 0 means remove item\n\n        # Sort by marginal gains (descending)\n        marginal_gains.sort(reverse=True, key=lambda x: x[0])\n\n        # Apply the best marginal gain moves\n        current_weight = np.sum(weight_lst * new_solution)\n        for _, i, action in marginal_gains:\n            if action == 1 and new_solution[i] == 0:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n            elif action == 0 and new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Dynamic perturbation: adjust based on solution's position in objective space\n    # Calculate the solution's dominance count\n    dominance_count = 0\n    for _, obj in archive:\n        if (obj[0] > archive[selected_idx][1][0] and obj[1] >= archive[selected_idx][1][1]) or \\\n           (obj[0] >= archive[selected_idx][1][0] and obj[1] > archive[selected_idx][1][1]):\n            dominance_count += 1\n\n    # More perturbation if the solution is non-dominated (higher quality)\n    perturbation_intensity = 0.1 if dominance_count == 0 else 0.3\n\n    # Apply perturbation\n    for i in range(len(new_solution)):\n        if np.random.random() < perturbation_intensity:\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n            else:\n                if np.sum(weight_lst * new_solution) + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.69134593850977,
               -18.079555253041722
          ]
     },
     {
          "algorithm": "{The new algorithm builds upon the common backbone of selecting promising solutions from the archive and applying intelligent local search, but introduces a novel approach that combines Pareto-frontier analysis with a dynamic value-weighted mutation strategy. It first identifies the most diverse non-dominated solutions in the archive, then applies a multi-stage local search that alternates between objective-specific mutations and capacity-preserving item swaps, while dynamically adjusting mutation probabilities based on both objective values and their relative importance in the current solution space. The algorithm also incorporates a guided diversification step that strategically reintroduces items based on their marginal contribution to both objectives, while maintaining feasibility through a probabilistic capacity-aware adjustment mechanism.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Identify diverse non-dominated solutions\n    objectives = np.array([obj for _, obj in archive])\n    solutions = np.array([sol for sol, _ in archive])\n\n    # Find Pareto frontier\n    pareto_indices = []\n    for i in range(len(objectives)):\n        dominated = False\n        for j in range(len(objectives)):\n            if i != j and objectives[j, 0] >= objectives[i, 0] and objectives[j, 1] >= objectives[i, 1]:\n                if objectives[j, 0] > objectives[i, 0] or objectives[j, 1] > objectives[i, 1]:\n                    dominated = True\n                    break\n        if not dominated:\n            pareto_indices.append(i)\n\n    if not pareto_indices:\n        pareto_indices = list(range(len(archive)))\n\n    # Calculate diversity scores for Pareto solutions\n    diversity_scores = np.zeros(len(pareto_indices))\n    for i in range(len(pareto_indices)):\n        min_dist = np.inf\n        for j in range(len(pareto_indices)):\n            if i != j:\n                dist = np.sqrt((objectives[pareto_indices[i], 0] - objectives[pareto_indices[j], 0])**2 +\n                              (objectives[pareto_indices[i], 1] - objectives[pareto_indices[j], 1])**2)\n                if dist < min_dist:\n                    min_dist = dist\n        diversity_scores[i] = min_dist\n\n    # Select the most diverse Pareto solution\n    selected_idx = pareto_indices[np.argmax(diversity_scores)]\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Dynamic value-weighted mutation\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate value weights for each objective\n    total_value1 = objectives[selected_idx, 0]\n    total_value2 = objectives[selected_idx, 1]\n\n    # Normalize value weights\n    if total_value1 + total_value2 > 0:\n        value_weight1 = total_value1 / (total_value1 + total_value2)\n        value_weight2 = total_value2 / (total_value1 + total_value2)\n    else:\n        value_weight1 = 0.5\n        value_weight2 = 0.5\n\n    # Calculate mutation probabilities based on value weights\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    # Calculate marginal contributions for in-items\n    marginal_contrib1 = np.zeros(len(in_items))\n    marginal_contrib2 = np.zeros(len(in_items))\n    for i, idx in enumerate(in_items):\n        marginal_contrib1[i] = value1_lst[idx] / (total_value1 + 1e-10)\n        marginal_contrib2[i] = value2_lst[idx] / (total_value2 + 1e-10)\n\n    # Calculate mutation probabilities\n    mutation_probs = np.zeros(len(new_solution))\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Higher probability to remove items with low marginal contribution\n            pos = np.where(in_items == i)[0][0]\n            mutation_probs[i] = 0.1 * (1 - value_weight1 * marginal_contrib1[pos] - value_weight2 * marginal_contrib2[pos])\n        else:\n            # Higher probability to add items with high value-to-weight ratio\n            if weight_lst[i] <= remaining_capacity:\n                value_ratio = (value_weight1 * value1_lst[i] + value_weight2 * value2_lst[i]) / (weight_lst[i] + 1e-10)\n                mutation_probs[i] = 0.5 * value_ratio\n\n    # Normalize mutation probabilities\n    mutation_probs = mutation_probs / (np.sum(mutation_probs) + 1e-10)\n\n    # Apply mutations\n    num_mutations = min(3, len(new_solution) // 4)\n    for _ in range(num_mutations):\n        if np.sum(mutation_probs) > 0:\n            item_idx = np.random.choice(len(new_solution), p=mutation_probs)\n\n            if new_solution[item_idx] == 1:\n                # Remove item\n                new_solution[item_idx] = 0\n                current_weight -= weight_lst[item_idx]\n                remaining_capacity += weight_lst[item_idx]\n            else:\n                # Add item if it fits\n                if weight_lst[item_idx] <= remaining_capacity:\n                    new_solution[item_idx] = 1\n                    current_weight += weight_lst[item_idx]\n                    remaining_capacity -= weight_lst[item_idx]\n\n    # Phase 3: Guided diversification\n    if np.random.rand() < 0.3:  # 30% chance for diversification\n        # Calculate value-to-weight ratios for out-items\n        value_ratios = (value_weight1 * value1_lst + value_weight2 * value2_lst) / (weight_lst + 1e-10)\n\n        # Select top 20% out-items by value-to-weight ratio\n        num_candidates = max(1, len(out_items) // 5)\n        top_candidates = np.argsort(value_ratios[out_items])[-num_candidates:]\n\n        for idx in out_items[top_candidates]:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -18.683702084350653,
               -18.368473124799703
          ]
     },
     {
          "algorithm": "{The heuristic function 'select_neighbor' first identifies the most promising solution in the archive by evaluating the potential for improvement in both objectives, considering the trade-off between them. It then applies a hybrid local search strategy that combines a novel \"multi-objective swap and flip\" operator with a guided random walk to explore the solution space, ensuring feasibility by dynamically adjusting the selection of items to swap or flip based on their marginal contributions to both objectives. The operator prioritizes items with high marginal gains in either objective while respecting the capacity constraint, and the guided random walk introduces controlled diversification to escape local optima. The function intelligently selects a solution from the archive by favoring those with high \"improvement potential\" (e.g., solutions close to the Pareto front but not yet dominated) and generates a neighbor by either swapping two items or flipping a single item, with a bias toward items that improve the underperforming objective while maintaining feasibility.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the most promising solution (e.g., with highest improvement potential)\n    # Here, we select the solution with the highest sum of normalized objectives\n    normalized_objectives = np.array([(obj[0] / np.max(value1_lst), obj[1] / np.max(value2_lst)) for _, obj in archive])\n    improvement_potential = np.sum(normalized_objectives, axis=1)\n    selected_idx = np.argmax(improvement_potential)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Generate a neighbor using a hybrid local search strategy\n    # 1. Calculate current total weight and values\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # 2. Identify items to consider for flipping/swapping\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # 3. Apply a multi-objective swap and flip operator\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Randomly select an included item and an excluded item\n        included_item = np.random.choice(included_items)\n        excluded_item = np.random.choice(excluded_items)\n\n        # Calculate potential new weight and values\n        new_weight = current_weight - weight_lst[included_item] + weight_lst[excluded_item]\n        new_value1 = current_value1 - value1_lst[included_item] + value1_lst[excluded_item]\n        new_value2 = current_value2 - value2_lst[included_item] + value2_lst[excluded_item]\n\n        # Check feasibility\n        if new_weight <= capacity:\n            # Perform the swap\n            new_solution[included_item] = 0\n            new_solution[excluded_item] = 1\n        else:\n            # If swap is infeasible, try flipping an item\n            # Select an item to flip (prefer items that improve the underperforming objective)\n            if current_value1 < current_value2:\n                # Prefer items that improve value1\n                candidates = included_items[value1_lst[included_items] > value2_lst[included_items]]\n            else:\n                # Prefer items that improve value2\n                candidates = included_items[value2_lst[included_items] > value1_lst[included_items]]\n\n            if len(candidates) > 0:\n                flip_item = np.random.choice(candidates)\n                new_weight = current_weight - weight_lst[flip_item]\n                if new_weight <= capacity:\n                    new_solution[flip_item] = 0\n            else:\n                # If no candidates, randomly flip an item\n                flip_item = np.random.choice(included_items)\n                new_weight = current_weight - weight_lst[flip_item]\n                if new_weight <= capacity:\n                    new_solution[flip_item] = 0\n    else:\n        # If all items are included or excluded, perform a random flip\n        flip_item = np.random.choice(len(new_solution))\n        if new_solution[flip_item] == 1:\n            new_weight = current_weight - weight_lst[flip_item]\n            if new_weight <= capacity:\n                new_solution[flip_item] = 0\n        else:\n            new_weight = current_weight + weight_lst[flip_item]\n            if new_weight <= capacity:\n                new_solution[flip_item] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.31320176969653,
               -18.221934149935365
          ]
     },
     {
          "algorithm": "{The proposed algorithm, named \"Adaptive Objective-Weighted Greedy Exploration (AOWGE)\", first evaluates the archive to identify solutions with high potential for improvement by analyzing their objective values and dominance relationships, then applies a novel hybrid search strategy that combines greedy selection with probabilistic exploration, where items are prioritized based on their adaptive weighted contributions to both objectives while maintaining feasibility, and finally refines the solution through a dynamic perturbation mechanism that adjusts the exploration intensity based on the solution's proximity to the Pareto front, ensuring a balance between exploitation of high-value items and exploration of diverse solution spaces to generate high-quality neighbors across multiple objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a base solution with weighted randomness based on objective values and dominance\n    scores = []\n    for sol, obj in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            scores.append(0.0)\n        else:\n            # Calculate dominance count\n            dominance = 0\n            for _, other_obj in archive:\n                if (other_obj[0] > obj[0] and other_obj[1] >= obj[1]) or (other_obj[0] >= obj[0] and other_obj[1] > obj[1]):\n                    dominance += 1\n            # Score based on combined objective values and dominance\n            score = (obj[0] + obj[1]) / (1 + dominance)\n            scores.append(score)\n\n    if all(s == 0 for s in scores):\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        probs = np.array(scores) / np.sum(scores)\n        selected_idx = np.random.choice(len(archive), p=probs)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Adaptive objective-weighted greedy exploration\n    for _ in range(5):  # Number of exploration steps\n        # Calculate adaptive weights based on current solution's objective values\n        obj1_weight = 1.0 if np.sum(value1_lst * new_solution) < np.median([obj[0] for _, obj in archive]) else 0.7\n        obj2_weight = 1.0 if np.sum(value2_lst * new_solution) < np.median([obj[1] for _, obj in archive]) else 0.7\n\n        # Calculate weighted marginal gains\n        marginal_gains = []\n        for i in range(len(new_solution)):\n            if new_solution[i] == 0:\n                if current_weight + weight_lst[i] <= capacity:\n                    gain = obj1_weight * value1_lst[i] + obj2_weight * value2_lst[i]\n                    marginal_gains.append((gain, i, 1))  # 1 means add item\n            else:\n                if current_weight - weight_lst[i] >= 0:\n                    gain = - (obj1_weight * value1_lst[i] + obj2_weight * value2_lst[i])\n                    marginal_gains.append((gain, i, 0))  # 0 means remove item\n\n        if not marginal_gains:\n            break\n\n        # Sort by marginal gains (descending)\n        marginal_gains.sort(reverse=True, key=lambda x: x[0])\n\n        # Apply the best marginal gain move\n        for _, i, action in marginal_gains[:3]:  # Consider top 3 moves\n            if action == 1 and new_solution[i] == 0:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    break\n            elif action == 0 and new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    break\n\n    # Dynamic perturbation based on solution quality\n    perturbation_intensity = 0.2 if np.random.random() < 0.5 else 0.4\n    for i in range(len(new_solution)):\n        if np.random.random() < perturbation_intensity:\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n            else:\n                if np.sum(weight_lst * new_solution) + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.354955028171528,
               -17.835952915242924
          ]
     },
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select the most under-explored solution based on local variance\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = np.argmax([np.var(objectives[np.sum(np.abs(objectives - obj), axis=1) < 0.1]) for obj in objectives])\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate a candidate solution using weighted random walk\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    weights = np.random.rand(len(base_solution)) * (value1_lst + value2_lst) / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-weights)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Adaptive local search: guided item replacement and probabilistic removal\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Guided item replacement\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Find best item to replace with\n            for j in range(len(new_solution)):\n                if new_solution[j] == 0 and weight_lst[j] <= (capacity - current_weight + weight_lst[i]):\n                    if (value1_lst[j] + value2_lst[j]) > (value1_lst[i] + value2_lst[i]):\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        break\n\n    # Probabilistic item removal\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and np.random.rand() < 0.3:\n            new_solution[i] = 0\n            current_weight -= weight_lst[i]\n\n    # Combine with candidate solution\n    for i in range(len(new_solution)):\n        if candidate_solution[i] == 1 and new_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_solution[i] = 1\n\n    return new_solution\n\n",
          "score": [
               -17.95277502398577,
               -17.95995289946539
          ]
     },
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with a probability inversely proportional to its dominance\n    # Solutions with higher crowding distance (more space to improve) are more likely to be selected\n    crowding_distances = np.zeros(len(archive))\n    for i in range(len(archive)):\n        # Calculate crowding distance (simplified)\n        neighbors = [j for j in range(len(archive)) if j != i]\n        if not neighbors:\n            crowding_distances[i] = 1.0\n            continue\n        dist1 = np.abs(archive[i][1][0] - archive[neighbors[0]][1][0])\n        dist2 = np.abs(archive[i][1][1] - archive[neighbors[0]][1][1])\n        for j in neighbors[1:]:\n            dist1 = min(dist1, np.abs(archive[i][1][0] - archive[j][1][0]))\n            dist2 = min(dist2, np.abs(archive[i][1][1] - archive[j][1][1]))\n        crowding_distances[i] = dist1 + dist2\n\n    # Normalize crowding distances and use as selection probabilities\n    if np.sum(crowding_distances) > 0:\n        probs = crowding_distances / np.sum(crowding_distances)\n    else:\n        probs = np.ones(len(archive)) / len(archive)\n\n    selected_idx = np.random.choice(len(archive), p=probs)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    current_value1 = np.sum(value1_lst * base_solution)\n    current_value2 = np.sum(value2_lst * base_solution)\n\n    # Step 2: Dynamic objective weighting based on current solution's position\n    # Solutions with lower values in either objective are prioritized for improvement\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    obj_weight1 = 1.0 - (current_value1 / total_value1) if total_value1 > 0 else 0.5\n    obj_weight2 = 1.0 - (current_value2 / total_value2) if total_value2 > 0 else 0.5\n    norm = obj_weight1 + obj_weight2\n    if norm > 0:\n        obj_weight1 /= norm\n        obj_weight2 /= norm\n\n    # Step 3: Probabilistic selection of items to add/remove\n    new_solution = base_solution.copy()\n    candidates = np.where(base_solution == 1)[0]\n    non_candidates = np.where(base_solution == 0)[0]\n\n    # Remove items with low probability based on their contribution to the objectives\n    if len(candidates) > 0:\n        remove_probs = obj_weight1 * value1_lst[candidates] + obj_weight2 * value2_lst[candidates]\n        remove_probs = remove_probs / np.sum(remove_probs) if np.sum(remove_probs) > 0 else np.ones(len(candidates)) / len(candidates)\n        to_remove = np.random.choice(candidates, size=min(2, len(candidates)), p=remove_probs, replace=False)\n        for idx in to_remove:\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Add items with high probability based on their contribution to the objectives\n    if len(non_candidates) > 0 and current_weight < capacity:\n        add_probs = obj_weight1 * value1_lst[non_candidates] + obj_weight2 * value2_lst[non_candidates]\n        add_probs = add_probs / np.sum(add_probs) if np.sum(add_probs) > 0 else np.ones(len(non_candidates)) / len(non_candidates)\n        to_add = np.random.choice(non_candidates, size=min(2, len(non_candidates)), p=add_probs, replace=False)\n        for idx in to_add:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 4: Swap and rebalance operator - temporarily swap items between objectives\n    # to identify high-impact moves while maintaining feasibility\n    if len(candidates) > 0 and len(non_candidates) > 0 and current_weight < capacity:\n        # Select a pair of items to swap (one in, one out)\n        swap_out = np.random.choice(candidates)\n        swap_in = np.random.choice(non_candidates)\n        delta_weight = weight_lst[swap_in] - weight_lst[swap_out]\n        if current_weight + delta_weight <= capacity:\n            new_solution[swap_out] = 0\n            new_solution[swap_in] = 1\n            current_weight += delta_weight\n\n    return new_solution\n\n",
          "score": [
               -17.97492684555088,
               -17.818315203935917
          ]
     },
     {
          "algorithm": "{The new algorithm employs a multi-phase approach to generate high-quality neighbor solutions by first identifying the most promising solution in the archive through a combination of objective dominance and solution diversity metrics, then applying a novel adaptive local search strategy that dynamically balances exploration and exploitation. This strategy combines probabilistic item selection based on both objective values and weights, with a guided mutation phase that strategically introduces changes to the solution while maintaining feasibility. The algorithm also incorporates a solution recombination step that merges features from the selected base solution and a randomly generated candidate solution, followed by a feasibility-preserving mutation phase that systematically explores the neighborhood while respecting capacity constraints. The entire process is guided by adaptive parameters that adjust based on the current solution quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Phase 1: Select the most promising solution using a combined metric\n    objectives = np.array([obj for _, obj in archive])\n    dominance_counts = np.zeros(len(archive))\n    diversity_scores = np.zeros(len(archive))\n\n    # Calculate dominance counts (number of solutions that dominate each solution)\n    for i in range(len(archive)):\n        for j in range(len(archive)):\n            if i != j:\n                if (objectives[i, 0] >= objectives[j, 0] and objectives[i, 1] > objectives[j, 1]) or \\\n                   (objectives[i, 0] > objectives[j, 0] and objectives[i, 1] >= objectives[j, 1]):\n                    dominance_counts[i] += 1\n\n    # Calculate diversity scores (distance to nearest neighbor in objective space)\n    for i in range(len(archive)):\n        min_dist = np.inf\n        for j in range(len(archive)):\n            if i != j:\n                dist = np.sqrt((objectives[i, 0] - objectives[j, 0])**2 + (objectives[i, 1] - objectives[j, 1])**2)\n                if dist < min_dist:\n                    min_dist = dist\n        diversity_scores[i] = min_dist\n\n    # Combine metrics to select the most promising solution\n    combined_scores = (1 - dominance_counts / (len(archive) - 1)) * diversity_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Adaptive local search with probabilistic selection\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - total_weight\n\n    # Calculate selection probabilities based on normalized values and weights\n    combined_values = value1_lst + value2_lst\n    normalized_scores = combined_values / (weight_lst + 1e-10)\n    selection_probs = normalized_scores / (np.sum(normalized_scores) + 1e-10)\n\n    # Phase 3: Guided mutation with feasibility check\n    mutation_size = min(5, len(new_solution) // 3)\n    for _ in range(mutation_size):\n        # Select an item to mutate based on probabilities\n        item_idx = np.random.choice(len(new_solution), p=selection_probs)\n\n        if new_solution[item_idx] == 1:\n            # Try to remove the item if it's in the solution\n            new_solution[item_idx] = 0\n            total_weight -= weight_lst[item_idx]\n        else:\n            # Try to add the item if it fits and improves at least one objective\n            if weight_lst[item_idx] <= remaining_capacity:\n                if (value1_lst[item_idx] > 0) or (value2_lst[item_idx] > 0):\n                    new_solution[item_idx] = 1\n                    total_weight += weight_lst[item_idx]\n                    remaining_capacity -= weight_lst[item_idx]\n\n    # Phase 4: Solution recombination with random candidate\n    # Generate a random candidate solution with some items selected\n    candidate_solution = np.zeros_like(new_solution)\n    candidate_weight = 0\n    for i in range(len(new_solution)):\n        if np.random.rand() < 0.3:  # 30% chance to include each item\n            if weight_lst[i] <= (capacity - candidate_weight):\n                candidate_solution[i] = 1\n                candidate_weight += weight_lst[i]\n\n    # Recombine solutions by taking items that are in either solution\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -17.836191286975296,
               -17.610764910920075
          ]
     },
     {
          "algorithm": "{The new algorithm employs a multi-phase approach that first identifies the most diverse solution in the archive through a combination of objective space distance and solution structure metrics, then applies a novel adaptive local search strategy that dynamically balances exploration and exploitation. This strategy combines probabilistic item selection based on both objective values and weights, with a guided mutation phase that strategically introduces changes to the solution while maintaining feasibility, followed by a solution recombination step that merges features from the selected base solution and a randomly generated candidate solution, and finally a feasibility-preserving mutation phase that systematically explores the neighborhood while respecting capacity constraints. The entire process is guided by adaptive parameters that adjust based on the current solution quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Phase 1: Select the most diverse solution\n    objectives = np.array([obj for _, obj in archive])\n    diversity_scores = np.zeros(len(archive))\n\n    # Calculate diversity scores (distance to nearest neighbor in objective space)\n    for i in range(len(archive)):\n        min_dist = np.inf\n        for j in range(len(archive)):\n            if i != j:\n                dist = np.sqrt((objectives[i, 0] - objectives[j, 0])**2 + (objectives[i, 1] - objectives[j, 1])**2)\n                if dist < min_dist:\n                    min_dist = dist\n        diversity_scores[i] = min_dist\n\n    selected_idx = np.argmax(diversity_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Adaptive local search with probabilistic selection\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - total_weight\n\n    # Calculate selection probabilities based on normalized values and weights\n    combined_values = value1_lst + value2_lst\n    normalized_scores = combined_values / (weight_lst + 1e-10)\n    selection_probs = normalized_scores / (np.sum(normalized_scores) + 1e-10)\n\n    # Phase 3: Guided mutation with feasibility check\n    mutation_size = min(5, len(new_solution) // 3)\n    for _ in range(mutation_size):\n        # Select an item to mutate based on probabilities\n        item_idx = np.random.choice(len(new_solution), p=selection_probs)\n\n        if new_solution[item_idx] == 1:\n            # Try to remove the item if it's in the solution\n            new_solution[item_idx] = 0\n            total_weight -= weight_lst[item_idx]\n        else:\n            # Try to add the item if it fits and improves at least one objective\n            if weight_lst[item_idx] <= remaining_capacity:\n                if (value1_lst[item_idx] > 0) or (value2_lst[item_idx] > 0):\n                    new_solution[item_idx] = 1\n                    total_weight += weight_lst[item_idx]\n                    remaining_capacity -= weight_lst[item_idx]\n\n    # Phase 4: Solution recombination with random candidate\n    # Generate a random candidate solution with some items selected\n    candidate_solution = np.zeros_like(new_solution)\n    candidate_weight = 0\n    for i in range(len(new_solution)):\n        if np.random.rand() < 0.3:  # 30% chance to include each item\n            if weight_lst[i] <= (capacity - candidate_weight):\n                candidate_solution[i] = 1\n                candidate_weight += weight_lst[i]\n\n    # Recombine solutions by taking items that are in either solution\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -17.392733136064805,
               -17.308530107504936
          ]
     }
]