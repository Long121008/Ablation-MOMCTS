[
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution (here, randomly from the archive)\n    selected_idx = np.random.randint(0, len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply hybrid local search\n    new_solution = base_solution.copy()\n\n    # Random flip some bits (exploration)\n    flip_indices = np.random.choice(len(base_solution), size=np.random.randint(1, min(5, len(base_solution))), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try to add the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Greedy improvement step (exploitation)\n    best_improvement = 0\n    best_idx = -1\n    best_action = None  # 'add' or 'remove'\n\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            # Evaluate removal\n            delta_weight = -weight_lst[idx]\n            delta_value1 = -value1_lst[idx]\n            delta_value2 = -value2_lst[idx]\n            if current_weight + delta_weight >= 0:\n                # Use a weighted sum of the two objectives for improvement\n                improvement = 0.5 * delta_value1 + 0.5 * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'remove'\n        else:\n            # Evaluate addition\n            delta_weight = weight_lst[idx]\n            delta_value1 = value1_lst[idx]\n            delta_value2 = value2_lst[idx]\n            if current_weight + delta_weight <= capacity:\n                improvement = 0.5 * delta_value1 + 0.5 * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'add'\n\n    if best_idx != -1:\n        if best_action == 'remove':\n            new_solution[best_idx] = 0\n        else:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.85684229040964,
               -18.702342658375688
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Driven Adaptive Neighborhood Evolution with Dynamic Feasibility Preservation (O-DANE-DFP)\", combines a multi-phase approach that first identifies critical items using an adaptive objective-driven selection mechanism, followed by a probabilistic neighborhood exploration phase that dynamically balances between objective improvements and feasibility preservation, and concludes with a solution consolidation step that merges features from the base solution and a greedily constructed candidate solution while systematically exploring the neighborhood while respecting capacity constraints. This approach leverages adaptive objective weighting to prioritize items that show the most potential for improvement across both objectives, while maintaining feasibility through dynamic capacity checks and probabilistic acceptance criteria that balance exploration and exploitation.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest combined objective value\n    objectives = np.array([obj for _, obj in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate candidate solution using adaptive objective-driven selection\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    objective_ratio = np.random.uniform(0.4, 0.6)  # Dynamic objective balance factor\n    combined_values = objective_ratio * value1_lst + (1 - objective_ratio) * value2_lst\n    value_to_weight_ratio = combined_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-value_to_weight_ratio)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Probabilistic neighborhood exploration with dynamic feasibility preservation\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Identify critical items and explore replacements\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and np.random.rand() < 0.4:\n            # Find items that can improve at least one objective while preserving feasibility\n            potential_replacements = []\n            for j in range(len(new_solution)):\n                if new_solution[j] == 0 and weight_lst[j] <= capacity:\n                    weight_diff = weight_lst[j] - weight_lst[i]\n                    if current_weight + weight_diff <= capacity:\n                        value_diff1 = value1_lst[j] - value1_lst[i]\n                        value_diff2 = value2_lst[j] - value2_lst[i]\n                        if (value_diff1 > 0 or value_diff2 > 0) and np.random.rand() < 0.6:  # Probabilistic acceptance\n                            potential_replacements.append((j, value_diff1 + value_diff2))\n\n            if potential_replacements:\n                best_replacement = max(potential_replacements, key=lambda x: x[1])\n                new_solution[i] = 0\n                new_solution[best_replacement[0]] = 1\n                current_weight += weight_lst[best_replacement[0]] - weight_lst[i]\n\n    # Solution consolidation with candidate merging\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    final_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            final_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return final_solution\n\n",
          "score": [
               -19.220895827039115,
               -18.517466624844758
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Objective Neighborhood Exploration with Dynamic Objective Balancing (AMONE-DOB)\", first selects a solution from the archive that exhibits high diversity in objective contributions and then applies a hybrid search strategy that combines adaptive objective weighting with a novel neighborhood exploration mechanism. This mechanism dynamically balances the exploration of both objectives through a three-stage process: first, it identifies critical items using a probabilistic selection based on their adaptive weighted contributions to both objectives while maintaining feasibility, second, it performs a guided item replacement phase that strategically swaps items between objectives to improve both values, and third, it incorporates a solution refinement step that merges features from the selected base solution and a randomly generated candidate solution while systematically exploring the neighborhood while respecting capacity constraints. The entire process is guided by adaptive parameters that adjust based on the current solution quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = np.argmax(np.std(objectives, axis=0))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate candidate solution using adaptive objective weighting\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    alpha = np.random.uniform(0.3, 0.7)  # Dynamic objective balance factor\n    weighted_values = alpha * value1_lst + (1 - alpha) * value2_lst\n    weights = weighted_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-weights)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Adaptive neighborhood exploration\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Critical item identification and replacement\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and np.random.rand() < 0.3:\n            # Find replacement items that improve both objectives\n            potential_replacements = []\n            for j in range(len(new_solution)):\n                if new_solution[j] == 0 and weight_lst[j] <= current_weight + weight_lst[j] - weight_lst[i]:\n                    value_diff1 = value1_lst[j] - value1_lst[i]\n                    value_diff2 = value2_lst[j] - value2_lst[i]\n                    if value_diff1 > 0 or value_diff2 > 0:\n                        potential_replacements.append((j, value_diff1 + value_diff2))\n\n            if potential_replacements:\n                best_replacement = max(potential_replacements, key=lambda x: x[1])\n                new_solution[i] = 0\n                new_solution[best_replacement[0]] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement[0]]\n\n    # Solution refinement with candidate merging\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -18.76309843274899,
               -18.686923793127768
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Dimensional Solution Exploration with Dynamic Objective Fusion (AMSE-DOF)\", first identifies the solution in the archive with the highest combined objective value while considering the trade-off between both objectives, then applies a hybrid search strategy that combines adaptive objective fusion with a novel neighborhood exploration mechanism. This mechanism dynamically balances the exploration of both objectives through a four-stage process: first, it performs a probabilistic selection of items based on their adaptive fusion of both objectives while maintaining feasibility, second, it conducts a guided item replacement phase that strategically swaps items between objectives to improve both values, third, it incorporates a solution refinement step that merges features from the selected base solution and a randomly generated candidate solution while systematically exploring the neighborhood while respecting capacity constraints, and fourth, it applies a dynamic objective fusion adjustment phase that adapts the weighting of the objectives based on the current solution's performance and the archive's diversity. The entire process is guided by adaptive parameters that adjust based on the current solution quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select solution with highest combined objective value considering trade-off\n    objectives = np.array([(v1 + v2) / (1 + abs(v1 - v2)) for _, (v1, v2) in archive])\n    selected_idx = np.argmax(objectives)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Generate candidate solution using adaptive objective fusion\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    beta = np.random.uniform(0.4, 0.6)  # Dynamic fusion factor\n    fused_values = beta * value1_lst + (1 - beta) * value2_lst\n    weights = fused_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-weights)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Adaptive neighborhood exploration with guided item replacement\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Identify critical items and potential replacements\n    critical_items = np.where(new_solution == 1)[0]\n    for i in critical_items:\n        if np.random.rand() < 0.4:\n            # Find replacement items that improve both objectives\n            potential_replacements = []\n            for j in range(len(new_solution)):\n                if new_solution[j] == 0 and weight_lst[j] <= current_weight + weight_lst[j] - weight_lst[i]:\n                    value_diff1 = value1_lst[j] - value1_lst[i]\n                    value_diff2 = value2_lst[j] - value2_lst[i]\n                    if value_diff1 > 0 and value_diff2 > 0:\n                        potential_replacements.append((j, value_diff1 + value_diff2))\n\n            if potential_replacements:\n                best_replacement = max(potential_replacements, key=lambda x: x[1])\n                new_solution[i] = 0\n                new_solution[best_replacement[0]] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement[0]]\n\n    # Step 4: Solution refinement with candidate merging and dynamic fusion adjustment\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Dynamic fusion adjustment based on current solution performance\n    current_v1 = np.sum(value1_lst[new_solution == 1])\n    current_v2 = np.sum(value2_lst[new_solution == 1])\n    if abs(current_v1 - current_v2) > np.mean([v1 - v2 for _, (v1, v2) in archive]):\n        beta = np.random.uniform(0.3, 0.7)  # Adjust fusion factor if objectives are imbalanced\n\n    return new_solution\n\n",
          "score": [
               -18.84941872503954,
               -18.662616742622543
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Objective Evolutionary Perturbation (AMEP)\", first identifies solutions in the archive with the highest combined objective values while maintaining feasibility, then applies a novel hybrid search strategy that combines Pareto-optimal boundary exploration with dynamic value-weighted item selection, where items are prioritized based on their adaptive contributions to both objectives through a multi-stage perturbation mechanism that alternates between objective-specific mutations and capacity-aware item swaps, while dynamically adjusting the exploration intensity based on the solution's proximity to the Pareto front, ensuring a balance between exploitation of high-value items and exploration of diverse solution spaces to generate high-quality neighbors across multiple objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective values\n    objectives = np.array([obj for _, obj in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_values)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Pareto-optimal boundary exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate Pareto-optimal boundary\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    # Calculate value ratios for in-items\n    value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n    in_value_ratios = value_ratios[in_items]\n\n    # Sort in-items by value ratio (descending)\n    sorted_in_items = in_items[np.argsort(-in_value_ratios)]\n\n    # Remove low-value items first\n    for idx in sorted_in_items[len(sorted_in_items)//2:]:\n        if np.random.rand() < 0.3:  # 30% chance to remove\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n\n    # Phase 3: Dynamic value-weighted item selection\n    # Calculate value weights for each objective\n    total_value1 = objectives[selected_idx, 0]\n    total_value2 = objectives[selected_idx, 1]\n\n    # Normalize value weights\n    if total_value1 + total_value2 > 0:\n        value_weight1 = total_value1 / (total_value1 + total_value2)\n        value_weight2 = total_value2 / (total_value1 + total_value2)\n    else:\n        value_weight1 = 0.5\n        value_weight2 = 0.5\n\n    # Calculate weighted value ratios for out-items\n    weighted_ratios = (value_weight1 * value1_lst + value_weight2 * value2_lst) / (weight_lst + 1e-10)\n    out_weighted_ratios = weighted_ratios[out_items]\n\n    # Sort out-items by weighted ratio (descending)\n    sorted_out_items = out_items[np.argsort(-out_weighted_ratios)]\n\n    # Add high-value items first\n    for idx in sorted_out_items[:len(sorted_out_items)//2]:\n        if weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Capacity-aware item swaps\n    if np.random.rand() < 0.4:  # 40% chance for swaps\n        # Find items to remove\n        remove_candidates = np.where(new_solution == 1)[0]\n        remove_candidates = remove_candidates[np.argsort(value_ratios[remove_candidates])]\n\n        # Find items to add\n        add_candidates = np.where(new_solution == 0)[0]\n        add_candidates = add_candidates[np.argsort(-weighted_ratios[add_candidates])]\n\n        # Perform swaps\n        for i in remove_candidates[:len(remove_candidates)//2]:\n            for j in add_candidates[:len(add_candidates)//2]:\n                if (current_weight - weight_lst[i] + weight_lst[j]) <= capacity:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.09405106960521,
               -18.51365665271757
          ]
     },
     {
          "algorithm": "{The proposed heuristic function 'select_neighbor' employs a novel hybrid local search strategy that combines adaptive neighborhood exploration with a probabilistic selection mechanism and a value-weighted mutation operator, while dynamically balancing exploration and exploitation through a temperature-based acceptance criterion and a penalty-based feasibility check. It first evaluates each solution in the archive based on its current objective values and potential marginal improvements, then selects a base solution with a probability weighted by both its objective quality and the diversity of its neighborhood. The algorithm then applies a hybrid local search operator that performs a series of controlled mutations, where each mutation is guided by a weighted combination of the item's marginal contributions to both objectives, while respecting the capacity constraint through a penalty-based feasibility check. To enhance exploration, the operator incorporates a temperature-based acceptance criterion that allows occasional uphill moves, gradually cooling down to focus on exploitation. The function returns the new neighbor solution after validating its feasibility and ensuring significant improvement in at least one of the objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a base solution with adaptive probability\n    scores = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            scores.append(0.0)\n        else:\n            # Score based on normalized objective values and marginal potential\n            norm_v1 = v1 / (np.sum(value1_lst) + 1e-6)\n            norm_v2 = v2 / (np.sum(value2_lst) + 1e-6)\n            marginal1 = np.sum(value1_lst * (1 - sol))\n            marginal2 = np.sum(value2_lst * (1 - sol))\n            score = (norm_v1 + norm_v2) * (marginal1 + marginal2)\n            scores.append(score)\n\n    if all(s == 0 for s in scores):\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        probs = np.array(scores) / np.sum(scores)\n        selected_idx = np.random.choice(len(archive), p=probs)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Hybrid local search with dynamic mutation\n    temperature = 0.5  # Initial temperature for simulated annealing\n    for _ in range(3):  # Number of mutation steps\n        # Calculate value-weighted mutation probabilities\n        marginal1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n        marginal2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n        weight_impact = weight_lst * (1 - 2 * new_solution)\n\n        # Combine objectives with temperature-based acceptance\n        scores = (marginal1 + marginal2) / (1 + abs(weight_impact))\n        temp_weight = current_weight + weight_impact\n        scores[temp_weight > capacity] = -np.inf\n\n        if np.all(scores <= -np.inf):\n            break\n\n        # Apply temperature-based selection\n        probs = np.exp(scores / temperature)\n        probs /= np.sum(probs)\n        selected_item = np.random.choice(len(scores), p=probs)\n\n        # Update solution and temperature\n        new_solution[selected_item] = 1 - new_solution[selected_item]\n        current_weight += weight_impact[selected_item]\n        temperature *= 0.9  # Cool down\n\n    return new_solution\n\n",
          "score": [
               -18.700457988079812,
               -18.666882570015645
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Centric Adaptive Greedy Exploration with Dynamic Objective Fusion (O-CAGE-DOF)\", first selects a solution from the archive that exhibits high variance in objective contributions and then applies a hybrid search strategy that combines adaptive objective fusion with a novel neighborhood exploration mechanism. This mechanism dynamically balances the exploration of both objectives through a four-stage process: first, it identifies critical items using a probabilistic selection based on their adaptive weighted contributions to both objectives while maintaining feasibility, second, it performs a guided item fusion phase that merges features from the selected base solution and a randomly generated candidate solution while systematically exploring the neighborhood while respecting capacity constraints, third, it incorporates a solution diversification step that strategically swaps items between objectives to improve both values, and fourth, it applies a solution refinement step that uses a weighted sum of both objectives to further optimize the solution. The entire process is guided by adaptive parameters that adjust based on the current solution quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest objective variance\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = np.argmax(np.std(objectives, axis=0))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate candidate solution using objective fusion\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    beta = np.random.uniform(0.4, 0.6)  # Dynamic objective fusion factor\n    fused_values = beta * value1_lst + (1 - beta) * value2_lst\n    weights = fused_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-weights)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Initialize new solution\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Guided item fusion\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    # Solution diversification\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and np.random.rand() < 0.2:\n            # Find replacement items that improve both objectives\n            potential_replacements = []\n            for j in range(len(new_solution)):\n                if new_solution[j] == 0 and weight_lst[j] <= current_weight + weight_lst[j] - weight_lst[i]:\n                    value_diff1 = value1_lst[j] - value1_lst[i]\n                    value_diff2 = value2_lst[j] - value2_lst[i]\n                    if value_diff1 > 0 or value_diff2 > 0:\n                        potential_replacements.append((j, value_diff1 + value_diff2))\n\n            if potential_replacements:\n                best_replacement = max(potential_replacements, key=lambda x: x[1])\n                new_solution[i] = 0\n                new_solution[best_replacement[0]] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement[0]]\n\n    # Solution refinement with weighted objective improvement\n    gamma = np.random.uniform(0.3, 0.7)  # Dynamic objective weighting factor\n    best_improvement = 0\n    best_idx = -1\n    best_action = None\n\n    for idx in range(len(new_solution)):\n        if new_solution[idx] == 1:\n            # Evaluate removal\n            delta_weight = -weight_lst[idx]\n            delta_value1 = -value1_lst[idx]\n            delta_value2 = -value2_lst[idx]\n            if current_weight + delta_weight >= 0:\n                improvement = gamma * delta_value1 + (1 - gamma) * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'remove'\n        else:\n            # Evaluate addition\n            delta_weight = weight_lst[idx]\n            delta_value1 = value1_lst[idx]\n            delta_value2 = value2_lst[idx]\n            if current_weight + delta_weight <= capacity:\n                improvement = gamma * delta_value1 + (1 - gamma) * delta_value2\n                if improvement > best_improvement:\n                    best_improvement = improvement\n                    best_idx = idx\n                    best_action = 'add'\n\n    if best_idx != -1:\n        if best_action == 'remove':\n            new_solution[best_idx] = 0\n        else:\n            new_solution[best_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.99594970203511,
               -18.495149066765517
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Objective Neighborhood Exploration with Dynamic Objective Balancing (AMONE-DOB)\", first selects a solution from the archive that exhibits high diversity in objective contributions and then applies a hybrid search strategy that combines adaptive objective weighting with a novel neighborhood exploration mechanism. This mechanism dynamically balances the exploration of both objectives through a three-stage process: first, it identifies critical items using a probabilistic selection based on their adaptive weighted contributions to both objectives while maintaining feasibility, second, it performs a guided item replacement phase that strategically swaps items between objectives to improve both values, and third, it incorporates a solution refinement step that merges features from the selected base solution and a randomly generated candidate solution while systematically exploring the neighborhood while respecting capacity constraints. The entire process is guided by adaptive parameters that adjust based on the current solution quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select solution with highest objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = np.argmax(np.std(objectives, axis=0))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate candidate solution using adaptive objective weighting\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    alpha = np.random.uniform(0.3, 0.7)  # Dynamic objective balance factor\n    weighted_values = alpha * value1_lst + (1 - alpha) * value2_lst\n    weights = weighted_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-weights)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Adaptive neighborhood exploration\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Critical item identification and replacement\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1 and np.random.rand() < 0.3:\n            # Find replacement items that improve both objectives\n            potential_replacements = []\n            for j in range(len(new_solution)):\n                if new_solution[j] == 0 and weight_lst[j] <= current_weight + weight_lst[j] - weight_lst[i]:\n                    value_diff1 = value1_lst[j] - value1_lst[i]\n                    value_diff2 = value2_lst[j] - value2_lst[i]\n                    if value_diff1 > 0 or value_diff2 > 0:\n                        potential_replacements.append((j, value_diff1 + value_diff2))\n\n            if potential_replacements:\n                best_replacement = max(potential_replacements, key=lambda x: x[1])\n                new_solution[i] = 0\n                new_solution[best_replacement[0]] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement[0]]\n\n    # Solution refinement with candidate merging\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -18.803208889092694,
               -18.528196117818283
          ]
     },
     {
          "algorithm": "{The proposed heuristic function 'select_neighbor' employs a novel adaptive neighborhood exploration strategy that dynamically balances between local improvement and global diversification by combining a probabilistic selection mechanism with a value-weighted mutation operator. It first evaluates each solution in the archive based on its current objective values and potential marginal improvements, then selects a base solution with a probability weighted by both its objective quality and the diversity of its neighborhood. The algorithm then applies a hybrid local search operator that performs a series of controlled mutations, where each mutation is guided by a weighted combination of the item's marginal contributions to both objectives, while respecting the capacity constraint through a penalty-based feasibility check. To enhance exploration, the operator incorporates a temperature-based acceptance criterion that allows occasional uphill moves, gradually cooling down to focus on exploitation. The function returns the new neighbor solution after validating its feasibility and ensuring significant improvement in at least one of the objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a base solution with adaptive probability\n    scores = []\n    for sol, (v1, v2) in archive:\n        total_weight = np.sum(weight_lst * sol)\n        if total_weight > capacity:\n            scores.append(0.0)\n        else:\n            # Score based on normalized objective values and marginal potential\n            norm_v1 = v1 / (np.sum(value1_lst) + 1e-6)\n            norm_v2 = v2 / (np.sum(value2_lst) + 1e-6)\n            marginal1 = np.sum(value1_lst * (1 - sol))\n            marginal2 = np.sum(value2_lst * (1 - sol))\n            score = (norm_v1 + norm_v2) * (marginal1 + marginal2)\n            scores.append(score)\n\n    if all(s == 0 for s in scores):\n        base_solution = random.choice(archive)[0].copy()\n    else:\n        probs = np.array(scores) / np.sum(scores)\n        selected_idx = np.random.choice(len(archive), p=probs)\n        base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Adaptive mutation operator\n    temperature = 0.5  # Initial temperature for simulated annealing\n    for _ in range(3):  # Number of mutation steps\n        # Calculate value-weighted mutation probabilities\n        marginal1 = value1_lst * (1 - new_solution) - value1_lst * new_solution\n        marginal2 = value2_lst * (1 - new_solution) - value2_lst * new_solution\n        weight_impact = weight_lst * (1 - 2 * new_solution)\n\n        # Combine objectives with temperature-based acceptance\n        scores = (marginal1 + marginal2) / (1 + abs(weight_impact))\n        temp_weight = current_weight + weight_impact\n        scores[temp_weight > capacity] = -np.inf\n\n        if np.all(scores <= -np.inf):\n            break\n\n        # Apply temperature-based selection\n        probs = np.exp(scores / temperature)\n        probs /= np.sum(probs)\n        selected_item = np.random.choice(len(scores), p=probs)\n\n        # Update solution and temperature\n        new_solution[selected_item] = 1 - new_solution[selected_item]\n        current_weight += weight_impact[selected_item]\n        temperature *= 0.9  # Cool down\n\n    return new_solution\n\n",
          "score": [
               -18.906346342175787,
               -18.508733039037597
          ]
     },
     {
          "algorithm": "{The new algorithm, named \"Objective-Driven Adaptive Neighborhood Search with Dynamic Trade-off Exploration (O-DANSE-DTE)\", first selects a solution from the archive that exhibits high marginal contributions to both objectives, then applies a hybrid search strategy that combines adaptive objective trade-off analysis with a novel neighborhood exploration mechanism. This mechanism dynamically explores the Pareto front by first identifying items with high marginal contributions to both objectives, then performs a probabilistic item swap phase that strategically reallocates items between objectives based on their adaptive trade-off values, followed by a solution refinement step that merges features from the selected base solution and a randomly generated candidate solution while systematically exploring the neighborhood while respecting capacity constraints. The entire process is guided by adaptive parameters that adjust based on the current solution quality and the archive's diversity, ensuring diverse and high-quality solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest marginal contributions to both objectives\n    objectives = np.array([obj for _, obj in archive])\n    marginal_contributions = objectives - np.min(objectives, axis=0)\n    selected_idx = np.argmax(np.sum(marginal_contributions, axis=1))\n    base_solution = archive[selected_idx][0].copy()\n\n    # Generate candidate solution using adaptive trade-off analysis\n    candidate_solution = np.zeros_like(base_solution)\n    remaining_capacity = capacity\n    beta = np.random.uniform(0.4, 0.6)  # Dynamic trade-off factor\n    trade_off_values = (1 - beta) * value1_lst + beta * value2_lst\n    weights = trade_off_values / (weight_lst + 1e-10)\n    sorted_indices = np.argsort(-weights)\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity and candidate_solution[idx] == 0:\n            candidate_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Adaptive neighborhood exploration with probabilistic swaps\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate marginal values for current solution\n    current_value1 = np.sum(value1_lst[new_solution == 1])\n    current_value2 = np.sum(value2_lst[new_solution == 1])\n\n    # Probabilistic item swap phase\n    for i in range(len(new_solution)):\n        if np.random.rand() < 0.4:  # 40% chance to consider swapping\n            if new_solution[i] == 1:\n                # Find items to swap with\n                potential_swaps = []\n                for j in range(len(new_solution)):\n                    if new_solution[j] == 0 and weight_lst[j] <= current_weight + weight_lst[j] - weight_lst[i]:\n                        # Calculate trade-off improvement\n                        delta_value1 = value1_lst[j] - value1_lst[i]\n                        delta_value2 = value2_lst[j] - value2_lst[i]\n                        trade_off_improvement = (1 - beta) * delta_value1 + beta * delta_value2\n                        if trade_off_improvement > 0:\n                            potential_swaps.append((j, trade_off_improvement))\n\n                if potential_swaps:\n                    best_swap = max(potential_swaps, key=lambda x: x[1])\n                    new_solution[i] = 0\n                    new_solution[best_swap[0]] = 1\n                    current_weight = current_weight - weight_lst[i] + weight_lst[best_swap[0]]\n                    current_value1 += value1_lst[best_swap[0]] - value1_lst[i]\n                    current_value2 += value2_lst[best_swap[0]] - value2_lst[i]\n\n    # Solution refinement with candidate merging\n    combined_items = np.where((new_solution == 1) | (candidate_solution == 1))[0]\n    np.random.shuffle(combined_items)\n\n    # Rebuild solution with combined items while respecting capacity\n    new_solution = np.zeros_like(new_solution)\n    current_weight = 0\n    for idx in combined_items:\n        if weight_lst[idx] <= (capacity - current_weight):\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -18.773335462653698,
               -18.5973125600552
          ]
     }
]