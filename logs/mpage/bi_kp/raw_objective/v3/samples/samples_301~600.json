[
     {
          "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm, named \"Dual-Objective Harmony Search with Adaptive Constraint Navigation and Elite Fusion (DOHS-ACNEF)\", combines elements from the provided algorithms by incorporating a harmony search-inspired approach that dynamically balances between objective-centric and capacity-aware operations, with adaptive constraint handling through probabilistic item selection and removal that maintains feasibility, while systematically incorporating features from elite solutions through a novel fusion mechanism that alternates between objective-specific and capacity-focused operations, all while employing a dynamic neighborhood exploration strategy that adapts to the current solution's quality and diversity in the archive.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dual-Objective Harmony Selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n\n    # Calculate harmony weights based on objective diversity and quality\n    quality_weights = 1 - np.std(normalized_obj, axis=0)\n    diversity_weights = np.mean(normalized_obj, axis=0)\n    combined_weights = 0.6 * quality_weights + 0.4 * diversity_weights\n    combined_weights /= np.sum(combined_weights)\n\n    # Select solution with highest combined score\n    weighted_scores = np.dot(normalized_obj, combined_weights)\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate initial state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Phase 2: Adaptive Constraint Navigation\n    # Determine operation mode (objective-focused or capacity-focused)\n    if np.random.rand() < 0.7:\n        # Objective-focused operation\n        if np.random.rand() < 0.5:\n            # Value-to-weight ratio based removal\n            in_items = np.where(new_solution == 1)[0]\n            value_ratio = (value1_lst[in_items] + value2_lst[in_items]) / (weight_lst[in_items] + 1e-10)\n            sorted_items = in_items[np.argsort(value_ratio)]\n            for idx in sorted_items[:len(sorted_items)//2]:\n                if np.random.rand() < 0.5:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n        else:\n            # Probabilistic removal based on objective importance\n            in_items = np.where(new_solution == 1)[0]\n            for idx in in_items:\n                if np.random.rand() < (0.3 + 0.4 * combined_weights[0] + 0.3 * combined_weights[1]):\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n\n        # Add items based on combined objective\n        out_items = np.where(new_solution == 0)[0]\n        combined_ratio = (combined_weights[0] * value1_lst[out_items] + combined_weights[1] * value2_lst[out_items]) / (weight_lst[out_items] + 1e-10)\n        sorted_out = out_items[np.argsort(-combined_ratio)]\n        for idx in sorted_out[:len(sorted_out)//2]:\n            if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.6:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n    else:\n        # Capacity-focused operation\n        # Remove items with low capacity utilization\n        in_items = np.where(new_solution == 1)[0]\n        capacity_util = weight_lst[in_items] / (capacity + 1e-10)\n        sorted_items = in_items[np.argsort(capacity_util)]\n        for idx in sorted_items[:len(sorted_items)//2]:\n            if np.random.rand() < 0.4:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n\n        # Add items that fill capacity gaps\n        out_items = np.where(new_solution == 0)[0]\n        sorted_out = out_items[np.argsort(-weight_lst[out_items])]\n        for idx in sorted_out[:len(sorted_out)//2]:\n            if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.5:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 3: Elite Fusion with Dynamic Perturbation\n    elite_indices = np.random.choice(len(archive), size=min(2, len(archive)), replace=False)\n    for idx in elite_indices:\n        elite_solution = archive[idx][0]\n        # Create hybrid solution by combining features\n        hybrid_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n        np.random.shuffle(hybrid_items)\n\n        temp_solution = np.zeros_like(new_solution)\n        temp_weight = 0\n        for item in hybrid_items:\n            if weight_lst[item] <= (capacity - temp_weight):\n                temp_solution[item] = 1\n                temp_weight += weight_lst[item]\n\n        # Accept if it improves the combined objective\n        temp_obj1 = np.sum(value1_lst[temp_solution == 1])\n        temp_obj2 = np.sum(value2_lst[temp_solution == 1])\n        current_obj1 = np.sum(value1_lst[new_solution == 1])\n        current_obj2 = np.sum(value2_lst[new_solution == 1])\n\n        if (temp_obj1 * combined_weights[0] + temp_obj2 * combined_weights[1]) > \\\n           (current_obj1 * combined_weights[0] + current_obj2 * combined_weights[1]) and \\\n           np.random.rand() < 0.7:\n            new_solution = temp_solution\n            current_weight = temp_weight\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm, named \"Objective-Aware Hybrid Evolutionary Neighborhood Exploration (OAHENE)\", combines a novel multi-objective solution selection mechanism that dynamically prioritizes solutions based on their objective trade-off characteristics with a hybrid neighborhood generation strategy that integrates objective-specific item swaps with capacity-aware perturbations, while incorporating a solution refinement phase that merges features from diverse elite solutions through a probabilistic item selection mechanism that balances objective improvements with solution diversity, all while systematically exploring the solution space through an adaptive perturbation schedule that adjusts its intensity based on the current solution's proximity to the Pareto front and its objective trade-off characteristics.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with balanced objective trade-off\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-10)\n    tradeoff_scores = np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    selected_idx = np.argmin(tradeoff_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-specific item swaps with capacity check\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-specific efficiencies\n    value1_efficiency = value1_lst / (weight_lst + 1e-10)\n    value2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by efficiency for each objective\n    sorted_items1 = np.argsort(-value1_efficiency)\n    sorted_items2 = np.argsort(-value2_efficiency)\n\n    # Perform alternating objective-driven swaps\n    for i in sorted_items1:\n        if new_solution[i] == 1 and np.random.rand() < 0.4:\n            # Try to replace with best value2 item\n            for j in sorted_items2:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if value2_lst[j] > value2_lst[i]:\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Adaptive capacity-aware perturbations\n    perturbation_intensity = 0.2 + 0.3 * (1 - (objectives[selected_idx][0] * objectives[selected_idx][1]) / (np.sum(objectives[:, 0]) * np.sum(objectives[:, 1])))\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.5:  # Moderate probability to remove\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.3:  # Lower probability to add\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution merging with trade-off aware selection\n    if len(archive) > 1:\n        # Select elite solutions based on their trade-off characteristics\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            elite_obj = objectives[elite_idx]\n            tradeoff_factor = np.abs(elite_obj[0] - elite_obj[1]) / (elite_obj[0] + elite_obj[1] + 1e-10)\n\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    if np.random.rand() < 0.5 * (1 + tradeoff_factor):  # Adjust probability based on trade-off\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one long, detail sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 301,
          "algorithm": "{The new algorithm, named \"Multi-Objective Evolutionary Exploration with Adaptive Trade-off Navigation and Elite Integration (MOEE-ATNEI)\", combines a dynamic solution selection mechanism that prioritizes solutions based on their objective diversity and trade-off characteristics with a hybrid neighborhood generation strategy that alternates between objective-specific item replacements and capacity-aware perturbations, while incorporating a novel elite integration phase that systematically merges features from diverse elite solutions through a probabilistic item selection mechanism that balances objective improvements with solution feasibility, all while employing an adaptive trade-off navigation strategy that dynamically adjusts its exploration focus based on the current solution's objective trade-off characteristics and its proximity to the Pareto front, ensuring a comprehensive and adaptive search process that effectively balances exploration and exploitation across multiple objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic Solution Selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-10)\n    diversity_scores = np.std(normalized_obj, axis=0)\n    tradeoff_scores = np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n\n    # Combine selection criteria\n    combined_scores = 0.4 * diversity_scores[0] + 0.4 * diversity_scores[1] + 0.2 * (1 - tradeoff_scores)\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate initial state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Phase 2: Adaptive Trade-off Navigation\n    tradeoff_factor = tradeoff_scores[selected_idx]\n    if np.random.rand() < 0.7:\n        # Objective-specific replacement\n        if tradeoff_factor < 0.3:\n            # Value1-focused operation\n            in_items = np.where(new_solution == 1)[0]\n            out_items = np.where(new_solution == 0)[0]\n\n            # Remove items with low value1 efficiency\n            value1_ratio = value1_lst[in_items] / (weight_lst[in_items] + 1e-10)\n            sorted_in = in_items[np.argsort(value1_ratio)]\n            for idx in sorted_in[:len(sorted_in)//3]:\n                if np.random.rand() < 0.4:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n\n            # Add items with high value1 efficiency\n            value1_ratio_out = value1_lst[out_items] / (weight_lst[out_items] + 1e-10)\n            sorted_out = out_items[np.argsort(-value1_ratio_out)]\n            for idx in sorted_out[:len(sorted_out)//2]:\n                if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.5:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n        else:\n            # Balanced operation\n            combined_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n            in_items = np.where(new_solution == 1)[0]\n            sorted_in = in_items[np.argsort(combined_ratio[in_items])]\n            for idx in sorted_in[:len(sorted_in)//3]:\n                if np.random.rand() < 0.3:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n\n            out_items = np.where(new_solution == 0)[0]\n            sorted_out = out_items[np.argsort(-combined_ratio[out_items])]\n            for idx in sorted_out[:len(sorted_out)//2]:\n                if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.4:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n    else:\n        # Capacity-focused operation\n        in_items = np.where(new_solution == 1)[0]\n        capacity_util = weight_lst[in_items] / capacity\n        sorted_in = in_items[np.argsort(capacity_util)]\n        for idx in sorted_in[:len(sorted_in)//2]:\n            if np.random.rand() < 0.3:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n\n        out_items = np.where(new_solution == 0)[0]\n        sorted_out = out_items[np.argsort(-weight_lst[out_items])]\n        for idx in sorted_out[:len(sorted_out)//2]:\n            if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.5:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 3: Elite Integration with Adaptive Perturbation\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            elite_obj = objectives[elite_idx]\n            elite_tradeoff = np.abs(elite_obj[0] - elite_obj[1]) / (elite_obj[0] + elite_obj[1] + 1e-10)\n\n            # Create hybrid solution\n            hybrid_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n            np.random.shuffle(hybrid_items)\n\n            temp_solution = np.zeros_like(new_solution)\n            temp_weight = 0\n            for item in hybrid_items:\n                if weight_lst[item] <= (capacity - temp_weight):\n                    if np.random.rand() < 0.7 * (1 - elite_tradeoff):\n                        temp_solution[item] = 1\n                        temp_weight += weight_lst[item]\n\n            # Accept if it improves the combined objective\n            temp_obj1 = np.sum(value1_lst[temp_solution == 1])\n            temp_obj2 = np.sum(value2_lst[temp_solution == 1])\n            current_obj1 = np.sum(value1_lst[new_solution == 1])\n            current_obj2 = np.sum(value2_lst[new_solution == 1])\n\n            combined_weight = 0.5 if tradeoff_factor < 0.5 else 0.3\n            if (temp_obj1 * combined_weight + temp_obj2 * (1 - combined_weight)) > \\\n               (current_obj1 * combined_weight + current_obj2 * (1 - combined_weight)):\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    return new_solution\n\n",
          "score": [
               -19.976040721971682,
               -17.03523626370004
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic Solution Selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-10)\n    diversity_scores = np.std(normalized_obj, axis=0)\n    tradeoff_scores = np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n\n    # Combine selection criteria\n    combined_scores = 0.4 * diversity_scores[0] + 0.4 * diversity_scores[1] + 0.2 * (1 - tradeoff_scores)\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate initial state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Phase 2: Adaptive Trade-off Navigation\n    tradeoff_factor = tradeoff_scores[selected_idx]\n    if np.random.rand() < 0.7:\n        # Objective-specific replacement\n        if tradeoff_factor < 0.3:\n            # Value1-focused operation\n            in_items = np.where(new_solution == 1)[0]\n            out_items = np.where(new_solution == 0)[0]\n\n            # Remove items with low value1 efficiency\n            value1_ratio = value1_lst[in_items] / (weight_lst[in_items] + 1e-10)\n            sorted_in = in_items[np.argsort(value1_ratio)]\n            for idx in sorted_in[:len(sorted_in)//3]:\n                if np.random.rand() < 0.4:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n\n            # Add items with high value1 efficiency\n            value1_ratio_out = value1_lst[out_items] / (weight_lst[out_items] + 1e-10)\n            sorted_out = out_items[np.argsort(-value1_ratio_out)]\n            for idx in sorted_out[:len(sorted_out)//2]:\n                if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.5:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n        else:\n            # Balanced operation\n            combined_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n            in_items = np.where(new_solution == 1)[0]\n            sorted_in = in_items[np.argsort(combined_ratio[in_items])]\n            for idx in sorted_in[:len(sorted_in)//3]:\n                if np.random.rand() < 0.3:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n\n            out_items = np.where(new_solution == 0)[0]\n            sorted_out = out_items[np.argsort(-combined_ratio[out_items])]\n            for idx in sorted_out[:len(sorted_out)//2]:\n                if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.4:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n    else:\n        # Capacity-focused operation\n        in_items = np.where(new_solution == 1)[0]\n        capacity_util = weight_lst[in_items] / capacity\n        sorted_in = in_items[np.argsort(capacity_util)]\n        for idx in sorted_in[:len(sorted_in)//2]:\n            if np.random.rand() < 0.3:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n\n        out_items = np.where(new_solution == 0)[0]\n        sorted_out = out_items[np.argsort(-weight_lst[out_items])]\n        for idx in sorted_out[:len(sorted_out)//2]:\n            if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.5:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 3: Elite Integration with Adaptive Perturbation\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            elite_obj = objectives[elite_idx]\n            elite_tradeoff = np.abs(elite_obj[0] - elite_obj[1]) / (elite_obj[0] + elite_obj[1] + 1e-10)\n\n            # Create hybrid solution\n            hybrid_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n            np.random.shuffle(hybrid_items)\n\n            temp_solution = np.zeros_like(new_solution)\n            temp_weight = 0\n            for item in hybrid_items:\n                if weight_lst[item] <= (capacity - temp_weight):\n                    if np.random.rand() < 0.7 * (1 - elite_tradeoff):\n                        temp_solution[item] = 1\n                        temp_weight += weight_lst[item]\n\n            # Accept if it improves the combined objective\n            temp_obj1 = np.sum(value1_lst[temp_solution == 1])\n            temp_obj2 = np.sum(value2_lst[temp_solution == 1])\n            current_obj1 = np.sum(value1_lst[new_solution == 1])\n            current_obj2 = np.sum(value2_lst[new_solution == 1])\n\n            combined_weight = 0.5 if tradeoff_factor < 0.5 else 0.3\n            if (temp_obj1 * combined_weight + temp_obj2 * (1 - combined_weight)) > \\\n               (current_obj1 * combined_weight + current_obj2 * (1 - combined_weight)):\n                new_solution = temp_solution\n                current_weight = temp_weight\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm, named \"Objective-Centric Adaptive Exploration with Dynamic Constraint Handling (OCAE-DCH)\", employs a three-stage approach that first identifies the most promising solution through a novel objective-centric selection mechanism that dynamically balances between the two objectives based on their current relative importance, then performs a constraint-aware neighborhood exploration that systematically evaluates potential item swaps while maintaining feasibility through a dynamic capacity threshold adjustment mechanism, and finally applies a solution refinement step that combines features from diverse elite solutions while systematically exploring the neighborhood through a novel adaptive perturbation mechanism that alternates between objective-centric and capacity-focused operations, ensuring both high-quality and diverse solutions across both objectives.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    min_obj = np.min(objectives, axis=0)\n\n    # Calculate objective importance weights\n    obj_importance = (max_obj - objectives) / (max_obj - min_obj + 1e-10)\n    obj_weights = np.random.dirichlet([1, 1]) if np.random.rand() < 0.5 else obj_importance.mean(axis=0)\n\n    # Select solution with highest weighted score\n    weighted_scores = np.dot(objectives, obj_weights)\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Constraint-aware neighborhood exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate dynamic capacity threshold\n    capacity_threshold = remaining_capacity * (0.5 + 0.5 * np.random.rand())\n\n    # Evaluate potential swaps\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    for i in in_items:\n        for j in out_items:\n            weight_diff = weight_lst[j] - weight_lst[i]\n            if abs(weight_diff) <= capacity_threshold:\n                # Calculate objective improvements\n                value1_diff = value1_lst[j] - value1_lst[i]\n                value2_diff = value2_lst[j] - value2_lst[i]\n\n                # Accept swap if beneficial for at least one objective\n                if (value1_diff > 0 or value2_diff > 0) and np.random.rand() < 0.6:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight += weight_diff\n                    remaining_capacity = capacity - current_weight\n                    capacity_threshold = remaining_capacity * (0.5 + 0.5 * np.random.rand())\n                    break\n\n    # Phase 3: Adaptive perturbation with elite features\n    elite_solutions = [sol for sol, _ in archive if np.random.rand() < 0.3]\n    if elite_solutions:\n        elite_solution = elite_solutions[np.random.randint(len(elite_solutions))]\n\n        # Combine features from elite solution\n        combined_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n        np.random.shuffle(combined_items)\n\n        final_solution = np.zeros_like(new_solution)\n        current_weight = 0\n        for idx in combined_items:\n            if weight_lst[idx] <= (capacity - current_weight):\n                final_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        new_solution = final_solution\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm, named \"Dual-Objective Harmony Search with Adaptive Constraint Navigation and Elite Fusion (DOHS-ACNEF)\", combines elements from the provided algorithms by incorporating a harmony search-inspired approach that dynamically balances between objective-centric and capacity-aware operations, with adaptive constraint handling through probabilistic item selection and removal that maintains feasibility, while systematically incorporating features from elite solutions through a novel fusion mechanism that alternates between objective-specific and capacity-focused operations, all while employing a dynamic neighborhood exploration strategy that adapts to the current solution's quality and diversity in the archive.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dual-Objective Harmony Selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n\n    # Calculate harmony weights based on objective diversity and quality\n    quality_weights = 1 - np.std(normalized_obj, axis=0)\n    diversity_weights = np.mean(normalized_obj, axis=0)\n    combined_weights = 0.6 * quality_weights + 0.4 * diversity_weights\n    combined_weights /= np.sum(combined_weights)\n\n    # Select solution with highest combined score\n    weighted_scores = np.dot(normalized_obj, combined_weights)\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate initial state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Phase 2: Adaptive Constraint Navigation\n    # Determine operation mode (objective-focused or capacity-focused)\n    if np.random.rand() < 0.7:\n        # Objective-focused operation\n        if np.random.rand() < 0.5:\n            # Value-to-weight ratio based removal\n            in_items = np.where(new_solution == 1)[0]\n            value_ratio = (value1_lst[in_items] + value2_lst[in_items]) / (weight_lst[in_items] + 1e-10)\n            sorted_items = in_items[np.argsort(value_ratio)]\n            for idx in sorted_items[:len(sorted_items)//2]:\n                if np.random.rand() < 0.5:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n        else:\n            # Probabilistic removal based on objective importance\n            in_items = np.where(new_solution == 1)[0]\n            for idx in in_items:\n                if np.random.rand() < (0.3 + 0.4 * combined_weights[0] + 0.3 * combined_weights[1]):\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n\n        # Add items based on combined objective\n        out_items = np.where(new_solution == 0)[0]\n        combined_ratio = (combined_weights[0] * value1_lst[out_items] + combined_weights[1] * value2_lst[out_items]) / (weight_lst[out_items] + 1e-10)\n        sorted_out = out_items[np.argsort(-combined_ratio)]\n        for idx in sorted_out[:len(sorted_out)//2]:\n            if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.6:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n    else:\n        # Capacity-focused operation\n        # Remove items with low capacity utilization\n        in_items = np.where(new_solution == 1)[0]\n        capacity_util = weight_lst[in_items] / (capacity + 1e-10)\n        sorted_items = in_items[np.argsort(capacity_util)]\n        for idx in sorted_items[:len(sorted_items)//2]:\n            if np.random.rand() < 0.4:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n\n        # Add items that fill capacity gaps\n        out_items = np.where(new_solution == 0)[0]\n        sorted_out = out_items[np.argsort(-weight_lst[out_items])]\n        for idx in sorted_out[:len(sorted_out)//2]:\n            if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.5:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 3: Elite Fusion with Dynamic Perturbation\n    elite_indices = np.random.choice(len(archive), size=min(2, len(archive)), replace=False)\n    for idx in elite_indices:\n        elite_solution = archive[idx][0]\n        # Create hybrid solution by combining features\n        hybrid_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n        np.random.shuffle(hybrid_items)\n\n        temp_solution = np.zeros_like(new_solution)\n        temp_weight = 0\n        for item in hybrid_items:\n            if weight_lst[item] <= (capacity - temp_weight):\n                temp_solution[item] = 1\n                temp_weight += weight_lst[item]\n\n        # Accept if it improves the combined objective\n        temp_obj1 = np.sum(value1_lst[temp_solution == 1])\n        temp_obj2 = np.sum(value2_lst[temp_solution == 1])\n        current_obj1 = np.sum(value1_lst[new_solution == 1])\n        current_obj2 = np.sum(value2_lst[new_solution == 1])\n\n        if (temp_obj1 * combined_weights[0] + temp_obj2 * combined_weights[1]) > \\\n           (current_obj1 * combined_weights[0] + current_obj2 * combined_weights[1]) and \\\n           np.random.rand() < 0.7:\n            new_solution = temp_solution\n            current_weight = temp_weight\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one long, detail sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 302,
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Objective Greedy Exploration with Dynamic Constraint Balancing (AMGE-DCB)\", combines elements from the provided algorithms by employing a three-stage approach that first identifies the most promising solution through a novel adaptive objective-centric selection mechanism that dynamically balances between the two objectives based on their current relative importance and archive diversity, then performs a constraint-aware neighborhood exploration that systematically evaluates potential item additions and removals while dynamically adjusting the exploration strategy between objective-focused and capacity-focused operations based on the current solution's quality and the archive's diversity, and finally applies a solution refinement step that combines features from diverse elite solutions while systematically exploring the neighborhood through a novel adaptive perturbation mechanism that alternates between objective-centric and capacity-focused operations, all while maintaining feasibility through a dynamic capacity threshold adjustment mechanism that adapts to the current solution's characteristics and the archive's diversity.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Adaptive Objective-Centric Selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n\n    # Calculate selection weights based on objective diversity and quality\n    quality_weights = 1 - np.std(normalized_obj, axis=0)\n    diversity_weights = np.mean(normalized_obj, axis=0)\n    combined_weights = 0.7 * quality_weights + 0.3 * diversity_weights\n    combined_weights /= np.sum(combined_weights)\n\n    # Select solution with highest combined score\n    weighted_scores = np.dot(normalized_obj, combined_weights)\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate initial state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Phase 2: Dynamic Constraint Balancing Exploration\n    # Determine exploration mode based on archive diversity\n    archive_diversity = np.mean(np.std(normalized_obj, axis=0))\n    if np.random.rand() < archive_diversity:\n        # Objective-focused exploration\n        if np.random.rand() < 0.6:\n            # Remove items with low combined value-to-weight ratio\n            in_items = np.where(new_solution == 1)[0]\n            combined_ratio = (combined_weights[0] * value1_lst[in_items] + combined_weights[1] * value2_lst[in_items]) / (weight_lst[in_items] + 1e-10)\n            sorted_items = in_items[np.argsort(combined_ratio)]\n            for idx in sorted_items[:len(sorted_items)//2]:\n                if np.random.rand() < 0.5:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n        else:\n            # Probabilistic removal based on objective importance\n            in_items = np.where(new_solution == 1)[0]\n            for idx in in_items:\n                if np.random.rand() < (0.4 + 0.5 * combined_weights[0] + 0.1 * combined_weights[1]):\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n\n        # Add items based on combined objective\n        out_items = np.where(new_solution == 0)[0]\n        combined_ratio = (combined_weights[0] * value1_lst[out_items] + combined_weights[1] * value2_lst[out_items]) / (weight_lst[out_items] + 1e-10)\n        sorted_out = out_items[np.argsort(-combined_ratio)]\n        for idx in sorted_out[:len(sorted_out)//2]:\n            if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.6:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n    else:\n        # Capacity-focused exploration\n        # Remove items with low capacity utilization\n        in_items = np.where(new_solution == 1)[0]\n        capacity_util = weight_lst[in_items] / (capacity + 1e-10)\n        sorted_items = in_items[np.argsort(capacity_util)]\n        for idx in sorted_items[:len(sorted_items)//2]:\n            if np.random.rand() < 0.4:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n\n        # Add items that fill capacity gaps\n        out_items = np.where(new_solution == 0)[0]\n        sorted_out = out_items[np.argsort(-weight_lst[out_items])]\n        for idx in sorted_out[:len(sorted_out)//2]:\n            if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.5:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 3: Adaptive Perturbation with Elite Fusion\n    elite_indices = np.random.choice(len(archive), size=min(2, len(archive)), replace=False)\n    for idx in elite_indices:\n        elite_solution = archive[idx][0]\n        # Create hybrid solution by combining features\n        hybrid_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n        np.random.shuffle(hybrid_items)\n\n        temp_solution = np.zeros_like(new_solution)\n        temp_weight = 0\n        for item in hybrid_items:\n            if weight_lst[item] <= (capacity - temp_weight):\n                temp_solution[item] = 1\n                temp_weight += weight_lst[item]\n\n        # Accept if it improves the combined objective\n        temp_obj1 = np.sum(value1_lst[temp_solution == 1])\n        temp_obj2 = np.sum(value2_lst[temp_solution == 1])\n        current_obj1 = np.sum(value1_lst[new_solution == 1])\n        current_obj2 = np.sum(value2_lst[new_solution == 1])\n\n        if (temp_obj1 * combined_weights[0] + temp_obj2 * combined_weights[1]) > \\\n           (current_obj1 * combined_weights[0] + current_obj2 * combined_weights[1]) and \\\n           np.random.rand() < 0.7:\n            new_solution = temp_solution\n            current_weight = temp_weight\n\n    return new_solution\n\n",
          "score": [
               -19.134379580785282,
               -18.660073666706836
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Adaptive Objective-Centric Selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - np.min(objectives, axis=0)) / (np.max(objectives, axis=0) - np.min(objectives, axis=0) + 1e-10)\n\n    # Calculate selection weights based on objective diversity and quality\n    quality_weights = 1 - np.std(normalized_obj, axis=0)\n    diversity_weights = np.mean(normalized_obj, axis=0)\n    combined_weights = 0.7 * quality_weights + 0.3 * diversity_weights\n    combined_weights /= np.sum(combined_weights)\n\n    # Select solution with highest combined score\n    weighted_scores = np.dot(normalized_obj, combined_weights)\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Calculate initial state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Phase 2: Dynamic Constraint Balancing Exploration\n    # Determine exploration mode based on archive diversity\n    archive_diversity = np.mean(np.std(normalized_obj, axis=0))\n    if np.random.rand() < archive_diversity:\n        # Objective-focused exploration\n        if np.random.rand() < 0.6:\n            # Remove items with low combined value-to-weight ratio\n            in_items = np.where(new_solution == 1)[0]\n            combined_ratio = (combined_weights[0] * value1_lst[in_items] + combined_weights[1] * value2_lst[in_items]) / (weight_lst[in_items] + 1e-10)\n            sorted_items = in_items[np.argsort(combined_ratio)]\n            for idx in sorted_items[:len(sorted_items)//2]:\n                if np.random.rand() < 0.5:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n        else:\n            # Probabilistic removal based on objective importance\n            in_items = np.where(new_solution == 1)[0]\n            for idx in in_items:\n                if np.random.rand() < (0.4 + 0.5 * combined_weights[0] + 0.1 * combined_weights[1]):\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n\n        # Add items based on combined objective\n        out_items = np.where(new_solution == 0)[0]\n        combined_ratio = (combined_weights[0] * value1_lst[out_items] + combined_weights[1] * value2_lst[out_items]) / (weight_lst[out_items] + 1e-10)\n        sorted_out = out_items[np.argsort(-combined_ratio)]\n        for idx in sorted_out[:len(sorted_out)//2]:\n            if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.6:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n    else:\n        # Capacity-focused exploration\n        # Remove items with low capacity utilization\n        in_items = np.where(new_solution == 1)[0]\n        capacity_util = weight_lst[in_items] / (capacity + 1e-10)\n        sorted_items = in_items[np.argsort(capacity_util)]\n        for idx in sorted_items[:len(sorted_items)//2]:\n            if np.random.rand() < 0.4:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n\n        # Add items that fill capacity gaps\n        out_items = np.where(new_solution == 0)[0]\n        sorted_out = out_items[np.argsort(-weight_lst[out_items])]\n        for idx in sorted_out[:len(sorted_out)//2]:\n            if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.5:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 3: Adaptive Perturbation with Elite Fusion\n    elite_indices = np.random.choice(len(archive), size=min(2, len(archive)), replace=False)\n    for idx in elite_indices:\n        elite_solution = archive[idx][0]\n        # Create hybrid solution by combining features\n        hybrid_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n        np.random.shuffle(hybrid_items)\n\n        temp_solution = np.zeros_like(new_solution)\n        temp_weight = 0\n        for item in hybrid_items:\n            if weight_lst[item] <= (capacity - temp_weight):\n                temp_solution[item] = 1\n                temp_weight += weight_lst[item]\n\n        # Accept if it improves the combined objective\n        temp_obj1 = np.sum(value1_lst[temp_solution == 1])\n        temp_obj2 = np.sum(value2_lst[temp_solution == 1])\n        current_obj1 = np.sum(value1_lst[new_solution == 1])\n        current_obj2 = np.sum(value2_lst[new_solution == 1])\n\n        if (temp_obj1 * combined_weights[0] + temp_obj2 * combined_weights[1]) > \\\n           (current_obj1 * combined_weights[0] + current_obj2 * combined_weights[1]) and \\\n           np.random.rand() < 0.7:\n            new_solution = temp_solution\n            current_weight = temp_weight\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm, named \"Objective-Centric Adaptive Exploration with Dynamic Constraint Handling (OCAE-DCH)\", employs a three-stage approach that first identifies the most promising solution through a novel objective-centric selection mechanism that dynamically balances between the two objectives based on their current relative importance, then performs a constraint-aware neighborhood exploration that systematically evaluates potential item swaps while maintaining feasibility through a dynamic capacity threshold adjustment mechanism, and finally applies a solution refinement step that combines features from diverse elite solutions while systematically exploring the neighborhood through a novel adaptive perturbation mechanism that alternates between objective-centric and capacity-focused operations, ensuring both high-quality and diverse solutions across both objectives.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    min_obj = np.min(objectives, axis=0)\n\n    # Calculate objective importance weights\n    obj_importance = (max_obj - objectives) / (max_obj - min_obj + 1e-10)\n    obj_weights = np.random.dirichlet([1, 1]) if np.random.rand() < 0.5 else obj_importance.mean(axis=0)\n\n    # Select solution with highest weighted score\n    weighted_scores = np.dot(objectives, obj_weights)\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Constraint-aware neighborhood exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate dynamic capacity threshold\n    capacity_threshold = remaining_capacity * (0.5 + 0.5 * np.random.rand())\n\n    # Evaluate potential swaps\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    for i in in_items:\n        for j in out_items:\n            weight_diff = weight_lst[j] - weight_lst[i]\n            if abs(weight_diff) <= capacity_threshold:\n                # Calculate objective improvements\n                value1_diff = value1_lst[j] - value1_lst[i]\n                value2_diff = value2_lst[j] - value2_lst[i]\n\n                # Accept swap if beneficial for at least one objective\n                if (value1_diff > 0 or value2_diff > 0) and np.random.rand() < 0.6:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight += weight_diff\n                    remaining_capacity = capacity - current_weight\n                    capacity_threshold = remaining_capacity * (0.5 + 0.5 * np.random.rand())\n                    break\n\n    # Phase 3: Adaptive perturbation with elite features\n    elite_solutions = [sol for sol, _ in archive if np.random.rand() < 0.3]\n    if elite_solutions:\n        elite_solution = elite_solutions[np.random.randint(len(elite_solutions))]\n\n        # Combine features from elite solution\n        combined_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n        np.random.shuffle(combined_items)\n\n        final_solution = np.zeros_like(new_solution)\n        current_weight = 0\n        for idx in combined_items:\n            if weight_lst[idx] <= (capacity - current_weight):\n                final_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        new_solution = final_solution\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm, named \"Adaptive Multi-Objective Knapsack Exploration via Dynamic Objective Fusion and Balanced Perturbation (AMKE-DOFBP)\", employs a novel two-phase selection mechanism that first identifies the most under-represented objective in the archive through a dynamic objective dominance analysis, then uses this information to guide a hybrid neighborhood exploration strategy that combines objective-specific item swaps with capacity-aware perturbations, while incorporating a solution refinement phase that fuses features from diverse elite solutions through a probabilistic item selection mechanism that balances objective improvements with solution diversity, all while systematically exploring the solution space through a novel adaptive perturbation schedule that adjusts its intensity based on the current solution's objective-centric efficiency and its proximity to the Pareto front, ensuring both high-quality and diverse solutions across both objectives.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic objective dominance analysis\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n\n    # Identify the most under-represented objective\n    obj_dominance = np.mean(normalized_obj > 0.5, axis=0)\n    target_obj = np.argmin(obj_dominance)\n\n    # Select base solution with the highest value in the target objective\n    if target_obj == 0:\n        selected_idx = np.argmax(objectives[:, 0])\n    else:\n        selected_idx = np.argmax(objectives[:, 1])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Hybrid neighborhood exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-specific efficiency scores\n    obj1_efficiency = value1_lst / (weight_lst + 1e-10)\n    obj2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Perform objective-specific item swaps\n    if target_obj == 0:\n        sorted_items = np.argsort(-obj1_efficiency)\n    else:\n        sorted_items = np.argsort(-obj2_efficiency)\n\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            # Find best replacement item based on the other objective\n            if target_obj == 0:\n                best_replacement = np.argmax(obj2_efficiency * (new_solution == 0) * (weight_lst <= remaining_capacity + weight_lst[i]))\n            else:\n                best_replacement = np.argmax(obj1_efficiency * (new_solution == 0) * (weight_lst <= remaining_capacity + weight_lst[i]))\n\n            if new_solution[best_replacement] == 0 and weight_lst[best_replacement] <= remaining_capacity + weight_lst[i]:\n                new_solution[i] = 0\n                new_solution[best_replacement] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement]\n                remaining_capacity = capacity - current_weight\n\n    # Phase 3: Balanced perturbation with dynamic intensity\n    perturbation_intensity = 0.2 + 0.6 * (1 - (objectives[selected_idx, target_obj] / (objectives[:, target_obj].max() + 1e-10)))\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.5:  # Equal probability to remove\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.4:  # Higher probability to add\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution fusion with probabilistic selection\n    if len(archive) > 1:\n        # Select elite solutions based on the other objective\n        if target_obj == 0:\n            elite_indices = np.argsort(-objectives[:, 1])[:min(2, len(archive)-1)]\n        else:\n            elite_indices = np.argsort(-objectives[:, 0])[:min(2, len(archive)-1)]\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    if target_obj == 0:\n                        fusion_prob = 0.4 + 0.6 * (obj1_efficiency[idx] / (obj1_efficiency.max() + 1e-10))\n                    else:\n                        fusion_prob = 0.4 + 0.6 * (obj2_efficiency[idx] / (obj2_efficiency.max() + 1e-10))\n                    if np.random.rand() < fusion_prob:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 303,
          "algorithm": "{The new algorithm, named \"Dual-Objective Guided Evolutionary Local Search with Adaptive Constraint-Aware Perturbations (DOGELS-ACAP)\", employs a unique four-stage approach that first identifies the most promising solution through a novel dual-objective dominance analysis that dynamically adapts its selection criteria based on the current state of the Pareto front, then performs a constraint-aware neighborhood exploration that systematically evaluates potential item additions and removals using a probabilistic acceptance mechanism that balances objective improvements with capacity constraints, followed by a solution diversification phase that introduces controlled perturbations based on the current solution's objective-centric efficiency and its proximity to the Pareto front, and finally applies a novel elite solution fusion mechanism that combines features from diverse high-quality solutions while systematically exploring the neighborhood through an adaptive perturbation schedule that adjusts its intensity based on the current solution's objective-centric efficiency and its proximity to the Pareto front, ensuring both high-quality and diverse solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dual-objective dominance analysis and solution selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n\n    # Calculate dominance scores for each objective\n    obj1_dominance = np.sum(normalized_obj[:, 0] > 0.7) / len(archive)\n    obj2_dominance = np.sum(normalized_obj[:, 1] > 0.7) / len(archive)\n\n    # Select base solution based on least dominated objective\n    if obj1_dominance < obj2_dominance:\n        selected_idx = np.argmax(objectives[:, 0])\n    else:\n        selected_idx = np.argmax(objectives[:, 1])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Constraint-aware probabilistic neighborhood exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate item efficiency scores\n    obj1_efficiency = value1_lst / (weight_lst + 1e-10)\n    obj2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Perform probabilistic item additions/removals\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Probability to remove based on efficiency and capacity\n            remove_prob = 0.1 + 0.4 * (1 - obj1_efficiency[i]) * (1 - obj2_efficiency[i]) * (weight_lst[i] / (capacity + 1e-10))\n            if np.random.rand() < remove_prob:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                remaining_capacity += weight_lst[i]\n        elif new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n            # Probability to add based on efficiency and capacity\n            add_prob = 0.2 + 0.3 * obj1_efficiency[i] * obj2_efficiency[i] * (weight_lst[i] / (capacity + 1e-10))\n            if np.random.rand() < add_prob:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                remaining_capacity -= weight_lst[i]\n\n    # Phase 3: Solution diversification with adaptive perturbations\n    diversity_intensity = 0.3 + 0.5 * (1 - (objectives[selected_idx].mean() / (objectives.mean(axis=0).max() + 1e-10)))\n    for i in range(len(new_solution)):\n        if np.random.rand() < diversity_intensity:\n            if new_solution[i] == 1:\n                if np.random.rand() < 0.4:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    remaining_capacity += weight_lst[i]\n            elif new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n                if np.random.rand() < 0.3:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    remaining_capacity -= weight_lst[i]\n\n    # Phase 4: Elite solution fusion with adaptive feature selection\n    if len(archive) > 1:\n        # Select elite solutions based on combined objective scores\n        elite_scores = objectives[:, 0] * 0.6 + objectives[:, 1] * 0.4\n        elite_indices = np.argsort(-elite_scores)[:min(3, len(archive)-1)]\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for i in np.where(elite_solution == 1)[0]:\n                if new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n                    # Fusion probability based on elite solution's objective scores\n                    fusion_prob = 0.3 + 0.5 * (objectives[elite_idx].mean() / (objectives.mean(axis=0).max() + 1e-10))\n                    if np.random.rand() < fusion_prob:\n                        new_solution[i] = 1\n                        current_weight += weight_lst[i]\n                        remaining_capacity -= weight_lst[i]\n\n    return new_solution\n\n",
          "score": [
               -18.607146852013603,
               -18.223990613308242
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dual-objective dominance analysis and solution selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n\n    # Calculate dominance scores for each objective\n    obj1_dominance = np.sum(normalized_obj[:, 0] > 0.7) / len(archive)\n    obj2_dominance = np.sum(normalized_obj[:, 1] > 0.7) / len(archive)\n\n    # Select base solution based on least dominated objective\n    if obj1_dominance < obj2_dominance:\n        selected_idx = np.argmax(objectives[:, 0])\n    else:\n        selected_idx = np.argmax(objectives[:, 1])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Constraint-aware probabilistic neighborhood exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate item efficiency scores\n    obj1_efficiency = value1_lst / (weight_lst + 1e-10)\n    obj2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Perform probabilistic item additions/removals\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            # Probability to remove based on efficiency and capacity\n            remove_prob = 0.1 + 0.4 * (1 - obj1_efficiency[i]) * (1 - obj2_efficiency[i]) * (weight_lst[i] / (capacity + 1e-10))\n            if np.random.rand() < remove_prob:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                remaining_capacity += weight_lst[i]\n        elif new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n            # Probability to add based on efficiency and capacity\n            add_prob = 0.2 + 0.3 * obj1_efficiency[i] * obj2_efficiency[i] * (weight_lst[i] / (capacity + 1e-10))\n            if np.random.rand() < add_prob:\n                new_solution[i] = 1\n                current_weight += weight_lst[i]\n                remaining_capacity -= weight_lst[i]\n\n    # Phase 3: Solution diversification with adaptive perturbations\n    diversity_intensity = 0.3 + 0.5 * (1 - (objectives[selected_idx].mean() / (objectives.mean(axis=0).max() + 1e-10)))\n    for i in range(len(new_solution)):\n        if np.random.rand() < diversity_intensity:\n            if new_solution[i] == 1:\n                if np.random.rand() < 0.4:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n                    remaining_capacity += weight_lst[i]\n            elif new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n                if np.random.rand() < 0.3:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                    remaining_capacity -= weight_lst[i]\n\n    # Phase 4: Elite solution fusion with adaptive feature selection\n    if len(archive) > 1:\n        # Select elite solutions based on combined objective scores\n        elite_scores = objectives[:, 0] * 0.6 + objectives[:, 1] * 0.4\n        elite_indices = np.argsort(-elite_scores)[:min(3, len(archive)-1)]\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for i in np.where(elite_solution == 1)[0]:\n                if new_solution[i] == 0 and weight_lst[i] <= remaining_capacity:\n                    # Fusion probability based on elite solution's objective scores\n                    fusion_prob = 0.3 + 0.5 * (objectives[elite_idx].mean() / (objectives.mean(axis=0).max() + 1e-10))\n                    if np.random.rand() < fusion_prob:\n                        new_solution[i] = 1\n                        current_weight += weight_lst[i]\n                        remaining_capacity -= weight_lst[i]\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm, named \"Objective-Balanced Adaptive Hybrid Exploration with Dynamic Perturbation and Elite Fusion (OBA-HEDEPF)\", combines a novel multi-objective selection mechanism that prioritizes solutions with balanced objective contributions through a dynamic weighting scheme, with an adaptive neighborhood exploration strategy that alternates between objective-specific item replacements and capacity-aware perturbations, while incorporating a solution refinement phase that fuses features from diverse elite solutions through a probabilistic item selection mechanism that balances objective improvements with solution diversity, all while systematically exploring the solution space through a novel adaptive perturbation schedule that adjusts its intensity based on the current solution's proximity to the Pareto front and its objective-centric efficiency, ensuring both high-quality and diverse solutions across both objectives.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = 1 - np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-centric item replacement with dynamic weights\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate dynamic objective weights\n    obj1_weight = 0.5 + 0.5 * (objectives[selected_idx, 0] / (objectives[selected_idx, 0] + objectives[selected_idx, 1] + 1e-10))\n    obj2_weight = 1 - obj1_weight\n\n    # Calculate combined efficiency scores\n    combined_efficiency = (obj1_weight * value1_lst + obj2_weight * value2_lst) / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-combined_efficiency)\n\n    # Perform adaptive item replacements\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            # Find best replacement item\n            best_replacement = -1\n            max_gain = 0\n            for j in sorted_items:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    gain = (obj1_weight * (value1_lst[j] - value1_lst[i]) +\n                            obj2_weight * (value2_lst[j] - value2_lst[i]))\n                    if gain > max_gain:\n                        max_gain = gain\n                        best_replacement = j\n\n            if best_replacement != -1 and max_gain > 0:\n                new_solution[i] = 0\n                new_solution[best_replacement] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement]\n                remaining_capacity = capacity - current_weight\n\n    # Phase 3: Adaptive perturbation with dynamic intensity\n    perturbation_intensity = 0.3 + 0.4 * (1 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) /\n                                        (objectives.max(axis=0).sum() + 1e-10))\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.6:  # Higher probability to remove\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.3:  # Lower probability to add\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution fusion with probabilistic selection\n    if len(archive) > 1:\n        # Select elite solutions based on their diversity\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    fusion_prob = 0.5 + 0.5 * (combined_efficiency[idx] / (combined_efficiency.max() + 1e-10))\n                    if np.random.rand() < fusion_prob:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm, named \"Diversity-Preserving Adaptive Multi-Objective Greedy Search (DAMOGS)\", employs a unique combination of objective-driven greedy selection with diversity-preserving perturbations, where it first identifies the most promising solution in the archive through a hybrid objective scoring mechanism that balances individual objective values with their relative contributions to the Pareto front, then systematically explores the solution space by iteratively applying a novel adaptive greedy replacement strategy that prioritizes items with complementary objective profiles while maintaining a strict capacity constraint, followed by a diversity-enhancing perturbation phase that selectively introduces or removes items based on their potential to create non-dominated solutions in the objective space, and finally incorporates a solution refinement step that merges features from multiple elite solutions through a probabilistic item selection mechanism that prioritizes items with high objective efficiency and low redundancy, all while dynamically adjusting the exploration intensity based on the current solution's proximity to the identified Pareto front.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with hybrid objective scoring\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    norm_obj = objectives / (max_obj + 1e-10)\n    hybrid_scores = 0.6 * norm_obj[:, 0] + 0.4 * norm_obj[:, 1] + 0.2 * (norm_obj[:, 0] * norm_obj[:, 1])\n    selected_idx = np.argmax(hybrid_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Adaptive greedy replacement with complementarity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate complementarity scores\n    comp_scores = value1_lst * value2_lst / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-comp_scores)\n\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            # Find best complementary item to replace\n            for j in sorted_items:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if (value1_lst[j] > value1_lst[i] and value2_lst[j] >= value2_lst[i]) or \\\n                       (value1_lst[j] >= value1_lst[i] and value2_lst[j] > value2_lst[i]):\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Diversity-preserving perturbation\n    diversity_factor = 0.3\n    for idx in range(len(new_solution)):\n        if np.random.rand() < diversity_factor:\n            if new_solution[idx] == 1 and np.random.rand() < 0.7:\n                # Remove item with high probability\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                # Add item with lower probability\n                if np.random.rand() < 0.3:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution merging with probabilistic selection\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    if np.random.rand() < 0.5:  # Moderate probability to accept from elite\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 304,
          "algorithm": "{The new algorithm, named \"Adaptive Objective-Centric Exploration with Dynamic Item Fusion and Capacity-Aware Diversification (AOCE-DIFCAD)\", employs a unique multi-phase approach that begins with an objective-centric solution selection mechanism that dynamically prioritizes solutions based on their relative contributions to each objective, followed by a novel adaptive item fusion strategy that probabilistically merges features from elite solutions while maintaining strict capacity constraints, then systematically explores the solution space through a capacity-aware diversification phase that selectively introduces or removes items based on their potential to create balanced objective improvements, and finally incorporates a solution refinement step that intelligently replaces items with those that exhibit complementary objective profiles while dynamically adjusting the exploration intensity based on the current solution's proximity to the Pareto front and its objective-centric efficiency, ensuring both high-quality and diverse solutions across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    obj_weights = objectives / (objectives.sum(axis=0) + 1e-10)\n    obj_scores = np.max(obj_weights, axis=1)\n    selected_idx = np.argmax(obj_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Adaptive item fusion with dynamic probabilities\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(3, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            elite_weight = np.sum(weight_lst[elite_solution == 1])\n            fusion_prob = min(0.7, 0.3 + 0.4 * (elite_weight / capacity))\n\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    if np.random.rand() < fusion_prob:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    # Phase 3: Capacity-aware diversification with objective balance\n    diversity_factor = 0.4\n    for idx in range(len(new_solution)):\n        if np.random.rand() < diversity_factor:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.6:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.2:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Complementary item replacement with dynamic weights\n    obj1_weight = objectives[selected_idx, 0] / (objectives[selected_idx].sum() + 1e-10)\n    obj2_weight = objectives[selected_idx, 1] / (objectives[selected_idx].sum() + 1e-10)\n\n    comp_scores = (obj1_weight * value2_lst + obj2_weight * value1_lst) / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-comp_scores)\n\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            for j in sorted_items:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if (value1_lst[j] > value1_lst[i] and value2_lst[j] >= value2_lst[i]) or \\\n                       (value1_lst[j] >= value1_lst[i] and value2_lst[j] > value2_lst[i]):\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    return new_solution\n\n",
          "score": [
               -17.998136150905232,
               -17.70300052301689
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    obj_weights = objectives / (objectives.sum(axis=0) + 1e-10)\n    obj_scores = np.max(obj_weights, axis=1)\n    selected_idx = np.argmax(obj_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Adaptive item fusion with dynamic probabilities\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(3, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            elite_weight = np.sum(weight_lst[elite_solution == 1])\n            fusion_prob = min(0.7, 0.3 + 0.4 * (elite_weight / capacity))\n\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    if np.random.rand() < fusion_prob:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    # Phase 3: Capacity-aware diversification with objective balance\n    diversity_factor = 0.4\n    for idx in range(len(new_solution)):\n        if np.random.rand() < diversity_factor:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.6:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.2:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Complementary item replacement with dynamic weights\n    obj1_weight = objectives[selected_idx, 0] / (objectives[selected_idx].sum() + 1e-10)\n    obj2_weight = objectives[selected_idx, 1] / (objectives[selected_idx].sum() + 1e-10)\n\n    comp_scores = (obj1_weight * value2_lst + obj2_weight * value1_lst) / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-comp_scores)\n\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            for j in sorted_items:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if (value1_lst[j] > value1_lst[i] and value2_lst[j] >= value2_lst[i]) or \\\n                       (value1_lst[j] >= value1_lst[i] and value2_lst[j] > value2_lst[i]):\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm, named \"Adaptive Multi-Objective Hybrid Exploration with Dynamic Objective-Centric Perturbation and Elite Solution Fusion (AMO-HEDEPF)\", combines a novel multi-objective selection mechanism that prioritizes solutions with balanced objective contributions through a dynamic weighting scheme with an adaptive neighborhood exploration strategy that alternates between objective-specific item replacements and capacity-aware perturbations, while incorporating a solution diversification phase that systematically explores the solution space through a novel adaptive perturbation schedule that adjusts its intensity based on the current solution's proximity to the Pareto front and its objective-centric efficiency, ensuring both high-quality and diverse solutions across both objectives. Additionally, it employs a probabilistic elite solution fusion mechanism that balances objective improvements with solution diversity, and a dynamic objective-centric perturbation that adapts its intensity and direction based on the current solution's objective-centric efficiency and the relative importance of each objective.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = 1 - np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-centric item replacement with dynamic weights\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    obj1_weight = 0.5 + 0.5 * (objectives[selected_idx, 0] / (objectives[selected_idx, 0] + objectives[selected_idx, 1] + 1e-10))\n    obj2_weight = 1 - obj1_weight\n\n    combined_efficiency = (obj1_weight * value1_lst + obj2_weight * value2_lst) / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-combined_efficiency)\n\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            best_replacement = -1\n            max_gain = 0\n            for j in sorted_items:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    gain = (obj1_weight * (value1_lst[j] - value1_lst[i]) +\n                            obj2_weight * (value2_lst[j] - value2_lst[i]))\n                    if gain > max_gain:\n                        max_gain = gain\n                        best_replacement = j\n\n            if best_replacement != -1 and max_gain > 0:\n                new_solution[i] = 0\n                new_solution[best_replacement] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement]\n                remaining_capacity = capacity - current_weight\n\n    # Phase 3: Adaptive perturbation with dynamic objective-centric intensity\n    perturbation_intensity = 0.3 + 0.4 * (1 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) /\n                                        (objectives.max(axis=0).sum() + 1e-10))\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.6:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.3:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution fusion with probabilistic selection\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    fusion_prob = 0.5 + 0.5 * (combined_efficiency[idx] / (combined_efficiency.max() + 1e-10))\n                    if np.random.rand() < fusion_prob:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm, named \"Objective-Centric Adaptive Hybrid Exploration with Dynamic Perturbation and Elite Fusion (OCA-HEDEPF)\", combines a novel multi-objective selection mechanism that prioritizes solutions with balanced objective contributions through a dynamic weighting scheme, with an adaptive neighborhood exploration strategy that alternates between objective-specific item replacements and capacity-aware perturbations, while incorporating a solution refinement phase that fuses features from diverse elite solutions through a probabilistic item selection mechanism that balances objective improvements with solution diversity, all while systematically exploring the solution space through a novel adaptive perturbation schedule that adjusts its intensity based on the current solution's proximity to the Pareto front and its objective-centric efficiency, ensuring both high-quality and diverse solutions across both objectives.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = 1 - np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-centric item replacement with dynamic weights\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate dynamic objective weights\n    obj1_weight = 0.5 + 0.5 * (objectives[selected_idx, 0] / (objectives[selected_idx, 0] + objectives[selected_idx, 1] + 1e-10))\n    obj2_weight = 1 - obj1_weight\n\n    # Calculate combined efficiency scores\n    combined_efficiency = (obj1_weight * value1_lst + obj2_weight * value2_lst) / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-combined_efficiency)\n\n    # Perform adaptive item replacements\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            # Find best replacement item\n            best_replacement = -1\n            max_gain = 0\n            for j in sorted_items:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    gain = (obj1_weight * (value1_lst[j] - value1_lst[i]) +\n                            obj2_weight * (value2_lst[j] - value2_lst[i]))\n                    if gain > max_gain:\n                        max_gain = gain\n                        best_replacement = j\n\n            if best_replacement != -1 and max_gain > 0:\n                new_solution[i] = 0\n                new_solution[best_replacement] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement]\n                remaining_capacity = capacity - current_weight\n\n    # Phase 3: Adaptive perturbation with dynamic intensity\n    perturbation_intensity = 0.3 + 0.4 * (1 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) /\n                                        (objectives.max(axis=0).sum() + 1e-10))\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.6:  # Higher probability to remove\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.3:  # Lower probability to add\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution fusion with probabilistic selection\n    if len(archive) > 1:\n        # Select elite solutions based on their diversity\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    fusion_prob = 0.5 + 0.5 * (combined_efficiency[idx] / (combined_efficiency.max() + 1e-10))\n                    if np.random.rand() < fusion_prob:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 305,
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Objective Hybrid Exploration with Dynamic Objective-Centric Perturbation and Elite Solution Fusion (AMO-HEDEPF)\", combines a novel multi-objective selection mechanism that prioritizes solutions with balanced objective contributions through a dynamic weighting scheme with an adaptive neighborhood exploration strategy that alternates between objective-specific item replacements and capacity-aware perturbations, while incorporating a solution diversification phase that systematically explores the solution space through a novel adaptive perturbation schedule that adjusts its intensity based on the current solution's proximity to the Pareto front and its objective-centric efficiency, ensuring both high-quality and diverse solutions across both objectives. Additionally, it employs a probabilistic elite solution fusion mechanism that balances objective improvements with solution diversity, and a dynamic objective-centric perturbation that adapts its intensity and direction based on the current solution's objective-centric efficiency and the relative importance of each objective.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = 1 - np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-centric item replacement with dynamic weights\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    obj1_weight = 0.5 + 0.5 * (objectives[selected_idx, 0] / (objectives[selected_idx, 0] + objectives[selected_idx, 1] + 1e-10))\n    obj2_weight = 1 - obj1_weight\n\n    combined_efficiency = (obj1_weight * value1_lst + obj2_weight * value2_lst) / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-combined_efficiency)\n\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            best_replacement = -1\n            max_gain = 0\n            for j in sorted_items:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    gain = (obj1_weight * (value1_lst[j] - value1_lst[i]) +\n                            obj2_weight * (value2_lst[j] - value2_lst[i]))\n                    if gain > max_gain:\n                        max_gain = gain\n                        best_replacement = j\n\n            if best_replacement != -1 and max_gain > 0:\n                new_solution[i] = 0\n                new_solution[best_replacement] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement]\n                remaining_capacity = capacity - current_weight\n\n    # Phase 3: Adaptive perturbation with dynamic objective-centric intensity\n    perturbation_intensity = 0.3 + 0.4 * (1 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) /\n                                        (objectives.max(axis=0).sum() + 1e-10))\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.6:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.3:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution fusion with probabilistic selection\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    fusion_prob = 0.5 + 0.5 * (combined_efficiency[idx] / (combined_efficiency.max() + 1e-10))\n                    if np.random.rand() < fusion_prob:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -19.916219243387673,
               -17.44449325831755
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Dynamic objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = (objectives - objectives.min(axis=0)) / (objectives.max(axis=0) - objectives.min(axis=0) + 1e-10)\n    balance_scores = 1 - np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    selected_idx = np.argmax(balance_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-centric item replacement with dynamic weights\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    obj1_weight = 0.5 + 0.5 * (objectives[selected_idx, 0] / (objectives[selected_idx, 0] + objectives[selected_idx, 1] + 1e-10))\n    obj2_weight = 1 - obj1_weight\n\n    combined_efficiency = (obj1_weight * value1_lst + obj2_weight * value2_lst) / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-combined_efficiency)\n\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            best_replacement = -1\n            max_gain = 0\n            for j in sorted_items:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    gain = (obj1_weight * (value1_lst[j] - value1_lst[i]) +\n                            obj2_weight * (value2_lst[j] - value2_lst[i]))\n                    if gain > max_gain:\n                        max_gain = gain\n                        best_replacement = j\n\n            if best_replacement != -1 and max_gain > 0:\n                new_solution[i] = 0\n                new_solution[best_replacement] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_replacement]\n                remaining_capacity = capacity - current_weight\n\n    # Phase 3: Adaptive perturbation with dynamic objective-centric intensity\n    perturbation_intensity = 0.3 + 0.4 * (1 - (objectives[selected_idx, 0] + objectives[selected_idx, 1]) /\n                                        (objectives.max(axis=0).sum() + 1e-10))\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.6:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.3:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution fusion with probabilistic selection\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    fusion_prob = 0.5 + 0.5 * (combined_efficiency[idx] / (combined_efficiency.max() + 1e-10))\n                    if np.random.rand() < fusion_prob:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm, named \"Objective-Centric Adaptive Exploration with Dynamic Constraint Handling (OCAE-DCH)\", employs a three-stage approach that first identifies the most promising solution through a novel objective-centric selection mechanism that dynamically balances between the two objectives based on their current relative importance, then performs a constraint-aware neighborhood exploration that systematically evaluates potential item swaps while maintaining feasibility through a dynamic capacity threshold adjustment mechanism, and finally applies a solution refinement step that combines features from diverse elite solutions while systematically exploring the neighborhood through a novel adaptive perturbation mechanism that alternates between objective-centric and capacity-focused operations, ensuring both high-quality and diverse solutions across both objectives.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Objective-centric solution selection\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    min_obj = np.min(objectives, axis=0)\n\n    # Calculate objective importance weights\n    obj_importance = (max_obj - objectives) / (max_obj - min_obj + 1e-10)\n    obj_weights = np.random.dirichlet([1, 1]) if np.random.rand() < 0.5 else obj_importance.mean(axis=0)\n\n    # Select solution with highest weighted score\n    weighted_scores = np.dot(objectives, obj_weights)\n    selected_idx = np.argmax(weighted_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Constraint-aware neighborhood exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate dynamic capacity threshold\n    capacity_threshold = remaining_capacity * (0.5 + 0.5 * np.random.rand())\n\n    # Evaluate potential swaps\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    for i in in_items:\n        for j in out_items:\n            weight_diff = weight_lst[j] - weight_lst[i]\n            if abs(weight_diff) <= capacity_threshold:\n                # Calculate objective improvements\n                value1_diff = value1_lst[j] - value1_lst[i]\n                value2_diff = value2_lst[j] - value2_lst[i]\n\n                # Accept swap if beneficial for at least one objective\n                if (value1_diff > 0 or value2_diff > 0) and np.random.rand() < 0.6:\n                    new_solution[i] = 0\n                    new_solution[j] = 1\n                    current_weight += weight_diff\n                    remaining_capacity = capacity - current_weight\n                    capacity_threshold = remaining_capacity * (0.5 + 0.5 * np.random.rand())\n                    break\n\n    # Phase 3: Adaptive perturbation with elite features\n    elite_solutions = [sol for sol, _ in archive if np.random.rand() < 0.3]\n    if elite_solutions:\n        elite_solution = elite_solutions[np.random.randint(len(elite_solutions))]\n\n        # Combine features from elite solution\n        combined_items = np.where((new_solution == 1) | (elite_solution == 1))[0]\n        np.random.shuffle(combined_items)\n\n        final_solution = np.zeros_like(new_solution)\n        current_weight = 0\n        for idx in combined_items:\n            if weight_lst[idx] <= (capacity - current_weight):\n                final_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        new_solution = final_solution\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm, named \"Diversity-Preserving Adaptive Multi-Objective Greedy Search (DAMOGS)\", employs a unique combination of objective-driven greedy selection with diversity-preserving perturbations, where it first identifies the most promising solution in the archive through a hybrid objective scoring mechanism that balances individual objective values with their relative contributions to the Pareto front, then systematically explores the solution space by iteratively applying a novel adaptive greedy replacement strategy that prioritizes items with complementary objective profiles while maintaining a strict capacity constraint, followed by a diversity-enhancing perturbation phase that selectively introduces or removes items based on their potential to create non-dominated solutions in the objective space, and finally incorporates a solution refinement step that merges features from multiple elite solutions through a probabilistic item selection mechanism that prioritizes items with high objective efficiency and low redundancy, all while dynamically adjusting the exploration intensity based on the current solution's proximity to the identified Pareto front.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with hybrid objective scoring\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    norm_obj = objectives / (max_obj + 1e-10)\n    hybrid_scores = 0.6 * norm_obj[:, 0] + 0.4 * norm_obj[:, 1] + 0.2 * (norm_obj[:, 0] * norm_obj[:, 1])\n    selected_idx = np.argmax(hybrid_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Adaptive greedy replacement with complementarity\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate complementarity scores\n    comp_scores = value1_lst * value2_lst / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-comp_scores)\n\n    for i in sorted_items:\n        if new_solution[i] == 1:\n            # Find best complementary item to replace\n            for j in sorted_items:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if (value1_lst[j] > value1_lst[i] and value2_lst[j] >= value2_lst[i]) or \\\n                       (value1_lst[j] >= value1_lst[i] and value2_lst[j] > value2_lst[i]):\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Diversity-preserving perturbation\n    diversity_factor = 0.3\n    for idx in range(len(new_solution)):\n        if np.random.rand() < diversity_factor:\n            if new_solution[idx] == 1 and np.random.rand() < 0.7:\n                # Remove item with high probability\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                # Add item with lower probability\n                if np.random.rand() < 0.3:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution merging with probabilistic selection\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    if np.random.rand() < 0.5:  # Moderate probability to accept from elite\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 306,
          "algorithm": "{The new algorithm, named \"Adaptive Multi-Objective Pathway Exploration with Constraint-Aware Diversification (AMOPE-CAD)\", employs a unique combination of solution pathway analysis with dynamic constraint handling, where it first identifies the most promising solution through a novel pathway-centric selection mechanism that evaluates both the current solution's objective performance and its potential to serve as a stepping stone for further exploration, then systematically explores the solution space by iteratively applying a pathway-based neighborhood generation strategy that constructs new solutions by following diverse exploration pathways derived from historical solution trajectories, followed by a constraint-aware diversification phase that selectively introduces or removes items based on their potential to create novel pathways in the objective space while maintaining strict capacity constraints through a dynamic slack-based adjustment mechanism, and finally incorporates a solution refinement step that merges features from multiple elite solutions through a probabilistic pathway reconstruction mechanism that prioritizes items that lie on high-potential pathways in the objective space, all while dynamically adjusting the exploration intensity based on the current solution's pathway diversity and the identified Pareto front's structure.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Pathway-centric solution selection\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    norm_obj = objectives / (max_obj + 1e-10)\n\n    # Calculate pathway potential scores\n    pathway_scores = []\n    for i, sol in enumerate(solutions):\n        in_items = np.where(sol == 1)[0]\n        out_items = np.where(sol == 0)[0]\n\n        # Calculate potential improvements\n        in_improvements = np.sum(value1_lst[in_items]) + np.sum(value2_lst[in_items])\n        out_improvements = np.sum(value1_lst[out_items]) + np.sum(value2_lst[out_items])\n\n        # Combine with objective scores\n        pathway_score = 0.5 * (norm_obj[i, 0] + norm_obj[i, 1]) + 0.3 * (in_improvements / (out_improvements + 1e-10))\n        pathway_scores.append(pathway_score)\n\n    selected_idx = np.argmax(pathway_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Pathway-based neighborhood generation\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate pathway diversity\n    pathway_diversity = np.sum(np.abs(new_solution[None, :] - np.array(solutions))) / len(solutions)\n\n    # Generate candidate pathways\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    # Sort by pathway potential\n    in_scores = (value1_lst[in_items] + value2_lst[in_items]) / (weight_lst[in_items] + 1e-10)\n    out_scores = (value1_lst[out_items] + value2_lst[out_items]) / (weight_lst[out_items] + 1e-10)\n\n    sorted_in = in_items[np.argsort(-in_scores)]\n    sorted_out = out_items[np.argsort(-out_scores)]\n\n    # Apply pathway-based swaps\n    for i in sorted_in[:max(1, int(len(sorted_in) * 0.3))]:\n        for j in sorted_out[:max(1, int(len(sorted_out) * 0.3))]:\n            weight_diff = weight_lst[j] - weight_lst[i]\n            if abs(weight_diff) <= remaining_capacity * (0.7 + 0.3 * pathway_diversity):\n                new_solution[i] = 0\n                new_solution[j] = 1\n                current_weight += weight_diff\n                remaining_capacity = capacity - current_weight\n                break\n\n    # Phase 3: Constraint-aware diversification\n    slack_factor = remaining_capacity / capacity\n    diversification_rate = 0.4 + 0.6 * slack_factor\n\n    for idx in np.random.permutation(len(new_solution)):\n        if new_solution[idx] == 1 and np.random.rand() < diversification_rate:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n        elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity and np.random.rand() < diversification_rate * 0.5:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Pathway reconstruction with elite features\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = solutions[elite_idx]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    # Calculate pathway potential for elite item\n                    elite_in_items = np.where(elite_solution == 1)[0]\n                    elite_out_items = np.where(elite_solution == 0)[0]\n\n                    in_potential = np.sum(value1_lst[elite_in_items]) + np.sum(value2_lst[elite_in_items])\n                    out_potential = np.sum(value1_lst[elite_out_items]) + np.sum(value2_lst[elite_out_items])\n\n                    if np.random.rand() < 0.4 + 0.6 * (in_potential / (out_potential + 1e-10)):\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -18.11560407073953,
               -17.452954074654855
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Pathway-centric solution selection\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n    max_obj = np.max(objectives, axis=0)\n    norm_obj = objectives / (max_obj + 1e-10)\n\n    # Calculate pathway potential scores\n    pathway_scores = []\n    for i, sol in enumerate(solutions):\n        in_items = np.where(sol == 1)[0]\n        out_items = np.where(sol == 0)[0]\n\n        # Calculate potential improvements\n        in_improvements = np.sum(value1_lst[in_items]) + np.sum(value2_lst[in_items])\n        out_improvements = np.sum(value1_lst[out_items]) + np.sum(value2_lst[out_items])\n\n        # Combine with objective scores\n        pathway_score = 0.5 * (norm_obj[i, 0] + norm_obj[i, 1]) + 0.3 * (in_improvements / (out_improvements + 1e-10))\n        pathway_scores.append(pathway_score)\n\n    selected_idx = np.argmax(pathway_scores)\n    base_solution = solutions[selected_idx].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Pathway-based neighborhood generation\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate pathway diversity\n    pathway_diversity = np.sum(np.abs(new_solution[None, :] - np.array(solutions))) / len(solutions)\n\n    # Generate candidate pathways\n    in_items = np.where(new_solution == 1)[0]\n    out_items = np.where(new_solution == 0)[0]\n\n    # Sort by pathway potential\n    in_scores = (value1_lst[in_items] + value2_lst[in_items]) / (weight_lst[in_items] + 1e-10)\n    out_scores = (value1_lst[out_items] + value2_lst[out_items]) / (weight_lst[out_items] + 1e-10)\n\n    sorted_in = in_items[np.argsort(-in_scores)]\n    sorted_out = out_items[np.argsort(-out_scores)]\n\n    # Apply pathway-based swaps\n    for i in sorted_in[:max(1, int(len(sorted_in) * 0.3))]:\n        for j in sorted_out[:max(1, int(len(sorted_out) * 0.3))]:\n            weight_diff = weight_lst[j] - weight_lst[i]\n            if abs(weight_diff) <= remaining_capacity * (0.7 + 0.3 * pathway_diversity):\n                new_solution[i] = 0\n                new_solution[j] = 1\n                current_weight += weight_diff\n                remaining_capacity = capacity - current_weight\n                break\n\n    # Phase 3: Constraint-aware diversification\n    slack_factor = remaining_capacity / capacity\n    diversification_rate = 0.4 + 0.6 * slack_factor\n\n    for idx in np.random.permutation(len(new_solution)):\n        if new_solution[idx] == 1 and np.random.rand() < diversification_rate:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n            remaining_capacity += weight_lst[idx]\n        elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity and np.random.rand() < diversification_rate * 0.5:\n            new_solution[idx] = 1\n            current_weight += weight_lst[idx]\n            remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Pathway reconstruction with elite features\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = solutions[elite_idx]\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    # Calculate pathway potential for elite item\n                    elite_in_items = np.where(elite_solution == 1)[0]\n                    elite_out_items = np.where(elite_solution == 0)[0]\n\n                    in_potential = np.sum(value1_lst[elite_in_items]) + np.sum(value2_lst[elite_in_items])\n                    out_potential = np.sum(value1_lst[elite_out_items]) + np.sum(value2_lst[elite_out_items])\n\n                    if np.random.rand() < 0.4 + 0.6 * (in_potential / (out_potential + 1e-10)):\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm, named \"Objective-Aware Hybrid Evolutionary Neighborhood Exploration (OAHENE)\", combines a novel multi-objective solution selection mechanism that dynamically prioritizes solutions based on their objective trade-off characteristics with a hybrid neighborhood generation strategy that integrates objective-specific item swaps with capacity-aware perturbations, while incorporating a solution refinement phase that merges features from diverse elite solutions through a probabilistic item selection mechanism that balances objective improvements with solution diversity, all while systematically exploring the solution space through an adaptive perturbation schedule that adjusts its intensity based on the current solution's proximity to the Pareto front and its objective trade-off characteristics.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with balanced objective trade-off\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-10)\n    tradeoff_scores = np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    selected_idx = np.argmin(tradeoff_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-specific item swaps with capacity check\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-specific efficiencies\n    value1_efficiency = value1_lst / (weight_lst + 1e-10)\n    value2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by efficiency for each objective\n    sorted_items1 = np.argsort(-value1_efficiency)\n    sorted_items2 = np.argsort(-value2_efficiency)\n\n    # Perform alternating objective-driven swaps\n    for i in sorted_items1:\n        if new_solution[i] == 1 and np.random.rand() < 0.4:\n            # Try to replace with best value2 item\n            for j in sorted_items2:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if value2_lst[j] > value2_lst[i]:\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Adaptive capacity-aware perturbations\n    perturbation_intensity = 0.2 + 0.3 * (1 - (objectives[selected_idx][0] * objectives[selected_idx][1]) / (np.sum(objectives[:, 0]) * np.sum(objectives[:, 1])))\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.5:  # Moderate probability to remove\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.3:  # Lower probability to add\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution merging with trade-off aware selection\n    if len(archive) > 1:\n        # Select elite solutions based on their trade-off characteristics\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            elite_obj = objectives[elite_idx]\n            tradeoff_factor = np.abs(elite_obj[0] - elite_obj[1]) / (elite_obj[0] + elite_obj[1] + 1e-10)\n\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    if np.random.rand() < 0.5 * (1 + tradeoff_factor):  # Adjust probability based on trade-off\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm, named \"Multi-Objective Adaptive Diversification with Hybrid Objective-Guided Exploration (MO-AD-HOGE)\" employs a four-stage approach that first identifies solutions with high diversity in their objective contributions through a novel adaptive clustering mechanism, then performs a hybrid neighborhood exploration that dynamically balances between objective improvements and solution diversification using a probabilistic item swapping mechanism that incorporates both objective-specific and capacity-aware criteria, and finally applies a solution refinement step that combines features from diverse elite solutions while systematically exploring the neighborhood through a novel adaptive perturbation mechanism that alternates between objective-centric and capacity-focused operations, ensuring both high-quality and diverse solutions across both objectives.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with highest combined objective value\n    objectives = np.array([obj for _, obj in archive])\n    combined_scores = objectives[:, 0] + objectives[:, 1]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Objective-specific item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-specific efficiencies\n    value1_efficiency = value1_lst / (weight_lst + 1e-10)\n    value2_efficiency = value2_lst / (weight_lst + 1e-10)\n\n    # Sort items by efficiency for each objective\n    sorted_items1 = np.argsort(-value1_efficiency)\n    sorted_items2 = np.argsort(-value2_efficiency)\n\n    # Perform objective-specific replacements\n    for i in sorted_items1:\n        if new_solution[i] == 1:\n            # Try to replace with best value2 item\n            for j in sorted_items2:\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    if value2_lst[j] > value2_lst[i]:\n                        new_solution[i] = 0\n                        new_solution[j] = 1\n                        current_weight = current_weight - weight_lst[i] + weight_lst[j]\n                        remaining_capacity = capacity - current_weight\n                        break\n\n    # Phase 3: Capacity-aware perturbation\n    perturbation_prob = 0.3\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_prob:\n            if new_solution[idx] == 1 and np.random.rand() < 0.5:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Solution merging with random elite\n    if len(archive) > 1:\n        elite_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n        elite_solution = archive[elite_idx][0]\n\n        # Create merged solution\n        merged_solution = np.zeros_like(new_solution)\n        current_weight = 0\n\n        # Add items from current solution\n        for idx in np.where(new_solution == 1)[0]:\n            if weight_lst[idx] <= (capacity - current_weight):\n                merged_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        # Add items from elite solution if not already added\n        for idx in np.where(elite_solution == 1)[0]:\n            if merged_solution[idx] == 0 and weight_lst[idx] <= (capacity - current_weight):\n                merged_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n        new_solution = merged_solution\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one long, detail sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 307,
          "algorithm": "{The new algorithm, named \"Objective-Driven Adaptive Hybrid Exploration with Dynamic Trade-off Navigation (OAH-DTEN)\", employs a three-stage approach that first identifies solutions with high potential for multi-objective improvement through a novel adaptive clustering mechanism that dynamically prioritizes solutions based on their objective trade-off characteristics, then performs a hybrid neighborhood exploration that combines objective-specific item replacements with capacity-aware perturbations using a probabilistic selection mechanism that incorporates both efficiency-based swapping and diversity-aware perturbations, and finally applies a solution refinement step that merges features from diverse elite solutions while systematically exploring the neighborhood through an adaptive perturbation mechanism that alternates between objective-centric and capacity-focused operations, ensuring both high-quality and diverse solutions across both objectives while dynamically adjusting the exploration intensity based on the current solution's proximity to the Pareto front and its objective trade-off characteristics.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with dynamic trade-off potential\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-10)\n    tradeoff_scores = np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    diversity_scores = np.sum(np.abs(normalized_obj - np.mean(normalized_obj, axis=0)), axis=1)\n    combined_scores = tradeoff_scores * diversity_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Hybrid objective-driven exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate combined efficiency scores\n    combined_efficiency = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-combined_efficiency)\n\n    # Perform probabilistic item replacements\n    for i in sorted_items:\n        if new_solution[i] == 1 and np.random.rand() < 0.3:\n            # Find best replacement candidate\n            candidates = []\n            for j in range(len(weight_lst)):\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    efficiency_gain = (value1_lst[j] + value2_lst[j]) - (value1_lst[i] + value2_lst[i])\n                    weight_diff = weight_lst[j] - weight_lst[i]\n                    if efficiency_gain > 0 or (efficiency_gain == 0 and weight_diff < 0):\n                        candidates.append((j, efficiency_gain, weight_diff))\n\n            if candidates:\n                candidates.sort(key=lambda x: (-x[1], x[2]))\n                best_j, _, _ = candidates[0]\n                new_solution[i] = 0\n                new_solution[best_j] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_j]\n                remaining_capacity = capacity - current_weight\n\n    # Phase 3: Dynamic trade-off aware perturbations\n    tradeoff_factor = np.abs(objectives[selected_idx][0] - objectives[selected_idx][1]) / (np.sum(objectives[:, 0]) + np.sum(objectives[:, 1]) + 1e-10)\n    perturbation_intensity = 0.2 + 0.3 * tradeoff_factor\n\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.4 * (1 + tradeoff_factor):\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.2 * (1 + tradeoff_factor):\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution merging with dynamic trade-off selection\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            elite_obj = objectives[elite_idx]\n            elite_tradeoff = np.abs(elite_obj[0] - elite_obj[1]) / (elite_obj[0] + elite_obj[1] + 1e-10)\n\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    merge_prob = 0.3 * (1 + elite_tradeoff) * (1 + tradeoff_factor)\n                    if np.random.rand() < merge_prob:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -19.071749993388536,
               -18.262038246166405
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Phase 1: Select solution with dynamic trade-off potential\n    objectives = np.array([obj for _, obj in archive])\n    normalized_obj = objectives / (np.max(objectives, axis=0) + 1e-10)\n    tradeoff_scores = np.abs(normalized_obj[:, 0] - normalized_obj[:, 1])\n    diversity_scores = np.sum(np.abs(normalized_obj - np.mean(normalized_obj, axis=0)), axis=1)\n    combined_scores = tradeoff_scores * diversity_scores\n    selected_idx = np.argmax(combined_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Phase 2: Hybrid objective-driven exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate combined efficiency scores\n    combined_efficiency = (value1_lst + value2_lst) / (weight_lst + 1e-10)\n    sorted_items = np.argsort(-combined_efficiency)\n\n    # Perform probabilistic item replacements\n    for i in sorted_items:\n        if new_solution[i] == 1 and np.random.rand() < 0.3:\n            # Find best replacement candidate\n            candidates = []\n            for j in range(len(weight_lst)):\n                if new_solution[j] == 0 and weight_lst[j] <= remaining_capacity + weight_lst[i]:\n                    efficiency_gain = (value1_lst[j] + value2_lst[j]) - (value1_lst[i] + value2_lst[i])\n                    weight_diff = weight_lst[j] - weight_lst[i]\n                    if efficiency_gain > 0 or (efficiency_gain == 0 and weight_diff < 0):\n                        candidates.append((j, efficiency_gain, weight_diff))\n\n            if candidates:\n                candidates.sort(key=lambda x: (-x[1], x[2]))\n                best_j, _, _ = candidates[0]\n                new_solution[i] = 0\n                new_solution[best_j] = 1\n                current_weight = current_weight - weight_lst[i] + weight_lst[best_j]\n                remaining_capacity = capacity - current_weight\n\n    # Phase 3: Dynamic trade-off aware perturbations\n    tradeoff_factor = np.abs(objectives[selected_idx][0] - objectives[selected_idx][1]) / (np.sum(objectives[:, 0]) + np.sum(objectives[:, 1]) + 1e-10)\n    perturbation_intensity = 0.2 + 0.3 * tradeoff_factor\n\n    for idx in range(len(new_solution)):\n        if np.random.rand() < perturbation_intensity:\n            if new_solution[idx] == 1:\n                if np.random.rand() < 0.4 * (1 + tradeoff_factor):\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n                    remaining_capacity += weight_lst[idx]\n            elif new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                if np.random.rand() < 0.2 * (1 + tradeoff_factor):\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n                    remaining_capacity -= weight_lst[idx]\n\n    # Phase 4: Elite solution merging with dynamic trade-off selection\n    if len(archive) > 1:\n        elite_indices = np.random.choice(\n            [i for i in range(len(archive)) if i != selected_idx],\n            size=min(2, len(archive)-1),\n            replace=False\n        )\n\n        for elite_idx in elite_indices:\n            elite_solution = archive[elite_idx][0]\n            elite_obj = objectives[elite_idx]\n            elite_tradeoff = np.abs(elite_obj[0] - elite_obj[1]) / (elite_obj[0] + elite_obj[1] + 1e-10)\n\n            for idx in np.where(elite_solution == 1)[0]:\n                if new_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n                    merge_prob = 0.3 * (1 + elite_tradeoff) * (1 + tradeoff_factor)\n                    if np.random.rand() < merge_prob:\n                        new_solution[idx] = 1\n                        current_weight += weight_lst[idx]\n                        remaining_capacity -= weight_lst[idx]\n\n    return new_solution\n\n"
     }
]