[
     {
          "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm builds upon the common backbone of identifying promising solutions through objective trade-off analysis and Pareto-front awareness, while introducing a novel multi-phase adaptive perturbation strategy that dynamically combines probabilistic item selection, objective-balanced flipping, and capacity-aware exploration. It first selects solutions based on their combined objective values and trade-off potential, then applies a hybrid local search that probabilistically flips items based on their marginal contributions to both objectives, selectively incorporates items near the Pareto frontier's knee point, and performs an adaptive capacity-aware random walk that explores weight-sensitive regions while maintaining feasibility through dynamic weight adjustment. The algorithm further refines the solution by incorporating a guided neighborhood exploration that prioritizes items with balanced contributions to both objectives, and concludes with a final greedy phase that adds the most promising items while respecting capacity constraints. The intensity of each perturbation phase is dynamically adjusted based on the solution's position relative to the Pareto front and the archive's diversity, ensuring both exploration and exploitation of the search space.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution based on combined objective values and trade-off potential\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    trade_off = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_score = combined_values * trade_off\n    best_idx = np.argmax(diversity_score)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Multi-phase local search with dynamic strategy adjustment\n    n_items = len(weight_lst)\n\n    # Phase 1: Objective-balanced perturbation with adaptive probability\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_improvement = (delta_value1 + delta_value2) / (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1]) + 1e-6)\n                prob = min(1.0, 0.2 + 0.8 * norm_improvement)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Phase 2: Frontier-aware swap with diversity consideration\n    if len(archive) > 2:\n        sorted_idx = np.argsort(objectives[:, 0] + objectives[:, 1])\n        middle_solution = archive[sorted_idx[len(archive)//2]][0]\n        for i in range(n_items):\n            if middle_solution[i] != new_solution[i] and np.random.rand() < 0.3:\n                if middle_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Phase 3: Capacity-sensitive mutation with neighborhood exploration\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        np.random.shuffle(candidates)\n        for i in candidates:\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < 0.5:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Phase 4: Dynamic strategy adjustment based on Pareto front characteristics\n    if np.random.rand() < 0.2:\n        knee_point = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_point][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.4:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm introduces a novel hybrid multi-objective transformation that first identifies solutions with high objective diversity and trade-off potential by analyzing both the normalized objective values and their distribution across the Pareto front, then applies a dynamic, phase-based local search strategy that combines a probabilistic item inversion guided by both objectives' marginal contributions weighted by their objective-space distances, a Pareto-frontier guided perturbation that explores regions near the knee point while maintaining feasibility, a capacity-aware item replacement that intelligently removes low-contribution items when exceeding capacity, and a final objective-balanced greedy refinement phase that selectively adds high-contribution items while ensuring both objectives are improved, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-correlation\" perturbation that flips items based on their cross-objective contribution patterns and a \"frontier-aware\" item replacement that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective diversity and correlation\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n    diversity_scores = np.prod(normalized, axis=1)\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    selection_scores = diversity_scores * correlation_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-correlation perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                v1_contrib = value1_lst[i] / (max_values[0] + 1e-6)\n                v2_contrib = value2_lst[i] / (max_values[1] + 1e-6)\n                correlation = np.abs(v1_contrib - v2_contrib)\n                prob = min(1.0, 0.2 + 0.8 * correlation)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware item replacement\n    if len(archive) > 1:\n        knee_idx = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.5:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1 and np.random.rand() < 0.3:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        item_contributions = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_contributions)]\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    # Step 5: Objective-balanced greedy addition\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            v1_norm = value1_lst[candidates] / (max_values[0] + 1e-6)\n            v2_norm = value2_lst[candidates] / (max_values[1] + 1e-6)\n            combined_scores = v1_norm + v2_norm\n            best_item = np.argmax(combined_scores[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one long, detail sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 301,
          "algorithm": "{The new algorithm introduces a novel multi-phase exploration strategy that first selects solutions based on their objective-space coverage and diversity, then applies a hybrid neighborhood generation that combines a probabilistic item inversion guided by both objectives' normalized contributions, a Pareto-frontier guided perturbation that explores regions near the knee point while maintaining feasibility, a capacity-aware item replacement that intelligently removes low-contribution items when exceeding capacity, and a final objective-balanced greedy refinement phase that selectively adds high-contribution items while ensuring both objectives are improved, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-correlation\" perturbation that flips items based on their cross-objective contribution patterns and a \"frontier-aware\" item replacement that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective coverage and diversity\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n    coverage_scores = np.prod(normalized, axis=1)\n    diversity_scores = np.std(normalized, axis=1)\n    selection_scores = coverage_scores * diversity_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-correlation perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                v1_norm = value1_lst[i] / (max_values[0] + 1e-6)\n                v2_norm = value2_lst[i] / (max_values[1] + 1e-6)\n                correlation = np.abs(v1_norm - v2_norm)\n                prob = min(1.0, 0.3 + 0.7 * correlation)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware item replacement\n    if len(archive) > 1:\n        knee_idx = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.4:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1 and np.random.rand() < 0.2:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        item_contributions = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_contributions)]\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    # Step 5: Objective-balanced greedy addition\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            v1_norm = value1_lst[candidates] / (max_values[0] + 1e-6)\n            v2_norm = value2_lst[candidates] / (max_values[1] + 1e-6)\n            combined_scores = v1_norm + v2_norm\n            best_item = np.argmax(combined_scores[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.426372617375993,
               -19.133490258855485
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective coverage and diversity\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n    coverage_scores = np.prod(normalized, axis=1)\n    diversity_scores = np.std(normalized, axis=1)\n    selection_scores = coverage_scores * diversity_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-correlation perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                v1_norm = value1_lst[i] / (max_values[0] + 1e-6)\n                v2_norm = value2_lst[i] / (max_values[1] + 1e-6)\n                correlation = np.abs(v1_norm - v2_norm)\n                prob = min(1.0, 0.3 + 0.7 * correlation)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware item replacement\n    if len(archive) > 1:\n        knee_idx = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.4:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1 and np.random.rand() < 0.2:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        item_contributions = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_contributions)]\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    # Step 5: Objective-balanced greedy addition\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            v1_norm = value1_lst[candidates] / (max_values[0] + 1e-6)\n            v2_norm = value2_lst[candidates] / (max_values[1] + 1e-6)\n            combined_scores = v1_norm + v2_norm\n            best_item = np.argmax(combined_scores[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm introduces a novel hybrid multi-objective transformation that first identifies solutions with high objective diversity and trade-off potential by analyzing both the normalized objective values and their distribution across the Pareto front, then applies a dynamic, phase-based local search strategy that combines a probabilistic item inversion guided by both objectives' marginal contributions weighted by their objective-space distances, a Pareto-frontier guided perturbation that explores regions near the knee point while maintaining feasibility, a capacity-aware item replacement that intelligently removes low-contribution items when exceeding capacity, and a final objective-balanced greedy refinement phase that selectively adds high-contribution items while ensuring both objectives are improved, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-correlation\" perturbation that flips items based on their cross-objective contribution patterns and a \"frontier-aware\" item replacement that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective diversity and correlation\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n    diversity_scores = np.prod(normalized, axis=1)\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    selection_scores = diversity_scores * correlation_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-correlation perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                v1_contrib = value1_lst[i] / (max_values[0] + 1e-6)\n                v2_contrib = value2_lst[i] / (max_values[1] + 1e-6)\n                correlation = np.abs(v1_contrib - v2_contrib)\n                prob = min(1.0, 0.2 + 0.8 * correlation)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware item replacement\n    if len(archive) > 1:\n        knee_idx = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.5:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1 and np.random.rand() < 0.3:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        item_contributions = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_contributions)]\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    # Step 5: Objective-balanced greedy addition\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            v1_norm = value1_lst[candidates] / (max_values[0] + 1e-6)\n            v2_norm = value2_lst[candidates] / (max_values[1] + 1e-6)\n            combined_scores = v1_norm + v2_norm\n            best_item = np.argmax(combined_scores[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm introduces a dynamic, objective-aware transformation that first identifies solutions with high potential for multi-objective improvement by analyzing both the normalized objective values and their distribution across the Pareto front, then applies a hybrid local search strategy that combines a probabilistic item inversion guided by both objectives' marginal contributions weighted by their objective-space distances, a Pareto-frontier guided perturbation that explores regions near the knee point while maintaining feasibility, a capacity-aware item replacement that intelligently removes low-contribution items when exceeding capacity, and a final objective-balanced greedy refinement phase that selectively adds high-contribution items while ensuring both objectives are improved, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-correlation\" perturbation that flips items based on their cross-objective contribution patterns and a \"frontier-aware\" item replacement that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints. Additionally, it introduces a novel \"knee-point guided\" transformation that selectively includes/excludes items near the knee point based on their potential to improve both objectives, and a \"diversity-aware\" selection mechanism that prioritizes solutions with high objective diversity and trade-off potential, while dynamically balancing exploration and exploitation by adjusting the selection probability of these strategies based on the archive's diversity.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective diversity and correlation\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n    diversity_scores = np.prod(normalized, axis=1)\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    selection_scores = diversity_scores * correlation_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Knee-point guided transformation\n    if len(archive) > 1:\n        knee_idx = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.5:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1 and np.random.rand() < 0.3:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 3: Objective-correlation perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                v1_contrib = value1_lst[i] / (max_values[0] + 1e-6)\n                v2_contrib = value2_lst[i] / (max_values[1] + 1e-6)\n                correlation = np.abs(v1_contrib - v2_contrib)\n                prob = min(1.0, 0.2 + 0.8 * correlation)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 4: Capacity-aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        item_contributions = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_contributions)]\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    # Step 5: Diversity-aware greedy addition\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            v1_norm = value1_lst[candidates] / (max_values[0] + 1e-6)\n            v2_norm = value2_lst[candidates] / (max_values[1] + 1e-6)\n            combined_scores = v1_norm + v2_norm\n            best_item = np.argmax(combined_scores[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one long, detail sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 302,
          "algorithm": "{The new algorithm introduces a novel adaptive, multi-phase local search strategy that first identifies solutions with high potential for improvement by analyzing both the normalized objective values and their distribution across the Pareto front, then applies a dynamic, phase-based transformation that combines a probabilistic item inversion guided by both objectives' marginal contributions weighted by their objective-space distances, a Pareto-frontier guided perturbation that explores regions near the knee point while maintaining feasibility, a capacity-aware item replacement that intelligently removes low-contribution items when exceeding capacity, and a final objective-balanced greedy refinement phase that selectively adds high-contribution items while ensuring both objectives are improved, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-correlation\" perturbation that flips items based on their cross-objective contribution patterns, a \"frontier-aware\" item replacement that prioritizes items near the Pareto frontier, and a unique \"trade-off aware\" selection mechanism that prioritizes solutions with high objective diversity and trade-off potential, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints. Additionally, it introduces a novel \"knee-point guided\" transformation that selectively includes/excludes items near the knee point based on their potential to improve both objectives, and a \"diversity-aware\" selection mechanism that prioritizes solutions with high objective diversity and trade-off potential, while dynamically balancing exploration and exploitation by adjusting the selection probability of these strategies based on the archive's diversity.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective diversity and trade-off potential\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n    diversity_scores = np.prod(normalized, axis=1)\n    tradeoff_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    selection_scores = diversity_scores * tradeoff_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Trade-off aware item perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                v1_contrib = value1_lst[i] / (max_values[0] + 1e-6)\n                v2_contrib = value2_lst[i] / (max_values[1] + 1e-6)\n                tradeoff = np.abs(v1_contrib - v2_contrib)\n                prob = min(1.0, 0.3 + 0.7 * tradeoff)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Knee-point guided transformation\n    if len(archive) > 1:\n        knee_idx = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.4:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1 and np.random.rand() < 0.2:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        item_contributions = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_contributions)]\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    # Step 5: Diversity-aware greedy addition\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            v1_norm = value1_lst[candidates] / (max_values[0] + 1e-6)\n            v2_norm = value2_lst[candidates] / (max_values[1] + 1e-6)\n            combined_scores = v1_norm + v2_norm\n            best_item = np.argmax(combined_scores[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.28763324145917,
               -19.12168761933173
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective diversity and trade-off potential\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n    diversity_scores = np.prod(normalized, axis=1)\n    tradeoff_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    selection_scores = diversity_scores * tradeoff_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Trade-off aware item perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                v1_contrib = value1_lst[i] / (max_values[0] + 1e-6)\n                v2_contrib = value2_lst[i] / (max_values[1] + 1e-6)\n                tradeoff = np.abs(v1_contrib - v2_contrib)\n                prob = min(1.0, 0.3 + 0.7 * tradeoff)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Knee-point guided transformation\n    if len(archive) > 1:\n        knee_idx = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.4:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1 and np.random.rand() < 0.2:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        item_contributions = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_contributions)]\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    # Step 5: Diversity-aware greedy addition\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            v1_norm = value1_lst[candidates] / (max_values[0] + 1e-6)\n            v2_norm = value2_lst[candidates] / (max_values[1] + 1e-6)\n            combined_scores = v1_norm + v2_norm\n            best_item = np.argmax(combined_scores[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm builds upon the common backbone of identifying promising solutions through objective trade-off analysis and Pareto-front awareness, while introducing a novel multi-phase adaptive perturbation strategy that dynamically combines probabilistic item selection, objective-balanced flipping, and capacity-aware exploration. It first selects solutions based on their combined objective values and trade-off potential, then applies a hybrid local search that probabilistically flips items based on their marginal contributions to both objectives, selectively incorporates items near the Pareto frontier's knee point, and performs an adaptive capacity-aware random walk that explores weight-sensitive regions while maintaining feasibility through dynamic weight adjustment. The algorithm further refines the solution by incorporating a guided neighborhood exploration that prioritizes items with balanced contributions to both objectives, and concludes with a final greedy phase that adds the most promising items while respecting capacity constraints. The intensity of each perturbation phase is dynamically adjusted based on the solution's position relative to the Pareto front and the archive's diversity, ensuring both exploration and exploitation of the search space.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution based on combined objective values and trade-off potential\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    trade_off = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_score = combined_values * trade_off\n    best_idx = np.argmax(diversity_score)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Multi-phase local search with dynamic strategy adjustment\n    n_items = len(weight_lst)\n\n    # Phase 1: Objective-balanced perturbation with adaptive probability\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_improvement = (delta_value1 + delta_value2) / (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1]) + 1e-6)\n                prob = min(1.0, 0.2 + 0.8 * norm_improvement)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Phase 2: Frontier-aware swap with diversity consideration\n    if len(archive) > 2:\n        sorted_idx = np.argsort(objectives[:, 0] + objectives[:, 1])\n        middle_solution = archive[sorted_idx[len(archive)//2]][0]\n        for i in range(n_items):\n            if middle_solution[i] != new_solution[i] and np.random.rand() < 0.3:\n                if middle_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Phase 3: Capacity-sensitive mutation with neighborhood exploration\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        np.random.shuffle(candidates)\n        for i in candidates:\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < 0.5:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Phase 4: Dynamic strategy adjustment based on Pareto front characteristics\n    if np.random.rand() < 0.2:\n        knee_point = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_point][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.4:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm introduces a novel multi-layered exploration strategy that first selects the most promising solution from the archive by analyzing both objective values and their trade-off potential, then applies a hybrid local search that combines a probabilistic item selection mechanism weighted by normalized objective improvements, a Pareto-front guided item replacement that leverages the archive's extreme points, and a capacity-aware random walk that explores weight-sensitive regions while dynamically adjusting the exploration intensity based on the current solution's position relative to the Pareto front and the remaining capacity. The algorithm further refines the solution by incorporating a guided neighborhood exploration that prioritizes items with balanced contributions to both objectives, and concludes with a final greedy phase that adds the most promising items while respecting capacity constraints. The intensity of each perturbation phase is dynamically adjusted based on the solution's position relative to the Pareto front and the archive's diversity, ensuring both exploration and exploitation of the search space.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution based on combined objective values and trade-off potential\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    trade_off = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_score = combined_values * trade_off\n    best_idx = np.argmax(diversity_score)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Multi-phase local search with dynamic strategy adjustment\n    n_items = len(weight_lst)\n\n    # Phase 1: Objective-balanced perturbation with adaptive probability\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_improvement = (delta_value1 + delta_value2) / (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1]) + 1e-6)\n                prob = min(1.0, 0.2 + 0.8 * norm_improvement)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Phase 2: Frontier-aware swap with diversity consideration\n    if len(archive) > 2:\n        sorted_idx = np.argsort(objectives[:, 0] + objectives[:, 1])\n        middle_solution = archive[sorted_idx[len(archive)//2]][0]\n        for i in range(n_items):\n            if middle_solution[i] != new_solution[i] and np.random.rand() < 0.3:\n                if middle_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Phase 3: Capacity-sensitive mutation with neighborhood exploration\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        np.random.shuffle(candidates)\n        for i in candidates:\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < 0.5:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Phase 4: Dynamic strategy adjustment based on Pareto front characteristics\n    if np.random.rand() < 0.2:\n        knee_point = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_point][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.4:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 303,
          "algorithm": "{The new algorithm introduces a novel adaptive multi-phase exploration strategy that first selects a solution based on a hybrid objective diversity metric combining both objectives and their trade-off potential, then applies a tiered local search that alternates between a probabilistic item selection mechanism weighted by normalized objective improvements, a Pareto-front guided item replacement that leverages the archive's extreme points, and a capacity-aware random walk that explores weight-sensitive regions while dynamically adjusting the exploration intensity based on the current solution's position relative to the Pareto front and the remaining capacity. The algorithm further refines the solution by incorporating a guided neighborhood exploration that prioritizes items with balanced contributions to both objectives, and concludes with a final greedy phase that adds the most promising items while respecting capacity constraints. The intensity of each perturbation phase is dynamically adjusted based on the solution's position relative to the Pareto front and the archive's diversity, ensuring both exploration and exploitation of the search space. Additionally, the algorithm incorporates a novel adaptive weight scaling mechanism that dynamically adjusts item weights during the search process to better navigate the multi-objective landscape, further enhancing the solution quality.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution based on hybrid objective diversity metric\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    trade_off = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_score = combined_values * trade_off * (1 - np.abs(trade_off - 1))\n    best_idx = np.argmax(diversity_score)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Tiered local search with adaptive weight scaling\n    n_items = len(weight_lst)\n\n    # Tier 1: Probabilistic item selection with normalized objective improvements\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_improvement = (delta_value1 + delta_value2) / (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1]) + 1e-6)\n                prob = min(1.0, 0.2 + 0.8 * norm_improvement)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Tier 2: Pareto-front guided item replacement\n    if len(archive) > 2:\n        sorted_idx = np.argsort(objectives[:, 0] + objectives[:, 1])\n        middle_solution = archive[sorted_idx[len(archive)//2]][0]\n        for i in range(n_items):\n            if middle_solution[i] != new_solution[i] and np.random.rand() < 0.3:\n                if middle_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Tier 3: Capacity-aware random walk with adaptive weight scaling\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        np.random.shuffle(candidates)\n        for i in candidates:\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < 0.5:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Tier 4: Dynamic strategy adjustment based on Pareto front characteristics\n    if np.random.rand() < 0.2:\n        knee_point = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_point][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.4:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Adaptive weight scaling mechanism\n    if np.random.rand() < 0.3:\n        weight_scaling = np.random.uniform(0.8, 1.2, size=n_items)\n        scaled_weights = weight_lst * weight_scaling\n        current_weight = np.sum(scaled_weights[new_solution == 1])\n        for i in range(n_items):\n            if new_solution[i] == 1 and current_weight > capacity:\n                new_solution[i] = 0\n                current_weight -= scaled_weights[i]\n\n    return new_solution\n\n",
          "score": [
               -19.148732845353685,
               -18.49562786767892
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution based on hybrid objective diversity metric\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    trade_off = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_score = combined_values * trade_off * (1 - np.abs(trade_off - 1))\n    best_idx = np.argmax(diversity_score)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Tiered local search with adaptive weight scaling\n    n_items = len(weight_lst)\n\n    # Tier 1: Probabilistic item selection with normalized objective improvements\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_improvement = (delta_value1 + delta_value2) / (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1]) + 1e-6)\n                prob = min(1.0, 0.2 + 0.8 * norm_improvement)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Tier 2: Pareto-front guided item replacement\n    if len(archive) > 2:\n        sorted_idx = np.argsort(objectives[:, 0] + objectives[:, 1])\n        middle_solution = archive[sorted_idx[len(archive)//2]][0]\n        for i in range(n_items):\n            if middle_solution[i] != new_solution[i] and np.random.rand() < 0.3:\n                if middle_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Tier 3: Capacity-aware random walk with adaptive weight scaling\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        np.random.shuffle(candidates)\n        for i in candidates:\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < 0.5:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Tier 4: Dynamic strategy adjustment based on Pareto front characteristics\n    if np.random.rand() < 0.2:\n        knee_point = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_point][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.4:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Adaptive weight scaling mechanism\n    if np.random.rand() < 0.3:\n        weight_scaling = np.random.uniform(0.8, 1.2, size=n_items)\n        scaled_weights = weight_lst * weight_scaling\n        current_weight = np.sum(scaled_weights[new_solution == 1])\n        for i in range(n_items):\n            if new_solution[i] == 1 and current_weight > capacity:\n                new_solution[i] = 0\n                current_weight -= scaled_weights[i]\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm introduces a novel adaptive multi-objective transformation that first selects solutions based on their objective correlation and diversity, then applies a three-phase strategy combining a probabilistic item inversion guided by both objectives' marginal contributions weighted by their normalized objective distances, a Pareto-front guided perturbation that explores regions near the knee point while maintaining feasibility, an adaptive capacity-aware random walk that ensures feasibility by considering both the current solution's weight and the remaining capacity, and a final greedy refinement phase that adds the most promising items that improve both objectives while respecting capacity constraints, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-balanced\" perturbation that selectively flips items based on their contribution to both objectives and a \"frontier-aware\" swap that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective correlation and diversity\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    diversity_scores = np.prod(normalized, axis=1)\n    selection_scores = correlation_scores * diversity_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-balanced perturbation with adaptive probability\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_distance = np.sqrt((delta_value1 / (max_values[0] - min_values[0] + 1e-6))**2 +\n                                       (delta_value2 / (max_values[1] - min_values[1] + 1e-6))**2)\n                prob = min(1.0, 0.2 + 0.8 * norm_distance)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware swap with knee-point guidance\n    if len(archive) > 1:\n        knee_point = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_point][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.5:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware random walk with adaptive step size\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] + value2_lst[candidates]) / candidate_weights\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            step_size = min(0.3, remaining_capacity / np.sum(candidate_weights[feasible]))\n            selected = np.random.choice(candidates[feasible], size=max(1, int(len(candidates[feasible]) * step_size)), replace=False)\n            for i in selected:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Step 5: Greedy refinement with balanced objective consideration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] / (max_values[0] + 1e-6) +\n                           value2_lst[candidates] / (max_values[1] + 1e-6)) / 2\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            best_item = np.argmax(candidate_values[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        item_values = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_values)]\n        excess = current_weight - capacity\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm introduces a novel adaptive multi-objective transformation that first selects solutions based on their objective correlation and diversity, then applies a three-phase strategy combining a probabilistic item inversion guided by both objectives' marginal contributions weighted by their normalized objective distances, a Pareto-front guided perturbation that explores regions near the knee point while maintaining feasibility, an adaptive capacity-aware random walk that ensures feasibility by considering both the current solution's weight and the remaining capacity, and a final greedy refinement phase that adds the most promising items that improve both objectives while respecting capacity constraints, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-balanced\" perturbation that selectively flips items based on their contribution to both objectives and a \"frontier-aware\" swap that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective correlation and diversity\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    diversity_scores = np.prod(normalized, axis=1)\n    selection_scores = correlation_scores * diversity_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-balanced perturbation with adaptive probability\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_distance = np.sqrt((delta_value1 / (max_values[0] - min_values[0] + 1e-6))**2 +\n                                       (delta_value2 / (max_values[1] - min_values[1] + 1e-6))**2)\n                prob = min(1.0, 0.2 + 0.8 * norm_distance)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware swap with knee-point guidance\n    if len(archive) > 1:\n        knee_point = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_point][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.5:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware random walk with adaptive step size\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] + value2_lst[candidates]) / candidate_weights\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            step_size = min(0.3, remaining_capacity / np.sum(candidate_weights[feasible]))\n            selected = np.random.choice(candidates[feasible], size=max(1, int(len(candidates[feasible]) * step_size)), replace=False)\n            for i in selected:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Step 5: Greedy refinement with balanced objective consideration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] / (max_values[0] + 1e-6) +\n                           value2_lst[candidates] / (max_values[1] + 1e-6)) / 2\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            best_item = np.argmax(candidate_values[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        item_values = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_values)]\n        excess = current_weight - capacity\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one long, detail sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 304,
          "algorithm": "{The new algorithm introduces a novel adaptive multi-objective transformation that first selects solutions based on their objective correlation and diversity, then applies a four-phase strategy combining a probabilistic item inversion guided by both objectives' marginal contributions weighted by their normalized objective distances, a Pareto-front guided perturbation that explores regions near the knee point while maintaining feasibility, an adaptive capacity-aware random walk that ensures feasibility by considering both the current solution's weight and the remaining capacity, and a final greedy refinement phase that adds the most promising items that improve both objectives while respecting capacity constraints, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-balanced\" perturbation that selectively flips items based on their contribution to both objectives and a \"frontier-aware\" swap that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints. Additionally, it introduces a novel \"knee-point biased\" selection mechanism that prioritizes solutions near the knee point of the Pareto front, and a \"diversity-aware\" perturbation that selectively explores regions of the objective space based on the current archive's diversity, and a \"trade-off aware\" swap that prioritizes items that improve both objectives while maintaining feasibility, ensuring a more balanced exploration of the trade-off space.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Knee-point biased selection\n    knee_point = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n    base_solution = archive[knee_point][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Diversity-aware perturbation\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n\n    diversity_scores = np.prod(normalized, axis=1)\n    for i in range(n_items):\n        if np.random.rand() < 0.3:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                diversity_contribution = diversity_scores.mean() * (1 - 2 * new_solution[i])\n                prob = min(1.0, 0.1 + 0.9 * diversity_contribution)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Trade-off aware swap\n    if len(archive) > 1:\n        for i in range(n_items):\n            if np.random.rand() < 0.4:\n                if new_solution[i] == 0 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware random walk with adaptive step size\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] + value2_lst[candidates]) / (candidate_weights + 1e-6)\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            step_size = min(0.4, remaining_capacity / np.sum(candidate_weights[feasible]))\n            selected = np.random.choice(candidates[feasible], size=max(1, int(len(candidates[feasible]) * step_size)), replace=False)\n            for i in selected:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Step 5: Greedy refinement with balanced objective consideration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] / (max_values[0] + 1e-6) +\n                           value2_lst[candidates] / (max_values[1] + 1e-6)) / 2\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            best_item = np.argmax(candidate_values[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        item_values = (value1_lst[excess_items] + value2_lst[excess_items]) / (weight_lst[excess_items] + 1e-6)\n        sorted_items = excess_items[np.argsort(item_values)]\n        excess = current_weight - capacity\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -16.96019799754138,
               -17.467986672438855
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Knee-point biased selection\n    knee_point = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n    base_solution = archive[knee_point][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Diversity-aware perturbation\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n\n    diversity_scores = np.prod(normalized, axis=1)\n    for i in range(n_items):\n        if np.random.rand() < 0.3:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                diversity_contribution = diversity_scores.mean() * (1 - 2 * new_solution[i])\n                prob = min(1.0, 0.1 + 0.9 * diversity_contribution)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Trade-off aware swap\n    if len(archive) > 1:\n        for i in range(n_items):\n            if np.random.rand() < 0.4:\n                if new_solution[i] == 0 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware random walk with adaptive step size\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] + value2_lst[candidates]) / (candidate_weights + 1e-6)\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            step_size = min(0.4, remaining_capacity / np.sum(candidate_weights[feasible]))\n            selected = np.random.choice(candidates[feasible], size=max(1, int(len(candidates[feasible]) * step_size)), replace=False)\n            for i in selected:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Step 5: Greedy refinement with balanced objective consideration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] / (max_values[0] + 1e-6) +\n                           value2_lst[candidates] / (max_values[1] + 1e-6)) / 2\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            best_item = np.argmax(candidate_values[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        item_values = (value1_lst[excess_items] + value2_lst[excess_items]) / (weight_lst[excess_items] + 1e-6)\n        sorted_items = excess_items[np.argsort(item_values)]\n        excess = current_weight - capacity\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm introduces a novel multi-objective neighborhood exploration strategy that first selects solutions based on their objective correlation and diversity, then applies a four-phase transformation combining a probabilistic item inversion guided by both objectives' marginal contributions weighted by their normalized objective distances, a Pareto-front guided perturbation that explores regions near the extreme points while maintaining feasibility, an adaptive capacity-aware random walk that ensures feasibility by considering both the current solution's weight and the remaining capacity, and a final greedy refinement phase that adds the most promising items that improve both objectives while respecting capacity constraints, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-balanced\" perturbation that selectively flips items based on their contribution to both objectives and a \"frontier-aware\" swap that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints, and finally employs a novel \"trade-off aware\" item replacement strategy that selectively removes items with poor trade-off ratios to maintain solution quality.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective correlation and diversity\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    diversity_scores = np.prod(normalized, axis=1)\n    selection_scores = correlation_scores * diversity_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-balanced perturbation with adaptive probability\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_distance = np.sqrt((delta_value1 / (max_values[0] - min_values[0] + 1e-6))**2 +\n                                       (delta_value2 / (max_values[1] - min_values[1] + 1e-6))**2)\n                prob = min(1.0, 0.2 + 0.8 * norm_distance)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware swap with extreme point guidance\n    if len(archive) > 1:\n        extreme_idx = np.argmax(objectives[:, 0] - objectives[:, 1])\n        extreme_solution = archive[extreme_idx][0]\n        for i in range(n_items):\n            if extreme_solution[i] != new_solution[i] and np.random.rand() < 0.5:\n                if extreme_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware random walk with adaptive step size\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] + value2_lst[candidates]) / candidate_weights\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            step_size = min(0.3, remaining_capacity / np.sum(candidate_weights[feasible]))\n            selected = np.random.choice(candidates[feasible], size=max(1, int(len(candidates[feasible]) * step_size)), replace=False)\n            for i in selected:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Step 5: Greedy refinement with balanced objective consideration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] / (max_values[0] + 1e-6) +\n                           value2_lst[candidates] / (max_values[1] + 1e-6)) / 2\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            best_item = np.argmax(candidate_values[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    # Step 6: Trade-off aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        item_tradeoffs = (value1_lst[excess_items] * value2_lst[excess_items]) / (weight_lst[excess_items] ** 2)\n        sorted_items = excess_items[np.argsort(item_tradeoffs)]\n        excess = current_weight - capacity\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The heuristic function 'select_neighbor' first identifies the most promising solution in the archive by evaluating the potential for improvement using a hybrid metric that combines the solution's current objective values with their spread across the Pareto front. It then applies a novel local search operator that intelligently combines three strategies: (1) a probabilistic swap of items based on their marginal contribution to both objectives, (2) a guided perturbation that selectively includes/excludes items near the Pareto front's knee point, and (3) a capacity-aware random walk that ensures feasibility by only considering moves that maintain or slightly reduce the total weight. The function dynamically balances exploration and exploitation by adjusting the selection probability of these strategies based on the archive's diversity, ensuring high-quality neighbors that efficiently navigate the trade-off space while always respecting the capacity constraint.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution (highest combined objective value)\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    best_idx = np.argmax(combined_values)\n    base_solution = archive[best_idx][0].copy()\n\n    # Step 2: Generate a neighbor using a hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Probabilistic swap based on marginal contribution\n    for _ in range(min(3, n_items // 2)):\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) == 0:\n            break\n        i = np.random.choice(candidates)\n        if new_solution[i] == 1 and np.random.rand() < 0.7:  # Higher probability to remove\n            new_solution[i] = 0\n            # Try to add a new item that improves both objectives\n            remaining_items = np.where(new_solution == 0)[0]\n            if len(remaining_items) > 0:\n                potential_adds = []\n                for j in remaining_items:\n                    if (weight_lst[j] <= capacity - np.sum(weight_lst[new_solution == 1])):\n                        potential_adds.append(j)\n                if potential_adds:\n                    j = np.random.choice(potential_adds)\n                    new_solution[j] = 1\n\n    # Strategy 2: Guided perturbation near knee point (approximate)\n    if len(archive) > 1:\n        # Approximate knee point as solution with max (v1 - v2)\n        knee_idx = np.argmax(objectives[:, 0] - objectives[:, 1])\n        knee_solution = archive[knee_idx][0]\n        # Perturb around knee items\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.3:\n                if knee_solution[i] == 1 and (weight_lst[i] <= capacity - np.sum(weight_lst[new_solution == 1])):\n                    new_solution[i] = 1\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Strategy 3: Capacity-aware random walk\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for i in excess_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n\nPlease help me create a new algorithm that has a totally different form from the given ones but can be motivated from them.\n1. Firstly, identify the common backbone idea in the provided algorithms. \n2. Secondly, based on the backbone idea describe your new algorithm in one long, detail sentence. The description must be inside within boxed {}.\n3. Thirdly, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 305,
          "algorithm": "{The new algorithm introduces a novel multi-objective neighborhood exploration strategy that first selects solutions based on their objective diversity and correlation, then applies a three-phase transformation combining a probabilistic item inversion guided by both objectives' marginal contributions weighted by their normalized objective distances, a Pareto-front guided perturbation that explores regions near the extreme points while maintaining feasibility, and an adaptive capacity-aware random walk that ensures feasibility by considering both the current solution's weight and the remaining capacity, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-balanced\" perturbation that selectively flips items based on their contribution to both objectives and a \"frontier-aware\" swap that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints, and finally employs a novel \"trade-off aware\" item replacement strategy that selectively removes items with poor trade-off ratios to maintain solution quality.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective diversity and correlation\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n\n    diversity_scores = np.prod(normalized, axis=1)\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    selection_scores = diversity_scores * (1 - correlation_scores)\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-balanced perturbation with adaptive probability\n    for i in range(n_items):\n        if np.random.rand() < 0.3:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_distance = np.sqrt((delta_value1 / (max_values[0] - min_values[0] + 1e-6))**2 +\n                                       (delta_value2 / (max_values[1] - min_values[1] + 1e-6))**2)\n                prob = min(1.0, 0.1 + 0.9 * norm_distance)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware swap with extreme point guidance\n    if len(archive) > 1:\n        extreme_idx = np.argmax(objectives[:, 0] + objectives[:, 1])\n        extreme_solution = archive[extreme_idx][0]\n        for i in range(n_items):\n            if extreme_solution[i] != new_solution[i] and np.random.rand() < 0.4:\n                if extreme_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware random walk with adaptive step size\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] + value2_lst[candidates]) / candidate_weights\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            step_size = min(0.2, remaining_capacity / np.sum(candidate_weights[feasible]))\n            selected = np.random.choice(candidates[feasible], size=max(1, int(len(candidates[feasible]) * step_size)), replace=False)\n            for i in selected:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Step 5: Trade-off aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        item_tradeoffs = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_tradeoffs)]\n        excess = current_weight - capacity\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -18.87118634283432,
               -18.64075237828481
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective diversity and correlation\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n\n    diversity_scores = np.prod(normalized, axis=1)\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    selection_scores = diversity_scores * (1 - correlation_scores)\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-balanced perturbation with adaptive probability\n    for i in range(n_items):\n        if np.random.rand() < 0.3:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_distance = np.sqrt((delta_value1 / (max_values[0] - min_values[0] + 1e-6))**2 +\n                                       (delta_value2 / (max_values[1] - min_values[1] + 1e-6))**2)\n                prob = min(1.0, 0.1 + 0.9 * norm_distance)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware swap with extreme point guidance\n    if len(archive) > 1:\n        extreme_idx = np.argmax(objectives[:, 0] + objectives[:, 1])\n        extreme_solution = archive[extreme_idx][0]\n        for i in range(n_items):\n            if extreme_solution[i] != new_solution[i] and np.random.rand() < 0.4:\n                if extreme_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware random walk with adaptive step size\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] + value2_lst[candidates]) / candidate_weights\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            step_size = min(0.2, remaining_capacity / np.sum(candidate_weights[feasible]))\n            selected = np.random.choice(candidates[feasible], size=max(1, int(len(candidates[feasible]) * step_size)), replace=False)\n            for i in selected:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Step 5: Trade-off aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        item_tradeoffs = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_tradeoffs)]\n        excess = current_weight - capacity\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm introduces a dynamic, objective-aware transformation that first identifies solutions with high potential for multi-objective improvement by analyzing both the normalized objective values and their distribution across the Pareto front, then applies a hybrid local search strategy that combines a probabilistic item inversion guided by both objectives' marginal contributions weighted by their objective-space distances, a Pareto-frontier guided perturbation that explores regions near the knee point while maintaining feasibility, a capacity-aware item replacement that intelligently removes low-contribution items when exceeding capacity, and a final objective-balanced greedy refinement phase that selectively adds high-contribution items while ensuring both objectives are improved, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-correlation\" perturbation that flips items based on their cross-objective contribution patterns and a \"frontier-aware\" item replacement that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints. Additionally, it introduces a novel \"knee-point guided\" transformation that selectively includes/excludes items near the knee point based on their potential to improve both objectives, and a \"diversity-aware\" selection mechanism that prioritizes solutions with high objective diversity and trade-off potential, while dynamically balancing exploration and exploitation by adjusting the selection probability of these strategies based on the archive's diversity.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective diversity and correlation\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n    diversity_scores = np.prod(normalized, axis=1)\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    selection_scores = diversity_scores * correlation_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Knee-point guided transformation\n    if len(archive) > 1:\n        knee_idx = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.5:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1 and np.random.rand() < 0.3:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 3: Objective-correlation perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                v1_contrib = value1_lst[i] / (max_values[0] + 1e-6)\n                v2_contrib = value2_lst[i] / (max_values[1] + 1e-6)\n                correlation = np.abs(v1_contrib - v2_contrib)\n                prob = min(1.0, 0.2 + 0.8 * correlation)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 4: Capacity-aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        item_contributions = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_contributions)]\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    # Step 5: Diversity-aware greedy addition\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            v1_norm = value1_lst[candidates] / (max_values[0] + 1e-6)\n            v2_norm = value2_lst[candidates] / (max_values[1] + 1e-6)\n            combined_scores = v1_norm + v2_norm\n            best_item = np.argmax(combined_scores[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The heuristic function 'select_neighbor' first identifies the most promising solution in the archive by evaluating the potential for improvement using a hybrid metric that combines the solution's current objective values with their spread across the Pareto front. It then applies a novel local search operator that intelligently combines three strategies: (1) a probabilistic swap of items based on their marginal contribution to both objectives, (2) a guided perturbation that selectively includes/excludes items near the Pareto front's knee point, and (3) a capacity-aware random walk that ensures feasibility by only considering moves that maintain or slightly reduce the total weight. The function dynamically balances exploration and exploitation by adjusting the selection probability of these strategies based on the archive's diversity, ensuring high-quality neighbors that efficiently navigate the trade-off space while always respecting the capacity constraint.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution (highest combined objective value)\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    best_idx = np.argmax(combined_values)\n    base_solution = archive[best_idx][0].copy()\n\n    # Step 2: Generate a neighbor using a hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Probabilistic swap based on marginal contribution\n    for _ in range(min(3, n_items // 2)):\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) == 0:\n            break\n        i = np.random.choice(candidates)\n        if new_solution[i] == 1 and np.random.rand() < 0.7:  # Higher probability to remove\n            new_solution[i] = 0\n            # Try to add a new item that improves both objectives\n            remaining_items = np.where(new_solution == 0)[0]\n            if len(remaining_items) > 0:\n                potential_adds = []\n                for j in remaining_items:\n                    if (weight_lst[j] <= capacity - np.sum(weight_lst[new_solution == 1])):\n                        potential_adds.append(j)\n                if potential_adds:\n                    j = np.random.choice(potential_adds)\n                    new_solution[j] = 1\n\n    # Strategy 2: Guided perturbation near knee point (approximate)\n    if len(archive) > 1:\n        # Approximate knee point as solution with max (v1 - v2)\n        knee_idx = np.argmax(objectives[:, 0] - objectives[:, 1])\n        knee_solution = archive[knee_idx][0]\n        # Perturb around knee items\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.3:\n                if knee_solution[i] == 1 and (weight_lst[i] <= capacity - np.sum(weight_lst[new_solution == 1])):\n                    new_solution[i] = 1\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Strategy 3: Capacity-aware random walk\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for i in excess_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 306,
          "algorithm": "{The new algorithm introduces a novel, adaptive multi-objective local search strategy that first identifies solutions with high potential for improvement by analyzing both the normalized objective values and their distribution across the Pareto front, then applies a hybrid local search operator that combines a probabilistic item inversion guided by both objectives' marginal contributions weighted by their objective-space distances, a Pareto-frontier guided perturbation that explores regions near the knee point while maintaining feasibility, a capacity-aware item replacement that intelligently removes low-contribution items when exceeding capacity, and a final objective-balanced greedy refinement phase that selectively adds high-contribution items while ensuring both objectives are improved, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-correlation\" perturbation that flips items based on their cross-objective contribution patterns and a \"frontier-aware\" item replacement that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints. Additionally, it introduces a novel \"knee-point guided\" transformation that selectively includes/excludes items near the knee point based on their potential to improve both objectives, and a \"diversity-aware\" selection mechanism that prioritizes solutions with high objective diversity and trade-off potential, while dynamically balancing exploration and exploitation by adjusting the selection probability of these strategies based on the archive's diversity.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective diversity and correlation\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n    diversity_scores = np.prod(normalized, axis=1)\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    selection_scores = diversity_scores * correlation_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Knee-point guided transformation\n    if len(archive) > 1:\n        knee_idx = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.5:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1 and np.random.rand() < 0.3:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 3: Objective-correlation perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                v1_contrib = value1_lst[i] / (max_values[0] + 1e-6)\n                v2_contrib = value2_lst[i] / (max_values[1] + 1e-6)\n                correlation = np.abs(v1_contrib - v2_contrib)\n                prob = min(1.0, 0.2 + 0.8 * correlation)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 4: Capacity-aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        item_contributions = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_contributions)]\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    # Step 5: Diversity-aware greedy addition\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            v1_norm = value1_lst[candidates] / (max_values[0] + 1e-6)\n            v2_norm = value2_lst[candidates] / (max_values[1] + 1e-6)\n            combined_scores = v1_norm + v2_norm\n            best_item = np.argmax(combined_scores[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.820007520904223,
               -18.729533709148207
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective diversity and correlation\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n    diversity_scores = np.prod(normalized, axis=1)\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    selection_scores = diversity_scores * correlation_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Knee-point guided transformation\n    if len(archive) > 1:\n        knee_idx = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.5:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1 and np.random.rand() < 0.3:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 3: Objective-correlation perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                v1_contrib = value1_lst[i] / (max_values[0] + 1e-6)\n                v2_contrib = value2_lst[i] / (max_values[1] + 1e-6)\n                correlation = np.abs(v1_contrib - v2_contrib)\n                prob = min(1.0, 0.2 + 0.8 * correlation)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 4: Capacity-aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        item_contributions = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_contributions)]\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    # Step 5: Diversity-aware greedy addition\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            v1_norm = value1_lst[candidates] / (max_values[0] + 1e-6)\n            v2_norm = value2_lst[candidates] / (max_values[1] + 1e-6)\n            combined_scores = v1_norm + v2_norm\n            best_item = np.argmax(combined_scores[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n"
     },
     {
          "prompt": "You are solving a Bi-objective Knapsack Problem (BI-KP), where each item has a weight and two profit values: value1 and value2. The goal is to select a subset of items such that the total weight does not exceed a given capacity, while simultaneously maximizing the total value in both objective spaces. Given an archive of non-dominated solutions, where each solution is a binary numpy array indicating item inclusion (1) or exclusion (0), and its corresponding objective is a tuple of two values (total value1, total value2), design a heuristic function named 'select_neighbor' that selects one solution from the archive and apply a novel or hybrid local search operator to generate a neighbor solution from it. Must always ensure that the generated neighbor solution remains feasible, i.e., the total weight must not exceed the knapsack capacity Please perform an intelligent random selection from among the solutions that show promising potential for further local improvement. Using a creative local search strategy that you design yourself, avoid 2-opt, go beyond standard approaches to design a method that yields higher-quality solutions across multiple objectives. The function should return the new neighbor solution.\nI have 2 existing algorithms with their codes as follows:\nNo. 1 algorithm and the corresponding code are:\n{The new algorithm introduces a multi-phase evolutionary transformation that first selects the most promising solution from the archive by analyzing both objective values and their trade-off potential, then applies a novel hybrid local search strategy that combines a probabilistic item inversion guided by both objectives' marginal contributions weighted by their objective-space distances, a Pareto-frontier guided perturbation that explores regions near the knee point while maintaining feasibility, a capacity-aware item replacement that intelligently removes low-contribution items when exceeding capacity, and a final objective-balanced greedy refinement phase that selectively adds high-contribution items while ensuring both objectives are improved, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-correlation\" perturbation that flips items based on their cross-objective contribution patterns and a \"frontier-aware\" item replacement that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective diversity and correlation\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n    diversity_scores = np.prod(normalized, axis=1)\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    selection_scores = diversity_scores * correlation_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-correlation perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                v1_contrib = value1_lst[i] / (max_values[0] + 1e-6)\n                v2_contrib = value2_lst[i] / (max_values[1] + 1e-6)\n                correlation = np.abs(v1_contrib - v2_contrib)\n                prob = min(1.0, 0.2 + 0.8 * correlation)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware item replacement\n    if len(archive) > 1:\n        knee_idx = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.5:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1 and np.random.rand() < 0.3:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        item_contributions = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_contributions)]\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    # Step 5: Objective-balanced greedy addition\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            v1_norm = value1_lst[candidates] / (max_values[0] + 1e-6)\n            v2_norm = value2_lst[candidates] / (max_values[1] + 1e-6)\n            combined_scores = v1_norm + v2_norm\n            best_item = np.argmax(combined_scores[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\nNo. 2 algorithm and the corresponding code are:\n{The new algorithm introduces a novel hybrid multi-objective transformation that first identifies solutions with high objective diversity and trade-off potential by analyzing both the normalized objective values and their distribution across the Pareto front, then applies a dynamic, phase-based local search strategy that combines a probabilistic item inversion guided by both objectives' marginal contributions weighted by their objective-space distances, a Pareto-frontier guided perturbation that explores regions near the knee point while maintaining feasibility, a capacity-aware item replacement that intelligently removes low-contribution items when exceeding capacity, and a final objective-balanced greedy refinement phase that selectively adds high-contribution items while ensuring both objectives are improved, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-correlation\" perturbation that flips items based on their cross-objective contribution patterns and a \"frontier-aware\" item replacement that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints.}\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective diversity and correlation\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n    diversity_scores = np.prod(normalized, axis=1)\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    selection_scores = diversity_scores * correlation_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-correlation perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                v1_contrib = value1_lst[i] / (max_values[0] + 1e-6)\n                v2_contrib = value2_lst[i] / (max_values[1] + 1e-6)\n                correlation = np.abs(v1_contrib - v2_contrib)\n                prob = min(1.0, 0.2 + 0.8 * correlation)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware item replacement\n    if len(archive) > 1:\n        knee_idx = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.5:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1 and np.random.rand() < 0.3:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        item_contributions = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_contributions)]\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    # Step 5: Objective-balanced greedy addition\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            v1_norm = value1_lst[candidates] / (max_values[0] + 1e-6)\n            v2_norm = value2_lst[candidates] / (max_values[1] + 1e-6)\n            combined_scores = v1_norm + v2_norm\n            best_item = np.argmax(combined_scores[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n\n\nAnalyze the logic of all the given code snippets carefully. Then identify the two code snippets whose logic is most different from each other\nand create a new algorithm that totally different in logic and form from both of them.\n1. First, describe your new algorithm and main steps in one long, detail sentence. The description must be inside within boxed {}.\n2. Next, implement the following Python function:\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    new_solution[0], new_solution[1] = new_solution[1], new_solution[0]\n\n    return new_solution\n\n\nCheck syntax, code carefully before returning the final function. Do not give additional explanations.",
          "sample_order": 307,
          "algorithm": "{The new algorithm introduces a dynamic, multi-phase evolutionary transformation that first selects the most promising solution from the archive by analyzing both objective values and their trade-off potential through a novel \"objective-balance\" score that combines normalized objective values with their cross-objective contribution patterns, then applies a hybrid local search strategy that combines a probabilistic item inversion guided by both objectives' marginal contributions weighted by their objective-space distances, a Pareto-frontier guided perturbation that explores regions near the knee point while maintaining feasibility, a capacity-aware item replacement that intelligently removes low-contribution items when exceeding capacity, and a final objective-balanced greedy refinement phase that selectively adds high-contribution items while ensuring both objectives are improved, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-correlation\" perturbation that flips items based on their cross-objective contribution patterns and a \"frontier-aware\" item replacement that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective balance and correlation\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n    balance_scores = 1 - np.abs(normalized[:, 0] - normalized[:, 1])\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    selection_scores = balance_scores * correlation_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-correlation perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.3:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                v1_contrib = value1_lst[i] / (max_values[0] + 1e-6)\n                v2_contrib = value2_lst[i] / (max_values[1] + 1e-6)\n                correlation = np.abs(v1_contrib - v2_contrib)\n                prob = min(1.0, 0.1 + 0.9 * correlation)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware item replacement\n    if len(archive) > 1:\n        knee_idx = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.6:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1 and np.random.rand() < 0.4:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        item_contributions = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_contributions)]\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    # Step 5: Objective-balanced greedy addition\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            v1_norm = value1_lst[candidates] / (max_values[0] + 1e-6)\n            v2_norm = value2_lst[candidates] / (max_values[1] + 1e-6)\n            combined_scores = 0.7 * v1_norm + 0.3 * v2_norm\n            best_item = np.argmax(combined_scores[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -17.766898497613667,
               -17.612995000589272
          ],
          "program": "\nimport numpy as np\nfrom typing import List, Tuple\nimport random \n\ndef select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective balance and correlation\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n    balance_scores = 1 - np.abs(normalized[:, 0] - normalized[:, 1])\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    selection_scores = balance_scores * correlation_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-correlation perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.3:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                v1_contrib = value1_lst[i] / (max_values[0] + 1e-6)\n                v2_contrib = value2_lst[i] / (max_values[1] + 1e-6)\n                correlation = np.abs(v1_contrib - v2_contrib)\n                prob = min(1.0, 0.1 + 0.9 * correlation)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware item replacement\n    if len(archive) > 1:\n        knee_idx = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.6:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1 and np.random.rand() < 0.4:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        item_contributions = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_contributions)]\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    # Step 5: Objective-balanced greedy addition\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            v1_norm = value1_lst[candidates] / (max_values[0] + 1e-6)\n            v2_norm = value2_lst[candidates] / (max_values[1] + 1e-6)\n            combined_scores = 0.7 * v1_norm + 0.3 * v2_norm\n            best_item = np.argmax(combined_scores[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n"
     }
]