[
     {
          "algorithm": "{The new algorithm combines a \"value-dominance clustering\" strategy with a \"multi-objective gradient ascent\" local search, where it first identifies clusters of items based on their dominance in either objective, then performs a gradient-like search in the objective space by iteratively selecting items that maximize the weighted sum of marginal gains in both objectives, where weights are dynamically adjusted based on the current solution's position in the objective space relative to the archive's distribution, while maintaining feasibility through a capacity-aware item replacement mechanism that prioritizes items with the highest marginal gain-to-weight ratios.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Cluster items based on value dominance\n    objectives = np.array([obj for _, obj in archive])\n    obj1_mean, obj2_mean = np.mean(objectives, axis=0)\n    dominance_scores = (value1_lst > obj1_mean).astype(int) + (value2_lst > obj2_mean).astype(int)\n    cluster_labels = np.unique(dominance_scores)\n    selected_cluster = random.choice(cluster_labels)\n    cluster_indices = np.where(dominance_scores == selected_cluster)[0]\n\n    # Step 2: Calculate position in objective space\n    current_obj = objectives[0]\n    obj_space_center = np.mean(objectives, axis=0)\n    direction_vector = current_obj - obj_space_center\n    direction_norm = np.linalg.norm(direction_vector)\n    if direction_norm > 0:\n        direction_vector /= direction_norm\n\n    # Step 3: Calculate gradient scores\n    remaining_capacity = capacity - np.sum(weight_lst * archive[0][0])\n    gradient_scores = np.zeros(len(weight_lst))\n    for i in cluster_indices:\n        if weight_lst[i] <= remaining_capacity:\n            weight_factor = 1 / (1 + weight_lst[i])\n            obj1_gain = value1_lst[i] * weight_factor\n            obj2_gain = value2_lst[i] * weight_factor\n            gradient_scores[i] = (direction_vector[0] * obj1_gain + direction_vector[1] * obj2_gain)\n\n    # Step 4: Select items to add/remove\n    new_solution = archive[0][0].copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Add most promising items\n    candidate_indices = np.argsort(gradient_scores)[::-1]\n    for i in candidate_indices:\n        if gradient_scores[i] <= 0:\n            break\n        if weight_lst[i] <= remaining_capacity and new_solution[i] == 0:\n            new_solution[i] = 1\n            remaining_capacity -= weight_lst[i]\n\n    # Remove least promising items if needed\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        remove_scores = gradient_scores[included_items]\n        sorted_indices = included_items[np.argsort(remove_scores)]\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n\n    return new_solution\n\n",
          "score": [
               -0.9659891977418682,
               1.0242119133472443
          ]
     },
     {
          "algorithm": "{The new algorithm employs a \"multi-objective adaptive knapsack transformation\" approach that first identifies solutions with the highest combined objective diversity, then applies a series of dynamic item replacement operations that systematically explore the trade-off space by considering both absolute and relative item contributions to each objective, while maintaining feasibility through a novel \"capacity-aware item substitution\" mechanism that prioritizes items based on their potential to improve the Pareto front through a calculated \"objective balance score,\" and incorporates an adaptive perturbation strategy that alternates between objective-specific and combined objective transformations based on the current solution's position relative to the archive's Pareto front, ensuring both exploration of under-explored regions and exploitation of promising areas.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution with highest combined objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = np.argmax(np.std(objectives, axis=0).sum(axis=0))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Calculate objective balance scores\n    obj1_total, obj2_total = archive[selected_idx][1]\n    balance_scores = (value1_lst * (obj2_total + 1e-6)) / (value2_lst * (obj1_total + 1e-6) + 1e-6)\n\n    # Step 3: Dynamic item replacement\n    for _ in range(3):  # Perform multiple replacement rounds\n        # Identify items to replace based on balance scores\n        candidate_items = np.where(new_solution == 1)[0]\n        if len(candidate_items) == 0:\n            break\n\n        # Select item with lowest balance score (worst trade-off)\n        worst_item = candidate_items[np.argmin(balance_scores[candidate_items])]\n        new_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n        # Find best replacement item (highest balance score, fits capacity)\n        potential_items = np.where(new_solution == 0)[0]\n        valid_items = potential_items[weight_lst[potential_items] <= capacity - current_weight]\n        if len(valid_items) == 0:\n            continue\n\n        best_item = valid_items[np.argmax(balance_scores[valid_items])]\n        new_solution[best_item] = 1\n\n    # Step 4: Adaptive perturbation\n    if np.random.random() < 0.5:\n        # Objective-specific transformation\n        if np.random.random() < 0.5:\n            # Focus on objective 1\n            items = np.argsort(-value1_lst / (weight_lst + 1e-6))\n        else:\n            # Focus on objective 2\n            items = np.argsort(-value2_lst / (weight_lst + 1e-6))\n\n        for item in items:\n            if new_solution[item] == 1 and current_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n                break\n            elif new_solution[item] == 0 and current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                break\n    else:\n        # Combined objective transformation\n        combined_value = value1_lst + value2_lst\n        items = np.argsort(-combined_value / (weight_lst + 1e-6))\n        for item in items:\n            if new_solution[item] == 0 and current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                break\n\n    return new_solution\n\n",
          "score": [
               -0.9970709662207471,
               3.5602318346500397
          ]
     },
     {
          "algorithm": "{The new algorithm leverages a \"multi-objective adaptive Pareto frontier expansion\" strategy that first identifies solutions with the highest combined objective diversity and then applies a novel \"dominance-aware item clustering\" approach that groups items based on their Pareto dominance relationships, followed by a multi-stage local search that systematically explores the trade-off space by considering both absolute and relative item contributions to each objective while maintaining feasibility through a \"dynamic capacity-aware item substitution\" mechanism that prioritizes items based on their potential to expand the Pareto frontier through a calculated \"objective dominance score,\" and incorporates an adaptive perturbation strategy that alternates between objective-specific and combined objective transformations based on the current solution's position relative to the archive's Pareto front, ensuring both exploration of under-explored regions and exploitation of promising areas through a \"guided neighborhood diversification\" mechanism that dynamically adjusts the search radius based on the current solution's quality and diversity.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution with highest combined objective diversity\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = np.argmax(np.std(objectives, axis=0).sum(axis=0))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Cluster items based on Pareto dominance\n    included_indices = np.where(new_solution == 1)[0]\n    excluded_indices = np.where(new_solution == 0)[0]\n\n    # Calculate dominance scores for both objectives\n    dominance_v1 = value1_lst / (weight_lst + 1e-6)\n    dominance_v2 = value2_lst / (weight_lst + 1e-6)\n\n    # Identify Pareto clusters\n    if len(included_indices) > 0:\n        # Cluster items based on dominance in both objectives\n        cluster1 = included_indices[(dominance_v1[included_indices] > dominance_v2[included_indices])]\n        cluster2 = included_indices[(dominance_v2[included_indices] > dominance_v1[included_indices])]\n        balanced_cluster = included_indices[(dominance_v1[included_indices] == dominance_v2[included_indices])]\n\n        # Remove weak items from balanced cluster\n        for idx in balanced_cluster:\n            if (dominance_v1[idx] < 0.5) and (dominance_v2[idx] < 0.5):\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    # Step 3: Multi-stage local search\n    # Stage 1: Expand in objective 1\n    candidate_items = excluded_indices[weight_lst[excluded_indices] <= capacity - current_weight]\n    if len(candidate_items) > 0:\n        best_item = candidate_items[np.argmax(dominance_v1[candidate_items])]\n        new_solution[best_item] = 1\n        current_weight += weight_lst[best_item]\n\n    # Stage 2: Expand in objective 2\n    candidate_items = excluded_indices[weight_lst[excluded_indices] <= capacity - current_weight]\n    if len(candidate_items) > 0:\n        best_item = candidate_items[np.argmax(dominance_v2[candidate_items])]\n        new_solution[best_item] = 1\n        current_weight += weight_lst[best_item]\n\n    # Stage 3: Balance both objectives\n    candidate_items = excluded_indices[weight_lst[excluded_indices] <= capacity - current_weight]\n    if len(candidate_items) > 0:\n        balance_scores = (value1_lst[candidate_items] + value2_lst[candidate_items]) / (weight_lst[candidate_items] + 1e-6)\n        best_item = candidate_items[np.argmax(balance_scores)]\n        new_solution[best_item] = 1\n\n    # Step 4: Guided neighborhood diversification\n    if np.random.random() < 0.3:\n        # Randomly remove items from clusters with low dominance\n        for idx in np.concatenate([cluster1, cluster2]):\n            if np.random.random() < 0.2 and (dominance_v1[idx] < 0.7 or dominance_v2[idx] < 0.7):\n                new_solution[idx] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        included_indices = np.where(new_solution == 1)[0]\n        sorted_indices = included_indices[np.argsort(weight_lst[included_indices])[::-1]]\n        for idx in sorted_indices:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -0.9289113816550663,
               0.9148957133293152
          ]
     },
     {
          "algorithm": "{The new algorithm combines the strengths of the existing approaches by first selecting a solution from the archive based on a novel \"objective-space entropy\" metric that measures the diversity and potential for improvement in both objectives, then applies a hybrid local search operator that alternates between \"value-driven\" and \"weight-aware\" perturbations, where value-driven perturbations prioritize items with high marginal gains in either objective while maintaining feasibility, and weight-aware perturbations systematically remove or add items based on their weight efficiency and current capacity utilization, dynamically adjusting the search strategy to balance exploitation of high-value items and exploration of underutilized capacity regions, with a special focus on maintaining a Pareto front-aware balance between the two objectives through a calculated \"trade-off sensitivity\" metric that guides the selection of items to replace or add.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution with highest objective-space entropy\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = np.argmax(np.sum(np.log(objectives + 1) * (1 - objectives/np.max(objectives + 1e-6, axis=0)), axis=1))\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Calculate trade-off sensitivity metric\n    obj1_total, obj2_total = archive[selected_idx][1]\n    trade_off_sensitivity = (value1_lst * (obj2_total + 1e-6)) / (value2_lst * (obj1_total + 1e-6) + 1e-6)\n\n    # Step 3: Hybrid local search with alternating perturbations\n    for _ in range(2):\n        if np.random.random() < 0.5:\n            # Value-driven perturbation (prioritize high-value items)\n            if np.random.random() < 0.5:\n                # Focus on objective 1\n                items = np.argsort(-value1_lst / (weight_lst + 1e-6))\n            else:\n                # Focus on objective 2\n                items = np.argsort(-value2_lst / (weight_lst + 1e-6))\n\n            for item in items:\n                if new_solution[item] == 0 and current_weight + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n                    break\n                elif new_solution[item] == 1 and current_weight - weight_lst[item] <= capacity:\n                    new_solution[item] = 0\n                    current_weight -= weight_lst[item]\n                    break\n        else:\n            # Weight-aware perturbation (balance capacity utilization)\n            if current_weight < capacity * 0.7:\n                # Add items to utilize capacity\n                items = np.argsort(-trade_off_sensitivity)\n                for item in items:\n                    if new_solution[item] == 0 and current_weight + weight_lst[item] <= capacity:\n                        new_solution[item] = 1\n                        current_weight += weight_lst[item]\n                        break\n            else:\n                # Remove items to balance capacity\n                items = np.argsort(trade_off_sensitivity)\n                for item in items:\n                    if new_solution[item] == 1 and current_weight - weight_lst[item] <= capacity:\n                        new_solution[item] = 0\n                        current_weight -= weight_lst[item]\n                        break\n\n    # Ensure feasibility with final adjustment\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        included_indices = np.where(new_solution == 1)[0]\n        sorted_indices = included_indices[np.argsort(weight_lst[included_indices])[::-1]]\n        for idx in sorted_indices:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -0.9924757185415524,
               1.6871644258499146
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the least crowded solution in the archive to focus on under-explored regions, then applies a targeted cluster-based local search that selectively flips items within high-value clusters while maintaining feasibility, using a dynamic capacity adjustment mechanism that prioritizes items with balanced marginal contributions to both objectives. The algorithm intelligently balances exploration of clustered high-value items with exploitation of underutilized capacity regions, ensuring the neighbor solution remains feasible by dynamically adjusting the selection based on cluster-based capacity utilization and probabilistic flip mechanisms weighted by both objective contributions.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the least crowded solution\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(2):\n        sorted_idx = np.argsort(objectives[:, i])\n        sorted_obj = objectives[sorted_idx, i]\n        crowding_distances[sorted_idx[0]] = np.inf\n        crowding_distances[sorted_idx[-1]] = np.inf\n        for j in range(1, len(sorted_idx) - 1):\n            crowding_distances[sorted_idx[j]] += (sorted_obj[j + 1] - sorted_obj[j - 1]) / (sorted_obj[-1] - sorted_obj[0] + 1e-10)\n\n    selected_idx = np.argmin(crowding_distances)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 2: Cluster-based local search\n    # Identify clusters of high-value items\n    value_combined = value1_lst + value2_lst\n    sorted_items = np.argsort(-value_combined)\n    cluster_size = max(1, len(weight_lst) // 10)  # Cluster top 10% items\n\n    # Process clusters in descending order of value\n    for i in sorted_items[:cluster_size]:\n        if new_solution[i] == 1:\n            # Remove item if it's in the cluster and has low marginal contribution\n            if np.random.rand() < 0.4:  # 40% chance to remove\n                new_solution[i] = 0\n        else:\n            # Add item if it fits and is in the cluster\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < 0.6:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n\n    # Ensure feasibility with dynamic adjustment\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items from least valuable clusters until feasible\n        for i in reversed(sorted_items):\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -0.9430162127106001,
               1.6847892701625824
          ]
     },
     {
          "algorithm": "{The new algorithm builds upon the backbone idea of selecting promising solutions from the archive by leveraging both objective trade-offs and solution diversity, but instead of using marginal contributions or novelty scores, it employs a \"dynamic trade-off exploration\" approach that first identifies solutions with high potential for improvement by analyzing their objective trade-offs and solution diversity, then applies a \"trade-off aware perturbation\" that selectively flips bits based on their relative contribution to both objectives, while dynamically adjusting the perturbation intensity to balance exploration and exploitation. This is achieved by calculating a dynamic trade-off score for each item that combines its value contributions with the current solution's objective trade-off, and then probabilistically selecting items to flip based on this score, ensuring feasibility through a capacity-aware selection process. The algorithm also incorporates a \"diversity-aware mutation\" step that randomly flips a small number of items to maintain diversity while still favoring those with high trade-off potential.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high trade-off potential\n    selected_idx = 0\n    max_tradeoff_score = -float('inf')\n    for i, (sol, obj) in enumerate(archive):\n        obj1, obj2 = obj\n        tradeoff_score = (obj1 / (obj2 + 1e-6)) + (obj2 / (obj1 + 1e-6))\n        if tradeoff_score > max_tradeoff_score:\n            max_tradeoff_score = tradeoff_score\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Calculate dynamic trade-off scores for items\n    obj1_total, obj2_total = archive[selected_idx][1]\n    tradeoff_scores = (value1_lst / (value2_lst + 1e-6)) * (obj2_total / (obj1_total + 1e-6))\n\n    # Step 3: Trade-off aware perturbation\n    items = np.arange(len(base_solution))\n    np.random.shuffle(items)\n\n    for item in items:\n        if new_solution[item] == 1:\n            # Try removing item if it has low trade-off contribution\n            new_weight = current_weight - weight_lst[item]\n            if new_weight <= capacity and tradeoff_scores[item] < 0.7:\n                new_solution[item] = 0\n                current_weight = new_weight\n                break\n        else:\n            # Try adding item if it has high trade-off contribution\n            new_weight = current_weight + weight_lst[item]\n            if new_weight <= capacity and tradeoff_scores[item] > 1.3:\n                new_solution[item] = 1\n                current_weight = new_weight\n                break\n\n    # Step 4: Diversity-aware mutation\n    if np.random.random() < 0.3:\n        # Select items with low trade-off contribution for mutation\n        low_tradeoff_items = np.where(tradeoff_scores < 0.9)[0]\n        if len(low_tradeoff_items) > 0:\n            mutation_items = np.random.choice(low_tradeoff_items, size=min(3, len(low_tradeoff_items)), replace=False)\n            for item in mutation_items:\n                if new_solution[item] == 1:\n                    if current_weight - weight_lst[item] <= capacity:\n                        new_solution[item] = 0\n                        current_weight -= weight_lst[item]\n                else:\n                    if current_weight + weight_lst[item] <= capacity:\n                        new_solution[item] = 1\n                        current_weight += weight_lst[item]\n\n    return new_solution\n\n",
          "score": [
               -0.6441608270367991,
               1.1908688843250275
          ]
     },
     {
          "algorithm": "{The new algorithm builds on the core idea of selecting promising solutions from the archive and applying a hybrid local search strategy, but instead of relying on marginal contributions or objective balancing, it employs a \"trade-off aware multi-objective flip\" approach. This method first identifies solutions with high potential for improvement by analyzing their objective trade-offs, then applies a \"value-weighted perturbation\" that selectively flips bits based on their relative contribution to both objectives, while dynamically adjusting the perturbation intensity to balance exploration and exploitation. The algorithm ensures feasibility by maintaining a running weight check and only allowing moves that don't exceed capacity, while also incorporating a novel \"trade-off sensitivity\" metric to prioritize items that could significantly improve the Pareto front by better addressing the current objective trade-offs.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the most unbalanced objectives\n    selected_idx = 0\n    max_balance_diff = -float('inf')\n    for i, (sol, obj) in enumerate(archive):\n        obj1, obj2 = obj\n        balance_diff = abs(obj1 - obj2) / max(1, obj1 + obj2)\n        if balance_diff > max_balance_diff:\n            max_balance_diff = balance_diff\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Calculate trade-off sensitivity for each item\n    obj1_total, obj2_total = archive[selected_idx][1]\n    trade_off = (value1_lst / (value2_lst + 1e-6)) * (obj2_total / (obj1_total + 1e-6))\n\n    # Value-weighted perturbation\n    items = np.arange(len(base_solution))\n    np.random.shuffle(items)\n\n    for item in items:\n        if new_solution[item] == 1:\n            # Try removing item\n            new_weight = current_weight - weight_lst[item]\n            if new_weight <= capacity:\n                # Remove if it improves trade-off\n                if trade_off[item] > 1.5 or (np.random.random() < 0.3 and trade_off[item] > 0.8):\n                    new_solution[item] = 0\n                    current_weight = new_weight\n                    break\n        else:\n            # Try adding item\n            new_weight = current_weight + weight_lst[item]\n            if new_weight <= capacity:\n                # Add if it improves trade-off\n                if trade_off[item] < 0.5 or (np.random.random() < 0.3 and trade_off[item] < 1.2):\n                    new_solution[item] = 1\n                    current_weight = new_weight\n                    break\n\n    # Additional diversification step\n    if np.random.random() < 0.2:\n        # Randomly flip a small number of items to maintain diversity\n        flip_indices = np.random.choice(len(base_solution), size=min(2, len(base_solution)), replace=False)\n        for idx in flip_indices:\n            if new_solution[idx] == 1:\n                if current_weight - weight_lst[idx] <= capacity:\n                    new_solution[idx] = 0\n                    current_weight -= weight_lst[idx]\n            else:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -0.6669301154527879,
               1.3673640489578247
          ]
     },
     {
          "algorithm": "{The new algorithm employs a 'value-space partitioning' strategy combined with a 'historical exclusion pattern' analysis to generate neighbors. It first partitions the value space into regions based on the distribution of the archive's solutions, then identifies items that have been consistently excluded from high-performing solutions in the archive. The algorithm then constructs a new solution by probabilistically selecting items from these underrepresented regions while favoring those with high marginal gains in both objectives, using a capacity-aware probabilistic acceptance process that dynamically adjusts its threshold based on the item's contribution to both objectives and its historical exclusion patterns. This approach balances exploitation of known good regions with exploration of underrepresented item combinations, ensuring both diversity and potentially high-quality solutions.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Calculate exclusion patterns for each item\n    exclusion_counts = np.zeros(len(weight_lst))\n    for sol, _ in archive:\n        exclusion_counts += (1 - sol)\n\n    # Step 2: Partition value space into regions\n    objectives = np.array([obj for _, obj in archive])\n    min_vals = np.min(objectives, axis=0)\n    max_vals = np.max(objectives, axis=0)\n    range_vals = max_vals - min_vals\n\n    # Create 4 value regions\n    region1 = (objectives[:,0] >= min_vals[0] + range_vals[0]*0.75) & (objectives[:,1] >= min_vals[1] + range_vals[1]*0.75)\n    region2 = (objectives[:,0] >= min_vals[0] + range_vals[0]*0.75) & (objectives[:,1] < min_vals[1] + range_vals[1]*0.25)\n    region3 = (objectives[:,0] < min_vals[0] + range_vals[0]*0.25) & (objectives[:,1] >= min_vals[1] + range_vals[1]*0.75)\n    region4 = (objectives[:,0] < min_vals[0] + range_vals[0]*0.25) & (objectives[:,1] < min_vals[1] + range_vals[1]*0.25)\n\n    # Select region with fewest solutions\n    region_counts = [np.sum(region1), np.sum(region2), np.sum(region3), np.sum(region4)]\n    selected_region = np.argmin(region_counts)\n\n    # Step 3: Calculate combined scores (exclusion pattern + marginal gain)\n    combined_scores = exclusion_counts * (value1_lst + value2_lst)\n\n    # Step 4: Select items from the selected region with high combined scores\n    new_solution = np.zeros(len(weight_lst), dtype=int)\n    remaining_capacity = capacity\n\n    # Get items in the selected region (approximate)\n    if selected_region == 0:\n        candidate_mask = (value1_lst >= min_vals[0] + range_vals[0]*0.75) & (value2_lst >= min_vals[1] + range_vals[1]*0.75)\n    elif selected_region == 1:\n        candidate_mask = (value1_lst >= min_vals[0] + range_vals[0]*0.75) & (value2_lst < min_vals[1] + range_vals[1]*0.25)\n    elif selected_region == 2:\n        candidate_mask = (value1_lst < min_vals[0] + range_vals[0]*0.25) & (value2_lst >= min_vals[1] + range_vals[1]*0.75)\n    else:\n        candidate_mask = (value1_lst < min_vals[0] + range_vals[0]*0.25) & (value2_lst < min_vals[1] + range_vals[1]*0.25)\n\n    candidate_indices = np.where(candidate_mask)[0]\n    sorted_indices = candidate_indices[np.argsort(-combined_scores[candidate_indices])]\n\n    # Greedily add items until capacity is reached\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        included_indices = np.where(new_solution == 1)[0]\n        sorted_indices = included_indices[np.argsort(weight_lst[included_indices])[::-1]]\n        for idx in sorted_indices:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -0.8839120837559324,
               1.3894456028938293
          ]
     },
     {
          "algorithm": "{The new algorithm employs a \"value-ratio swarm optimization\" approach that first identifies high-potential items through a hybrid scoring mechanism combining normalized value ratios and historical performance tracking, then uses a swarm intelligence-based local search where multiple candidate solutions are simultaneously evolved through parallel item swaps and merges, with solutions periodically sharing information about their most successful item combinations, while maintaining feasibility through a dynamic capacity-adjustment mechanism that prioritizes items with the highest marginal efficiency scores in both objectives, and incorporates a novelty-enhancing component that periodically introduces random item perturbations to escape local optima.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select base solution and initialize\n    base_solution = archive[0][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Step 2: Calculate hybrid item scores\n    value1_ratio = value1_lst / (weight_lst + 1e-6)\n    value2_ratio = value2_lst / (weight_lst + 1e-6)\n    hybrid_scores = (value1_ratio + value2_ratio) / 2\n\n    # Step 3: Perform swarm-based local search\n    swarm_size = min(5, len(weight_lst))\n    for _ in range(3):\n        # Randomly select candidate items\n        candidates = np.random.choice(len(weight_lst), size=swarm_size, replace=False)\n\n        # Evaluate each candidate swap\n        best_candidate = None\n        best_score = -np.inf\n        for i in candidates:\n            temp_solution = new_solution.copy()\n            if temp_solution[i] == 0:\n                temp_solution[i] = 1\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    score = hybrid_scores[i]\n                    if score > best_score:\n                        best_score = score\n                        best_candidate = i\n            else:\n                temp_solution[i] = 0\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight >= 0:\n                    score = -hybrid_scores[i]\n                    if score > best_score:\n                        best_score = score\n                        best_candidate = i\n\n        # Apply best swap if found\n        if best_candidate is not None:\n            if new_solution[best_candidate] == 0:\n                new_solution[best_candidate] = 1\n                current_weight += weight_lst[best_candidate]\n            else:\n                new_solution[best_candidate] = 0\n                current_weight -= weight_lst[best_candidate]\n\n    # Step 4: Dynamic capacity adjustment\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        included_items = np.where(new_solution == 1)[0]\n        efficiency_scores = hybrid_scores[included_items] / weight_lst[included_items]\n        sorted_indices = included_items[np.argsort(efficiency_scores)]\n        for i in sorted_indices:\n            if excess <= 0:\n                break\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n\n    # Step 5: Add novelty with random perturbation\n    if np.random.random() < 0.3:\n        perturb_items = np.random.choice(len(weight_lst), size=2, replace=False)\n        for i in perturb_items:\n            if weight_lst[i] <= remaining_capacity or new_solution[i] == 1:\n                new_solution[i] = 1 - new_solution[i]\n\n    return new_solution\n\n",
          "score": [
               -0.8845711469438093,
               1.6525487899780273
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the solution with the highest combined objective value by normalizing both objectives and then applies a novel 'adaptive dominance-aware perturbation' strategy that combines probabilistic item selection with a guided exploration of adjacent solutions, where items are selected based on their dominance in either objective while dynamically adjusting the selection to maintain feasibility, ensuring the generated neighbor solution remains feasible and explores diverse regions of the search space by balancing exploration and exploitation through adaptive neighborhood exploration and probabilistic selection of items with high dominance in either objective, while also incorporating a dynamic capacity adjustment mechanism that prioritizes items with balanced dominance contributions to both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the solution with the highest combined normalized objective value\n    objectives = np.array([obj for _, obj in archive])\n    max_v1, max_v2 = np.max(objectives, axis=0)\n    normalized_obj = objectives / np.array([max_v1, max_v2])\n    combined_obj = np.sum(normalized_obj, axis=1)\n    selected_idx = np.argmax(combined_obj)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 2: Adaptive dominance-aware perturbation\n    # Calculate dominance scores for both objectives\n    dominance_v1 = value1_lst / (weight_lst + 1e-6)\n    dominance_v2 = value2_lst / (weight_lst + 1e-6)\n\n    # Select items to add based on dominance in either objective\n    candidate_indices = np.where(new_solution == 0)[0]\n    if len(candidate_indices) > 0:\n        # Select items that are dominant in either objective\n        v1_dominant = candidate_indices[dominance_v1[candidate_indices] > dominance_v2[candidate_indices]]\n        v2_dominant = candidate_indices[dominance_v2[candidate_indices] > dominance_v1[candidate_indices]]\n\n        # Add items from both dominant sets with probability\n        for idx in v1_dominant:\n            if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.7:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n        for idx in v2_dominant:\n            if weight_lst[idx] <= remaining_capacity and np.random.rand() < 0.7:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Guided exploration of adjacent solutions\n    # Remove items based on dominance in the opposite objective\n    in_solution_indices = np.where(new_solution == 1)[0]\n    if len(in_solution_indices) > 0:\n        # Remove items that are weak in both objectives\n        weak_items = in_solution_indices[(dominance_v1[in_solution_indices] < 0.5) & (dominance_v2[in_solution_indices] < 0.5)]\n        for idx in weak_items:\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Ensure feasibility with dynamic adjustment\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        included_indices = np.where(new_solution == 1)[0]\n        sorted_indices = included_indices[np.argsort(weight_lst[included_indices])[::-1]]\n        for idx in sorted_indices:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -0.9672504101123383,
               2.7086717784404755
          ]
     }
]