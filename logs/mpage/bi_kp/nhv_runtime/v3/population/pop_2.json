[
     {
          "algorithm": "{The heuristic function 'select_neighbor' first identifies the most promising solution in the archive using a combination of crowding distance and objective diversity metrics to ensure it is non-dominated and has potential for improvement. It then applies a novel hybrid local search operator that selectively flips items based on their marginal contribution to both objectives, combined with a targeted random walk that explores adjacent solutions while maintaining feasibility. The operator balances exploitation of high-margin items and exploration of underrepresented regions in the objective space, ensuring the neighbor solution remains feasible by dynamically adjusting the selection based on remaining capacity. The selection process prioritizes solutions with high crowding distance or low dominance count to focus on less-explored areas, while the local search operator uses a probabilistic flip mechanism weighted by the item's contribution to both objectives, with a small random perturbation to escape local optima.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution (high crowding distance or low dominance count)\n    # Calculate crowding distance for each solution in the archive\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_idx = np.argsort(objectives[:, i])\n        sorted_obj = objectives[sorted_idx, i]\n        crowding_distances[sorted_idx[0]] = np.inf\n        crowding_distances[sorted_idx[-1]] = np.inf\n        for j in range(1, len(sorted_idx) - 1):\n            crowding_distances[sorted_idx[j]] += (sorted_obj[j + 1] - sorted_obj[j - 1]) / (sorted_obj[-1] - sorted_obj[0] + 1e-10)\n\n    # Select the solution with the highest crowding distance\n    selected_idx = np.argmax(crowding_distances)\n    base_solution, _ = archive[selected_idx]\n\n    # Step 2: Generate a neighbor solution using a hybrid local search operator\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal contributions for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    marginal_combined = marginal_value1 + marginal_value2\n\n    # Probabilistic flip based on marginal contribution and remaining capacity\n    for i in range(len(new_solution)):\n        if new_solution[i] == 1:\n            if np.random.rand() < 0.3:  # 30% chance to remove item\n                new_solution[i] = 0\n        else:\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < 0.7 * (marginal_combined[i] / (np.max(marginal_combined) + 1e-10)):\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # If not feasible, remove items with lowest marginal contribution until feasible\n        while current_weight > capacity:\n            item_to_remove = np.argmax(new_solution * marginal_combined)\n            if new_solution[item_to_remove] == 1:\n                new_solution[item_to_remove] = 0\n                current_weight -= weight_lst[item_to_remove]\n\n    return new_solution\n\n",
          "score": [
               -0.8772999931781975,
               3.516489714384079
          ]
     },
     {
          "algorithm": "{The heuristic function 'select_neighbor' first identifies promising solutions in the archive by prioritizing those with high objective values and low crowding distance, then applies a novel 'adaptive diversity-aware perturbation' strategy that combines probabilistic item selection with a guided exploration of adjacent solutions, where items are selected based on their marginal contribution to both objectives while dynamically adjusting the selection to maintain feasibility, ensuring the generated neighbor solution remains feasible and explores diverse regions of the search space by balancing exploration and exploitation through adaptive neighborhood exploration and probabilistic selection of items with high marginal gains in either objective.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # Prioritize solutions with high objective values and low crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    fronts = np.argsort(-objectives[:, 0])  # Sort by objective 1 in descending order\n    top_k = max(1, len(fronts) // 10)\n    selected_indices = fronts[:top_k]\n    selected_solutions = [archive[i][0] for i in selected_indices]\n    base_solution = selected_solutions[np.random.choice(len(selected_solutions))].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 2: Adaptive diversity-aware perturbation\n    # Calculate marginal contributions for both objectives\n    marginal_v1 = value1_lst / (weight_lst + 1e-6)\n    marginal_v2 = value2_lst / (weight_lst + 1e-6)\n    marginal_combined = marginal_v1 + marginal_v2\n\n    # Select items to add based on marginal contributions\n    candidate_indices = np.where(new_solution == 0)[0]\n    if len(candidate_indices) > 0:\n        num_add = min(3, len(candidate_indices))\n        add_indices = candidate_indices[np.argsort(marginal_combined[candidate_indices])[::-1]][:num_add]\n\n        for idx in add_indices:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    # Step 3: Guided exploration of adjacent solutions\n    # Select items to remove based on marginal contributions\n    in_solution_indices = np.where(new_solution == 1)[0]\n    if len(in_solution_indices) > 0:\n        num_remove = min(2, len(in_solution_indices))\n        remove_indices = in_solution_indices[np.argsort(marginal_combined[in_solution_indices])[:num_remove]]\n\n        for idx in remove_indices:\n            if np.sum(weight_lst[new_solution == 1]) - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst[new_solution == 1])\n    if total_weight > capacity:\n        included_indices = np.where(new_solution == 1)[0]\n        sorted_indices = included_indices[np.argsort(weight_lst[included_indices])[::-1]]\n        for idx in sorted_indices:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -0.8749579165349102,
               1.7395542860031128
          ]
     },
     {
          "algorithm": "{The new algorithm builds upon the common backbone of selecting promising solutions from the archive by prioritizing high-objective-value or diverse candidates, but instead of using marginal contribution or random swaps, it employs a novelty-based search that dynamically evaluates items based on their potential to create novel combinations, balancing exploitation of known good regions with exploration of less-explored item interactions. This is achieved by calculating a novelty score for each item based on its historical inclusion patterns in the archive, then probabilistically selecting items with low novelty to introduce diversity while still favoring those with high marginal gains. The local search operator then constructs a new solution by iteratively adding items in descending order of their combined novelty and marginal gains, ensuring feasibility through a capacity-aware greedy selection process.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Calculate novelty scores for each item\n    item_inclusion_counts = np.zeros(len(weight_lst))\n    for sol, _ in archive:\n        item_inclusion_counts += sol\n\n    novelty_scores = 1.0 / (1.0 + item_inclusion_counts)  # Lower count = higher novelty\n\n    # Step 2: Select a base solution (prioritize high-objective-value solutions)\n    objectives = np.array([obj for _, obj in archive])\n    max_values = np.max(objectives, axis=0)\n    threshold1 = max_values[0] * 0.8\n    threshold2 = max_values[1] * 0.8\n\n    promising_indices = [\n        i for i, (obj1, obj2) in enumerate(objectives)\n        if obj1 >= threshold1 or obj2 >= threshold2\n    ]\n\n    if not promising_indices:\n        promising_indices = list(range(len(archive)))\n\n    selected_idx = random.choice(promising_indices)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 3: Generate neighbor solution using novelty-aware greedy construction\n    new_solution = np.zeros(len(weight_lst), dtype=int)\n    remaining_capacity = capacity\n    candidate_indices = np.where(base_solution == 0)[0]\n\n    # Calculate combined scores (novelty + marginal gain)\n    combined_scores = novelty_scores * (value1_lst + value2_lst)\n\n    # Sort candidates by combined score (descending)\n    sorted_indices = candidate_indices[np.argsort(-combined_scores[candidate_indices])]\n\n    for idx in sorted_indices:\n        if weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n\n    # Ensure feasibility by removing heaviest items if needed\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        included_indices = np.where(new_solution == 1)[0]\n        sorted_indices = included_indices[np.argsort(weight_lst[included_indices])[::-1]]\n        for idx in sorted_indices:\n            if total_weight <= capacity:\n                break\n            new_solution[idx] = 0\n            total_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -0.4108628732063897,
               1.336624413728714
          ]
     },
     {
          "algorithm": "{The new algorithm selects a base solution from the archive by prioritizing those with the highest combined value ratio (value1 + value2) per unit weight, then applies a novel 'value-balanced insertion' operator that iteratively inserts items with the highest marginal value improvement in either objective while maintaining feasibility, followed by a 'weight-adaptive removal' step that removes items with the lowest marginal value impact to free up capacity for potentially better items, ensuring the solution remains feasible and balanced across objectives through a dynamic threshold-based acceptance criterion.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select base solution with highest combined value ratio\n    value_ratios = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    base_solution, _ = max(archive, key=lambda x: np.sum(value_ratios * x[0]))\n    current_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * current_solution)\n\n    # Value-balanced insertion\n    for _ in range(2):  # Limit iterations\n        candidate_indices = np.where(current_solution == 0)[0]\n        if len(candidate_indices) == 0:\n            break\n\n        # Calculate marginal improvements\n        marginal_v1 = value1_lst[candidate_indices]\n        marginal_v2 = value2_lst[candidate_indices]\n        marginal_weights = weight_lst[candidate_indices]\n\n        # Select item with highest marginal improvement in either objective\n        max_idx = np.argmax(marginal_v1 + marginal_v2)\n        best_item = candidate_indices[max_idx]\n\n        if current_weight + marginal_weights[max_idx] <= capacity:\n            current_solution[best_item] = 1\n            current_weight += marginal_weights[max_idx]\n\n    # Weight-adaptive removal\n    for _ in range(1):  # Limit iterations\n        in_solution = np.where(current_solution == 1)[0]\n        if len(in_solution) == 0:\n            break\n\n        # Calculate marginal impacts\n        marginal_v1 = value1_lst[in_solution]\n        marginal_v2 = value2_lst[in_solution]\n\n        # Select item with lowest marginal impact\n        min_idx = np.argmin(marginal_v1 + marginal_v2)\n        worst_item = in_solution[min_idx]\n\n        current_solution[worst_item] = 0\n        current_weight -= weight_lst[worst_item]\n\n    return current_solution\n\n",
          "score": [
               -0.9163510042270796,
               4.2997867166996
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the least crowded solution in the archive to focus on under-explored regions, then applies a targeted cluster-based local search that selectively flips items within high-value clusters while maintaining feasibility, using a dynamic capacity adjustment mechanism that prioritizes items with balanced marginal contributions to both objectives. The algorithm intelligently balances exploration of clustered high-value items with exploitation of underutilized capacity regions, ensuring the neighbor solution remains feasible by dynamically adjusting the selection based on cluster-based capacity utilization and probabilistic flip mechanisms weighted by both objective contributions.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the least crowded solution (opposite of first algorithm)\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(2):\n        sorted_idx = np.argsort(objectives[:, i])\n        sorted_obj = objectives[sorted_idx, i]\n        crowding_distances[sorted_idx[0]] = np.inf\n        crowding_distances[sorted_idx[-1]] = np.inf\n        for j in range(1, len(sorted_idx) - 1):\n            crowding_distances[sorted_idx[j]] += (sorted_obj[j + 1] - sorted_obj[j - 1]) / (sorted_obj[-1] - sorted_obj[0] + 1e-10)\n\n    selected_idx = np.argmin(crowding_distances)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 2: Cluster-based local search\n    # Identify clusters of high-value items\n    value_combined = value1_lst + value2_lst\n    sorted_items = np.argsort(-value_combined)\n    cluster_size = max(1, len(weight_lst) // 10)  # Cluster top 10% items\n\n    # Process clusters in descending order of value\n    for i in sorted_items[:cluster_size]:\n        if new_solution[i] == 1:\n            # Remove item if it's in the cluster and has low marginal contribution\n            if np.random.rand() < 0.4:  # 40% chance to remove\n                new_solution[i] = 0\n        else:\n            # Add item if it fits and is in the cluster\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < 0.6:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n\n    # Ensure feasibility with dynamic adjustment\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Remove items from least valuable clusters until feasible\n        for i in reversed(sorted_items):\n            if new_solution[i] == 1:\n                new_solution[i] = 0\n                current_weight -= weight_lst[i]\n                if current_weight <= capacity:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -0.8484414568147814,
               3.034553349018097
          ]
     },
     {
          "algorithm": "{The new algorithm builds on the core idea of selecting promising solutions from the archive and applying a hybrid local search strategy, but instead of relying on random flips or greedy insertions, it employs a novel \"objective-driven diversification\" approach. This method first identifies solutions with high potential for improvement by analyzing their objective trade-offs, then applies a \"weight-balanced perturbation\" that selectively flips bits based on their marginal contribution to both objectives, while dynamically adjusting the perturbation intensity to balance exploration and exploitation. The algorithm ensures feasibility by maintaining a running weight check and only allowing moves that don't exceed capacity, ultimately generating neighbors that both diversify the archive and push the Pareto front forward.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with the most balanced objectives\n    selected_idx = 0\n    min_balance_diff = float('inf')\n    for i, (sol, obj) in enumerate(archive):\n        obj1, obj2 = obj\n        balance_diff = abs(obj1 - obj2) / max(1, obj1 + obj2)\n        if balance_diff < min_balance_diff:\n            min_balance_diff = balance_diff\n            selected_idx = i\n\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    new_solution = base_solution.copy()\n\n    # Calculate objective weights for perturbation\n    obj1_total, obj2_total = archive[selected_idx][1]\n    obj1_weight = obj1_total / max(1, obj1_total + obj2_total)\n    obj2_weight = obj2_total / max(1, obj1_total + obj2_total)\n\n    # Weight-balanced perturbation\n    for _ in range(5):  # Limit iterations\n        items = np.arange(len(base_solution))\n        np.random.shuffle(items)\n\n        for item in items:\n            if base_solution[item] == 1:\n                # Try removing item\n                new_weight = current_weight - weight_lst[item]\n                if new_weight <= capacity:\n                    # Remove if it improves balance\n                    if (obj1_weight > obj2_weight and value1_lst[item] > value2_lst[item]) or \\\n                       (obj2_weight > obj1_weight and value2_lst[item] > value1_lst[item]):\n                        new_solution[item] = 0\n                        current_weight = new_weight\n                        break\n            else:\n                # Try adding item\n                new_weight = current_weight + weight_lst[item]\n                if new_weight <= capacity:\n                    # Add if it improves balance\n                    if (obj1_weight > obj2_weight and value1_lst[item] > value2_lst[item]) or \\\n                       (obj2_weight > obj1_weight and value2_lst[item] > value1_lst[item]):\n                        new_solution[item] = 1\n                        current_weight = new_weight\n                        break\n\n    return new_solution\n\n",
          "score": [
               -0.7060157671961238,
               2.0638526678085327
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the least crowded solution in the archive by calculating the crowding distance for each solution and selecting the one with the smallest distance, ensuring it represents an under-explored region. It then applies a novel hybrid local search operator that combines a targeted item swapping mechanism with a probabilistic exploration component. The operator dynamically selects pairs of items to swap based on their combined marginal contribution to both objectives, while also incorporating a small probability of random swaps to escape local optima. The operator ensures feasibility by recalculating the total weight after each swap and adjusting the solution to stay within capacity. The selection process prioritizes solutions with low crowding distance to focus on less-explored areas, and the local search operator uses a weighted probability mechanism based on the items' contributions to both objectives, with a small random perturbation to explore adjacent solutions.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the least crowded solution (low crowding distance)\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(2):  # For each objective\n        sorted_idx = np.argsort(objectives[:, i])\n        sorted_obj = objectives[sorted_idx, i]\n        crowding_distances[sorted_idx[0]] = np.inf\n        crowding_distances[sorted_idx[-1]] = np.inf\n        for j in range(1, len(sorted_idx) - 1):\n            crowding_distances[sorted_idx[j]] += (sorted_obj[j + 1] - sorted_obj[j - 1]) / (sorted_obj[-1] - sorted_obj[0] + 1e-10)\n\n    # Select the solution with the lowest crowding distance\n    selected_idx = np.argmin(crowding_distances)\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Hybrid local search operator with targeted swapping\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal contributions for each item\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    marginal_combined = marginal_value1 + marginal_value2\n\n    # Identify candidate items for swapping\n    zero_indices = np.where(new_solution == 0)[0]\n    one_indices = np.where(new_solution == 1)[0]\n\n    # Perform targeted swaps based on marginal contributions\n    for _ in range(3):  # Limit the number of swaps\n        if len(zero_indices) > 0 and len(one_indices) > 0:\n            # Select items to swap based on their marginal contributions\n            candidate_zero = zero_indices[np.argsort(marginal_combined[zero_indices])[-3:]]  # Top 3 items to add\n            candidate_one = one_indices[np.argsort(marginal_combined[one_indices])[:3]]  # Bottom 3 items to remove\n\n            if len(candidate_zero) > 0 and len(candidate_one) > 0:\n                for i in candidate_zero:\n                    for j in candidate_one:\n                        if weight_lst[i] <= remaining_capacity + weight_lst[j]:\n                            # Perform swap\n                            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n                            remaining_capacity = capacity - np.sum(weight_lst[new_solution == 1])\n                            break\n                    else:\n                        continue\n                    break\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # If not feasible, remove items with lowest marginal contribution until feasible\n        while current_weight > capacity:\n            item_to_remove = np.argmax(new_solution * marginal_combined)\n            if new_solution[item_to_remove] == 1:\n                new_solution[item_to_remove] = 0\n                current_weight -= weight_lst[item_to_remove]\n\n    return new_solution\n\n",
          "score": [
               -0.8492211977074424,
               4.702699899673462
          ]
     },
     {
          "algorithm": "{The proposed heuristic function 'select_neighbor' first identifies promising solutions in the archive by evaluating their potential for improvement through a hybrid local search strategy. This involves selecting solutions with high objective values and low redundancy, then applying a dynamic neighborhood exploration that combines random item swaps, targeted flips based on marginal gains, and a guided local search that prioritizes items with high marginal utility ratios (value1/weight and value2/weight) while ensuring feasibility. The function intelligently balances exploration and exploitation by dynamically adjusting the search scope based on the current solution's characteristics, ensuring the generated neighbor solution remains feasible and potentially dominates or improves upon the original solution across both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution (highest sum of objectives)\n    archive_solutions = [sol_obj[0] for sol_obj in archive]\n    archive_objectives = [sol_obj[1] for sol_obj in archive]\n    objective_sums = np.array([sum(obj) for obj in archive_objectives])\n    selected_idx = np.argmax(objective_sums)\n    base_solution = archive_solutions[selected_idx].copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Generate candidate items for potential swap/flip\n    candidate_items = np.where(base_solution == 1)[0]\n    if len(candidate_items) > 0:\n        # Randomly select an item to flip (with higher probability for items with high marginal utility)\n        probs = np.zeros(len(candidate_items))\n        for i, item in enumerate(candidate_items):\n            marginal_value1 = value1_lst[item] / weight_lst[item] if weight_lst[item] > 0 else 0\n            marginal_value2 = value2_lst[item] / weight_lst[item] if weight_lst[item] > 0 else 0\n            probs[i] = marginal_value1 + marginal_value2\n        probs = probs / np.sum(probs) if np.sum(probs) > 0 else np.ones(len(candidate_items)) / len(candidate_items)\n        selected_item = np.random.choice(candidate_items, p=probs)\n    else:\n        # If no items are selected, find a feasible item to add\n        feasible_items = np.where(weight_lst <= (capacity - current_weight))[0]\n        if len(feasible_items) == 0:\n            return base_solution  # No feasible move possible\n        selected_item = np.random.choice(feasible_items)\n\n    # Create neighbor solution\n    new_solution = base_solution.copy()\n    new_solution[selected_item] = 1 - new_solution[selected_item]  # Flip the selected item\n\n    # Ensure feasibility\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # If flipping makes it infeasible, try to remove the most \"expensive\" item\n        if new_solution[selected_item] == 1:  # We just added it, remove it\n            new_solution[selected_item] = 0\n        else:  # We just removed it, try to add another feasible item\n            feasible_items = np.where((weight_lst <= (capacity - current_weight)) & (base_solution == 0))[0]\n            if len(feasible_items) > 0:\n                add_item = np.random.choice(feasible_items)\n                new_solution[add_item] = 1\n            else:\n                # If no feasible addition, return original solution\n                return base_solution\n\n    return new_solution\n\n",
          "score": [
               -0.8072126207495933,
               4.307053357362747
          ]
     },
     {
          "algorithm": "{The heuristic function 'select_neighbor' first identifies promising solutions in the archive by filtering those with objective values that are within a specified percentage of the Pareto front (e.g., top 20% in each objective). It then intelligently selects a base solution by prioritizing those with the highest diversity in their objective values or those that have not been extensively explored in the archive. For local search, it employs a novel adaptive exchange operator that dynamically selects items to swap or flip based on their marginal contribution to both objectives, ensuring feasibility by recalculating weights and adjusting the solution to stay within capacity. The operator also incorporates a probabilistic exploration component to escape local optima, where items are randomly selected with a decaying probability to explore less promising but potentially high-quality regions of the solution space. The function returns the new neighbor solution after applying this hybrid local search strategy, guaranteeing feasibility by always checking the total weight against the capacity constraint.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Filter promising solutions (top 20% in each objective)\n    objectives = np.array([obj for _, obj in archive])\n    max_values = np.max(objectives, axis=0)\n    min_values = np.min(objectives, axis=0)\n    threshold1 = max_values[0] - 0.2 * (max_values[0] - min_values[0])\n    threshold2 = max_values[1] - 0.2 * (max_values[1] - min_values[1])\n\n    promising_indices = [\n        i for i, (obj1, obj2) in enumerate(objectives)\n        if obj1 >= threshold1 or obj2 >= threshold2\n    ]\n\n    if not promising_indices:\n        promising_indices = list(range(len(archive)))\n\n    # Step 2: Select a base solution (prioritize diversity or unexplored regions)\n    selected_idx = random.choice(promising_indices)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 3: Hybrid local search operator\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Identify candidate items for flipping\n    zero_indices = np.where(new_solution == 0)[0]\n    one_indices = np.where(new_solution == 1)[0]\n\n    # Adaptive exchange: flip items with high marginal contribution\n    for _ in range(5):  # Limit the number of flips to avoid excessive computation\n        if random.random() < 0.7:  # Probabilistic exploration\n            # Flip a random item\n            if len(zero_indices) > 0 and len(one_indices) > 0:\n                flip_idx = random.choice(zero_indices)\n                new_solution[flip_idx] = 1\n                new_weight = current_weight + weight_lst[flip_idx]\n                if new_weight > capacity:\n                    new_solution[flip_idx] = 0\n                else:\n                    current_weight = new_weight\n                    current_value1 += value1_lst[flip_idx]\n                    current_value2 += value2_lst[flip_idx]\n                    zero_indices = np.where(new_solution == 0)[0]\n                    one_indices = np.where(new_solution == 1)[0]\n        else:\n            # Flip a random item from the current solution\n            if len(one_indices) > 0:\n                flip_idx = random.choice(one_indices)\n                new_solution[flip_idx] = 0\n                current_weight -= weight_lst[flip_idx]\n                current_value1 -= value1_lst[flip_idx]\n                current_value2 -= value2_lst[flip_idx]\n                zero_indices = np.where(new_solution == 0)[0]\n                one_indices = np.where(new_solution == 1)[0]\n\n    return new_solution\n\n",
          "score": [
               -0.3690393270039769,
               2.8620464503765106
          ]
     },
     {
          "algorithm": "{The heuristic function 'select_neighbor' first identifies promising solutions in the archive by evaluating their potential for further local improvement, prioritizing those with high marginal gains in either objective or balance between objectives. It then applies a hybrid local search strategy combining a novel 'value-focused flip' operator (randomly flipping items with high value ratios) and a 'weight-aware swap' operator (swapping items to balance weight distribution), ensuring feasibility by rejecting any moves that exceed capacity. The function intelligently selects a solution from the archive based on these criteria, applies the hybrid operator, and returns the improved neighbor solution while maintaining feasibility.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a promising solution from the archive\n    selected_idx = random.randint(0, len(archive) - 1)\n    base_solution, (current_v1, current_v2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Hybrid local search strategy\n    # Step 1: Value-focused flip\n    value_ratio = (value1_lst + value2_lst) / (weight_lst + 1e-6)  # Avoid division by zero\n    sorted_indices = np.argsort(value_ratio)[::-1]  # Highest ratio first\n\n    for idx in sorted_indices:\n        if new_solution[idx] == 1:\n            # Try removing the item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 2: Weight-aware swap (if still space)\n    if current_weight < capacity:\n        # Find items not in solution with good value\n        candidate_indices = np.where(new_solution == 0)[0]\n        if len(candidate_indices) > 0:\n            # Select a random candidate\n            swap_candidate = random.choice(candidate_indices)\n            # Find an item in solution to swap with\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) > 0:\n                swap_item = random.choice(in_solution)\n                # Check if swap is feasible\n                if (current_weight - weight_lst[swap_item] + weight_lst[swap_candidate]) <= capacity:\n                    new_solution[swap_item] = 0\n                    new_solution[swap_candidate] = 1\n                    current_weight = current_weight - weight_lst[swap_item] + weight_lst[swap_candidate]\n\n    return new_solution\n\n",
          "score": [
               -0.8430062511573345,
               5.058723509311676
          ]
     }
]