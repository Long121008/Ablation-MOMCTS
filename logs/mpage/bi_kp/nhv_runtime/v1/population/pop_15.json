[
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating its potential for improvement through a novel hybrid local search strategy that combines a multi-objective greedy insertion strategy with a probabilistic multi-item perturbation, while ensuring feasibility by using a capacity-aware knapsack construction heuristic. It then applies a creative local search operator that dynamically adapts between item swaps, insertions, and removals based on the current solution's objective values and the archive's distribution, prioritizing items that offer the highest marginal gain in either objective while allowing controlled exploration of the solution space to balance exploitation and exploration. The operator explores neighboring solutions by flipping bits of items with high marginal contributions to both objectives, while also considering the impact on the solution's position in the Pareto front, and the selection of the base solution is biased towards those with the highest potential for improvement as estimated by the ratio of the current objective values to the maximum possible values in the archive, with the perturbation intensity adaptively adjusted based on the solution's proximity to the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select base solution with highest potential improvement\n    obj1_vals = np.array([obj[0] for _, obj in archive])\n    obj2_vals = np.array([obj[1] for _, obj in archive])\n    max_values = (np.max(obj1_vals), np.max(obj2_vals))\n\n    # Calculate potential for each solution (normalized difference)\n    potentials = [(max_values[0] - obj[0])/max_values[0] + (max_values[1] - obj[1])/max_values[1] for _, obj in archive]\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Dynamic operator selection based on solution's position\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate dominance score (number of solutions dominated by this solution)\n    dominance_scores = []\n    for sol, obj in archive:\n        dominates = (obj[0] >= archive[selected_idx][1][0] and obj[1] >= archive[selected_idx][1][1]) and \\\n                    (obj[0] > archive[selected_idx][1][0] or obj[1] > archive[selected_idx][1][1])\n        dominance_scores.append(dominates)\n    dominance_score = sum(dominance_scores)\n\n    # Operator selection probabilities\n    if dominance_score > len(archive) * 0.6:  # Solution is on Pareto front\n        operator_probs = [0.3, 0.4, 0.3]  # More exploration (insert/remove)\n    else:\n        operator_probs = [0.6, 0.2, 0.2]  # More exploitation (swap)\n\n    operator = np.random.choice(['swap', 'insert', 'remove'], p=operator_probs)\n\n    # Step 4: Apply selected operator\n    if operator == 'swap' and len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate marginal gains using a weighted combination of objectives\n        weight_obj1 = 0.6 if np.random.rand() > 0.5 else 0.4\n        weight_obj2 = 1 - weight_obj1\n\n        marginal_gain_in = (weight_obj1 * value1_lst[excluded_items] + weight_obj2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        marginal_gain_out = (weight_obj1 * value1_lst[included_items] + weight_obj2 * value2_lst[included_items]) / weight_lst[included_items]\n\n        best_in_idx = excluded_items[np.argmax(marginal_gain_in)]\n        best_out_idx = included_items[np.argmax(marginal_gain_out)]\n\n        # Check if swap is feasible\n        if weight_lst[best_in_idx] <= remaining_capacity + weight_lst[best_out_idx]:\n            new_solution[best_in_idx] = 1\n            new_solution[best_out_idx] = 0\n\n    elif operator == 'insert' and len(excluded_items) > 0:\n        # Insert items with highest combined marginal gain with adaptive weights\n        weight_obj1 = 0.7 if np.random.rand() > 0.5 else 0.3\n        weight_obj2 = 1 - weight_obj1\n\n        marginal_gain = (weight_obj1 * value1_lst[excluded_items] + weight_obj2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        sorted_indices = excluded_items[np.argsort(-marginal_gain)]\n\n        # Adaptive insertion intensity based on remaining capacity and randomness\n        insertion_intensity = min(0.4, remaining_capacity / capacity) * (0.8 + 0.4 * np.random.rand())\n        num_to_insert = max(1, int(len(sorted_indices) * insertion_intensity))\n\n        for idx in sorted_indices[:num_to_insert]:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    elif operator == 'remove' and len(included_items) > 0:\n        # Remove items with lowest combined marginal gain with adaptive weights\n        weight_obj1 = 0.5 if np.random.rand() > 0.5 else 0.5\n        weight_obj2 = 1 - weight_obj1\n\n        marginal_gain = (weight_obj1 * value1_lst[included_items] + weight_obj2 * value2_lst[included_items]) / weight_lst[included_items]\n        sorted_indices = included_items[np.argsort(marginal_gain)]\n\n        # Adaptive removal intensity based on solution's position and randomness\n        removal_intensity = (0.3 if dominance_score > len(archive) * 0.6 else 0.1) * (0.8 + 0.4 * np.random.rand())\n        num_to_remove = max(1, int(len(sorted_indices) * removal_intensity))\n\n        for idx in sorted_indices[:num_to_remove]:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        heaviest_idx = included_items[np.argmax(weight_lst[included_items])]\n        new_solution[heaviest_idx] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.9081133291918136,
               0.875940591096878
          ]
     },
     {
          "algorithm": "{The proposed algorithm selects a solution from the archive by identifying the least explored region of the Pareto front based on the local density of solutions, then applies a novel local search operator that performs a series of intelligent, multi-objective flips by considering the Pareto front contributions of items. The operator dynamically adjusts the selection based on a hybrid of lexicographic ordering and dominance-based selection, prioritizing solutions that are either non-dominated or have the highest combined marginal utility for both objectives, while also incorporating a probabilistic acceptance criterion that favors flips leading to non-dominated solutions or significant trade-offs. The selection process is guided by a utility function that weighs both objective improvements and solution diversity, ensuring a robust exploration of the search space, and includes an additional perturbation mechanism that randomly swaps items between objectives with a small probability to further explore the solution space while maintaining feasibility. Additionally, the algorithm employs a novel \"value-weighted random walk\" mechanism that probabilistically selects items to flip based on their normalized values, biased towards items that offer the highest marginal improvements in either objective, with a dynamic adjustment of the selection probability based on the current solution's objective values. This approach ensures a balance between exploitation of high-value items and exploration of the solution space, leading to more diverse and high-quality solutions.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify the least explored region of the Pareto front\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Calculate local density around each solution\n        distances = np.linalg.norm(objectives[:, None] - objectives, axis=2)\n        np.fill_diagonal(distances, np.inf)\n        min_distances = np.min(distances, axis=1)\n        selected_idx = np.argmin(min_distances)\n        base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate normalized marginal contributions\n    total_value1 = np.sum(value1_lst * base_solution)\n    total_value2 = np.sum(value2_lst * base_solution)\n\n    # Normalize values to [0, 1] range\n    max_value1 = np.max(value1_lst) if np.max(value1_lst) > 0 else 1\n    max_value2 = np.max(value2_lst) if np.max(value2_lst) > 0 else 1\n    norm_value1 = value1_lst / max_value1\n    norm_value2 = value2_lst / max_value2\n\n    # Step 3: Value-weighted random walk for item selection\n    candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                # Probability based on normalized values and current solution's objectives\n                prob = (norm_value1[i] * (1 - total_value1 / (total_value1 + total_value2 + 1e-10)) +\n                        norm_value2[i] * (total_value1 / (total_value1 + total_value2 + 1e-10)))\n                candidates.append((i, -1, prob))\n        else:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                prob = (norm_value1[i] * (1 - total_value1 / (total_value1 + total_value2 + 1e-10)) +\n                        norm_value2[i] * (total_value1 / (total_value1 + total_value2 + 1e-10)))\n                candidates.append((i, 1, prob))\n\n    if not candidates:\n        # No feasible flips, perform a random feasible flip\n        feasible_indices = [i for i in range(len(base_solution))\n                          if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                             (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # Step 4: Select items to flip based on probability distribution\n    items, flips, probs = zip(*candidates)\n    probs = np.array(probs) / np.sum(probs)  # Normalize probabilities\n    selected_idx = np.random.choice(len(items), p=probs)\n    flip_idx = items[selected_idx]\n    flip = flips[selected_idx]\n\n    new_solution[flip_idx] = 1 if flip == 1 else 0\n\n    # Step 5: Additional perturbation - swap items if beneficial\n    if random.random() < 0.2:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) >= 2:\n            i, j = random.sample(list(included_items), 2)\n            if (current_weight - weight_lst[i] - weight_lst[j] + weight_lst[i] + weight_lst[j]) <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
          "score": [
               -0.9980802905176362,
               1.773117333650589
          ]
     },
     {
          "algorithm": "{The novel algorithm first identifies the solution in the archive with the highest combined marginal utility for both objectives while considering the solution's position in the Pareto front, then applies a dynamic multi-phase local search operator that sequentially performs item additions, removals, and swaps based on an adaptive priority score that combines objective improvements, solution diversity, and capacity utilization, with each phase's intensity and selection criteria dynamically adjusted based on the current solution's performance and the archive's distribution, while maintaining feasibility through a capacity-aware filtering mechanism that prioritizes items with the highest marginal gains for both objectives and ensures the solution remains within the capacity constraint through a greedy repair mechanism when necessary.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select base solution with highest combined marginal utility\n    objectives = np.array([obj for _, obj in archive])\n    max_obj1, max_obj2 = np.max(objectives, axis=0)\n\n    marginal_utility = []\n    for sol, obj in archive:\n        utility = (max_obj1 - obj[0]) + (max_obj2 - obj[1])\n        marginal_utility.append(utility)\n\n    selected_idx = np.argmax(marginal_utility)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Calculate adaptive priority scores for items\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Priority for inclusion: combined marginal gain normalized by weight\n    if len(excluded_items) > 0:\n        marginal_gain_in = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n        priority_in = marginal_gain_in / (np.max(marginal_gain_in) + 1e-10)\n    else:\n        priority_in = np.array([])\n\n    # Priority for exclusion: combined marginal gain normalized by weight\n    if len(included_items) > 0:\n        marginal_gain_out = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        priority_out = marginal_gain_out / (np.max(marginal_gain_out) + 1e-10)\n    else:\n        priority_out = np.array([])\n\n    # Step 4: Dynamic multi-phase local search\n    phases = ['add', 'remove', 'swap']\n    phase_order = random.sample(phases, len(phases))\n\n    for phase in phase_order:\n        if phase == 'add' and len(excluded_items) > 0:\n            # Add items with highest priority\n            sorted_in = excluded_items[np.argsort(-priority_in)]\n            for idx in sorted_in:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n                    break  # Only add one item per phase\n\n        elif phase == 'remove' and len(included_items) > 0:\n            # Remove items with lowest priority\n            sorted_out = included_items[np.argsort(priority_out)]\n            for idx in sorted_out:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n                break  # Only remove one item per phase\n\n        elif phase == 'swap' and len(included_items) > 0 and len(excluded_items) > 0:\n            # Find best pair to swap\n            best_in = excluded_items[np.argmax(priority_in)]\n            best_out = included_items[np.argmax(priority_out)]\n\n            # Check if swap is feasible\n            if weight_lst[best_in] <= remaining_capacity + weight_lst[best_out]:\n                new_solution[best_in] = 1\n                new_solution[best_out] = 0\n                remaining_capacity += weight_lst[best_out] - weight_lst[best_in]\n\n    # Step 5: Ensure feasibility through greedy repair\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    while current_weight > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        # Remove the item with the lowest marginal utility\n        marginal_gain = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        worst_idx = included_items[np.argmin(marginal_gain)]\n        new_solution[worst_idx] = 0\n        current_weight -= weight_lst[worst_idx]\n\n    return new_solution\n\n",
          "score": [
               -0.8207603697696247,
               0.7856537103652954
          ]
     },
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a solution with high potential for improvement based on its objective values and weight utilization\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate the normalized objective values to determine the focus of improvement\n    max_val1 = np.max([obj[0] for _, obj in archive])\n    max_val2 = np.max([obj[1] for _, obj in archive])\n    norm_val1 = base_val1 / max_val1 if max_val1 > 0 else 0\n    norm_val2 = base_val2 / max_val2 if max_val2 > 0 else 0\n\n    # Step 3: Determine the focus of improvement (the objective that is relatively weaker)\n    focus_obj = 1 if norm_val1 < norm_val2 else 2\n\n    # Step 4: Generate candidate items for flipping based on their potential to improve the focused objective\n    candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Consider removing item i if it doesn't significantly reduce the focused objective\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                if focus_obj == 1:\n                    candidates.append((i, -1, value1_lst[i], value2_lst[i]))\n                else:\n                    candidates.append((i, -1, value2_lst[i], value1_lst[i]))\n        else:\n            # Consider adding item i if it improves the focused objective\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                if focus_obj == 1:\n                    candidates.append((i, 1, value1_lst[i], value2_lst[i]))\n                else:\n                    candidates.append((i, 1, value2_lst[i], value1_lst[i]))\n\n    if not candidates:\n        # Step 5: No feasible flips, perform a random feasible flip\n        feasible_indices = [i for i in range(len(base_solution))\n                          if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                             (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # Step 6: Select the best candidate based on the focused objective\n    best_candidate = None\n    best_score = -np.inf\n    for candidate in candidates:\n        idx, flip, val_focus, val_other = candidate\n        if flip == 1:\n            score = val_focus  # Adding item: maximize the focused objective\n        else:\n            score = -val_focus  # Removing item: minimize the focused objective\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate\n\n    if best_candidate is not None:\n        idx, flip, _, _ = best_candidate\n        new_solution[idx] = 1 if flip == 1 else 0\n\n    # Step 7: Additional perturbation: perform a series of intelligent swaps between objectives\n    if random.random() < 0.3 and len(new_solution) > 1:\n        # Select a subset of items to consider for swapping\n        swap_candidates = np.where(new_solution == 1)[0]\n        if len(swap_candidates) > 1:\n            np.random.shuffle(swap_candidates)\n            for i in range(min(3, len(swap_candidates)-1)):\n                j = i + 1\n                if j >= len(swap_candidates):\n                    break\n                # Swap items if it maintains feasibility\n                if (current_weight - weight_lst[swap_candidates[i]] - weight_lst[swap_candidates[j]] +\n                    weight_lst[swap_candidates[i]] + weight_lst[swap_candidates[j]]) <= capacity:\n                    new_solution[swap_candidates[i]], new_solution[swap_candidates[j]] = \\\n                    new_solution[swap_candidates[j]], new_solution[swap_candidates[i]]\n\n    return new_solution\n\n",
          "score": [
               -0.9451131052842658,
               1.2690076529979706
          ]
     },
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select base solution with highest potential improvement\n    obj1_vals = np.array([obj[0] for _, obj in archive])\n    obj2_vals = np.array([obj[1] for _, obj in archive])\n    max_values = (np.max(obj1_vals), np.max(obj2_vals))\n\n    # Calculate potential for each solution (normalized difference)\n    potentials = [(max_values[0] - obj[0])/max_values[0] + (max_values[1] - obj[1])/max_values[1] for _, obj in archive]\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Dynamic operator selection based on solution's position\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate dominance score (number of solutions dominated by this solution)\n    dominance_scores = []\n    for sol, obj in archive:\n        dominates = (obj[0] >= archive[selected_idx][1][0] and obj[1] >= archive[selected_idx][1][1]) and \\\n                    (obj[0] > archive[selected_idx][1][0] or obj[1] > archive[selected_idx][1][1])\n        dominance_scores.append(dominates)\n    dominance_score = sum(dominance_scores)\n\n    # Operator selection probabilities\n    if dominance_score > len(archive) * 0.6:  # Solution is on Pareto front\n        operator_probs = [0.3, 0.4, 0.3]  # More exploration (insert/remove)\n    else:\n        operator_probs = [0.6, 0.2, 0.2]  # More exploitation (swap)\n\n    operator = np.random.choice(['swap', 'insert', 'remove'], p=operator_probs)\n\n    # Step 4: Apply selected operator\n    if operator == 'swap' and len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate marginal gains using a weighted combination of objectives\n        weight_obj1 = 0.6 if np.random.rand() > 0.5 else 0.4\n        weight_obj2 = 1 - weight_obj1\n\n        marginal_gain_in = (weight_obj1 * value1_lst[excluded_items] + weight_obj2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        marginal_gain_out = (weight_obj1 * value1_lst[included_items] + weight_obj2 * value2_lst[included_items]) / weight_lst[included_items]\n\n        best_in_idx = excluded_items[np.argmax(marginal_gain_in)]\n        best_out_idx = included_items[np.argmax(marginal_gain_out)]\n\n        # Check if swap is feasible\n        if weight_lst[best_in_idx] <= remaining_capacity + weight_lst[best_out_idx]:\n            new_solution[best_in_idx] = 1\n            new_solution[best_out_idx] = 0\n\n    elif operator == 'insert' and len(excluded_items) > 0:\n        # Insert items with highest combined marginal gain with adaptive weights\n        weight_obj1 = 0.7 if np.random.rand() > 0.5 else 0.3\n        weight_obj2 = 1 - weight_obj1\n\n        marginal_gain = (weight_obj1 * value1_lst[excluded_items] + weight_obj2 * value2_lst[excluded_items]) / weight_lst[excluded_items]\n        sorted_indices = excluded_items[np.argsort(-marginal_gain)]\n\n        # Adaptive insertion intensity based on remaining capacity and randomness\n        insertion_intensity = min(0.4, remaining_capacity / capacity) * (0.8 + 0.4 * np.random.rand())\n        num_to_insert = max(1, int(len(sorted_indices) * insertion_intensity))\n\n        for idx in sorted_indices[:num_to_insert]:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    elif operator == 'remove' and len(included_items) > 0:\n        # Remove items with lowest combined marginal gain with adaptive weights\n        weight_obj1 = 0.5 if np.random.rand() > 0.5 else 0.5\n        weight_obj2 = 1 - weight_obj1\n\n        marginal_gain = (weight_obj1 * value1_lst[included_items] + weight_obj2 * value2_lst[included_items]) / weight_lst[included_items]\n        sorted_indices = included_items[np.argsort(marginal_gain)]\n\n        # Adaptive removal intensity based on solution's position and randomness\n        removal_intensity = (0.3 if dominance_score > len(archive) * 0.6 else 0.1) * (0.8 + 0.4 * np.random.rand())\n        num_to_remove = max(1, int(len(sorted_indices) * removal_intensity))\n\n        for idx in sorted_indices[:num_to_remove]:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        heaviest_idx = included_items[np.argmax(weight_lst[included_items])]\n        new_solution[heaviest_idx] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.9109883968367493,
               1.0249983668327332
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating its potential for improvement through a novel hybrid local search strategy that combines a multi-objective greedy insertion strategy with a probabilistic multi-item perturbation, while ensuring feasibility by using a capacity-aware knapsack construction heuristic. It then applies a creative local search operator that dynamically adapts between item swaps, insertions, and removals based on the current solution's objective values and the archive's distribution, prioritizing items that offer the highest marginal gain in either objective while allowing controlled exploration of the solution space to balance exploitation and exploration. The operator explores neighboring solutions by flipping bits of items with high marginal contributions to both objectives, while also considering the impact on the solution's position in the Pareto front, and the selection of the base solution is biased towards those with the highest potential for improvement as estimated by the ratio of the current objective values to the maximum possible values in the archive, with the perturbation intensity adaptively adjusted based on the solution's proximity to the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the base solution with the highest potential for improvement\n    obj1_vals = np.array([obj[0] for _, obj in archive])\n    obj2_vals = np.array([obj[1] for _, obj in archive])\n    max_values = (np.max(obj1_vals), np.max(obj2_vals))\n\n    potentials = [(max_values[0] - obj[0]) + (max_values[1] - obj[1]) for _, obj in archive]\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Dynamic operator selection based on solution's position in Pareto front\n    dominance_scores = []\n    for sol, obj in archive:\n        dominates = (obj[0] >= archive[selected_idx][1][0] and obj[1] >= archive[selected_idx][1][1]) and \\\n                    (obj[0] > archive[selected_idx][1][0] or obj[1] > archive[selected_idx][1][1])\n        dominance_scores.append(dominates)\n    dominance_score = sum(dominance_scores)\n\n    # Adaptive operator probabilities\n    if dominance_score > len(archive) * 0.7:  # Solution is on Pareto front\n        operator_probs = [0.2, 0.5, 0.3]  # More exploration (insert/remove)\n    else:\n        operator_probs = [0.5, 0.3, 0.2]  # More exploitation (swap)\n\n    operator = np.random.choice(['swap', 'insert', 'remove'], p=operator_probs)\n\n    # Step 4: Apply selected operator\n    if operator == 'swap':\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Calculate marginal gains for both objectives\n            marginal_gain_in1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n            marginal_gain_in2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n            marginal_gain_out1 = value1_lst[included_items] / weight_lst[included_items]\n            marginal_gain_out2 = value2_lst[included_items] / weight_lst[included_items]\n\n            # Find best pair to swap considering both objectives\n            best_in_idx = excluded_items[np.argmax(marginal_gain_in1 + marginal_gain_in2)]\n            best_out_idx = included_items[np.argmax(marginal_gain_out1 + marginal_gain_out2)]\n\n            # Check if swap is feasible\n            if weight_lst[best_in_idx] <= remaining_capacity + weight_lst[best_out_idx]:\n                new_solution[best_in_idx] = 1\n                new_solution[best_out_idx] = 0\n\n    elif operator == 'insert':\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            # Insert items with highest combined marginal gain\n            marginal_gain = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            sorted_indices = excluded_items[np.argsort(-marginal_gain)]\n\n            # Adaptive insertion intensity\n            insertion_intensity = min(0.3, remaining_capacity / capacity)\n            num_to_insert = max(1, int(len(sorted_indices) * insertion_intensity))\n\n            for idx in sorted_indices[:num_to_insert]:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n\n    elif operator == 'remove':\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Remove items with lowest combined marginal gain\n            marginal_gain = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            sorted_indices = included_items[np.argsort(marginal_gain)]\n\n            # Adaptive removal intensity\n            removal_intensity = 0.2 if dominance_score > len(archive) * 0.7 else 0.1\n            num_to_remove = max(1, int(len(sorted_indices) * removal_intensity))\n\n            for idx in sorted_indices[:num_to_remove]:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        heaviest_idx = included_items[np.argmax(weight_lst[included_items])]\n        new_solution[heaviest_idx] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.8675355070144595,
               0.9293537139892578
          ]
     },
     {
          "algorithm": "{The new algorithm identifies the most under-explored solution in the archive by evaluating its potential for improvement through a hybrid local search strategy that combines a multi-objective greedy insertion strategy with a probabilistic multi-item perturbation, while ensuring feasibility by using a capacity-aware knapsack construction heuristic. It then applies a novel local search operator that dynamically adapts between item swaps, insertions, and removals based on the current solution's objective values and the archive's distribution, prioritizing items that offer the highest marginal gain in either objective while allowing controlled exploration of the solution space to balance exploitation and exploration. The operator explores neighboring solutions by flipping bits of items with high marginal contributions to both objectives, while also considering the impact on the solution's position in the Pareto front, and the selection of the base solution is biased towards those with the lowest dominance count as estimated by the number of solutions they dominate, with the perturbation intensity adaptively adjusted based on the solution's proximity to the Pareto front and the current archive's diversity.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select the most under-explored solution based on dominance count\n    dominance_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        sol_i, (val1_i, val2_i) = archive[i]\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            sol_j, (val1_j, val2_j) = archive[j]\n            if (val1_i >= val1_j and val2_i >= val2_j) and (val1_i > val1_j or val2_i > val2_j):\n                dominance_counts[i] += 1\n\n    min_dominance_idx = np.argmin(dominance_counts)\n    base_solution = archive[min_dominance_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Dynamic operator selection with dominance-aware probabilities\n    operator = np.random.choice(['swap', 'insert', 'remove'], p=[0.5, 0.3, 0.2])\n\n    if operator == 'swap':\n        # Find items to swap (one in, one out)\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Calculate dominance-aware marginal gains\n            marginal_gain_in = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            marginal_gain_out = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n\n            # Find best pair to swap\n            best_in_idx = excluded_items[np.argmax(marginal_gain_in)]\n            best_out_idx = included_items[np.argmax(marginal_gain_out)]\n\n            # Check if swap is feasible\n            if weight_lst[best_in_idx] <= remaining_capacity + weight_lst[best_out_idx]:\n                new_solution[best_in_idx] = 1\n                new_solution[best_out_idx] = 0\n\n    elif operator == 'insert':\n        # Insert high-margin items with dominance consideration\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            # Calculate dominance-aware marginal gains\n            marginal_gain = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            sorted_indices = excluded_items[np.argsort(-marginal_gain)]\n\n            for idx in sorted_indices:\n                if weight_lst[idx] <= remaining_capacity:\n                    # Check if adding this item would create a dominated solution\n                    temp_weight = current_weight + weight_lst[idx]\n                    if temp_weight <= capacity:\n                        new_solution[idx] = 1\n                        remaining_capacity -= weight_lst[idx]\n\n    elif operator == 'remove':\n        # Remove low-margin items with dominance consideration\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Calculate dominance-aware marginal gains\n            marginal_gain = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            sorted_indices = included_items[np.argsort(marginal_gain)]\n\n            for idx in sorted_indices:\n                if np.random.rand() < 0.6:  # Higher probability for worse items\n                    # Check if removing this item would improve dominance\n                    temp_sol = new_solution.copy()\n                    temp_sol[idx] = 0\n                    temp_weight = np.sum(weight_lst[temp_sol == 1])\n                    if temp_weight <= capacity:\n                        new_solution[idx] = 0\n                        remaining_capacity += weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        heaviest_idx = included_items[np.argmax(weight_lst[included_items])]\n        new_solution[heaviest_idx] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.976392311834265,
               2.6729755997657776
          ]
     },
     {
          "algorithm": "{The new algorithm identifies the most under-explored solution in the archive by evaluating its potential for improvement through a hybrid local search strategy that combines multi-objective dominance analysis with a probabilistic multi-item perturbation, while ensuring feasibility by using a capacity-aware knapsack construction heuristic. It then applies a novel local search operator that dynamically adapts between item swaps, insertions, and removals based on the current solution's objective values and the archive's distribution, prioritizing items that offer the highest marginal gain in either objective while allowing controlled exploration of the solution space to balance exploitation and exploration. The operator explores neighboring solutions by flipping bits of items with high marginal contributions to both objectives, while also considering the impact on the solution's position in the Pareto front, and the selection of the base solution is biased towards those with the lowest dominance count as estimated by the number of solutions they dominate, with the perturbation intensity adaptively adjusted based on the solution's proximity to the Pareto front and the current archive's diversity.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select the most under-explored solution based on dominance count\n    dominance_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        sol_i, (val1_i, val2_i) = archive[i]\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            sol_j, (val1_j, val2_j) = archive[j]\n            if (val1_i >= val1_j and val2_i >= val2_j) and (val1_i > val1_j or val2_i > val2_j):\n                dominance_counts[i] += 1\n\n    min_dominance_idx = np.argmin(dominance_counts)\n    base_solution = archive[min_dominance_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Dynamic operator selection with dominance-aware probabilities\n    operator = np.random.choice(['swap', 'insert', 'remove'], p=[0.5, 0.3, 0.2])\n\n    if operator == 'swap':\n        # Find items to swap (one in, one out)\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Calculate dominance-aware marginal gains\n            marginal_gain_in = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            marginal_gain_out = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n\n            # Find best pair to swap\n            best_in_idx = excluded_items[np.argmax(marginal_gain_in)]\n            best_out_idx = included_items[np.argmax(marginal_gain_out)]\n\n            # Check if swap is feasible\n            if weight_lst[best_in_idx] <= remaining_capacity + weight_lst[best_out_idx]:\n                new_solution[best_in_idx] = 1\n                new_solution[best_out_idx] = 0\n\n    elif operator == 'insert':\n        # Insert high-margin items with dominance consideration\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            # Calculate dominance-aware marginal gains\n            marginal_gain = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            sorted_indices = excluded_items[np.argsort(-marginal_gain)]\n\n            for idx in sorted_indices:\n                if weight_lst[idx] <= remaining_capacity:\n                    # Check if adding this item would create a dominated solution\n                    temp_weight = current_weight + weight_lst[idx]\n                    if temp_weight <= capacity:\n                        new_solution[idx] = 1\n                        remaining_capacity -= weight_lst[idx]\n\n    elif operator == 'remove':\n        # Remove low-margin items with dominance consideration\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Calculate dominance-aware marginal gains\n            marginal_gain = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            sorted_indices = included_items[np.argsort(marginal_gain)]\n\n            for idx in sorted_indices:\n                if np.random.rand() < 0.6:  # Higher probability for worse items\n                    # Check if removing this item would improve dominance\n                    temp_sol = new_solution.copy()\n                    temp_sol[idx] = 0\n                    temp_weight = np.sum(weight_lst[temp_sol == 1])\n                    if temp_weight <= capacity:\n                        new_solution[idx] = 0\n                        remaining_capacity += weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        heaviest_idx = included_items[np.argmax(weight_lst[included_items])]\n        new_solution[heaviest_idx] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.9643176834052205,
               2.042050540447235
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating its potential for improvement through a novel hybrid local search strategy that combines a multi-objective greedy insertion strategy with a probabilistic multi-item perturbation, while ensuring feasibility by using a capacity-aware knapsack construction heuristic. It then applies a creative local search operator that dynamically adapts between item swaps, insertions, and removals based on the current solution's objective values and the archive's distribution, prioritizing items that offer the highest marginal gain in either objective while allowing controlled exploration of the solution space to balance exploitation and exploration. The operator explores neighboring solutions by flipping bits of items with high marginal contributions to both objectives, while also considering the impact on the solution's position in the Pareto front, and the selection of the base solution is biased towards those with the highest potential for improvement as estimated by the ratio of the current objective values to the maximum possible values in the archive, with the perturbation intensity adaptively adjusted based on the solution's proximity to the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the base solution with highest potential for improvement\n    obj1_vals = np.array([obj[0] for _, obj in archive])\n    obj2_vals = np.array([obj[1] for _, obj in archive])\n    max_values = (np.max(obj1_vals), np.max(obj2_vals))\n\n    max_potential = -1\n    selected_solution = None\n\n    for sol, obj in archive:\n        potential = (max_values[0] - obj[0]) + (max_values[1] - obj[1])\n        if potential > max_potential:\n            max_potential = potential\n            selected_solution = sol\n\n    base_solution = selected_solution.copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Dynamic operator selection\n    operator = np.random.choice(['swap', 'insert', 'remove'], p=[0.4, 0.3, 0.3])\n\n    if operator == 'swap':\n        # Find items to swap (one in, one out)\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Calculate marginal gains\n            marginal_gain_in = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            marginal_gain_out = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n\n            # Find best pair to swap\n            best_in_idx = excluded_items[np.argmax(marginal_gain_in)]\n            best_out_idx = included_items[np.argmax(marginal_gain_out)]\n\n            # Check if swap is feasible\n            if weight_lst[best_in_idx] <= remaining_capacity + weight_lst[best_out_idx]:\n                new_solution[best_in_idx] = 1\n                new_solution[best_out_idx] = 0\n\n    elif operator == 'insert':\n        # Insert high-margin items\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            # Calculate marginal gains\n            marginal_gain = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            sorted_indices = excluded_items[np.argsort(-marginal_gain)]\n\n            for idx in sorted_indices:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n\n    elif operator == 'remove':\n        # Remove low-margin items\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Calculate marginal gains\n            marginal_gain = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            sorted_indices = included_items[np.argsort(marginal_gain)]\n\n            for idx in sorted_indices:\n                if np.random.rand() < 0.7:  # Higher probability for worse items\n                    new_solution[idx] = 0\n                    remaining_capacity += weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        heaviest_idx = included_items[np.argmax(weight_lst[included_items])]\n        new_solution[heaviest_idx] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.7574856289025504,
               0.9178695380687714
          ]
     },
     {
          "algorithm": "{The proposed algorithm selects a solution from the archive by prioritizing those with the highest combined marginal utility for both objectives, then applies a novel local search operator that performs a series of intelligent, multi-objective flips by considering the Pareto front contributions of items, dynamically adjusting the selection to balance feasibility and improvement potential. The operator uses a probabilistic acceptance criterion that favors flips leading to non-dominated solutions or significant trade-offs, while also incorporating a diversity-preserving mechanism to avoid premature convergence. The selection process is guided by a utility function that weighs both objective improvements and solution diversity, ensuring a robust exploration of the search space. The algorithm differs from both existing ones by employing a hybrid of lexicographic ordering and dominance-based selection, prioritizing solutions that are either non-dominated or have the highest combined marginal utility for both objectives, and then applying a novel local search operator that performs a series of intelligent, multi-objective flips by considering the Pareto front contributions of items, dynamically adjusting the selection to balance feasibility and improvement potential.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with the highest combined marginal utility\n    best_idx = 0\n    best_score = -np.inf\n    for i, (solution, (value1, value2)) in enumerate(archive):\n        current_weight = np.sum(weight_lst * solution)\n        if current_weight > capacity:\n            continue  # Skip infeasible solutions\n        marginal_value1 = value1 / (current_weight + 1e-6)\n        marginal_value2 = value2 / (current_weight + 1e-6)\n        score = marginal_value1 + marginal_value2\n        if score > best_score:\n            best_score = score\n            best_idx = i\n    base_solution = archive[best_idx][0].copy()\n\n    # Step 2: Calculate current total weight and identify feasible flips\n    current_weight = np.sum(weight_lst * base_solution)\n    items = np.arange(len(base_solution))\n    candidates = []\n\n    for i in items:\n        if base_solution[i] == 1:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, -1, value1_lst[i], value2_lst[i]))\n        else:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, 1, value1_lst[i], value2_lst[i]))\n\n    if not candidates:\n        # No feasible flips, return a random feasible neighbor\n        feasible_indices = [i for i in range(len(base_solution)) if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                           (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution = base_solution.copy()\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            return new_solution\n        else:\n            return base_solution.copy()\n\n    # Step 3: Select the best candidate based on Pareto front contribution\n    best_candidate = None\n    best_score = -np.inf\n    for candidate in candidates:\n        idx, flip, val1, val2 = candidate\n        if flip == 1:\n            score = (val1 + val2) / (1 + current_weight)  # Adding item: maximize both objectives\n        else:\n            score = - (val1 + val2) / (1 + (capacity - current_weight))  # Removing item: minimize both objectives\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate\n\n    if best_candidate is None:\n        return base_solution.copy()\n\n    # Step 4: Apply the selected flip\n    new_solution = base_solution.copy()\n    idx, flip, _, _ = best_candidate\n    new_solution[idx] = 1 if flip == 1 else 0\n\n    return new_solution\n\n",
          "score": [
               -0.9232314124183499,
               1.5609795153141022
          ]
     }
]