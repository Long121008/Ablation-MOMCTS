[
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating its potential for improvement through a novel hybrid local search strategy that combines a multi-objective greedy insertion strategy with a probabilistic multi-item perturbation, while ensuring feasibility by using a capacity-aware knapsack construction heuristic. It then applies a creative local search operator that dynamically adapts between item swaps, insertions, and removals based on the current solution's objective values and the archive's distribution, prioritizing items that offer the highest marginal gain in either objective while allowing controlled exploration of the solution space to balance exploitation and exploration. The operator explores neighboring solutions by flipping bits of items with high marginal contributions to both objectives, while also considering the impact on the solution's position in the Pareto front, and the selection of the base solution is biased towards those with the highest potential for improvement as estimated by the ratio of the current objective values to the maximum possible values in the archive, with the perturbation intensity adaptively adjusted based on the solution's proximity to the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the base solution with highest potential for improvement\n    obj1_vals = np.array([obj[0] for _, obj in archive])\n    obj2_vals = np.array([obj[1] for _, obj in archive])\n    max_values = (np.max(obj1_vals), np.max(obj2_vals))\n\n    max_potential = -1\n    selected_solution = None\n\n    for sol, obj in archive:\n        potential = (max_values[0] - obj[0]) + (max_values[1] - obj[1])\n        if potential > max_potential:\n            max_potential = potential\n            selected_solution = sol\n\n    base_solution = selected_solution.copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Dynamic operator selection\n    operator = np.random.choice(['swap', 'insert', 'remove'], p=[0.4, 0.3, 0.3])\n\n    if operator == 'swap':\n        # Find items to swap (one in, one out)\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Calculate marginal gains\n            marginal_gain_in = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            marginal_gain_out = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n\n            # Find best pair to swap\n            best_in_idx = excluded_items[np.argmax(marginal_gain_in)]\n            best_out_idx = included_items[np.argmax(marginal_gain_out)]\n\n            # Check if swap is feasible\n            if weight_lst[best_in_idx] <= remaining_capacity + weight_lst[best_out_idx]:\n                new_solution[best_in_idx] = 1\n                new_solution[best_out_idx] = 0\n\n    elif operator == 'insert':\n        # Insert high-margin items\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            # Calculate marginal gains\n            marginal_gain = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            sorted_indices = excluded_items[np.argsort(-marginal_gain)]\n\n            for idx in sorted_indices:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n\n    elif operator == 'remove':\n        # Remove low-margin items\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Calculate marginal gains\n            marginal_gain = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            sorted_indices = included_items[np.argsort(marginal_gain)]\n\n            for idx in sorted_indices:\n                if np.random.rand() < 0.7:  # Higher probability for worse items\n                    new_solution[idx] = 0\n                    remaining_capacity += weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        heaviest_idx = included_items[np.argmax(weight_lst[included_items])]\n        new_solution[heaviest_idx] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.7574856289025504,
               0.9178695380687714
          ]
     },
     {
          "algorithm": "{The new algorithm identifies the most under-explored solution in the archive by evaluating its potential for improvement through a hybrid local search strategy that combines multi-objective dominance analysis with a probabilistic multi-item perturbation, while ensuring feasibility by using a capacity-aware knapsack construction heuristic. It then applies a novel local search operator that dynamically adapts between item swaps, insertions, and removals based on the current solution's objective values and the archive's distribution, prioritizing items that offer the highest marginal gain in either objective while allowing controlled exploration of the solution space to balance exploitation and exploration. The operator explores neighboring solutions by flipping bits of items with high marginal contributions to both objectives, while also considering the impact on the solution's position in the Pareto front, and the selection of the base solution is biased towards those with the lowest dominance count as estimated by the number of solutions they dominate, with the perturbation intensity adaptively adjusted based on the solution's proximity to the Pareto front and the current archive's diversity.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select the most under-explored solution based on dominance count\n    dominance_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        sol_i, (val1_i, val2_i) = archive[i]\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            sol_j, (val1_j, val2_j) = archive[j]\n            if (val1_i >= val1_j and val2_i >= val2_j) and (val1_i > val1_j or val2_i > val2_j):\n                dominance_counts[i] += 1\n\n    min_dominance_idx = np.argmin(dominance_counts)\n    base_solution = archive[min_dominance_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Dynamic operator selection with dominance-aware probabilities\n    operator = np.random.choice(['swap', 'insert', 'remove'], p=[0.5, 0.3, 0.2])\n\n    if operator == 'swap':\n        # Find items to swap (one in, one out)\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Calculate dominance-aware marginal gains\n            marginal_gain_in = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            marginal_gain_out = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n\n            # Find best pair to swap\n            best_in_idx = excluded_items[np.argmax(marginal_gain_in)]\n            best_out_idx = included_items[np.argmax(marginal_gain_out)]\n\n            # Check if swap is feasible\n            if weight_lst[best_in_idx] <= remaining_capacity + weight_lst[best_out_idx]:\n                new_solution[best_in_idx] = 1\n                new_solution[best_out_idx] = 0\n\n    elif operator == 'insert':\n        # Insert high-margin items with dominance consideration\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            # Calculate dominance-aware marginal gains\n            marginal_gain = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            sorted_indices = excluded_items[np.argsort(-marginal_gain)]\n\n            for idx in sorted_indices:\n                if weight_lst[idx] <= remaining_capacity:\n                    # Check if adding this item would create a dominated solution\n                    temp_weight = current_weight + weight_lst[idx]\n                    if temp_weight <= capacity:\n                        new_solution[idx] = 1\n                        remaining_capacity -= weight_lst[idx]\n\n    elif operator == 'remove':\n        # Remove low-margin items with dominance consideration\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Calculate dominance-aware marginal gains\n            marginal_gain = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            sorted_indices = included_items[np.argsort(marginal_gain)]\n\n            for idx in sorted_indices:\n                if np.random.rand() < 0.6:  # Higher probability for worse items\n                    # Check if removing this item would improve dominance\n                    temp_sol = new_solution.copy()\n                    temp_sol[idx] = 0\n                    temp_weight = np.sum(weight_lst[temp_sol == 1])\n                    if temp_weight <= capacity:\n                        new_solution[idx] = 0\n                        remaining_capacity += weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        heaviest_idx = included_items[np.argmax(weight_lst[included_items])]\n        new_solution[heaviest_idx] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.9643176834052205,
               2.042050540447235
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating its potential for improvement through a novel hybrid local search strategy that combines a multi-objective greedy insertion strategy with a probabilistic multi-item perturbation, while ensuring feasibility by using a capacity-aware knapsack construction heuristic. It then applies a creative local search operator that dynamically adapts between item swaps, insertions, and removals based on the current solution's objective values and the archive's distribution, prioritizing items that offer the highest marginal gain in either objective while allowing controlled exploration of the solution space to balance exploitation and exploration. The operator explores neighboring solutions by flipping bits of items with high marginal contributions to both objectives, while also considering the impact on the solution's position in the Pareto front, and the selection of the base solution is biased towards those with the highest potential for improvement as estimated by the ratio of the current objective values to the maximum possible values in the archive, with the perturbation intensity adaptively adjusted based on the solution's proximity to the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the base solution with highest potential for improvement\n    obj1_vals = np.array([obj[0] for _, obj in archive])\n    obj2_vals = np.array([obj[1] for _, obj in archive])\n    max_values = (np.max(obj1_vals), np.max(obj2_vals))\n\n    # Calculate potential for each solution and select the one with highest potential\n    potentials = [(max_values[0] - obj[0]) + (max_values[1] - obj[1]) for _, obj in archive]\n    selected_idx = np.argmax(potentials)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Adaptive operator selection based on solution's position in Pareto front\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    # Calculate dominance score (number of solutions dominated by this solution)\n    dominance_scores = []\n    for sol, obj in archive:\n        dominates = (obj[0] >= archive[selected_idx][1][0] and obj[1] >= archive[selected_idx][1][1]) and \\\n                    (obj[0] > archive[selected_idx][1][0] or obj[1] > archive[selected_idx][1][1])\n        dominance_scores.append(dominates)\n\n    dominance_score = sum(dominance_scores)\n\n    # Adaptive operator probabilities\n    if dominance_score > len(archive) * 0.7:  # Solution is on Pareto front\n        operator_probs = [0.2, 0.5, 0.3]  # More exploration (insert/remove)\n    else:\n        operator_probs = [0.5, 0.3, 0.2]  # More exploitation (swap)\n\n    operator = np.random.choice(['swap', 'insert', 'remove'], p=operator_probs)\n\n    # Step 4: Apply selected operator\n    if operator == 'swap' and len(included_items) > 0 and len(excluded_items) > 0:\n        # Calculate marginal gains for both objectives separately\n        marginal_gain_in1 = value1_lst[excluded_items] / weight_lst[excluded_items]\n        marginal_gain_in2 = value2_lst[excluded_items] / weight_lst[excluded_items]\n        marginal_gain_out1 = value1_lst[included_items] / weight_lst[included_items]\n        marginal_gain_out2 = value2_lst[included_items] / weight_lst[included_items]\n\n        # Find best pair to swap considering both objectives\n        best_in_idx = excluded_items[np.argmax(marginal_gain_in1 + marginal_gain_in2)]\n        best_out_idx = included_items[np.argmax(marginal_gain_out1 + marginal_gain_out2)]\n\n        # Check if swap is feasible\n        if weight_lst[best_in_idx] <= remaining_capacity + weight_lst[best_out_idx]:\n            new_solution[best_in_idx] = 1\n            new_solution[best_out_idx] = 0\n\n    elif operator == 'insert' and len(excluded_items) > 0:\n        # Insert items with highest combined marginal gain\n        marginal_gain = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n        sorted_indices = excluded_items[np.argsort(-marginal_gain)]\n\n        # Adaptive insertion intensity based on remaining capacity\n        insertion_intensity = min(0.3, remaining_capacity / capacity)\n        num_to_insert = max(1, int(len(sorted_indices) * insertion_intensity))\n\n        for idx in sorted_indices[:num_to_insert]:\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n\n    elif operator == 'remove' and len(included_items) > 0:\n        # Remove items with lowest combined marginal gain\n        marginal_gain = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n        sorted_indices = included_items[np.argsort(marginal_gain)]\n\n        # Adaptive removal intensity based on solution's position\n        removal_intensity = 0.2 if dominance_score > len(archive) * 0.7 else 0.1\n        num_to_remove = max(1, int(len(sorted_indices) * removal_intensity))\n\n        for idx in sorted_indices[:num_to_remove]:\n            new_solution[idx] = 0\n            remaining_capacity += weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        heaviest_idx = included_items[np.argmax(weight_lst[included_items])]\n        new_solution[heaviest_idx] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.8793306885479759,
               1.001692682504654
          ]
     },
     {
          "algorithm": "{The proposed algorithm selects a solution from the archive by identifying the \"underexplored\" region of the Pareto front based on the local density of solutions, then applies a novel local search operator that performs a series of intelligent, multi-objective flips by considering the Pareto front contributions of items. The operator dynamically adjusts the selection based on a hybrid of lexicographic ordering and dominance-based selection, prioritizing solutions that are either non-dominated or have the highest combined marginal utility for both objectives, while also incorporating a probabilistic acceptance criterion that favors flips leading to non-dominated solutions or significant trade-offs. The selection process is guided by a utility function that weighs both objective improvements and solution diversity, ensuring a robust exploration of the search space, and includes an additional perturbation mechanism that randomly swaps items between objectives with a small probability to further explore the solution space while maintaining feasibility.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify the underexplored region of the Pareto front\n    objectives = np.array([obj for _, obj in archive])\n    if len(objectives) == 1:\n        base_solution = archive[0][0].copy()\n    else:\n        # Calculate local density around each solution\n        distances = np.linalg.norm(objectives[:, None] - objectives, axis=2)\n        np.fill_diagonal(distances, np.inf)\n        min_distances = np.min(distances, axis=1)\n        selected_idx = np.argmin(min_distances)\n        base_solution = archive[selected_idx][0].copy()\n\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate marginal contributions\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 3: Select items to flip based on Pareto front contributions\n    candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, -1, combined_marginal[i]))\n        else:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, 1, combined_marginal[i]))\n\n    if not candidates:\n        # No feasible flips, perform a random feasible flip\n        feasible_indices = [i for i in range(len(base_solution))\n                          if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                             (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # Step 4: Select top candidates based on combined marginal contributions\n    candidates.sort(key=lambda x: x[2], reverse=True)\n    max_flips = min(2, len(candidates))\n    selected_flips = candidates[:max_flips]\n\n    # Step 5: Apply selected flips with probabilistic acceptance\n    for idx, flip, _ in selected_flips:\n        if random.random() < 0.7:  # 70% chance to accept the flip\n            new_solution[idx] = 1 if flip == 1 else 0\n\n    # Step 6: Additional perturbation - swap items if beneficial\n    if random.random() < 0.2:\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) >= 2:\n            i, j = random.sample(list(included_items), 2)\n            if (current_weight - weight_lst[i] - weight_lst[j] + weight_lst[i] + weight_lst[j]) <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
          "score": [
               -0.8947258685729016,
               1.0429315865039825
          ]
     },
     {
          "algorithm": "{The proposed algorithm selects a promising solution from the archive using a hybrid approach that combines crowding distance and objective space diversity to prioritize solutions with high potential for improvement. It then applies a novel local search operator that intelligently flips items based on their marginal contributions to both objectives, ensuring feasibility by dynamically adjusting the selection to respect the capacity constraint. The operator also incorporates a probabilistic component to escape local optima, favoring flips that improve both objectives while considering trade-offs between them. The selection process is biased towards solutions with higher crowding distances or those lying on the Pareto front, ensuring a balance between exploration and exploitation.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution from the archive (prioritize solutions with high crowding distance or on the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    selected_solution, selected_objective = archive[selected_idx]\n    base_solution = selected_solution.copy()\n\n    # Step 2: Compute marginal contributions of each item to both objectives\n    marginal_value1 = value1_lst / weight_lst\n    marginal_value2 = value2_lst / weight_lst\n\n    # Step 3: Identify items that can be flipped to improve both objectives or trade-off between them\n    current_weight = np.sum(weight_lst * base_solution)\n    candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Consider removing item i if it doesn't significantly reduce both objectives\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, -1, marginal_value1[i], marginal_value2[i]))\n        else:\n            # Consider adding item i if it improves both objectives or has a good trade-off\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, 1, marginal_value1[i], marginal_value2[i]))\n\n    if not candidates:\n        # No feasible flips, return a random neighbor by flipping a single item\n        feasible_indices = [i for i in range(len(base_solution)) if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                           (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution = base_solution.copy()\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            return new_solution\n        else:\n            return base_solution.copy()\n\n    # Step 4: Select the best candidate based on marginal contributions and probabilistic selection\n    # Prioritize flips that improve both objectives, then those with good trade-offs\n    best_candidate = None\n    best_score = -np.inf\n    for candidate in candidates:\n        idx, flip, m_val1, m_val2 = candidate\n        if flip == 1:\n            score = m_val1 + m_val2  # Adding item: maximize both objectives\n        else:\n            score = -m_val1 - m_val2  # Removing item: minimize both objectives\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate\n\n    if best_candidate is None:\n        return base_solution.copy()\n\n    # Step 5: Apply the selected flip\n    new_solution = base_solution.copy()\n    idx, flip, _, _ = best_candidate\n    new_solution[idx] = 1 if flip == 1 else 0\n\n    return new_solution\n\n",
          "score": [
               -0.9632164304649085,
               7.020322293043137
          ]
     },
     {
          "algorithm": "{The proposed algorithm selects a solution from the archive based on a hybrid of lexicographic ordering and dominance-based selection, prioritizing solutions that are either non-dominated or have the highest combined marginal utility for both objectives. It then applies a novel local search operator that performs a series of intelligent, multi-objective flips by considering the Pareto front contributions of items, dynamically adjusting the selection to balance feasibility and improvement potential. The operator uses a probabilistic acceptance criterion that favors flips leading to non-dominated solutions or significant trade-offs, while also incorporating a diversity-preserving mechanism to avoid premature convergence. The selection process is guided by a utility function that weighs both objective improvements and solution diversity, ensuring a robust exploration of the search space.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a solution based on lexicographic ordering and dominance\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = 0\n    for i in range(1, len(archive)):\n        if (objectives[i, 0] > objectives[selected_idx, 0] and objectives[i, 1] >= objectives[selected_idx, 1]) or \\\n           (objectives[i, 0] >= objectives[selected_idx, 0] and objectives[i, 1] > objectives[selected_idx, 1]):\n            selected_idx = i\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current total weight and identify Pareto front items\n    current_weight = np.sum(weight_lst * base_solution)\n    items_included = np.where(base_solution == 1)[0]\n    items_excluded = np.where(base_solution == 0)[0]\n\n    # Step 3: Calculate marginal contributions for both objectives\n    marginal_value1 = value1_lst / weight_lst\n    marginal_value2 = value2_lst / weight_lst\n\n    # Step 4: Identify items that can improve both objectives or trade-offs\n    candidates = []\n    for i in items_included:\n        new_weight = current_weight - weight_lst[i]\n        if new_weight <= capacity:\n            candidates.append((i, -1, marginal_value1[i], marginal_value2[i]))\n    for i in items_excluded:\n        new_weight = current_weight + weight_lst[i]\n        if new_weight <= capacity:\n            candidates.append((i, 1, marginal_value1[i], marginal_value2[i]))\n\n    if not candidates:\n        # No feasible flips, return a random neighbor by flipping a single item\n        feasible_indices = [i for i in range(len(base_solution)) if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                           (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution = base_solution.copy()\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            return new_solution\n        else:\n            return base_solution.copy()\n\n    # Step 5: Select the best candidate based on Pareto front contribution\n    best_candidate = None\n    best_score = -np.inf\n    for candidate in candidates:\n        idx, flip, m_val1, m_val2 = candidate\n        if flip == 1:\n            score = m_val1 + m_val2  # Adding item: maximize both objectives\n        else:\n            score = -m_val1 - m_val2  # Removing item: minimize both objectives\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate\n\n    if best_candidate is None:\n        return base_solution.copy()\n\n    # Step 6: Apply the selected flip\n    new_solution = base_solution.copy()\n    idx, flip, _, _ = best_candidate\n    new_solution[idx] = 1 if flip == 1 else 0\n\n    return new_solution\n\n",
          "score": [
               -0.9331449268435238,
               2.120920091867447
          ]
     },
     {
          "algorithm": "{The proposed algorithm selects a solution from the archive by first identifying the \"weakest\" objective in the solution (based on normalized values) and then applies a novel local search operator that performs a series of intelligent, multi-objective flips by considering the Pareto front contributions of items. The operator dynamically adjusts the selection based on a hybrid of lexicographic ordering and dominance-based selection, prioritizing solutions that are either non-dominated or have the highest combined marginal utility for both objectives. It then uses a probabilistic acceptance criterion that favors flips leading to non-dominated solutions or significant trade-offs, while also incorporating a diversity-preserving mechanism to avoid premature convergence. The selection process is guided by a utility function that weighs both objective improvements and solution diversity, ensuring a robust exploration of the search space. The algorithm also includes an additional perturbation mechanism that randomly swaps items between objectives with a small probability to further explore the solution space while maintaining feasibility.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a solution with high potential for improvement based on its objective values and weight utilization\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate the normalized objective values to determine the focus of improvement\n    max_val1 = np.max([obj[0] for _, obj in archive])\n    max_val2 = np.max([obj[1] for _, obj in archive])\n    norm_val1 = base_val1 / max_val1 if max_val1 > 0 else 0\n    norm_val2 = base_val2 / max_val2 if max_val2 > 0 else 0\n\n    # Step 3: Determine the focus of improvement (the objective that is relatively weaker)\n    focus_obj = 1 if norm_val1 < norm_val2 else 2\n\n    # Step 4: Generate candidate items for flipping based on their potential to improve the focused objective\n    candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Consider removing item i if it doesn't significantly reduce the focused objective\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                if focus_obj == 1:\n                    candidates.append((i, -1, value1_lst[i], value2_lst[i]))\n                else:\n                    candidates.append((i, -1, value2_lst[i], value1_lst[i]))\n        else:\n            # Consider adding item i if it improves the focused objective\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                if focus_obj == 1:\n                    candidates.append((i, 1, value1_lst[i], value2_lst[i]))\n                else:\n                    candidates.append((i, 1, value2_lst[i], value1_lst[i]))\n\n    if not candidates:\n        # Step 5: No feasible flips, perform a random feasible flip\n        feasible_indices = [i for i in range(len(base_solution))\n                          if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                             (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # Step 6: Select the best candidate based on the focused objective\n    best_candidate = None\n    best_score = -np.inf\n    for candidate in candidates:\n        idx, flip, val_focus, val_other = candidate\n        if flip == 1:\n            score = val_focus  # Adding item: maximize the focused objective\n        else:\n            score = -val_focus  # Removing item: minimize the focused objective\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate\n\n    if best_candidate is not None:\n        idx, flip, _, _ = best_candidate\n        new_solution[idx] = 1 if flip == 1 else 0\n\n    # Step 7: Additional perturbation: perform a series of intelligent swaps between objectives\n    if random.random() < 0.3 and len(new_solution) > 1:\n        # Select a subset of items to consider for swapping\n        swap_candidates = np.where(new_solution == 1)[0]\n        if len(swap_candidates) > 1:\n            np.random.shuffle(swap_candidates)\n            for i in range(min(3, len(swap_candidates)-1)):\n                j = i + 1\n                if j >= len(swap_candidates):\n                    break\n                # Swap items if it maintains feasibility\n                if (current_weight - weight_lst[swap_candidates[i]] - weight_lst[swap_candidates[j]] +\n                    weight_lst[swap_candidates[i]] + weight_lst[swap_candidates[j]]) <= capacity:\n                    new_solution[swap_candidates[i]], new_solution[swap_candidates[j]] = \\\n                    new_solution[swap_candidates[j]], new_solution[swap_candidates[i]]\n\n    return new_solution\n\n",
          "score": [
               -0.9591348538510646,
               2.596752852201462
          ]
     },
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with the highest combined value of both objectives\n    best_idx = 0\n    best_score = 0\n    for i, (solution, (value1, value2)) in enumerate(archive):\n        score = value1 + value2\n        if score > best_score:\n            best_score = score\n            best_idx = i\n    base_solution = archive[best_idx][0].copy()\n\n    # Step 2: Generate a neighbor solution using a novel local search strategy\n    new_solution = base_solution.copy()\n    items = np.arange(len(new_solution))\n\n    # Calculate the current weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 3: Identify items that can be flipped (added or removed) without exceeding capacity\n    candidates = []\n    for i in items:\n        if new_solution[i] == 1:\n            # Consider removing item i if it is the least valuable in either objective\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, -1, value1_lst[i], value2_lst[i]))\n        else:\n            # Consider adding item i if it fits within the capacity\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, 1, value1_lst[i], value2_lst[i]))\n\n    if not candidates:\n        # No feasible flips, return the base solution\n        return base_solution.copy()\n\n    # Step 4: Select the best candidate based on a novel scoring mechanism\n    # The score is a weighted combination of the item's value and its contribution to the solution's diversity\n    best_candidate = None\n    best_score = -np.inf\n    for candidate in candidates:\n        idx, flip, val1, val2 = candidate\n        # Calculate the score based on the item's value and its potential impact on the solution\n        if flip == 1:\n            # Adding an item: prioritize high-value items that complement the current solution\n            score = (val1 + val2) / (1 + current_weight)\n        else:\n            # Removing an item: prioritize low-value items that are least critical to the current solution\n            score = - (val1 + val2) / (1 + (capacity - current_weight))\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate\n\n    if best_candidate is None:\n        return base_solution.copy()\n\n    # Step 5: Apply the selected flip\n    idx, flip, _, _ = best_candidate\n    new_solution[idx] = 1 if flip == 1 else 0\n\n    return new_solution\n\n",
          "score": [
               -0.8933798289249997,
               1.3035264611244202
          ]
     },
     {
          "algorithm": "{The proposed algorithm selects a solution from the archive by first identifying the \"weakest\" objective in the solution (based on normalized values) and then applies a novel local search operator that performs a series of intelligent, multi-objective flips by considering the Pareto front contributions of items. The operator dynamically adjusts the selection based on a hybrid of lexicographic ordering and dominance-based selection, prioritizing solutions that are either non-dominated or have the highest combined marginal utility for both objectives. It then uses a probabilistic acceptance criterion that favors flips leading to non-dominated solutions or significant trade-offs, while also incorporating a diversity-preserving mechanism to avoid premature convergence. The selection process is guided by a utility function that weighs both objective improvements and solution diversity, ensuring a robust exploration of the search space. The algorithm also includes an additional perturbation mechanism that randomly swaps items between objectives with a small probability to further explore the solution space while maintaining feasibility.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high potential for improvement based on its objective values and weight utilization\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate the normalized objective values to determine the focus of improvement\n    max_val1 = np.max([obj[0] for _, obj in archive])\n    max_val2 = np.max([obj[1] for _, obj in archive])\n    norm_val1 = base_val1 / max_val1 if max_val1 > 0 else 0\n    norm_val2 = base_val2 / max_val2 if max_val2 > 0 else 0\n\n    # Step 3: Determine the focus of improvement (the objective that is relatively weaker)\n    focus_obj = 1 if norm_val1 < norm_val2 else 2\n\n    # Step 4: Generate candidate items for flipping based on their potential to improve the focused objective\n    candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Consider removing item i if it doesn't significantly reduce the focused objective\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                if focus_obj == 1:\n                    candidates.append((i, -1, value1_lst[i], value2_lst[i]))\n                else:\n                    candidates.append((i, -1, value2_lst[i], value1_lst[i]))\n        else:\n            # Consider adding item i if it improves the focused objective\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                if focus_obj == 1:\n                    candidates.append((i, 1, value1_lst[i], value2_lst[i]))\n                else:\n                    candidates.append((i, 1, value2_lst[i], value1_lst[i]))\n\n    if not candidates:\n        # Step 5: No feasible flips, perform a random feasible flip\n        feasible_indices = [i for i in range(len(base_solution))\n                          if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                             (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # Step 6: Select the best candidate based on the focused objective\n    best_candidate = None\n    best_score = -np.inf\n    for candidate in candidates:\n        idx, flip, val_focus, val_other = candidate\n        if flip == 1:\n            score = val_focus  # Adding item: maximize the focused objective\n        else:\n            score = -val_focus  # Removing item: minimize the focused objective\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate\n\n    if best_candidate is not None:\n        idx, flip, _, _ = best_candidate\n        new_solution[idx] = 1 if flip == 1 else 0\n\n    # Step 7: Additional perturbation: perform a series of intelligent swaps between objectives\n    if random.random() < 0.3 and len(new_solution) > 1:\n        # Select a subset of items to consider for swapping\n        swap_candidates = np.where(new_solution == 1)[0]\n        if len(swap_candidates) > 1:\n            np.random.shuffle(swap_candidates)\n            for i in range(min(3, len(swap_candidates)-1)):\n                j = i + 1\n                if j >= len(swap_candidates):\n                    break\n                # Swap items if it maintains feasibility\n                if (current_weight - weight_lst[swap_candidates[i]] - weight_lst[swap_candidates[j]] +\n                    weight_lst[swap_candidates[i]] + weight_lst[swap_candidates[j]]) <= capacity:\n                    new_solution[swap_candidates[i]], new_solution[swap_candidates[j]] = \\\n                    new_solution[swap_candidates[j]], new_solution[swap_candidates[i]]\n\n    return new_solution\n\n",
          "score": [
               -0.7765104046817304,
               1.326211005449295
          ]
     },
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the solution with the highest combined objective value\n    combined_values = [obj[0] + obj[1] for _, obj in archive]\n    selected_idx = np.argmax(combined_values)\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Calculate objective-specific improvement factors\n    max_val1 = np.max([obj[0] for _, obj in archive])\n    max_val2 = np.max([obj[1] for _, obj in archive])\n    if max_val1 == 0 or max_val2 == 0:\n        return new_solution  # Avoid division by zero\n\n    # Step 3: Generate candidate solutions through hybrid neighborhood exploration\n    candidates = []\n    for i in range(len(base_solution)):\n        # Value-based selection\n        if base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity:\n            new_val1 = base_val1 + value1_lst[i]\n            new_val2 = base_val2 + value2_lst[i]\n            candidates.append((i, 1, new_val1, new_val2))\n\n        # Weight-aware flipping\n        if base_solution[i] == 1:\n            # Consider removing item i\n            new_weight = current_weight - weight_lst[i]\n            if new_weight >= 0:\n                new_val1 = base_val1 - value1_lst[i]\n                new_val2 = base_val2 - value2_lst[i]\n                candidates.append((i, 0, new_val1, new_val2))\n\n    # Step 4: Evaluate candidates using utility function\n    best_candidate = None\n    best_utility = -np.inf\n    for candidate in candidates:\n        idx, flip, new_val1, new_val2 = candidate\n        # Calculate utility based on improvement factors and diversity\n        improvement1 = (new_val1 - base_val1) / max_val1\n        improvement2 = (new_val2 - base_val2) / max_val2\n        utility = improvement1 + improvement2 + 0.1 * random.random()  # Add small randomness\n        if utility > best_utility:\n            best_utility = utility\n            best_candidate = candidate\n\n    if best_candidate is not None:\n        idx, flip, _, _ = best_candidate\n        new_solution[idx] = flip\n\n    # Step 5: Apply Pareto-front guided perturbations\n    if random.random() < 0.4 and len(new_solution) > 1:\n        # Select two items to swap\n        selected_items = np.where(new_solution == 1)[0]\n        if len(selected_items) >= 2:\n            i, j = random.sample(list(selected_items), 2)\n            # Check feasibility\n            if (current_weight - weight_lst[i] - weight_lst[j] +\n                weight_lst[i] + weight_lst[j]) <= capacity:\n                new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
          "score": [
               -0.9095171262906906,
               4.403090536594391
          ]
     }
]