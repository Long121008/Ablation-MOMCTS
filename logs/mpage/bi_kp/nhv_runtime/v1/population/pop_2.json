[
     {
          "algorithm": "{The proposed algorithm selects a promising solution from the archive using a hybrid approach that combines crowding distance and objective space diversity to prioritize solutions with high potential for improvement. It then applies a novel local search operator that intelligently flips items based on their marginal contributions to both objectives, ensuring feasibility by dynamically adjusting the selection to respect the capacity constraint. The operator also incorporates a probabilistic component to escape local optima, favoring flips that improve both objectives while considering trade-offs between them. The selection process is biased towards solutions with higher crowding distances or those lying on the Pareto front, ensuring a balance between exploration and exploitation.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution from the archive (prioritize solutions with high crowding distance or on the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    selected_solution, selected_objective = archive[selected_idx]\n    base_solution = selected_solution.copy()\n\n    # Step 2: Compute marginal contributions of each item to both objectives\n    marginal_value1 = value1_lst / weight_lst\n    marginal_value2 = value2_lst / weight_lst\n\n    # Step 3: Identify items that can be flipped to improve both objectives or trade-off between them\n    current_weight = np.sum(weight_lst * base_solution)\n    candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Consider removing item i if it doesn't significantly reduce both objectives\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, -1, marginal_value1[i], marginal_value2[i]))\n        else:\n            # Consider adding item i if it improves both objectives or has a good trade-off\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, 1, marginal_value1[i], marginal_value2[i]))\n\n    if not candidates:\n        # No feasible flips, return a random neighbor by flipping a single item\n        feasible_indices = [i for i in range(len(base_solution)) if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                           (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution = base_solution.copy()\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            return new_solution\n        else:\n            return base_solution.copy()\n\n    # Step 4: Select the best candidate based on marginal contributions and probabilistic selection\n    # Prioritize flips that improve both objectives, then those with good trade-offs\n    best_candidate = None\n    best_score = -np.inf\n    for candidate in candidates:\n        idx, flip, m_val1, m_val2 = candidate\n        if flip == 1:\n            score = m_val1 + m_val2  # Adding item: maximize both objectives\n        else:\n            score = -m_val1 - m_val2  # Removing item: minimize both objectives\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate\n\n    if best_candidate is None:\n        return base_solution.copy()\n\n    # Step 5: Apply the selected flip\n    new_solution = base_solution.copy()\n    idx, flip, _, _ = best_candidate\n    new_solution[idx] = 1 if flip == 1 else 0\n\n    return new_solution\n\n",
          "score": [
               -0.9632164304649085,
               7.020322293043137
          ]
     },
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Generate a neighbor solution using a hybrid local search strategy\n    new_solution = base_solution.copy()\n    items = np.arange(len(new_solution))\n\n    # Calculate marginal gains for each item\n    marginal_gain1 = value1_lst - (value1_lst * new_solution)\n    marginal_gain2 = value2_lst - (value2_lst * new_solution)\n    marginal_weights = weight_lst - (weight_lst * new_solution)\n\n    # Rank items by their potential to improve both objectives\n    scores = marginal_gain1 + marginal_gain2\n    sorted_indices = np.argsort(scores)[::-1]\n\n    # Try to flip items in order of highest potential gain\n    for idx in sorted_indices:\n        if new_solution[idx] == 0:\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n        else:\n            new_solution[idx] = 0\n            current_weight -= weight_lst[idx]\n\n    # If no improvement, try a different strategy: flip a random subset\n    if np.array_equal(new_solution, base_solution):\n        np.random.shuffle(items)\n        for idx in items:\n            if new_solution[idx] == 0:\n                if current_weight + weight_lst[idx] <= capacity:\n                    new_solution[idx] = 1\n                    current_weight += weight_lst[idx]\n            else:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n\n    return new_solution\n\n",
          "score": [
               -0.9546836449070784,
               5.297566622495651
          ]
     },
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution (highest crowding distance)\n    def crowding_distance(solutions):\n        n = len(solutions)\n        if n == 0:\n            return [0.0] * n\n        distances = [0.0] * n\n        objectives = [sol[1] for sol in solutions]\n        for m in range(2):  # For each objective\n            sorted_idx = np.argsort([obj[m] for obj in objectives])\n            distances[sorted_idx[0]] = float('inf')\n            distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, n-1):\n                if objectives[sorted_idx[-1]][m] == objectives[sorted_idx[0]][m]:\n                    continue\n                distances[sorted_idx[i]] += (objectives[sorted_idx[i+1]][m] - objectives[sorted_idx[i-1]][m]) / (objectives[sorted_idx[-1]][m] - objectives[sorted_idx[0]][m])\n        return distances\n\n    distances = crowding_distance(archive)\n    selected_idx = np.argmax(distances)\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Hybrid local search operator\n    # Strategy 1: Value-based swap prioritizing high-value items\n    # Strategy 2: Weight-based adjustment ensuring feasibility\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Strategy 1: Value-based swap\n    # Find items not in the solution with high value\n    not_in_solution = np.where(new_solution == 0)[0]\n    if len(not_in_solution) > 0:\n        # Calculate value density for each objective\n        value1_density = value1_lst[not_in_solution] / weight_lst[not_in_solution]\n        value2_density = value2_lst[not_in_solution] / weight_lst[not_in_solution]\n\n        # Combine densities for multi-objective consideration\n        combined_density = value1_density + value2_density\n        best_candidate_idx = np.argmax(combined_density)\n\n        # Check if adding this item keeps the solution feasible\n        candidate_item = not_in_solution[best_candidate_idx]\n        if current_weight + weight_lst[candidate_item] <= capacity:\n            new_solution[candidate_item] = 1\n            current_weight += weight_lst[candidate_item]\n\n    # Strategy 2: Weight-based adjustment if no improvement possible\n    if current_weight < capacity:\n        # Find items in the solution with low value density\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) > 0:\n            # Calculate value density for items in solution\n            value1_density_in = value1_lst[in_solution] / weight_lst[in_solution]\n            value2_density_in = value2_lst[in_solution] / weight_lst[in_solution]\n            combined_density_in = value1_density_in + value2_density_in\n\n            # Sort by density and remove the least valuable items first\n            sorted_indices = np.argsort(combined_density_in)\n            for i in sorted_indices:\n                item_to_remove = in_solution[i]\n                if current_weight - weight_lst[item_to_remove] >= 0:\n                    new_solution[item_to_remove] = 0\n                    current_weight -= weight_lst[item_to_remove]\n                    if current_weight <= capacity:\n                        break\n\n    # Ensure the solution is feasible (shouldn't be needed due to checks above)\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If not feasible, remove items randomly until feasible\n        while np.sum(weight_lst * new_solution) > capacity:\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            item_to_remove = np.random.choice(in_solution)\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.8323389795714071,
               1.3690161108970642
          ]
     },
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating the trade-off between the two objectives using an adaptive weighting scheme that dynamically adjusts based on the current distribution of solutions in the archive. It then applies a novel hybrid local search operator that combines a multi-objective greedy insertion strategy with a probabilistic multi-item perturbation to explore the solution space, while ensuring feasibility by using a capacity-aware knapsack construction heuristic. The operator prioritizes items that offer the highest marginal gain in either objective while allowing controlled exploration of the solution space to balance exploitation and exploration, with the selection of the base solution biased towards those with the highest potential for improvement as estimated by the ratio of the current objective values to the maximum possible values in the archive, and the perturbation intensity adaptively adjusted based on the solution's proximity to the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Adaptive weighting based on archive distribution\n    obj1_vals = np.array([obj[0] for _, obj in archive])\n    obj2_vals = np.array([obj[1] for _, obj in archive])\n    obj1_range = np.max(obj1_vals) - np.min(obj1_vals)\n    obj2_range = np.max(obj2_vals) - np.min(obj2_vals)\n\n    if obj1_range == 0 or obj2_range == 0:\n        weight1, weight2 = 0.5, 0.5\n    else:\n        weight1 = obj2_range / (obj1_range + obj2_range)\n        weight2 = obj1_range / (obj1_range + obj2_range)\n\n    # Select base solution with highest weighted potential\n    max_potential = -1\n    selected_solution = None\n    max_values = (np.max(obj1_vals), np.max(obj2_vals))\n\n    for sol, obj in archive:\n        potential = weight1 * (1 - obj[0] / max_values[0]) + weight2 * (1 - obj[1] / max_values[1])\n        if potential > max_potential:\n            max_potential = potential\n            selected_solution = sol\n\n    base_solution = selected_solution.copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Multi-objective greedy insertion\n    marginal_gain = (weight1 * value1_lst + weight2 * value2_lst) / weight_lst\n    sorted_indices = np.argsort(-marginal_gain)\n\n    for idx in sorted_indices:\n        if base_solution[idx] == 0 and weight_lst[idx] <= remaining_capacity:\n            if np.random.rand() < 0.7:  # Higher probability for better items\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n                current_weight += weight_lst[idx]\n\n    # Probabilistic multi-item perturbation\n    perturbation_intensity = 0.1 + 0.2 * (1 - max_potential)  # Higher intensity for less promising solutions\n    num_items = len(new_solution)\n    num_perturbations = max(1, int(perturbation_intensity * num_items))\n\n    for _ in range(num_perturbations):\n        candidate_indices = np.where(new_solution != base_solution)[0]\n        if len(candidate_indices) > 0:\n            idx = np.random.choice(candidate_indices)\n            if new_solution[idx] == 1:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n            else:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n                    current_weight += weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        included_indices = np.where(new_solution == 1)[0]\n        heaviest_idx = included_indices[np.argmax(weight_lst[included_indices])]\n        new_solution[heaviest_idx] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.8586975261892452,
               4.262470066547394
          ]
     },
     {
          "algorithm": "{The novel heuristic function 'select_neighbor' first identifies the most promising solution in the archive by evaluating both the solution's objective values and its potential for local improvement through a dynamic crowding distance metric that considers both objectives. It then applies a hybrid local search strategy that combines a greedy item swap with a probabilistic item perturbation to generate a neighbor solution. The greedy swap evaluates all possible single-item swaps (additions or removals) to maximize a weighted sum of the two objectives, while the probabilistic perturbation randomly flips a small subset of items to escape local optima. The function ensures feasibility by rejecting any swaps or perturbations that would exceed the capacity, and it intelligently selects the most promising solution for local improvement by prioritizing those with high crowding distance and low dominance.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select the most promising solution (high crowding distance and low dominance)\n    def crowding_distance(solutions):\n        if len(solutions) < 3:\n            return [0.0] * len(solutions)\n        distances = [0.0] * len(solutions)\n        for obj_idx in range(2):\n            sorted_idx = np.argsort([obj[obj_idx] for _, obj in solutions])\n            min_val = solutions[sorted_idx[0]][1][obj_idx]\n            max_val = solutions[sorted_idx[-1]][1][obj_idx]\n            if max_val == min_val:\n                continue\n            distances[sorted_idx[0]] = np.inf\n            distances[sorted_idx[-1]] = np.inf\n            for i in range(1, len(solutions) - 1):\n                distances[sorted_idx[i]] += (solutions[sorted_idx[i+1]][1][obj_idx] - solutions[sorted_idx[i-1]][1][obj_idx]) / (max_val - min_val)\n        return distances\n\n    distances = crowding_distance(archive)\n    selected_idx = np.argmax(distances)\n    base_solution, base_obj = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Apply hybrid local search (greedy swap + probabilistic perturbation)\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Greedy swap: evaluate all possible single-item swaps\n    best_delta = 0\n    best_item = -1\n    best_action = None  # 'add' or 'remove'\n\n    for i in range(n_items):\n        if new_solution[i] == 1:\n            # Evaluate removing item i\n            delta_weight = -weight_lst[i]\n            delta_value1 = -value1_lst[i]\n            delta_value2 = -value2_lst[i]\n            if current_weight + delta_weight <= capacity:\n                # Weighted sum of objectives (can be adjusted)\n                delta = 0.5 * delta_value1 + 0.5 * delta_value2\n                if delta < best_delta:\n                    best_delta = delta\n                    best_item = i\n                    best_action = 'remove'\n        else:\n            # Evaluate adding item i\n            delta_weight = weight_lst[i]\n            delta_value1 = value1_lst[i]\n            delta_value2 = value2_lst[i]\n            if current_weight + delta_weight <= capacity:\n                delta = 0.5 * delta_value1 + 0.5 * delta_value2\n                if delta > best_delta:\n                    best_delta = delta\n                    best_item = i\n                    best_action = 'add'\n\n    if best_item != -1:\n        if best_action == 'add':\n            new_solution[best_item] = 1\n        else:\n            new_solution[best_item] = 0\n\n    # Probabilistic perturbation: flip a small random subset of items\n    perturbation_prob = 0.1\n    for i in range(n_items):\n        if np.random.rand() < perturbation_prob:\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n\n    return new_solution\n\n",
          "score": [
               -0.8891006467033533,
               5.790628999471664
          ]
     },
     {
          "algorithm": "{The heuristic function 'select_neighbor' first identifies promising solutions in the archive by evaluating their potential for local improvement through a novel hybrid local search strategy. It uses a combination of crowding distance and objective-space dominance to prioritize solutions with high diversity and potential for multi-objective optimization. The selected solution undergoes a creative local search operator that dynamically adapts between item swaps, insertions, and removals based on the current solution's objective values and the archive's distribution, ensuring feasibility by always validating weight constraints. The operator explores neighboring solutions by flipping bits of items with high marginal contributions to both objectives, while also considering the impact on the solution's position in the Pareto front. The generated neighbor solution is guaranteed to be feasible and is returned as the new solution.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # Calculate crowding distance for each solution in the archive\n    solutions = [sol for sol, _ in archive]\n    objectives = np.array([obj for _, obj in archive])\n\n    # Normalize objectives for crowding distance calculation\n    min_obj = np.min(objectives, axis=0)\n    max_obj = np.max(objectives, axis=0)\n    normalized_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n\n    # Compute crowding distance\n    crowding_dist = np.zeros(len(archive))\n    for m in range(2):  # For each objective\n        sorted_indices = np.argsort(normalized_obj[:, m])\n        crowding_dist[sorted_indices[0]] = np.inf\n        crowding_dist[sorted_indices[-1]] = np.inf\n        for i in range(1, len(archive) - 1):\n            crowding_dist[sorted_indices[i]] += (normalized_obj[sorted_indices[i+1], m] - normalized_obj[sorted_indices[i-1], m])\n\n    # Select solution with highest crowding distance (most diverse)\n    selected_idx = np.argmax(crowding_dist)\n    base_solution = solutions[selected_idx].copy()\n\n    # Step 2: Generate a neighbor solution using hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Calculate current total weight and values\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Determine which items to consider for modification\n    # We'll consider items that are either in the solution or have high potential\n    candidate_items = []\n    for i in range(n_items):\n        if new_solution[i] == 1:\n            candidate_items.append(i)\n        else:\n            # Only consider items that can fit when added\n            if current_weight + weight_lst[i] <= capacity:\n                # Calculate marginal contribution for both objectives\n                marginal1 = value1_lst[i] / weight_lst[i] if weight_lst[i] > 0 else 0\n                marginal2 = value2_lst[i] / weight_lst[i] if weight_lst[i] > 0 else 0\n                # Add items with high marginal contribution to either objective\n                if marginal1 > 0.5 * np.max(value1_lst / weight_lst) or marginal2 > 0.5 * np.max(value2_lst / weight_lst):\n                    candidate_items.append(i)\n\n    if not candidate_items:\n        # If no candidates, randomly select an item to flip\n        candidate_items = list(range(n_items))\n\n    # Randomly select an item to modify\n    item_to_modify = np.random.choice(candidate_items)\n\n    # Perform modification based on current solution state\n    if new_solution[item_to_modify] == 1:\n        # If item is in solution, consider removing it\n        new_solution[item_to_modify] = 0\n    else:\n        # If item is not in solution, consider adding it\n        new_solution[item_to_modify] = 1\n\n    # Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # If adding causes overflow, try to remove another item\n        # Find items to remove that would make the solution feasible\n        included_items = np.where(new_solution == 1)[0]\n        for i in included_items:\n            if total_weight - weight_lst[i] <= capacity:\n                new_solution[i] = 0\n                total_weight -= weight_lst[i]\n                break\n\n    # If still not feasible, revert to base solution\n    if np.sum(weight_lst * new_solution) > capacity:\n        new_solution = base_solution.copy()\n\n    return new_solution\n\n",
          "score": [
               -0.7887797633141523,
               3.8655914068222046
          ]
     },
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a base solution with high potential for improvement\n    # Calculate dominance counts and objective densities\n    dominance_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        sol_i, (val1_i, val2_i) = archive[i]\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            sol_j, (val1_j, val2_j) = archive[j]\n            if (val1_i >= val1_j and val2_i >= val2_j) and (val1_i > val1_j or val2_i > val2_j):\n                dominance_counts[i] += 1\n\n    # Select solution with lowest dominance count (most under-explored)\n    min_dominance_idx = np.argmin(dominance_counts)\n    base_solution = archive[min_dominance_idx][0].copy()\n    base_val1, base_val2 = archive[min_dominance_idx][1]\n\n    # Step 2: Generate a neighbor using adaptive objective-driven exploration\n    new_solution = base_solution.copy()\n    current_weight = np.sum(new_solution * weight_lst)\n    num_items = len(weight_lst)\n\n    # Calculate objective gradients\n    total_val1 = np.sum(value1_lst)\n    total_val2 = np.sum(value2_lst)\n    grad1 = value1_lst / (total_val1 + 1e-8)\n    grad2 = value2_lst / (total_val2 + 1e-8)\n    combined_grad = grad1 + grad2\n\n    # Dynamic perturbation scaling based on objective values and weight\n    perturbation_scale = 0.5 + 0.5 * (base_val1 + base_val2) / (total_val1 + total_val2 + 1e-8)\n    perturbation_scale *= (1 - current_weight / capacity)\n\n    # Apply objective-aware perturbations\n    for i in range(num_items):\n        if random.random() < perturbation_scale:\n            if new_solution[i] == 1:\n                new_weight = current_weight - weight_lst[i]\n                delta_val1 = -value1_lst[i]\n                delta_val2 = -value2_lst[i]\n            else:\n                new_weight = current_weight + weight_lst[i]\n                delta_val1 = value1_lst[i]\n                delta_val2 = value2_lst[i]\n\n            # Apply perturbation with probability based on combined gradient\n            if new_weight <= capacity and random.random() < combined_grad[i]:\n                new_solution[i] = 1 - new_solution[i]\n                current_weight = new_weight\n\n    # Additional gradient-guided exploration\n    if random.random() < 0.3:  # 30% chance for gradient-guided move\n        # Find items with high gradient that can be added\n        candidate_items = [i for i in range(num_items) if new_solution[i] == 0 and\n                          (current_weight + weight_lst[i]) <= capacity]\n\n        if candidate_items:\n            # Select item with highest combined gradient\n            best_item = max(candidate_items, key=lambda x: combined_grad[x])\n            new_solution[best_item] = 1\n\n    # Ensure feasibility\n    while np.sum(new_solution * weight_lst) > capacity:\n        # Remove item with lowest normalized marginal contribution\n        marginal_contributions = []\n        for i in range(num_items):\n            if new_solution[i] == 1:\n                temp_sol = new_solution.copy()\n                temp_sol[i] = 0\n                val1 = np.sum(temp_sol * value1_lst)\n                val2 = np.sum(temp_sol * value2_lst)\n                marginal_contributions.append((val1 + val2) / (weight_lst[i] + 1e-8))\n            else:\n                marginal_contributions.append(float('inf'))\n\n        worst_item = np.argmin(marginal_contributions)\n        new_solution[worst_item] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.7697751228333782,
               2.57902592420578
          ]
     },
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Select a promising solution based on a combination of randomness and objective-based prioritization\n    selected_idx = np.random.choice(len(archive))\n    base_solution, _ = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Identify items that can be flipped (either added or removed)\n    items_to_consider = np.where(new_solution == 1)[0]\n    if len(items_to_consider) == 0:\n        items_to_consider = np.where(new_solution == 0)[0]\n\n    # Calculate marginal contributions for each item\n    marginal_value1 = value1_lst[items_to_consider] / weight_lst[items_to_consider]\n    marginal_value2 = value2_lst[items_to_consider] / weight_lst[items_to_consider]\n    marginal_scores = marginal_value1 + marginal_value2  # Combined score for prioritization\n\n    # Sort items by marginal score (descending)\n    sorted_indices = np.argsort(marginal_scores)[::-1]\n    items_to_consider = items_to_consider[sorted_indices]\n\n    # Try to flip items in order of priority, ensuring feasibility\n    for item in items_to_consider:\n        if new_solution[item] == 1:\n            # Try to remove the item\n            if current_weight - weight_lst[item] >= 0:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n        else:\n            # Try to add the item\n            if current_weight + weight_lst[item] <= capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    return new_solution\n\n",
          "score": [
               -0.8846790501092237,
               6.0916441679000854
          ]
     },
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement based on its objective values and weight utilization\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Calculate the normalized objective values to determine the focus of improvement\n    max_val1 = np.max([obj[0] for _, obj in archive])\n    max_val2 = np.max([obj[1] for _, obj in archive])\n    norm_val1 = base_val1 / max_val1 if max_val1 > 0 else 0\n    norm_val2 = base_val2 / max_val2 if max_val2 > 0 else 0\n\n    # Determine the focus of improvement: prioritize the objective that is relatively weaker\n    focus_obj = 1 if norm_val1 < norm_val2 else 2\n\n    # Generate candidate items for flipping based on their potential to improve the focused objective\n    candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Consider removing item i if it doesn't significantly reduce the focused objective\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                if focus_obj == 1:\n                    candidates.append((i, -1, value1_lst[i], value2_lst[i]))\n                else:\n                    candidates.append((i, -1, value2_lst[i], value1_lst[i]))\n        else:\n            # Consider adding item i if it improves the focused objective\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                if focus_obj == 1:\n                    candidates.append((i, 1, value1_lst[i], value2_lst[i]))\n                else:\n                    candidates.append((i, 1, value2_lst[i], value1_lst[i]))\n\n    if not candidates:\n        # No feasible flips, perform a random feasible flip\n        feasible_indices = [i for i in range(len(base_solution))\n                          if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                             (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # Select the best candidate based on the focused objective\n    best_candidate = None\n    best_score = -np.inf\n    for candidate in candidates:\n        idx, flip, val_focus, val_other = candidate\n        if flip == 1:\n            score = val_focus  # Adding item: maximize the focused objective\n        else:\n            score = -val_focus  # Removing item: minimize the focused objective\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate\n\n    if best_candidate is not None:\n        idx, flip, _, _ = best_candidate\n        new_solution[idx] = 1 if flip == 1 else 0\n\n    # Additional perturbation: randomly swap items between objectives with a small probability\n    if random.random() < 0.1 and len(new_solution) > 1:\n        swap_indices = np.random.choice(len(new_solution), 2, replace=False)\n        i, j = swap_indices\n        if (new_solution[i] == 1 and new_solution[j] == 1 and\n            (current_weight - weight_lst[i] - weight_lst[j] + weight_lst[i] + weight_lst[j]) <= capacity):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n\n    return new_solution\n\n",
          "score": [
               -0.7575370121711582,
               2.624890059232712
          ]
     },
     {
          "algorithm": "{The heuristic function 'select_neighbor' employs a novel \"diversity-driven dynamic subset replacement\" strategy that combines Pareto-optimal region exploration with a probabilistic item set replacement mechanism. First, it identifies the least crowded region in the objective space by analyzing the archive's diversity, then systematically selects a subset of items to replace with new items from a candidate pool, prioritizing those that improve both objectives while maintaining feasibility. The replacement mechanism dynamically adjusts the subset size and selection probability based on the current solution's objective values and the archive's non-dominated front, using a weighted randomness that considers both objective improvements and weight constraints. The function then performs a feasibility check and repair step to ensure the total weight does not exceed capacity, followed by an optional intensification phase that further optimizes the solution by selectively flipping items that show marginal improvements in either objective. The process repeats for a fixed number of iterations or until no further improvements are found, guaranteeing feasibility at every step.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify the least crowded region in the objective space\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(2):\n        sorted_idx = np.argsort(objectives[:, i])\n        crowding_distances[sorted_idx[0]] = np.inf\n        crowding_distances[sorted_idx[-1]] = np.inf\n        for j in range(1, len(archive) - 1):\n            crowding_distances[sorted_idx[j]] += (objectives[sorted_idx[j+1], i] - objectives[sorted_idx[j-1], i])\n\n    least_crowded_idx = np.argmin(crowding_distances)\n    base_solution = archive[least_crowded_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Dynamic subset replacement\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Identify items to potentially replace\n    items_in_solution = np.where(base_solution == 1)[0]\n    items_not_in_solution = np.where(base_solution == 0)[0]\n\n    # Calculate subset size based on remaining capacity and diversity\n    subset_size = min(len(items_in_solution), max(1, int(0.3 * len(items_in_solution))))\n\n    # Select items to replace\n    if subset_size > 0 and len(items_in_solution) > 0:\n        replace_indices = np.random.choice(items_in_solution, size=subset_size, replace=False)\n        new_solution[replace_indices] = 0\n\n        # Add new items from candidate pool\n        candidate_items = items_not_in_solution[weight_lst[items_not_in_solution] <= remaining_capacity]\n        if len(candidate_items) > 0:\n            # Prioritize items that improve both objectives\n            value_density1 = value1_lst[candidate_items] / weight_lst[candidate_items]\n            value_density2 = value2_lst[candidate_items] / weight_lst[candidate_items]\n\n            # Weighted random selection\n            weights = value_density1 + value_density2\n            if np.sum(weights) > 0:\n                weights = weights / np.sum(weights)\n                selected_items = np.random.choice(candidate_items, size=min(subset_size, len(candidate_items)), p=weights, replace=False)\n                new_solution[selected_items] = 1\n\n    # Step 3: Feasibility check and repair\n    current_weight = np.sum(weight_lst * new_solution)\n    while current_weight > capacity:\n        selected_items = np.where(new_solution == 1)[0]\n        if len(selected_items) == 0:\n            break\n        remove_idx = np.random.choice(selected_items)\n        new_solution[remove_idx] = 0\n        current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 4: Intensification phase (optional)\n    if np.random.rand() < 0.3:\n        for i in range(len(new_solution)):\n            if new_solution[i] == 1:\n                # Try removing item\n                temp_weight = current_weight - weight_lst[i]\n                if temp_weight >= 0:\n                    new_solution[i] = 0\n                    current_weight = temp_weight\n            else:\n                # Try adding item\n                temp_weight = current_weight + weight_lst[i]\n                if temp_weight <= capacity:\n                    new_solution[i] = 1\n                    current_weight = temp_weight\n\n    return new_solution\n\n",
          "score": [
               -0.3858813475857329,
               2.8622884452342987
          ]
     }
]