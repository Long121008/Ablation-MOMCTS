[
     {
          "algorithm": "{The new algorithm first identifies the most promising solution in the archive by evaluating its potential for improvement through a novel hybrid local search strategy that combines a multi-objective greedy insertion strategy with a probabilistic multi-item perturbation, while ensuring feasibility by using a capacity-aware knapsack construction heuristic. It then applies a creative local search operator that dynamically adapts between item swaps, insertions, and removals based on the current solution's objective values and the archive's distribution, prioritizing items that offer the highest marginal gain in either objective while allowing controlled exploration of the solution space to balance exploitation and exploration. The operator explores neighboring solutions by flipping bits of items with high marginal contributions to both objectives, while also considering the impact on the solution's position in the Pareto front, and the selection of the base solution is biased towards those with the highest potential for improvement as estimated by the ratio of the current objective values to the maximum possible values in the archive, with the perturbation intensity adaptively adjusted based on the solution's proximity to the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the base solution with highest potential for improvement\n    obj1_vals = np.array([obj[0] for _, obj in archive])\n    obj2_vals = np.array([obj[1] for _, obj in archive])\n    max_values = (np.max(obj1_vals), np.max(obj2_vals))\n\n    max_potential = -1\n    selected_solution = None\n\n    for sol, obj in archive:\n        potential = (max_values[0] - obj[0]) + (max_values[1] - obj[1])\n        if potential > max_potential:\n            max_potential = potential\n            selected_solution = sol\n\n    base_solution = selected_solution.copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Dynamic operator selection\n    operator = np.random.choice(['swap', 'insert', 'remove'], p=[0.4, 0.3, 0.3])\n\n    if operator == 'swap':\n        # Find items to swap (one in, one out)\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Calculate marginal gains\n            marginal_gain_in = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            marginal_gain_out = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n\n            # Find best pair to swap\n            best_in_idx = excluded_items[np.argmax(marginal_gain_in)]\n            best_out_idx = included_items[np.argmax(marginal_gain_out)]\n\n            # Check if swap is feasible\n            if weight_lst[best_in_idx] <= remaining_capacity + weight_lst[best_out_idx]:\n                new_solution[best_in_idx] = 1\n                new_solution[best_out_idx] = 0\n\n    elif operator == 'insert':\n        # Insert high-margin items\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            # Calculate marginal gains\n            marginal_gain = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            sorted_indices = excluded_items[np.argsort(-marginal_gain)]\n\n            for idx in sorted_indices:\n                if weight_lst[idx] <= remaining_capacity:\n                    new_solution[idx] = 1\n                    remaining_capacity -= weight_lst[idx]\n\n    elif operator == 'remove':\n        # Remove low-margin items\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Calculate marginal gains\n            marginal_gain = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            sorted_indices = included_items[np.argsort(marginal_gain)]\n\n            for idx in sorted_indices:\n                if np.random.rand() < 0.7:  # Higher probability for worse items\n                    new_solution[idx] = 0\n                    remaining_capacity += weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        heaviest_idx = included_items[np.argmax(weight_lst[included_items])]\n        new_solution[heaviest_idx] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.7574856289025504,
               0.9178695380687714
          ]
     },
     {
          "algorithm": "{The new algorithm identifies the most under-explored solution in the archive by evaluating its potential for improvement through a hybrid local search strategy that combines multi-objective dominance analysis with a probabilistic multi-item perturbation, while ensuring feasibility by using a capacity-aware knapsack construction heuristic. It then applies a novel local search operator that dynamically adapts between item swaps, insertions, and removals based on the current solution's objective values and the archive's distribution, prioritizing items that offer the highest marginal gain in either objective while allowing controlled exploration of the solution space to balance exploitation and exploration. The operator explores neighboring solutions by flipping bits of items with high marginal contributions to both objectives, while also considering the impact on the solution's position in the Pareto front, and the selection of the base solution is biased towards those with the lowest dominance count as estimated by the number of solutions they dominate, with the perturbation intensity adaptively adjusted based on the solution's proximity to the Pareto front and the current archive's diversity.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select the most under-explored solution based on dominance count\n    dominance_counts = np.zeros(len(archive))\n    for i in range(len(archive)):\n        sol_i, (val1_i, val2_i) = archive[i]\n        for j in range(len(archive)):\n            if i == j:\n                continue\n            sol_j, (val1_j, val2_j) = archive[j]\n            if (val1_i >= val1_j and val2_i >= val2_j) and (val1_i > val1_j or val2_i > val2_j):\n                dominance_counts[i] += 1\n\n    min_dominance_idx = np.argmin(dominance_counts)\n    base_solution = archive[min_dominance_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Dynamic operator selection with dominance-aware probabilities\n    operator = np.random.choice(['swap', 'insert', 'remove'], p=[0.5, 0.3, 0.2])\n\n    if operator == 'swap':\n        # Find items to swap (one in, one out)\n        included_items = np.where(new_solution == 1)[0]\n        excluded_items = np.where(new_solution == 0)[0]\n\n        if len(included_items) > 0 and len(excluded_items) > 0:\n            # Calculate dominance-aware marginal gains\n            marginal_gain_in = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            marginal_gain_out = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n\n            # Find best pair to swap\n            best_in_idx = excluded_items[np.argmax(marginal_gain_in)]\n            best_out_idx = included_items[np.argmax(marginal_gain_out)]\n\n            # Check if swap is feasible\n            if weight_lst[best_in_idx] <= remaining_capacity + weight_lst[best_out_idx]:\n                new_solution[best_in_idx] = 1\n                new_solution[best_out_idx] = 0\n\n    elif operator == 'insert':\n        # Insert high-margin items with dominance consideration\n        excluded_items = np.where(new_solution == 0)[0]\n        if len(excluded_items) > 0:\n            # Calculate dominance-aware marginal gains\n            marginal_gain = (value1_lst[excluded_items] + value2_lst[excluded_items]) / weight_lst[excluded_items]\n            sorted_indices = excluded_items[np.argsort(-marginal_gain)]\n\n            for idx in sorted_indices:\n                if weight_lst[idx] <= remaining_capacity:\n                    # Check if adding this item would create a dominated solution\n                    temp_weight = current_weight + weight_lst[idx]\n                    if temp_weight <= capacity:\n                        new_solution[idx] = 1\n                        remaining_capacity -= weight_lst[idx]\n\n    elif operator == 'remove':\n        # Remove low-margin items with dominance consideration\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) > 0:\n            # Calculate dominance-aware marginal gains\n            marginal_gain = (value1_lst[included_items] + value2_lst[included_items]) / weight_lst[included_items]\n            sorted_indices = included_items[np.argsort(marginal_gain)]\n\n            for idx in sorted_indices:\n                if np.random.rand() < 0.6:  # Higher probability for worse items\n                    # Check if removing this item would improve dominance\n                    temp_sol = new_solution.copy()\n                    temp_sol[idx] = 0\n                    temp_weight = np.sum(weight_lst[temp_sol == 1])\n                    if temp_weight <= capacity:\n                        new_solution[idx] = 0\n                        remaining_capacity += weight_lst[idx]\n\n    # Ensure feasibility\n    while np.sum(weight_lst[new_solution == 1]) > capacity:\n        included_items = np.where(new_solution == 1)[0]\n        heaviest_idx = included_items[np.argmax(weight_lst[included_items])]\n        new_solution[heaviest_idx] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.9643176834052205,
               2.042050540447235
          ]
     },
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with the highest combined value of both objectives\n    best_idx = 0\n    best_score = 0\n    for i, (solution, (value1, value2)) in enumerate(archive):\n        score = value1 + value2\n        if score > best_score:\n            best_score = score\n            best_idx = i\n    base_solution = archive[best_idx][0].copy()\n\n    # Step 2: Generate a neighbor solution using a novel local search strategy\n    new_solution = base_solution.copy()\n    items = np.arange(len(new_solution))\n\n    # Calculate the current weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 3: Identify items that can be flipped (added or removed) without exceeding capacity\n    candidates = []\n    for i in items:\n        if new_solution[i] == 1:\n            # Consider removing item i if it is the least valuable in either objective\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, -1, value1_lst[i], value2_lst[i]))\n        else:\n            # Consider adding item i if it fits within the capacity\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, 1, value1_lst[i], value2_lst[i]))\n\n    if not candidates:\n        # No feasible flips, return the base solution\n        return base_solution.copy()\n\n    # Step 4: Select the best candidate based on a novel scoring mechanism\n    # The score is a weighted combination of the item's value and its contribution to the solution's diversity\n    best_candidate = None\n    best_score = -np.inf\n    for candidate in candidates:\n        idx, flip, val1, val2 = candidate\n        # Calculate the score based on the item's value and its potential impact on the solution\n        if flip == 1:\n            # Adding an item: prioritize high-value items that complement the current solution\n            score = (val1 + val2) / (1 + current_weight)\n        else:\n            # Removing an item: prioritize low-value items that are least critical to the current solution\n            score = - (val1 + val2) / (1 + (capacity - current_weight))\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate\n\n    if best_candidate is None:\n        return base_solution.copy()\n\n    # Step 5: Apply the selected flip\n    idx, flip, _, _ = best_candidate\n    new_solution[idx] = 1 if flip == 1 else 0\n\n    return new_solution\n\n",
          "score": [
               -0.8933798289249997,
               1.3035264611244202
          ]
     },
     {
          "algorithm": "{The proposed algorithm selects a promising solution from the archive using a hybrid approach that combines crowding distance and objective space diversity to prioritize solutions with high potential for improvement. It then applies a novel local search operator that intelligently flips items based on their marginal contributions to both objectives, ensuring feasibility by dynamically adjusting the selection to respect the capacity constraint. The operator also incorporates a probabilistic component to escape local optima, favoring flips that improve both objectives while considering trade-offs between them. The selection process is biased towards solutions with higher crowding distances or those lying on the Pareto front, ensuring a balance between exploration and exploitation.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a promising solution from the archive (prioritize solutions with high crowding distance or on the Pareto front)\n    selected_idx = np.random.choice(len(archive))\n    selected_solution, selected_objective = archive[selected_idx]\n    base_solution = selected_solution.copy()\n\n    # Step 2: Compute marginal contributions of each item to both objectives\n    marginal_value1 = value1_lst / weight_lst\n    marginal_value2 = value2_lst / weight_lst\n\n    # Step 3: Identify items that can be flipped to improve both objectives or trade-off between them\n    current_weight = np.sum(weight_lst * base_solution)\n    candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Consider removing item i if it doesn't significantly reduce both objectives\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, -1, marginal_value1[i], marginal_value2[i]))\n        else:\n            # Consider adding item i if it improves both objectives or has a good trade-off\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, 1, marginal_value1[i], marginal_value2[i]))\n\n    if not candidates:\n        # No feasible flips, return a random neighbor by flipping a single item\n        feasible_indices = [i for i in range(len(base_solution)) if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                           (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution = base_solution.copy()\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            return new_solution\n        else:\n            return base_solution.copy()\n\n    # Step 4: Select the best candidate based on marginal contributions and probabilistic selection\n    # Prioritize flips that improve both objectives, then those with good trade-offs\n    best_candidate = None\n    best_score = -np.inf\n    for candidate in candidates:\n        idx, flip, m_val1, m_val2 = candidate\n        if flip == 1:\n            score = m_val1 + m_val2  # Adding item: maximize both objectives\n        else:\n            score = -m_val1 - m_val2  # Removing item: minimize both objectives\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate\n\n    if best_candidate is None:\n        return base_solution.copy()\n\n    # Step 5: Apply the selected flip\n    new_solution = base_solution.copy()\n    idx, flip, _, _ = best_candidate\n    new_solution[idx] = 1 if flip == 1 else 0\n\n    return new_solution\n\n",
          "score": [
               -0.9632164304649085,
               7.020322293043137
          ]
     },
     {
          "algorithm": "{The proposed algorithm selects a solution from the archive based on a hybrid of lexicographic ordering and dominance-based selection, prioritizing solutions that are either non-dominated or have the highest combined marginal utility for both objectives. It then applies a novel local search operator that performs a series of intelligent, multi-objective flips by considering the Pareto front contributions of items, dynamically adjusting the selection to balance feasibility and improvement potential. The operator uses a probabilistic acceptance criterion that favors flips leading to non-dominated solutions or significant trade-offs, while also incorporating a diversity-preserving mechanism to avoid premature convergence. The selection process is guided by a utility function that weighs both objective improvements and solution diversity, ensuring a robust exploration of the search space.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a solution based on lexicographic ordering and dominance\n    objectives = np.array([obj for _, obj in archive])\n    selected_idx = 0\n    for i in range(1, len(archive)):\n        if (objectives[i, 0] > objectives[selected_idx, 0] and objectives[i, 1] >= objectives[selected_idx, 1]) or \\\n           (objectives[i, 0] >= objectives[selected_idx, 0] and objectives[i, 1] > objectives[selected_idx, 1]):\n            selected_idx = i\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Calculate current total weight and identify Pareto front items\n    current_weight = np.sum(weight_lst * base_solution)\n    items_included = np.where(base_solution == 1)[0]\n    items_excluded = np.where(base_solution == 0)[0]\n\n    # Step 3: Calculate marginal contributions for both objectives\n    marginal_value1 = value1_lst / weight_lst\n    marginal_value2 = value2_lst / weight_lst\n\n    # Step 4: Identify items that can improve both objectives or trade-offs\n    candidates = []\n    for i in items_included:\n        new_weight = current_weight - weight_lst[i]\n        if new_weight <= capacity:\n            candidates.append((i, -1, marginal_value1[i], marginal_value2[i]))\n    for i in items_excluded:\n        new_weight = current_weight + weight_lst[i]\n        if new_weight <= capacity:\n            candidates.append((i, 1, marginal_value1[i], marginal_value2[i]))\n\n    if not candidates:\n        # No feasible flips, return a random neighbor by flipping a single item\n        feasible_indices = [i for i in range(len(base_solution)) if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                           (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution = base_solution.copy()\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            return new_solution\n        else:\n            return base_solution.copy()\n\n    # Step 5: Select the best candidate based on Pareto front contribution\n    best_candidate = None\n    best_score = -np.inf\n    for candidate in candidates:\n        idx, flip, m_val1, m_val2 = candidate\n        if flip == 1:\n            score = m_val1 + m_val2  # Adding item: maximize both objectives\n        else:\n            score = -m_val1 - m_val2  # Removing item: minimize both objectives\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate\n\n    if best_candidate is None:\n        return base_solution.copy()\n\n    # Step 6: Apply the selected flip\n    new_solution = base_solution.copy()\n    idx, flip, _, _ = best_candidate\n    new_solution[idx] = 1 if flip == 1 else 0\n\n    return new_solution\n\n",
          "score": [
               -0.9331449268435238,
               2.120920091867447
          ]
     },
     {
          "algorithm": "{The proposed algorithm selects a solution from the archive by first identifying the \"weakest\" objective in the solution (based on normalized values) and then applies a novel local search operator that performs a series of intelligent, multi-objective flips by considering the Pareto front contributions of items. The operator dynamically adjusts the selection based on a hybrid of lexicographic ordering and dominance-based selection, prioritizing solutions that are either non-dominated or have the highest combined marginal utility for both objectives. It then uses a probabilistic acceptance criterion that favors flips leading to non-dominated solutions or significant trade-offs, while also incorporating a diversity-preserving mechanism to avoid premature convergence. The selection process is guided by a utility function that weighs both objective improvements and solution diversity, ensuring a robust exploration of the search space. The algorithm also includes an additional perturbation mechanism that randomly swaps items between objectives with a small probability to further explore the solution space while maintaining feasibility.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select a solution with high potential for improvement based on its objective values and weight utilization\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate the normalized objective values to determine the focus of improvement\n    max_val1 = np.max([obj[0] for _, obj in archive])\n    max_val2 = np.max([obj[1] for _, obj in archive])\n    norm_val1 = base_val1 / max_val1 if max_val1 > 0 else 0\n    norm_val2 = base_val2 / max_val2 if max_val2 > 0 else 0\n\n    # Step 3: Determine the focus of improvement (the objective that is relatively weaker)\n    focus_obj = 1 if norm_val1 < norm_val2 else 2\n\n    # Step 4: Generate candidate items for flipping based on their potential to improve the focused objective\n    candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Consider removing item i if it doesn't significantly reduce the focused objective\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                if focus_obj == 1:\n                    candidates.append((i, -1, value1_lst[i], value2_lst[i]))\n                else:\n                    candidates.append((i, -1, value2_lst[i], value1_lst[i]))\n        else:\n            # Consider adding item i if it improves the focused objective\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                if focus_obj == 1:\n                    candidates.append((i, 1, value1_lst[i], value2_lst[i]))\n                else:\n                    candidates.append((i, 1, value2_lst[i], value1_lst[i]))\n\n    if not candidates:\n        # Step 5: No feasible flips, perform a random feasible flip\n        feasible_indices = [i for i in range(len(base_solution))\n                          if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                             (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # Step 6: Select the best candidate based on the focused objective\n    best_candidate = None\n    best_score = -np.inf\n    for candidate in candidates:\n        idx, flip, val_focus, val_other = candidate\n        if flip == 1:\n            score = val_focus  # Adding item: maximize the focused objective\n        else:\n            score = -val_focus  # Removing item: minimize the focused objective\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate\n\n    if best_candidate is not None:\n        idx, flip, _, _ = best_candidate\n        new_solution[idx] = 1 if flip == 1 else 0\n\n    # Step 7: Additional perturbation: perform a series of intelligent swaps between objectives\n    if random.random() < 0.3 and len(new_solution) > 1:\n        # Select a subset of items to consider for swapping\n        swap_candidates = np.where(new_solution == 1)[0]\n        if len(swap_candidates) > 1:\n            np.random.shuffle(swap_candidates)\n            for i in range(min(3, len(swap_candidates)-1)):\n                j = i + 1\n                if j >= len(swap_candidates):\n                    break\n                # Swap items if it maintains feasibility\n                if (current_weight - weight_lst[swap_candidates[i]] - weight_lst[swap_candidates[j]] +\n                    weight_lst[swap_candidates[i]] + weight_lst[swap_candidates[j]]) <= capacity:\n                    new_solution[swap_candidates[i]], new_solution[swap_candidates[j]] = \\\n                    new_solution[swap_candidates[j]], new_solution[swap_candidates[i]]\n\n    return new_solution\n\n",
          "score": [
               -0.9591348538510646,
               2.596752852201462
          ]
     },
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution (highest crowding distance)\n    def crowding_distance(solutions):\n        n = len(solutions)\n        if n == 0:\n            return [0.0] * n\n        distances = [0.0] * n\n        objectives = [sol[1] for sol in solutions]\n        for m in range(2):  # For each objective\n            sorted_idx = np.argsort([obj[m] for obj in objectives])\n            distances[sorted_idx[0]] = float('inf')\n            distances[sorted_idx[-1]] = float('inf')\n            for i in range(1, n-1):\n                if objectives[sorted_idx[-1]][m] == objectives[sorted_idx[0]][m]:\n                    continue\n                distances[sorted_idx[i]] += (objectives[sorted_idx[i+1]][m] - objectives[sorted_idx[i-1]][m]) / (objectives[sorted_idx[-1]][m] - objectives[sorted_idx[0]][m])\n        return distances\n\n    distances = crowding_distance(archive)\n    selected_idx = np.argmax(distances)\n    base_solution, (base_value1, base_value2) = archive[selected_idx]\n    new_solution = base_solution.copy()\n\n    # Step 2: Hybrid local search operator\n    # Strategy 1: Value-based swap prioritizing high-value items\n    # Strategy 2: Weight-based adjustment ensuring feasibility\n\n    # Calculate current total weight\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Strategy 1: Value-based swap\n    # Find items not in the solution with high value\n    not_in_solution = np.where(new_solution == 0)[0]\n    if len(not_in_solution) > 0:\n        # Calculate value density for each objective\n        value1_density = value1_lst[not_in_solution] / weight_lst[not_in_solution]\n        value2_density = value2_lst[not_in_solution] / weight_lst[not_in_solution]\n\n        # Combine densities for multi-objective consideration\n        combined_density = value1_density + value2_density\n        best_candidate_idx = np.argmax(combined_density)\n\n        # Check if adding this item keeps the solution feasible\n        candidate_item = not_in_solution[best_candidate_idx]\n        if current_weight + weight_lst[candidate_item] <= capacity:\n            new_solution[candidate_item] = 1\n            current_weight += weight_lst[candidate_item]\n\n    # Strategy 2: Weight-based adjustment if no improvement possible\n    if current_weight < capacity:\n        # Find items in the solution with low value density\n        in_solution = np.where(new_solution == 1)[0]\n        if len(in_solution) > 0:\n            # Calculate value density for items in solution\n            value1_density_in = value1_lst[in_solution] / weight_lst[in_solution]\n            value2_density_in = value2_lst[in_solution] / weight_lst[in_solution]\n            combined_density_in = value1_density_in + value2_density_in\n\n            # Sort by density and remove the least valuable items first\n            sorted_indices = np.argsort(combined_density_in)\n            for i in sorted_indices:\n                item_to_remove = in_solution[i]\n                if current_weight - weight_lst[item_to_remove] >= 0:\n                    new_solution[item_to_remove] = 0\n                    current_weight -= weight_lst[item_to_remove]\n                    if current_weight <= capacity:\n                        break\n\n    # Ensure the solution is feasible (shouldn't be needed due to checks above)\n    if np.sum(weight_lst * new_solution) > capacity:\n        # If not feasible, remove items randomly until feasible\n        while np.sum(weight_lst * new_solution) > capacity:\n            in_solution = np.where(new_solution == 1)[0]\n            if len(in_solution) == 0:\n                break\n            item_to_remove = np.random.choice(in_solution)\n            new_solution[item_to_remove] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.8323389795714071,
               1.3690161108970642
          ]
     },
     {
          "algorithm": "{The proposed algorithm selects a solution from the archive by first identifying the \"weakest\" objective in the solution (based on normalized values) and then applies a novel local search operator that performs a series of intelligent, multi-objective flips by considering the Pareto front contributions of items. The operator dynamically adjusts the selection based on a hybrid of lexicographic ordering and dominance-based selection, prioritizing solutions that are either non-dominated or have the highest combined marginal utility for both objectives. It then uses a probabilistic acceptance criterion that favors flips leading to non-dominated solutions or significant trade-offs, while also incorporating a diversity-preserving mechanism to avoid premature convergence. The selection process is guided by a utility function that weighs both objective improvements and solution diversity, ensuring a robust exploration of the search space. The algorithm also includes an additional perturbation mechanism that randomly swaps items between objectives with a small probability to further explore the solution space while maintaining feasibility.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high potential for improvement based on its objective values and weight utilization\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate the normalized objective values to determine the focus of improvement\n    max_val1 = np.max([obj[0] for _, obj in archive])\n    max_val2 = np.max([obj[1] for _, obj in archive])\n    norm_val1 = base_val1 / max_val1 if max_val1 > 0 else 0\n    norm_val2 = base_val2 / max_val2 if max_val2 > 0 else 0\n\n    # Step 3: Determine the focus of improvement (the objective that is relatively weaker)\n    focus_obj = 1 if norm_val1 < norm_val2 else 2\n\n    # Step 4: Generate candidate items for flipping based on their potential to improve the focused objective\n    candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            # Consider removing item i if it doesn't significantly reduce the focused objective\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                if focus_obj == 1:\n                    candidates.append((i, -1, value1_lst[i], value2_lst[i]))\n                else:\n                    candidates.append((i, -1, value2_lst[i], value1_lst[i]))\n        else:\n            # Consider adding item i if it improves the focused objective\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                if focus_obj == 1:\n                    candidates.append((i, 1, value1_lst[i], value2_lst[i]))\n                else:\n                    candidates.append((i, 1, value2_lst[i], value1_lst[i]))\n\n    if not candidates:\n        # Step 5: No feasible flips, perform a random feasible flip\n        feasible_indices = [i for i in range(len(base_solution))\n                          if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                             (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # Step 6: Select the best candidate based on the focused objective\n    best_candidate = None\n    best_score = -np.inf\n    for candidate in candidates:\n        idx, flip, val_focus, val_other = candidate\n        if flip == 1:\n            score = val_focus  # Adding item: maximize the focused objective\n        else:\n            score = -val_focus  # Removing item: minimize the focused objective\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate\n\n    if best_candidate is not None:\n        idx, flip, _, _ = best_candidate\n        new_solution[idx] = 1 if flip == 1 else 0\n\n    # Step 7: Additional perturbation: perform a series of intelligent swaps between objectives\n    if random.random() < 0.3 and len(new_solution) > 1:\n        # Select a subset of items to consider for swapping\n        swap_candidates = np.where(new_solution == 1)[0]\n        if len(swap_candidates) > 1:\n            np.random.shuffle(swap_candidates)\n            for i in range(min(3, len(swap_candidates)-1)):\n                j = i + 1\n                if j >= len(swap_candidates):\n                    break\n                # Swap items if it maintains feasibility\n                if (current_weight - weight_lst[swap_candidates[i]] - weight_lst[swap_candidates[j]] +\n                    weight_lst[swap_candidates[i]] + weight_lst[swap_candidates[j]]) <= capacity:\n                    new_solution[swap_candidates[i]], new_solution[swap_candidates[j]] = \\\n                    new_solution[swap_candidates[j]], new_solution[swap_candidates[i]]\n\n    return new_solution\n\n",
          "score": [
               -0.7765104046817304,
               1.326211005449295
          ]
     },
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with high potential for improvement based on its objective values and weight utilization\n    selected_idx = np.random.choice(len(archive))\n    base_solution, (base_val1, base_val2) = archive[selected_idx]\n    current_weight = np.sum(weight_lst * base_solution)\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate the normalized objective values to determine the focus of improvement\n    max_val1 = np.max([obj[0] for _, obj in archive])\n    max_val2 = np.max([obj[1] for _, obj in archive])\n    norm_val1 = base_val1 / max_val1 if max_val1 > 0 else 0\n    norm_val2 = base_val2 / max_val2 if max_val2 > 0 else 0\n\n    # Step 3: Determine the focus of improvement (the objective that is relatively weaker)\n    focus_obj = 1 if norm_val1 < norm_val2 else 2\n\n    # Step 4: Cluster items based on value-weight ratio and dominance potential\n    items = np.arange(len(weight_lst))\n    value_weight_ratio = (value1_lst + value2_lst) / weight_lst\n\n    # Sort items by value-weight ratio in descending order\n    sorted_items = items[np.argsort(-value_weight_ratio)]\n\n    # Step 5: Generate candidate items for flipping based on clustering and dominance\n    candidates = []\n    for i in sorted_items:\n        if base_solution[i] == 1:\n            # Consider removing item i if it doesn't significantly reduce the focused objective\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                if focus_obj == 1:\n                    candidates.append((i, -1, value1_lst[i], value2_lst[i]))\n                else:\n                    candidates.append((i, -1, value2_lst[i], value1_lst[i]))\n        else:\n            # Consider adding item i if it improves the focused objective\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                if focus_obj == 1:\n                    candidates.append((i, 1, value1_lst[i], value2_lst[i]))\n                else:\n                    candidates.append((i, 1, value2_lst[i], value1_lst[i]))\n\n    if not candidates:\n        # Step 6: No feasible flips, perform a random feasible flip\n        feasible_indices = [i for i in range(len(base_solution))\n                          if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                             (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n        return new_solution\n\n    # Step 7: Select the best candidate based on trade-off awareness\n    best_candidate = None\n    best_score = -np.inf\n    for candidate in candidates:\n        idx, flip, val_focus, val_other = candidate\n        if flip == 1:\n            # Adding item: maximize the focused objective while considering trade-off\n            score = val_focus * 0.7 + val_other * 0.3\n        else:\n            # Removing item: minimize the focused objective while considering trade-off\n            score = -val_focus * 0.7 - val_other * 0.3\n        if score > best_score:\n            best_score = score\n            best_candidate = candidate\n\n    if best_candidate is not None:\n        idx, flip, _, _ = best_candidate\n        new_solution[idx] = 1 if flip == 1 else 0\n\n    # Step 8: Additional perturbation: perform a series of intelligent swaps between objectives\n    if random.random() < 0.3 and len(new_solution) > 1:\n        # Select a subset of items to consider for swapping\n        swap_candidates = np.where(new_solution == 1)[0]\n        if len(swap_candidates) > 1:\n            np.random.shuffle(swap_candidates)\n            for i in range(min(3, len(swap_candidates)-1)):\n                j = i + 1\n                if j >= len(swap_candidates):\n                    break\n                # Swap items if it maintains feasibility\n                if (current_weight - weight_lst[swap_candidates[i]] - weight_lst[swap_candidates[j]] +\n                    weight_lst[swap_candidates[i]] + weight_lst[swap_candidates[j]]) <= capacity:\n                    new_solution[swap_candidates[i]], new_solution[swap_candidates[j]] = \\\n                    new_solution[swap_candidates[j]], new_solution[swap_candidates[i]]\n\n    return new_solution\n\n",
          "score": [
               -0.8787428923804161,
               1.5737963318824768
          ]
     },
     {
          "algorithm": "{The proposed algorithm first identifies the most diverse solution in the archive by calculating the Euclidean distance between each solution's objective values and the centroid of all solutions, then selects this solution for local improvement. It then applies a novel local search operator that intelligently flips multiple items in a single move, prioritizing flips that maximize the sum of squared marginal contributions to both objectives, while ensuring feasibility by dynamically adjusting the number of flips to respect the capacity constraint. The operator also incorporates a probabilistic component to escape local optima, favoring flips that improve both objectives while considering trade-offs between them, and uses a greedy selection mechanism to iteratively improve the solution until no further beneficial flips are possible.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most diverse solution in the archive\n    objectives = np.array([obj for _, obj in archive])\n    centroid = np.mean(objectives, axis=0)\n    distances = np.linalg.norm(objectives - centroid, axis=1)\n    selected_idx = np.argmax(distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    # Step 2: Compute marginal contributions of each item to both objectives\n    current_weight = np.sum(weight_lst * base_solution)\n    marginal_value1 = value1_lst / (weight_lst + 1e-10)\n    marginal_value2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = marginal_value1 + marginal_value2\n\n    # Step 3: Identify items that can be flipped to improve both objectives\n    candidates = []\n    for i in range(len(base_solution)):\n        if base_solution[i] == 1:\n            new_weight = current_weight - weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, -1, combined_marginal[i]))\n        else:\n            new_weight = current_weight + weight_lst[i]\n            if new_weight <= capacity:\n                candidates.append((i, 1, combined_marginal[i]))\n\n    if not candidates:\n        # No feasible flips, return a random neighbor by flipping a single item\n        feasible_indices = [i for i in range(len(base_solution)) if (base_solution[i] == 1 and current_weight - weight_lst[i] <= capacity) or\n                           (base_solution[i] == 0 and current_weight + weight_lst[i] <= capacity)]\n        if feasible_indices:\n            flip_idx = np.random.choice(feasible_indices)\n            new_solution = base_solution.copy()\n            new_solution[flip_idx] = 1 - new_solution[flip_idx]\n            return new_solution\n        else:\n            return base_solution.copy()\n\n    # Step 4: Select multiple flips based on combined marginal contributions\n    new_solution = base_solution.copy()\n    candidates.sort(key=lambda x: x[2], reverse=True)\n    max_flips = min(3, len(candidates))  # Limit the number of flips to avoid excessive changes\n    for i in range(max_flips):\n        idx, flip, _ = candidates[i]\n        new_solution[idx] = 1 if flip == 1 else 0\n\n    # Ensure feasibility\n    new_weight = np.sum(weight_lst * new_solution)\n    if new_weight > capacity:\n        # If not feasible, undo the last flip\n        for i in range(max_flips):\n            idx, flip, _ = candidates[i]\n            new_solution[idx] = 1 - new_solution[idx]\n            new_weight = np.sum(weight_lst * new_solution)\n            if new_weight <= capacity:\n                break\n\n    return new_solution\n\n",
          "score": [
               -0.8111118225578708,
               1.458364725112915
          ]
     }
]