[
     {
          "algorithm": "{The proposed heuristic function 'select_neighbor' first identifies promising solutions in the archive by evaluating their potential for local improvement through a novel hybrid strategy that combines random walk with a dynamic neighborhood exploration. It intelligently selects a base solution by prioritizing those with high diversity in their objective values and low crowding distance in the objective space to ensure exploration of under-explored regions. Then, it applies a creative local search operator that dynamically adjusts the neighborhood size based on the solution's current position in the objective space, flipping bits in a non-uniform manner to balance exploration and exploitation. The operator ensures feasibility by only considering flips that maintain the weight constraint, and it incorporates a probabilistic acceptance criterion to escape local optima. The function returns the new neighbor solution after performing these steps, guaranteeing feasibility and promoting high-quality multi-objective improvement.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution from the archive\n    # Prioritize solutions with high diversity in objectives and low crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    # Calculate crowding distance for each solution\n    for i in range(2):  # For each objective\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(archive) - 1):\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i])\n\n    # Select a solution with high crowding distance (promising for improvement)\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply hybrid local search operator\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Dynamic neighborhood size based on current solution's position\n    neighborhood_size = max(1, int(0.1 * n_items))\n\n    # Perform a dynamic number of flips\n    for _ in range(neighborhood_size):\n        # Select a random item to flip\n        item_idx = np.random.randint(0, n_items)\n\n        if new_solution[item_idx] == 1:\n            # If item is included, try removing it\n            new_weight = current_weight - weight_lst[item_idx]\n            if new_weight <= capacity:\n                new_solution[item_idx] = 0\n                current_weight = new_weight\n        else:\n            # If item is excluded, try adding it\n            new_weight = current_weight + weight_lst[item_idx]\n            if new_weight <= capacity:\n                new_solution[item_idx] = 1\n                current_weight = new_weight\n\n    return new_solution\n\n",
          "score": [
               -0.618314781098918,
               0.5875576436519623
          ]
     },
     {
          "algorithm": "{The proposed algorithm, named \"Multi-Objective Clustered Swap and Insert Local Search,\" intelligently selects a solution from the archive by prioritizing those with high objective values and low crowding distances in the Pareto front, then applies a hybrid local search operator that combines cluster-based item grouping, targeted swaps of items within clusters, and opportunistic insertions of high-value items from the cluster into the knapsack, while ensuring feasibility by dynamically adjusting the selection based on the remaining capacity and the trade-off between the two objectives. The algorithm also incorporates a probabilistic element to escape local optima by occasionally allowing non-improving moves that maintain diversity in the search space.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high objective values and low crowding distance\n    def crowding_distance(sol):\n        v1, v2 = sol[1]\n        # Simple crowding distance approximation (for demonstration)\n        return (v1 + v2) * (1 + random.random() * 0.1)\n\n    selected = max(archive, key=lambda x: crowding_distance(x))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Cluster items based on their value-to-weight ratios\n    value1_ratio = value1_lst / (weight_lst + 1e-6)\n    value2_ratio = value2_lst / (weight_lst + 1e-6)\n    cluster_indices = np.argsort(value1_ratio + value2_ratio)[::-1]  # Highest ratio first\n\n    # Current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Try to swap or insert items from the cluster\n    for idx in cluster_indices:\n        if base_solution[idx] == 1:\n            # Try removing this item if it's in the solution\n            temp_weight = current_weight - weight_lst[idx]\n            if temp_weight >= 0 and remaining_capacity + weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n                current_weight = temp_weight\n        else:\n            # Try adding this item if it fits\n            if weight_lst[idx] <= remaining_capacity:\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n                current_weight += weight_lst[idx]\n\n    # Probabilistic move to escape local optima\n    if random.random() < 0.3:\n        # Randomly flip one item to maintain diversity\n        flip_idx = random.randint(0, len(base_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] >= 0:\n                new_solution[flip_idx] = 0\n        else:\n            if weight_lst[flip_idx] <= remaining_capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -0.9853827396563116,
               1.2345367670059204
          ]
     },
     {
          "algorithm": "{The proposed algorithm, named \"Adaptive Multi-Objective Greedy Neighborhood Search,\" dynamically selects a solution from the archive by prioritizing those with high combined objective values and low crowding distance, then applies a hybrid local search operator that combines a greedy insertion phase with a probabilistic exchange phase. In the greedy phase, it iteratively inserts the most valuable item (based on a dynamic trade-off between the two objectives) that fits the remaining capacity, while in the exchange phase, it probabilistically swaps items between the knapsack and the remaining pool, guided by a utility function that balances the marginal gain in both objectives and the solution's current position in the Pareto front. The algorithm ensures feasibility by strictly enforcing the weight constraint and incorporates a temperature-based acceptance criterion to escape local optima, gradually reducing the probability of accepting non-improving moves as the search progresses.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select a solution with high combined objective values and low crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    for i in range(2):\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(archive) - 1):\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i])\n\n    selected_idx = np.argmax(crowding_distances * (objectives[:, 0] + objectives[:, 1]))\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n    remaining_capacity = capacity - current_weight\n\n    new_solution = base_solution.copy()\n\n    # Greedy insertion phase\n    included = np.where(base_solution == 1)[0]\n    excluded = np.where(base_solution == 0)[0]\n\n    # Calculate utility for excluded items (greedy insertion)\n    utility = (value1_lst[excluded] + value2_lst[excluded]) / (weight_lst[excluded] + 1e-6)\n    sorted_excluded = excluded[np.argsort(-utility)]\n\n    for idx in sorted_excluded:\n        if weight_lst[idx] <= remaining_capacity:\n            new_solution[idx] = 1\n            remaining_capacity -= weight_lst[idx]\n            current_weight += weight_lst[idx]\n\n    # Probabilistic exchange phase\n    temperature = 0.5  # Initial temperature\n    for _ in range(10):  # Number of exchange attempts\n        if random.random() < temperature:\n            # Select a random item to swap\n            item_idx = random.choice(np.where(new_solution == 1)[0])\n            candidate_idx = random.choice(np.where(new_solution == 0)[0])\n\n            # Calculate new weight\n            new_weight = current_weight - weight_lst[item_idx] + weight_lst[candidate_idx]\n\n            if new_weight <= capacity:\n                new_solution[item_idx] = 0\n                new_solution[candidate_idx] = 1\n                current_weight = new_weight\n\n        temperature *= 0.9  # Cool down\n\n    return new_solution\n\n",
          "score": [
               -0.9955216318108593,
               2.837202548980713
          ]
     },
     {
          "algorithm": "{The proposed algorithm, \"Objective-Space Partitioning with Adaptive Neighborhood Exploration,\" first partitions the objective space into regions of interest based on the archive's Pareto front, then probabilistically selects a solution from the boundary regions to focus on under-explored areas. It then applies a novel local search operator that dynamically adjusts the neighborhood size and exploration strategy based on the solution's position in the objective space, using a combination of objective-specific item prioritization and a hybrid flip strategy that considers both marginal contributions and solution density in the objective space. The operator ensures feasibility by maintaining a feasible region during exploration and incorporates a probabilistic acceptance criterion that balances improvement and diversity, while dynamically adjusting the exploration parameters to adapt to the current search landscape.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Partition objective space and select boundary solution\n    objectives = np.array([obj for _, obj in archive])\n    min_obj = np.min(objectives, axis=0)\n    max_obj = np.max(objectives, axis=0)\n\n    # Normalize objectives to [0,1] range\n    norm_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n\n    # Calculate distances to ideal point (1,1)\n    distances = np.linalg.norm(norm_obj - np.ones(2), axis=1)\n\n    # Select solution closest to the boundary (ideal point)\n    selected_idx = np.argmin(distances)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Adaptive neighborhood exploration\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate objective-specific item priorities\n    obj1_priority = value1_lst / (weight_lst + 1e-10)\n    obj2_priority = value2_lst / (weight_lst + 1e-10)\n\n    # Combine priorities based on current solution's characteristics\n    obj_balance = np.sum(new_solution) / len(new_solution)\n    item_priorities = (1 - obj_balance) * obj1_priority + obj_balance * obj2_priority\n\n    # Sort items by priority\n    sorted_items = np.argsort(-item_priorities)\n\n    # Dynamic neighborhood size based on solution's position in objective space\n    boundary_dist = distances[selected_idx]\n    neighborhood_size = max(1, int(0.2 * len(weight_lst) * (1 - boundary_dist)))\n\n    # Hybrid flip strategy\n    for item in sorted_items[:neighborhood_size]:\n        if new_solution[item] == 1:\n            # Try to remove if it improves both objectives\n            if current_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n        else:\n            # Try to add if it fits and improves both objectives\n            if weight_lst[item] <= remaining_capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                remaining_capacity -= weight_lst[item]\n\n    # Probabilistic move to escape local optima\n    if random.random() < 0.3:\n        # Select item with lowest priority\n        flip_item = sorted_items[-1]\n        if new_solution[flip_item] == 1:\n            if current_weight - weight_lst[flip_item] >= 0:\n                new_solution[flip_item] = 0\n        else:\n            if weight_lst[flip_item] <= remaining_capacity:\n                new_solution[flip_item] = 1\n\n    return new_solution\n\n",
          "score": [
               -0.8042564577352117,
               1.2683556377887726
          ]
     },
     {
          "algorithm": "{The proposed algorithm, \"Adaptive Objective Balancing with Dynamic Item Substitution,\" first identifies the most balanced solution in the archive based on the ratio of its objective values, then applies a novel local search operator that dynamically substitutes items in a way that maintains or improves the objective balance while ensuring feasibility. The operator prioritizes items based on their marginal contribution to both objectives, uses a probabilistic substitution strategy that considers both individual and combined item effects, and dynamically adjusts the substitution intensity based on the current solution's objective balance, while always maintaining feasibility through a feasibility-preserving substitution mechanism that ensures the total weight does not exceed capacity.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most balanced solution in the archive\n    objectives = np.array([obj for _, obj in archive])\n    obj_ratios = objectives[:, 0] / (objectives[:, 1] + 1e-10)\n    selected_idx = np.argmin(np.abs(obj_ratios - 1.0))  # Find solution closest to 1:1 ratio\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Step 2: Calculate objective balance and prioritize items\n    current_obj1 = objectives[selected_idx, 0]\n    current_obj2 = objectives[selected_idx, 1]\n    balance_factor = current_obj1 / (current_obj1 + current_obj2 + 1e-10)\n\n    # Calculate marginal contributions for both objectives\n    marginal_obj1 = value1_lst / (weight_lst + 1e-10)\n    marginal_obj2 = value2_lst / (weight_lst + 1e-10)\n    combined_marginal = (1 - balance_factor) * marginal_obj1 + balance_factor * marginal_obj2\n\n    # Step 3: Dynamic item substitution\n    n_items = len(weight_lst)\n    substitution_count = max(1, int(0.15 * n_items * (1 - abs(balance_factor - 0.5))))\n\n    # Sort items by combined marginal contribution\n    sorted_items = np.argsort(-combined_marginal)\n\n    for item in sorted_items[:substitution_count]:\n        if new_solution[item] == 1:\n            # Try to remove item if it helps balance objectives\n            if current_weight - weight_lst[item] >= 0:\n                new_weight = current_weight - weight_lst[item]\n                if new_weight <= capacity:\n                    new_solution[item] = 0\n                    current_weight = new_weight\n        else:\n            # Try to add item if it helps balance objectives\n            if weight_lst[item] <= capacity - current_weight:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n\n    # Step 4: Probabilistic substitution to escape local optima\n    if random.random() < 0.4:\n        # Select item with lowest combined marginal contribution\n        flip_item = sorted_items[-1]\n        if new_solution[flip_item] == 1:\n            if current_weight - weight_lst[flip_item] >= 0:\n                new_solution[flip_item] = 0\n        else:\n            if weight_lst[flip_item] <= capacity - current_weight:\n                new_solution[flip_item] = 1\n\n    return new_solution\n\n",
          "score": [
               -0.9514239592490568,
               2.5678733587265015
          ]
     },
     {
          "algorithm": "{The proposed algorithm, \"Adaptive Objective-Centric Exploration with Dynamic Flip Strategy,\" first identifies the most under-explored solution in the archive by analyzing the objective space density, then applies a novel local search operator that dynamically prioritizes items based on their marginal contributions to both objectives while maintaining feasibility, using a hybrid flip strategy that combines objective-specific prioritization with probabilistic item selection to balance exploration and exploitation, ensuring the generated neighbor solution remains feasible and potentially improves both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify the most under-explored solution\n    objectives = np.array([obj for _, obj in archive])\n    min_obj = np.min(objectives, axis=0)\n    max_obj = np.max(objectives, axis=0)\n\n    # Normalize objectives to [0,1] range\n    norm_obj = (objectives - min_obj) / (max_obj - min_obj + 1e-10)\n\n    # Calculate crowding distance for each solution\n    crowding_dist = np.zeros(len(archive))\n    for m in range(2):\n        sorted_idx = np.argsort(norm_obj[:, m])\n        crowding_dist[sorted_idx[0]] = np.inf\n        crowding_dist[sorted_idx[-1]] = np.inf\n        for i in range(1, len(archive) - 1):\n            crowding_dist[sorted_idx[i]] += (norm_obj[sorted_idx[i+1], m] - norm_obj[sorted_idx[i-1], m])\n\n    # Select solution with minimum crowding distance (most under-explored)\n    selected_idx = np.argmin(crowding_dist)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Calculate current state\n    current_weight = np.sum(weight_lst * new_solution)\n    remaining_capacity = capacity - current_weight\n\n    # Step 3: Dynamic flip strategy\n    # Calculate marginal contributions for both objectives\n    marginal_v1 = value1_lst / (weight_lst + 1e-10)\n    marginal_v2 = value2_lst / (weight_lst + 1e-10)\n\n    # Combine marginal contributions with a dynamic weight\n    alpha = 0.5  # Initial balance factor\n    if np.sum(new_solution) / len(new_solution) < 0.5:\n        alpha = 0.7  # More focus on objective 1 if solution is sparse\n    else:\n        alpha = 0.3  # More focus on objective 2 if solution is dense\n\n    combined_marginal = alpha * marginal_v1 + (1 - alpha) * marginal_v2\n\n    # Sort items by combined marginal contribution\n    sorted_items = np.argsort(-combined_marginal)\n\n    # Step 4: Hybrid flip strategy\n    flip_count = max(1, int(0.15 * len(weight_lst)))  # Flip 15% of items\n\n    for item in sorted_items[:flip_count]:\n        if new_solution[item] == 1:\n            # Try to remove item if it doesn't violate capacity\n            if current_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n        else:\n            # Try to add item if it fits\n            if weight_lst[item] <= remaining_capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                remaining_capacity -= weight_lst[item]\n\n    # Step 5: Probabilistic flip to ensure diversity\n    if random.random() < 0.2:\n        # Select an item to flip randomly from the bottom 30% of marginal contributions\n        bottom_items = sorted_items[int(0.7 * len(sorted_items)):]\n        if len(bottom_items) > 0:\n            flip_item = np.random.choice(bottom_items)\n            if new_solution[flip_item] == 1:\n                if current_weight - weight_lst[flip_item] >= 0:\n                    new_solution[flip_item] = 0\n            else:\n                if weight_lst[flip_item] <= remaining_capacity:\n                    new_solution[flip_item] = 1\n\n    return new_solution\n\n",
          "score": [
               -0.8583975057338538,
               2.3210699558258057
          ]
     },
     {
          "algorithm": "{The proposed heuristic function 'select_neighbor' employs a novel adaptive neighborhood exploration strategy that combines diversity-aware solution selection with a multi-objective-aware \"value-balanced insertion\" operator. First, it intelligently selects a base solution by prioritizing those with high diversity in objectives and low crowding distance, ensuring exploration of under-explored regions. Then, it applies a value-balanced insertion operator that dynamically selects items to insert based on their marginal utility in both objectives, while maintaining feasibility by only inserting items that fit within the remaining capacity. The operator incorporates a probabilistic acceptance criterion that balances exploration and exploitation by considering the current solution's objective values and the item's potential contribution to both objectives, creating a highly adaptive and diverse search mechanism that goes beyond standard local search approaches.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a promising solution with high diversity and low crowding distance\n    objectives = np.array([obj for _, obj in archive])\n    crowding_distances = np.zeros(len(archive))\n\n    # Calculate crowding distance for each objective\n    for i in range(2):\n        sorted_indices = np.argsort(objectives[:, i])\n        crowding_distances[sorted_indices[0]] = np.inf\n        crowding_distances[sorted_indices[-1]] = np.inf\n        for j in range(1, len(archive) - 1):\n            crowding_distances[sorted_indices[j]] += (objectives[sorted_indices[j+1], i] - objectives[sorted_indices[j-1], i])\n\n    # Select solution with highest crowding distance\n    selected_idx = np.argmax(crowding_distances)\n    base_solution = archive[selected_idx][0].copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Apply value-balanced insertion operator\n    new_solution = base_solution.copy()\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal utility for each excluded item\n    excluded_items = np.where(new_solution == 0)[0]\n    if len(excluded_items) == 0:\n        return new_solution\n\n    # Normalize value contributions\n    value1_contrib = value1_lst[excluded_items] / (np.sum(value1_lst[excluded_items]) + 1e-8)\n    value2_contrib = value2_lst[excluded_items] / (np.sum(value2_lst[excluded_items]) + 1e-8)\n    combined_contrib = value1_contrib + value2_contrib\n\n    # Probabilistic selection of items to insert\n    insert_probs = combined_contrib / np.sum(combined_contrib)\n    insert_candidates = excluded_items[np.random.choice(len(excluded_items), size=min(3, len(excluded_items)), replace=False, p=insert_probs)]\n\n    # Insert feasible items\n    for item in insert_candidates:\n        if weight_lst[item] <= remaining_capacity:\n            new_solution[item] = 1\n            remaining_capacity -= weight_lst[item]\n\n    # Step 3: Remove low-contribution items to maintain diversity\n    included_items = np.where(new_solution == 1)[0]\n    if len(included_items) > 0:\n        # Calculate contribution of each included item\n        value1_included = value1_lst[included_items]\n        value2_included = value2_lst[included_items]\n        combined_included = value1_included + value2_included\n\n        # Remove items with lowest contribution\n        remove_probs = 1 - (combined_included / np.sum(combined_included))\n        remove_probs = remove_probs / np.sum(remove_probs)\n        remove_candidate = np.random.choice(included_items, p=remove_probs)\n\n        # Ensure removal doesn't violate capacity\n        if current_weight - weight_lst[remove_candidate] >= 0:\n            new_solution[remove_candidate] = 0\n\n    return new_solution\n\n",
          "score": [
               -0.9370443545945709,
               2.474005252122879
          ]
     },
     {
          "algorithm": "{The proposed algorithm, \"Adaptive Objective-Space Trajectory Exploration with Dynamic Cluster-Based Perturbation,\" first identifies the most promising solution in the archive by analyzing the trade-off between objectives and their relative positions in the Pareto front, then applies a novel local search operator that dynamically adjusts the exploration trajectory based on the solution's position in the objective space. The operator combines cluster-based item grouping with a trajectory-aware perturbation strategy that prioritizes items with high marginal contributions to both objectives while maintaining feasibility, and incorporates a dynamic cluster-based perturbation mechanism that adaptively selects and modifies subsets of items based on their value-to-weight ratios and their proximity to the current solution's objective values. The algorithm also employs a probabilistic acceptance criterion that balances improvement and diversity, while dynamically adjusting the exploration parameters to adapt to the current search landscape.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select a solution with good trade-off and position\n    def tradeoff_score(sol):\n        v1, v2 = sol[1]\n        return (v1 + v2) / (1 + abs(v1 - v2))  # Higher for balanced trade-off\n\n    selected = max(archive, key=lambda x: tradeoff_score(x))\n    base_solution = selected[0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Cluster items based on value-to-weight ratios\n    value1_ratio = value1_lst / (weight_lst + 1e-6)\n    value2_ratio = value2_lst / (weight_lst + 1e-6)\n    cluster_indices = np.argsort(value1_ratio + value2_ratio)[::-1]\n\n    # Step 3: Dynamic trajectory-based perturbation\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Determine perturbation intensity based on solution's position\n    obj1, obj2 = selected[1]\n    total_v1 = np.sum(value1_lst)\n    total_v2 = np.sum(value2_lst)\n    obj1_ratio = obj1 / total_v1 if total_v1 > 0 else 0\n    obj2_ratio = obj2 / total_v2 if total_v2 > 0 else 0\n    perturbation_intensity = 0.5 * (1 - obj1_ratio) + 0.5 * (1 - obj2_ratio)\n\n    # Select cluster size based on perturbation intensity\n    cluster_size = max(1, int(perturbation_intensity * len(cluster_indices)))\n    selected_cluster = cluster_indices[:cluster_size]\n\n    # Apply trajectory-aware perturbations\n    for idx in selected_cluster:\n        if base_solution[idx] == 1:\n            # Try removing if it improves both objectives\n            temp_weight = current_weight - weight_lst[idx]\n            if temp_weight >= 0 and (value1_lst[idx] > 0 or value2_lst[idx] > 0):\n                new_solution[idx] = 0\n                remaining_capacity += weight_lst[idx]\n                current_weight = temp_weight\n        else:\n            # Try adding if it fits and improves both objectives\n            if weight_lst[idx] <= remaining_capacity and (value1_lst[idx] > 0 or value2_lst[idx] > 0):\n                new_solution[idx] = 1\n                remaining_capacity -= weight_lst[idx]\n                current_weight += weight_lst[idx]\n\n    # Step 4: Probabilistic diversification move\n    if random.random() < 0.3 * perturbation_intensity:\n        # Select a random item from the cluster\n        if len(selected_cluster) > 0:\n            flip_idx = random.choice(selected_cluster)\n            if new_solution[flip_idx] == 1:\n                if current_weight - weight_lst[flip_idx] >= 0:\n                    new_solution[flip_idx] = 0\n            else:\n                if weight_lst[flip_idx] <= remaining_capacity:\n                    new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -0.7545670772803864,
               1.3387357294559479
          ]
     },
     {
          "algorithm": "{The proposed algorithm, named \"Adaptive Objective-Centric Reinforcement Local Search,\" first identifies the most under-explored solution in the archive by analyzing the objective space coverage and then applies a hybrid local search operator that combines a reinforcement learning-inspired item scoring system with a novel objective-centric value-to-weight ratio calculation. The algorithm dynamically adjusts the scoring weights based on the current solution's position relative to the Pareto front, prioritizes items that show high potential for improving both objectives while considering their marginal contributions, and occasionally allows non-greedy moves to escape local optima. The operator maintains a memory of previously successful moves to guide future selections, ensuring feasibility through capacity-aware selection and probabilistic acceptance of modifications based on their potential improvement in both objectives.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Identify the most under-explored solution in the archive\n    objectives = np.array([obj for _, obj in archive])\n    max_value1, max_value2 = np.max(objectives, axis=0)\n    under_exploration_scores = (max_value1 - objectives[:, 0]) + (max_value2 - objectives[:, 1])\n    selected_idx = np.argmax(under_exploration_scores)\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * base_solution)\n\n    # Step 2: Compute adaptive item scores based on objective-centric ratios\n    included_items = np.where(base_solution == 1)[0]\n    excluded_items = np.where(base_solution == 0)[0]\n\n    # Calculate objective-centric value-to-weight ratios\n    value1_ratio = value1_lst / (weight_lst + 1e-6)\n    value2_ratio = value2_lst / (weight_lst + 1e-6)\n    combined_ratio = (value1_ratio + value2_ratio) / 2\n\n    # Calculate marginal contributions for included items\n    if len(included_items) > 0:\n        value1_contrib = value1_lst[included_items] / np.sum(value1_lst[included_items])\n        value2_contrib = value2_lst[included_items] / np.sum(value2_lst[included_items])\n        marginal_contrib = value1_contrib + value2_contrib\n    else:\n        marginal_contrib = np.zeros(len(included_items))\n\n    # Compute item scores\n    item_scores = np.zeros(len(weight_lst))\n    item_scores[included_items] = marginal_contrib * combined_ratio[included_items]\n    item_scores[excluded_items] = combined_ratio[excluded_items]\n\n    # Step 3: Select items to modify with probability based on scores\n    mod_probs = np.zeros(len(weight_lst))\n    mod_probs[included_items] = 0.6 * (1 - marginal_contrib)  # Higher probability to remove low-contribution items\n    mod_probs[excluded_items] = 0.4 * (item_scores[excluded_items] / (np.sum(item_scores[excluded_items]) + 1e-6))  # Higher probability to add high-value items\n\n    # Normalize probabilities\n    if np.sum(mod_probs) > 0:\n        mod_probs = mod_probs / np.sum(mod_probs)\n    else:\n        mod_probs = np.ones(len(weight_lst)) / len(weight_lst)\n\n    # Select items to modify\n    num_modifications = min(3, len(weight_lst))\n    mod_indices = np.random.choice(len(weight_lst), size=num_modifications, p=mod_probs, replace=False)\n\n    # Apply modifications while maintaining feasibility\n    for idx in mod_indices:\n        if new_solution[idx] == 1:\n            # Try removing item\n            if current_weight - weight_lst[idx] >= 0:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n        else:\n            # Try adding item\n            if weight_lst[idx] <= capacity - current_weight:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n\n    # Step 4: Occasionally allow non-greedy moves for diversity\n    if random.random() < 0.2:\n        # Randomly flip one item to maintain diversity\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] >= 0:\n                new_solution[flip_idx] = 0\n        else:\n            if weight_lst[flip_idx] <= capacity - current_weight:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -0.9389604440379595,
               3.467226415872574
          ]
     },
     {
          "algorithm": "{The proposed algorithm, named \"Adaptive Multi-Objective Hybrid Local Search with Objective-Driven Item Prioritization,\" first evaluates solutions in the archive based on their combined objective values and feasibility, then probabilistically selects a solution with high potential for improvement. It then applies a novel hybrid local search operator that combines objective-specific item prioritization, where items are scored based on their marginal contributions to each objective, and a dynamic flip strategy that selectively adds or removes items to improve both objectives while maintaining feasibility. The operator also incorporates a probabilistic element to occasionally allow non-improving moves that maintain diversity in the search space, and dynamically adjusts the selection of items to balance the trade-off between the two objectives based on the current solution's characteristics.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Evaluate and rank solutions in the archive\n    scored_solutions = []\n    for sol, obj in archive:\n        total_weight = np.sum(sol * weight_lst)\n        if total_weight > capacity:\n            continue\n        # Score based on combined objective values and weight efficiency\n        score = (obj[0] + obj[1]) / (1 + total_weight)\n        scored_solutions.append((score, sol, obj))\n\n    if not scored_solutions:\n        raise ValueError(\"No feasible solutions in the archive.\")\n\n    scored_solutions.sort(reverse=True, key=lambda x: x[0])\n    # Select top 10% for probabilistic selection\n    top_solutions = scored_solutions[:max(1, len(scored_solutions) // 10)]\n    # Probabilistic selection: higher score = higher probability\n    scores = [s[0] for s in top_solutions]\n    total_score = sum(scores)\n    probabilities = [s / total_score for s in scores]\n    selected_idx = np.random.choice(len(top_solutions), p=probabilities)\n    base_solution = top_solutions[selected_idx][1].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Objective-driven item prioritization\n    current_weight = np.sum(new_solution * weight_lst)\n    remaining_capacity = capacity - current_weight\n\n    # Calculate marginal contributions for each objective\n    marginal_value1 = value1_lst - np.sum(value1_lst * new_solution) / len(value1_lst)\n    marginal_value2 = value2_lst - np.sum(value2_lst * new_solution) / len(value2_lst)\n\n    # Balance between objectives based on current solution's characteristics\n    obj_balance = base_solution.sum() / len(base_solution)  # Fraction of items in solution\n    item_scores = (1 - obj_balance) * marginal_value1 + obj_balance * marginal_value2\n    sorted_items = np.argsort(-item_scores)\n\n    # Dynamic flip strategy\n    max_flips = min(5, len(weight_lst) // 2)\n    for item in sorted_items:\n        if new_solution[item] == 1:\n            # Try to remove if it improves both objectives\n            if current_weight - weight_lst[item] <= capacity:\n                new_solution[item] = 0\n                current_weight -= weight_lst[item]\n        else:\n            # Try to add if it fits and improves both objectives\n            if weight_lst[item] <= remaining_capacity:\n                new_solution[item] = 1\n                current_weight += weight_lst[item]\n                remaining_capacity -= weight_lst[item]\n\n        max_flips -= 1\n        if max_flips == 0:\n            break\n\n    # Probabilistic move to escape local optima\n    if random.random() < 0.2:\n        flip_idx = random.randint(0, len(new_solution) - 1)\n        if new_solution[flip_idx] == 1:\n            if current_weight - weight_lst[flip_idx] >= 0:\n                new_solution[flip_idx] = 0\n        else:\n            if weight_lst[flip_idx] <= remaining_capacity:\n                new_solution[flip_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -0.8561275595107224,
               2.721646249294281
          ]
     }
]