[
     {
          "algorithm": "{The new algorithm introduces an adaptive Pareto frontier exploration strategy that first selects solutions based on their objective diversity and trade-off potential, then applies a multi-phase transformation combining a probabilistic item inversion guided by both objectives' marginal contributions weighted by their normalized objective distances, a Pareto-frontier guided perturbation that explores regions near the extreme points, a dynamic capacity-aware random walk that ensures feasibility by considering both the current solution's weight and the remaining capacity, and a final hybrid refinement phase that combines greedy selection with a novel \"objective-balanced\" swap that prioritizes items with complementary contributions to both objectives, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a \"frontier-aware\" replacement mechanism that selectively flips items based on their contribution to the Pareto frontier and a \"trade-off sensitive\" perturbation that explores regions near the knee point, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective diversity and trade-off potential\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    diversity_scores = np.prod((objectives - min_values) / (max_values - min_values + 1e-6), axis=1)\n    trade_off_scores = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    selection_scores = diversity_scores * trade_off_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-balanced inversion with adaptive probability\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_distance = np.sqrt((delta_value1 / (max_values[0] - min_values[0] + 1e-6))**2 +\n                                       (delta_value2 / (max_values[1] - min_values[1] + 1e-6))**2)\n                prob = min(1.0, 0.2 + 0.8 * norm_distance)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware replacement with extreme point guidance\n    if len(archive) > 1:\n        extreme_idx1 = np.argmax(objectives[:, 0])\n        extreme_idx2 = np.argmax(objectives[:, 1])\n        extreme_solution1 = archive[extreme_idx1][0]\n        extreme_solution2 = archive[extreme_idx2][0]\n\n        for i in range(n_items):\n            if extreme_solution1[i] != new_solution[i] and np.random.rand() < 0.7:\n                if extreme_solution1[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n            if extreme_solution2[i] != new_solution[i] and np.random.rand() < 0.7:\n                if extreme_solution2[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware random walk with adaptive step size\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] / (max_values[0] + 1e-6) +\n                           value2_lst[candidates] / (max_values[1] + 1e-6)) / 2\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            step_size = min(0.5, remaining_capacity / np.sum(candidate_weights[feasible]))\n            selected = np.random.choice(candidates[feasible], size=max(1, int(len(candidates[feasible]) * step_size)), replace=False)\n            for i in selected:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Step 5: Hybrid refinement with trade-off sensitive selection\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] * value2_lst[candidates]) / (weight_lst[candidates] + 1e-6)\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            best_item = np.argmax(candidate_values[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        item_values = (value1_lst[excess_items] * value2_lst[excess_items]) / (weight_lst[excess_items] + 1e-6)\n        sorted_items = excess_items[np.argsort(item_values)]\n        excess = current_weight - capacity\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -17.364206991473516,
               -19.36511591316043
          ]
     },
     {
          "algorithm": "{The new algorithm combines the selection of promising solutions based on their objective values and trade-off potential with an innovative multi-phase local search strategy that dynamically adapts to the Pareto front's characteristics. It first identifies solutions with high combined objective values and strong trade-off potential by analyzing the archive's diversity and distribution, then applies a hybrid local search that intelligently combines a probabilistic item selection based on marginal contributions, a Pareto-front guided perturbation that explores regions near the knee point, and an adaptive capacity-aware random walk that ensures feasibility by considering both the current solution's weight and the remaining capacity, with the probability of each strategy being dynamically adjusted based on the solution's position relative to the Pareto front and the archive's state. Additionally, it incorporates a novel \"objective-balanced\" perturbation that selectively flips items based on their contribution to both objectives, a \"frontier-aware\" swap that prioritizes items near the Pareto frontier, and a \"capacity-sensitive\" mutation that ensures feasibility by only considering moves that maintain or slightly reduce the total weight, while dynamically balancing exploration and exploitation by adjusting the selection probability of these strategies based on the archive's diversity and the current solution's position relative to the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on combined objective values and trade-off potential\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    trade_off = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_score = combined_values * trade_off\n    best_idx = np.argmax(diversity_score)\n    base_solution = archive[best_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Multi-phase local search with dynamic strategy adjustment\n    # Phase 1: Objective-balanced perturbation with adaptive probability\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_improvement = (delta_value1 + delta_value2) / (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1]) + 1e-6)\n                prob = min(1.0, 0.2 + 0.8 * norm_improvement)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Phase 2: Frontier-aware swap with diversity consideration\n    if len(archive) > 2:\n        sorted_idx = np.argsort(objectives[:, 0] + objectives[:, 1])\n        middle_solution = archive[sorted_idx[len(archive)//2]][0]\n        for i in range(n_items):\n            if middle_solution[i] != new_solution[i] and np.random.rand() < 0.3:\n                if middle_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Phase 3: Capacity-sensitive mutation with neighborhood exploration\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        np.random.shuffle(candidates)\n        for i in candidates:\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < 0.5:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Phase 4: Dynamic strategy adjustment based on Pareto front characteristics\n    if np.random.rand() < 0.2:\n        # Apply a more aggressive perturbation when near the knee point\n        knee_point = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_point][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.4:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    return new_solution\n\n",
          "score": [
               -20.279907927702475,
               -16.010123918625908
          ]
     },
     {
          "algorithm": "{The new algorithm introduces a dynamic multi-objective neighborhood exploration strategy that combines adaptive solution selection based on both objective values and their trade-off potential with a hybrid local search operator that intelligently integrates a probabilistic item flipping mechanism weighted by normalized objective improvements, a Pareto-front guided item replacement that leverages the archive's diversity and extreme points, and a capacity-aware random walk that explores weight-sensitive regions while dynamically adjusting the exploration intensity based on the current solution's position relative to the Pareto front and the remaining capacity, ensuring feasibility through an adaptive weight adjustment mechanism that prioritizes items with balanced contributions to both objectives, while dynamically balancing exploration and exploitation by adjusting the selection probability of these strategies based on the solution's current objective trade-off and the archive's state.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution based on objective trade-off and diversity\n    objectives = np.array([obj for (sol, obj) in archive])\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized_objectives = (objectives - min_values) / (max_values - min_values + 1e-6)\n    trade_off_scores = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_scores = np.prod(normalized_objectives, axis=1)\n    selection_scores = trade_off_scores * diversity_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Dynamic probabilistic item flipping based on normalized improvements\n    n_items = len(weight_lst)\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_improvement = (delta_value1 + delta_value2) / (max_values.sum() + 1e-6)\n                prob = min(1.0, 0.2 + 0.8 * norm_improvement)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Pareto-front guided item replacement with adaptive intensity\n    if len(archive) > 1:\n        extreme_idx = np.argmax(objectives[:, 0] - objectives[:, 1])\n        extreme_solution = archive[extreme_idx][0]\n        exploration_intensity = 0.4 + 0.6 * (1 - current_weight / capacity)\n        for i in range(n_items):\n            if extreme_solution[i] != new_solution[i] and np.random.rand() < exploration_intensity:\n                if extreme_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware random walk with dynamic weight adjustment\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] + value2_lst[candidates]) / candidate_weights\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            feasible_candidates = candidates[feasible]\n            np.random.shuffle(feasible_candidates)\n            for i in feasible_candidates:\n                if np.random.rand() < 0.5 * (1 - current_weight / capacity):\n                    new_solution[i] = 1\n                    remaining_capacity -= weight_lst[i]\n                    if remaining_capacity <= 0:\n                        break\n\n    # Step 5: Final greedy refinement for balanced items\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] / (max_values[0] + 1e-6) +\n                           value2_lst[candidates] / (max_values[1] + 1e-6)) / 2\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            best_item = np.argmax(candidate_values[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        item_values = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_values)]\n        excess = current_weight - capacity\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.808660724536768,
               -17.738974545687324
          ]
     },
     {
          "algorithm": "{The new algorithm builds upon the common backbone of identifying promising solutions through objective trade-off analysis and Pareto-front awareness, while introducing a novel multi-phase adaptive perturbation strategy that dynamically combines probabilistic item selection, objective-balanced flipping, and capacity-aware exploration. It first selects solutions based on their combined objective values and trade-off potential, then applies a hybrid local search that probabilistically flips items based on their marginal contributions to both objectives, selectively incorporates items near the Pareto frontier's knee point, and performs an adaptive capacity-aware random walk that explores weight-sensitive regions while maintaining feasibility through dynamic weight adjustment. The algorithm further refines the solution by incorporating a guided neighborhood exploration that prioritizes items with balanced contributions to both objectives, and concludes with a final greedy phase that adds the most promising items while respecting capacity constraints. The intensity of each perturbation phase is dynamically adjusted based on the solution's position relative to the Pareto front and the archive's diversity, ensuring both exploration and exploitation of the search space.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select solution based on combined objective values and trade-off potential\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    trade_off = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_score = combined_values * trade_off\n    best_idx = np.argmax(diversity_score)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Probabilistic item flipping based on marginal contributions\n    n_items = len(weight_lst)\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_contribution = (delta_value1 + delta_value2) / (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1]) + 1e-6)\n                if np.random.rand() < min(1.0, 0.3 + 0.7 * norm_contribution):\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Knee-point guided perturbation\n    if len(archive) > 1:\n        knee_idx = np.argmin(np.abs(objectives[:, 0] - objectives[:, 1]))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.35:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Adaptive capacity-aware exploration\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] + value2_lst[candidates]) / 2\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            feasible_candidates = candidates[feasible]\n            np.random.shuffle(feasible_candidates)\n            for i in feasible_candidates:\n                if np.random.rand() < 0.5 * (1 - current_weight / capacity):\n                    new_solution[i] = 1\n                    remaining_capacity -= weight_lst[i]\n                    if remaining_capacity <= 0:\n                        break\n\n    # Step 5: Balanced objective refinement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] / (np.max(value1_lst) + 1e-6) +\n                           value2_lst[candidates] / (np.max(value2_lst) + 1e-6)) / 2\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            best_item = np.argmax(candidate_values[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        item_values = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_values)]\n        excess = current_weight - capacity\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.99363681733657,
               -16.96559208225029
          ]
     },
     {
          "algorithm": "{The new algorithm combines objective-aware selection with a dynamic, multi-stage transformation process that first identifies promising solutions by analyzing their normalized objective distances and trade-off potential, then applies a novel hybrid perturbation strategy that dynamically alternates between probabilistic item flipping based on both objectives' marginal contributions, a Pareto-front guided exploration that selectively incorporates items near the extreme points, and an adaptive capacity-aware random walk that explores weight-sensitive regions while maintaining feasibility through an intelligent weight adjustment mechanism. The algorithm further refines the solution by incorporating a guided neighborhood exploration that prioritizes items with balanced contributions to both objectives, and concludes with a final greedy phase that adds the most promising items while respecting capacity constraints. The intensity of each perturbation phase is dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, ensuring both exploration and exploitation of the search space.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on normalized objective distances and trade-off potential\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized_objectives = (objectives - min_values) / (max_values - min_values + 1e-6)\n    trade_off_scores = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    selection_scores = np.prod(normalized_objectives, axis=1) * trade_off_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Dynamic hybrid perturbation - probabilistic flipping\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_contribution = (delta_value1 + delta_value2) / (np.sum(value1_lst) + np.sum(value2_lst) + 1e-6)\n                if np.random.rand() < min(1.0, 0.3 + 0.7 * norm_contribution):\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Pareto-front guided exploration\n    if len(archive) > 1:\n        extreme_idx = np.argmax(objectives[:, 0] - objectives[:, 1])\n        extreme_solution = archive[extreme_idx][0]\n        for i in range(n_items):\n            if extreme_solution[i] != new_solution[i] and np.random.rand() < 0.3:\n                if extreme_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Adaptive capacity-aware random walk\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] / (max_values[0] + 1e-6) +\n                           value2_lst[candidates] / (max_values[1] + 1e-6)) / 2\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            feasible_candidates = candidates[feasible]\n            np.random.shuffle(feasible_candidates)\n            for i in feasible_candidates:\n                if np.random.rand() < 0.5 * (1 - current_weight / capacity):\n                    new_solution[i] = 1\n                    remaining_capacity -= weight_lst[i]\n                    if remaining_capacity <= 0:\n                        break\n\n    # Step 5: Guided neighborhood exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] + value2_lst[candidates]) / weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            best_item = np.argmax(candidate_values[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    # Step 6: Final greedy refinement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] + value2_lst[candidates]) / (np.sum(value1_lst) + np.sum(value2_lst) + 1e-6)\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            best_item = np.argmax(candidate_values[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        item_values = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_values)]\n        excess = current_weight - capacity\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.54179928124757,
               -18.158297126363905
          ]
     },
     {
          "algorithm": "{The new algorithm introduces a multi-criteria evolutionary transformation that first identifies solutions with high objective diversity and trade-off potential by analyzing both the normalized objective values and their distribution across the Pareto front, then applies a dynamic, phase-based local search strategy that combines a probabilistic item inversion guided by both objectives' marginal contributions weighted by their objective-space distances, a Pareto-frontier guided perturbation that explores regions near the knee point while maintaining feasibility, a capacity-aware item replacement that intelligently removes low-contribution items when exceeding capacity, and a final objective-balanced greedy refinement phase that selectively adds high-contribution items while ensuring both objectives are improved, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-correlation\" perturbation that flips items based on their cross-objective contribution patterns and a \"frontier-aware\" item replacement that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective diversity and correlation\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    normalized = (objectives - min_values) / (max_values - min_values + 1e-6)\n    diversity_scores = np.prod(normalized, axis=1)\n    correlation_scores = np.abs(normalized[:, 0] - normalized[:, 1])\n    selection_scores = diversity_scores * correlation_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-correlation perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                v1_contrib = value1_lst[i] / (max_values[0] + 1e-6)\n                v2_contrib = value2_lst[i] / (max_values[1] + 1e-6)\n                correlation = np.abs(v1_contrib - v2_contrib)\n                prob = min(1.0, 0.2 + 0.8 * correlation)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware item replacement\n    if len(archive) > 1:\n        knee_idx = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.5:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1 and np.random.rand() < 0.3:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware item replacement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        item_contributions = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_contributions)]\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    # Step 5: Objective-balanced greedy addition\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            v1_norm = value1_lst[candidates] / (max_values[0] + 1e-6)\n            v2_norm = value2_lst[candidates] / (max_values[1] + 1e-6)\n            combined_scores = v1_norm + v2_norm\n            best_item = np.argmax(combined_scores[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.3760927537009,
               -19.168786816342347
          ]
     },
     {
          "algorithm": "{The new algorithm introduces a hybrid evolutionary transformation that first selects solutions based on their objective diversity and trade-off potential, then applies a multi-phase strategy combining a probabilistic item inversion guided by both objectives' marginal contributions weighted by their normalized objective distances, a Pareto-front guided perturbation that explores regions near the knee point, an adaptive capacity-aware random walk that ensures feasibility by considering both the current solution's weight and the remaining capacity, and a final greedy refinement phase that adds the most promising items that improve both objectives while respecting capacity constraints, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, while incorporating a novel \"objective-balanced\" perturbation that selectively flips items based on their contribution to both objectives and a \"frontier-aware\" swap that prioritizes items near the Pareto frontier, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective diversity and trade-off potential\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    diversity_scores = np.prod((objectives - min_values) / (max_values - min_values + 1e-6), axis=1)\n    trade_off_scores = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    selection_scores = diversity_scores * trade_off_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-balanced perturbation with adaptive probability\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_distance = np.sqrt((delta_value1 / (max_values[0] - min_values[0] + 1e-6))**2 +\n                                       (delta_value2 / (max_values[1] - min_values[1] + 1e-6))**2)\n                prob = min(1.0, 0.3 + 0.7 * norm_distance)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware swap with knee-point guidance\n    if len(archive) > 1:\n        knee_point = np.argmin(objectives[:, 0] / (objectives[:, 1] + 1e-6))\n        knee_solution = archive[knee_point][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.6:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-aware random walk with adaptive step size\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] + value2_lst[candidates]) / candidate_weights\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            step_size = min(0.4, remaining_capacity / np.sum(candidate_weights[feasible]))\n            selected = np.random.choice(candidates[feasible], size=max(1, int(len(candidates[feasible]) * step_size)), replace=False)\n            for i in selected:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Step 5: Greedy refinement with balanced objective consideration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] / (max_values[0] + 1e-6) +\n                           value2_lst[candidates] / (max_values[1] + 1e-6)) / 2\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            best_item = np.argmax(candidate_values[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        item_values = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_values)]\n        excess = current_weight - capacity\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -17.598768458513234,
               -19.33711665059404
          ]
     },
     {
          "algorithm": "{The heuristic function 'select_neighbor' first identifies the most promising solution in the archive by evaluating the potential for improvement using a hybrid metric that combines the solution's current objective values with their spread across the Pareto front. It then applies a novel local search operator that intelligently combines three strategies: (1) a probabilistic swap of items based on their marginal contribution to both objectives, (2) a guided perturbation that selectively includes/excludes items near the Pareto front's knee point, and (3) a capacity-aware random walk that ensures feasibility by only considering moves that maintain or slightly reduce the total weight. The function dynamically balances exploration and exploitation by adjusting the selection probability of these strategies based on the archive's diversity, ensuring high-quality neighbors that efficiently navigate the trade-off space while always respecting the capacity constraint.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution (highest combined objective value)\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    best_idx = np.argmax(combined_values)\n    base_solution = archive[best_idx][0].copy()\n\n    # Step 2: Generate a neighbor using a hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Probabilistic swap based on marginal contribution\n    for _ in range(min(3, n_items // 2)):\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) == 0:\n            break\n        i = np.random.choice(candidates)\n        if new_solution[i] == 1 and np.random.rand() < 0.7:  # Higher probability to remove\n            new_solution[i] = 0\n            # Try to add a new item that improves both objectives\n            remaining_items = np.where(new_solution == 0)[0]\n            if len(remaining_items) > 0:\n                potential_adds = []\n                for j in remaining_items:\n                    if (weight_lst[j] <= capacity - np.sum(weight_lst[new_solution == 1])):\n                        potential_adds.append(j)\n                if potential_adds:\n                    j = np.random.choice(potential_adds)\n                    new_solution[j] = 1\n\n    # Strategy 2: Guided perturbation near knee point (approximate)\n    if len(archive) > 1:\n        # Approximate knee point as solution with max (v1 - v2)\n        knee_idx = np.argmax(objectives[:, 0] - objectives[:, 1])\n        knee_solution = archive[knee_idx][0]\n        # Perturb around knee items\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.3:\n                if knee_solution[i] == 1 and (weight_lst[i] <= capacity - np.sum(weight_lst[new_solution == 1])):\n                    new_solution[i] = 1\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Strategy 3: Capacity-aware random walk\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for i in excess_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.18646270182542,
               -18.508972406433266
          ]
     },
     {
          "algorithm": "{The new algorithm introduces a multi-phase adaptive transformation strategy that first selects solutions based on their objective trade-off potential and diversity, then applies a four-stage transformation: (1) a probabilistic item inversion based on both objectives' marginal contributions weighted by their normalized objective distances, (2) a Pareto-aware item replacement that considers the solution's position relative to the extreme points of the Pareto front, (3) a dynamic capacity-aware perturbation that explores weight-sensitive regions while maintaining feasibility through an adaptive weight adjustment mechanism, and (4) a final guided neighborhood exploration that prioritizes items with balanced contributions to both objectives, with the intensity of each transformation phase dynamically adjusted based on the solution's current position in the objective space and the archive's diversity, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on objective trade-off potential and diversity\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    trade_off_scores = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_scores = np.prod((objectives - min_values) / (max_values - min_values + 1e-6), axis=1)\n    selection_scores = trade_off_scores * diversity_scores\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Phase 1 - Probabilistic marginal contribution inversion\n    for i in range(n_items):\n        if np.random.rand() < 0.4:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_distance = np.sqrt((delta_value1 / (max_values[0] - min_values[0] + 1e-6))**2 +\n                                       (delta_value2 / (max_values[1] - min_values[1] + 1e-6))**2)\n                if np.random.rand() < min(1.0, 0.15 + 0.85 * norm_distance):\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Phase 2 - Pareto-aware item replacement\n    if len(archive) > 1:\n        extreme_idx1 = np.argmax(objectives[:, 0] - objectives[:, 1])\n        extreme_idx2 = np.argmin(objectives[:, 0] - objectives[:, 1])\n        extreme_solution1 = archive[extreme_idx1][0]\n        extreme_solution2 = archive[extreme_idx2][0]\n\n        for i in range(n_items):\n            if extreme_solution1[i] != new_solution[i] and np.random.rand() < 0.5:\n                if extreme_solution1[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n            if extreme_solution2[i] != new_solution[i] and np.random.rand() < 0.5:\n                if extreme_solution2[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Phase 3 - Adaptive capacity-aware perturbation\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] / (max_values[0] + 1e-6) +\n                           value2_lst[candidates] / (max_values[1] + 1e-6)) / 2\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            feasible_candidates = candidates[feasible]\n            np.random.shuffle(feasible_candidates)\n            for i in feasible_candidates:\n                if np.random.rand() < 0.6 * (1 - current_weight / capacity):\n                    new_solution[i] = 1\n                    remaining_capacity -= weight_lst[i]\n                    if remaining_capacity <= 0:\n                        break\n\n    # Step 5: Phase 4 - Guided neighborhood exploration\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] / (max_values[0] + 1e-6) +\n                           value2_lst[candidates] / (max_values[1] + 1e-6)) / 2\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            best_item = np.argmax(candidate_values[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        item_values = (value1_lst[excess_items] / (max_values[0] + 1e-6) +\n                      value2_lst[excess_items] / (max_values[1] + 1e-6)) / 2\n        sorted_items = excess_items[np.argsort(item_values)]\n        excess = current_weight - capacity\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -18.56146386608881,
               -18.98460973417019
          ]
     },
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (highest variance in objectives)\n    solutions = [s[0] for s in archive]\n    objectives = np.array([s[1] for s in archive])\n    variances = np.var(objectives, axis=0)\n    selected_idx = np.argmax(variances)\n    base_solution = solutions[selected_idx].copy()\n\n    # Generate a neighbor by randomly swapping items\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    swap_count = min(3, n_items)  # Limit the number of swaps to avoid excessive perturbation\n\n    # Randomly select items to swap\n    swap_indices = np.random.choice(n_items, size=swap_count, replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Check feasibility and repair if necessary\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Greedy repair: remove items until feasible\n        excess_weight = total_weight - capacity\n        while excess_weight > 0:\n            # Find the item with the smallest ratio of weight to value (sum of both objectives)\n            item_weights = weight_lst[new_solution == 1]\n            item_values = value1_lst[new_solution == 1] + value2_lst[new_solution == 1]\n            if len(item_weights) == 0:\n                break  # No items left to remove\n            ratios = item_values / item_weights\n            worst_item_idx = np.argmin(ratios)\n            actual_idx = np.where(new_solution == 1)[0][worst_item_idx]\n            new_solution[actual_idx] = 0\n            excess_weight -= weight_lst[actual_idx]\n\n    # Greedy improvement: add items that improve both objectives without exceeding capacity\n    remaining_weight = capacity - np.sum(new_solution * weight_lst)\n    if remaining_weight > 0:\n        # Find items not in the solution that can be added without exceeding capacity\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidate_items]\n        candidate_values = value1_lst[candidate_items] + value2_lst[candidate_items]\n        feasible_items = candidate_weights <= remaining_weight\n\n        if np.any(feasible_items):\n            best_item_idx = np.argmax(candidate_values[feasible_items])\n            actual_idx = candidate_items[feasible_items][best_item_idx]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.909604645239646,
               -18.814088175738103
          ]
     }
]