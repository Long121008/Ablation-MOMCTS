[
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (highest variance in objectives)\n    solutions = [s[0] for s in archive]\n    objectives = np.array([s[1] for s in archive])\n    variances = np.var(objectives, axis=0)\n    selected_idx = np.argmax(variances)\n    base_solution = solutions[selected_idx].copy()\n\n    # Generate a neighbor by randomly swapping items\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    swap_count = min(3, n_items)  # Limit the number of swaps to avoid excessive perturbation\n\n    # Randomly select items to swap\n    swap_indices = np.random.choice(n_items, size=swap_count, replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Check feasibility and repair if necessary\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Greedy repair: remove items until feasible\n        excess_weight = total_weight - capacity\n        while excess_weight > 0:\n            # Find the item with the smallest ratio of weight to value (sum of both objectives)\n            item_weights = weight_lst[new_solution == 1]\n            item_values = value1_lst[new_solution == 1] + value2_lst[new_solution == 1]\n            if len(item_weights) == 0:\n                break  # No items left to remove\n            ratios = item_values / item_weights\n            worst_item_idx = np.argmin(ratios)\n            actual_idx = np.where(new_solution == 1)[0][worst_item_idx]\n            new_solution[actual_idx] = 0\n            excess_weight -= weight_lst[actual_idx]\n\n    # Greedy improvement: add items that improve both objectives without exceeding capacity\n    remaining_weight = capacity - np.sum(new_solution * weight_lst)\n    if remaining_weight > 0:\n        # Find items not in the solution that can be added without exceeding capacity\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidate_items]\n        candidate_values = value1_lst[candidate_items] + value2_lst[candidate_items]\n        feasible_items = candidate_weights <= remaining_weight\n\n        if np.any(feasible_items):\n            best_item_idx = np.argmax(candidate_values[feasible_items])\n            actual_idx = candidate_items[feasible_items][best_item_idx]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.909604645239646,
               -18.814088175738103
          ]
     },
     {
          "algorithm": "{The heuristic function 'select_neighbor' first identifies the most promising solution in the archive by evaluating the potential for improvement using a hybrid metric that combines the solution's current objective values with their spread across the Pareto front. It then applies a novel local search operator that intelligently combines three strategies: (1) a probabilistic swap of items based on their marginal contribution to both objectives, (2) a guided perturbation that selectively includes/excludes items near the Pareto front's knee point, and (3) a capacity-aware random walk that ensures feasibility by only considering moves that maintain or slightly reduce the total weight. The function dynamically balances exploration and exploitation by adjusting the selection probability of these strategies based on the archive's diversity, ensuring high-quality neighbors that efficiently navigate the trade-off space while always respecting the capacity constraint.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution (highest combined objective value)\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    best_idx = np.argmax(combined_values)\n    base_solution = archive[best_idx][0].copy()\n\n    # Step 2: Generate a neighbor using a hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Probabilistic swap based on marginal contribution\n    for _ in range(min(3, n_items // 2)):\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) == 0:\n            break\n        i = np.random.choice(candidates)\n        if new_solution[i] == 1 and np.random.rand() < 0.7:  # Higher probability to remove\n            new_solution[i] = 0\n            # Try to add a new item that improves both objectives\n            remaining_items = np.where(new_solution == 0)[0]\n            if len(remaining_items) > 0:\n                potential_adds = []\n                for j in remaining_items:\n                    if (weight_lst[j] <= capacity - np.sum(weight_lst[new_solution == 1])):\n                        potential_adds.append(j)\n                if potential_adds:\n                    j = np.random.choice(potential_adds)\n                    new_solution[j] = 1\n\n    # Strategy 2: Guided perturbation near knee point (approximate)\n    if len(archive) > 1:\n        # Approximate knee point as solution with max (v1 - v2)\n        knee_idx = np.argmax(objectives[:, 0] - objectives[:, 1])\n        knee_solution = archive[knee_idx][0]\n        # Perturb around knee items\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.3:\n                if knee_solution[i] == 1 and (weight_lst[i] <= capacity - np.sum(weight_lst[new_solution == 1])):\n                    new_solution[i] = 1\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Strategy 3: Capacity-aware random walk\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for i in excess_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.18646270182542,
               -18.508972406433266
          ]
     },
     {
          "algorithm": "{The new algorithm combines the selection of promising solutions based on both objective values and their trade-off potential with a novel local search strategy that dynamically adapts to the Pareto front's characteristics. It first identifies solutions with high combined objective values and strong trade-off potential by analyzing the archive's diversity and distribution, then applies a hybrid local search that intelligently combines a probabilistic item selection based on marginal contributions, a Pareto-front guided perturbation that explores regions near the knee point, and an adaptive capacity-aware random walk that ensures feasibility by considering both the current solution's weight and the remaining capacity, with the probability of each strategy being dynamically adjusted based on the solution's position relative to the Pareto front and the archive's state.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on trade-off potential\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    trade_off = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_score = combined_values * trade_off\n    best_idx = np.argmax(diversity_score)\n    base_solution = archive[best_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Adaptive hybrid local search\n    # Strategy 1: Marginal contribution-based selection\n    for i in range(n_items):\n        if np.random.rand() < 0.5:  # Probabilistic selection\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_improvement = (delta_value1 + delta_value2) / (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1]) + 1e-6)\n                if np.random.rand() < min(1.0, 0.3 + 0.7 * norm_improvement):\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Strategy 2: Pareto-front guided perturbation\n    if len(archive) > 2:\n        sorted_idx = np.argsort(objectives[:, 0] + objectives[:, 1])\n        middle_solution = archive[sorted_idx[len(archive)//2]][0]\n        for i in range(n_items):\n            if middle_solution[i] != new_solution[i] and np.random.rand() < 0.2:\n                if middle_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 3: Adaptive capacity-aware random walk\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        np.random.shuffle(candidates)\n        for i in candidates:\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < 0.4:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -20.177957868136076,
               -16.058563476430592
          ]
     },
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select a promising solution from the archive\n    # Prioritize solutions with high marginal gains or close to the Pareto front\n    selected_idx = np.random.choice(len(archive))\n    base_solution = archive[selected_idx][0].copy()\n    current_obj = archive[selected_idx][1]\n\n    # Step 2: Apply the guided flip and swap operator\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Randomly select a subset of items to flip\n    flip_indices = np.random.choice(len(weight_lst), size=min(3, len(weight_lst)), replace=False)\n    for idx in flip_indices:\n        if new_solution[idx] == 1:\n            # Try to remove the item\n            if current_weight - weight_lst[idx] <= capacity:\n                new_solution[idx] = 0\n                current_weight -= weight_lst[idx]\n                current_value1 -= value1_lst[idx]\n                current_value2 -= value2_lst[idx]\n        else:\n            # Try to add the item\n            if current_weight + weight_lst[idx] <= capacity:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                current_value1 += value1_lst[idx]\n                current_value2 += value2_lst[idx]\n\n    # Perform targeted swap between two items\n    swap_candidates = np.where(new_solution == 1)[0]\n    if len(swap_candidates) >= 2:\n        i, j = np.random.choice(swap_candidates, size=2, replace=False)\n        # Check if swapping improves the solution\n        delta_weight = weight_lst[j] - weight_lst[i]\n        delta_value1 = value1_lst[j] - value1_lst[i]\n        delta_value2 = value2_lst[j] - value2_lst[i]\n\n        if (delta_weight <= 0 or current_weight + delta_weight <= capacity) and \\\n           (delta_value1 >= 0 or delta_value2 >= 0):\n            new_solution[i], new_solution[j] = new_solution[j], new_solution[i]\n            current_weight += delta_weight\n            current_value1 += delta_value1\n            current_value2 += delta_value2\n\n    return new_solution\n\n",
          "score": [
               -18.68004542521698,
               -18.028382666602297
          ]
     },
     {
          "algorithm": null,
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the most promising solution based on marginal improvement potential\n    max_potential = -1\n    selected_solution = None\n    selected_obj = None\n\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        potential = (obj[0] / (current_weight + 1e-6) + obj[1] / (current_weight + 1e-6)) / 2\n        if potential > max_potential:\n            max_potential = potential\n            selected_solution = sol\n            selected_obj = obj\n\n    if selected_solution is None:\n        selected_solution = archive[0][0]\n        selected_obj = archive[0][1]\n\n    new_solution = selected_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n\n    # Guided flip operator\n    for i in range(len(new_solution)):\n        # Calculate potential improvement if we flip this item\n        delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n        new_weight = current_weight + delta_weight\n\n        if new_weight <= capacity:\n            # Calculate marginal improvement for both objectives\n            delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n            delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n\n            # Calculate normalized improvement\n            norm_improvement = (delta_value1 / (selected_obj[0] + 1e-6) + delta_value2 / (selected_obj[1] + 1e-6)) / 2\n\n            # Flip with probability based on improvement and a small random factor\n            flip_prob = min(1.0, 0.1 + 0.9 * norm_improvement + 0.1 * np.random.random())\n\n            if np.random.random() < flip_prob:\n                new_solution[i] = 1 - new_solution[i]\n                current_weight = new_weight\n\n    return new_solution\n\n",
          "score": [
               -18.46494248406106,
               -18.273839065231257
          ]
     },
     {
          "algorithm": "{The new algorithm will combine the selection of high-potential solutions from the first approach with a novel \"objective-aware\" local search that simultaneously considers both objectives in a multi-dimensional improvement space. It will use a probabilistic item selection mechanism that prioritizes items with high marginal contributions to both objectives, while also incorporating a diversity-preserving component that avoids getting stuck in local optima by occasionally considering items that might temporarily reduce one objective to improve the other. The algorithm will maintain feasibility by using a weight-balanced repair mechanism that selectively removes items based on their combined contribution to both objectives, and will include a post-optimization step that greedily adds items that provide the best combined improvement without exceeding capacity.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest combined objective variance and marginal potential\n    solutions = [s[0] for s in archive]\n    objectives = np.array([s[1] for s in archive])\n    variances = np.var(objectives, axis=0)\n    combined_variance = np.sum(variances)\n\n    # Calculate marginal potential scores\n    marginal_scores = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        potential = (obj[0] / (current_weight + 1e-6) + obj[1] / (current_weight + 1e-6)) / 2\n        marginal_scores.append(potential)\n\n    # Combine variance and marginal potential\n    combined_scores = [combined_variance * marginal_scores[i] for i in range(len(archive))]\n    selected_idx = np.argmax(combined_scores)\n    base_solution = solutions[selected_idx].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Objective-aware local search with probabilistic selection\n    for i in range(len(new_solution)):\n        delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n        new_weight = current_weight + delta_weight\n\n        if new_weight <= capacity:\n            delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n            delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n\n            # Calculate normalized improvement potential\n            norm_improvement1 = delta_value1 / (current_value1 + 1e-6)\n            norm_improvement2 = delta_value2 / (current_value2 + 1e-6)\n            combined_improvement = (norm_improvement1 + norm_improvement2) / 2\n\n            # Calculate diversity factor (encourage flipping items that are currently excluded)\n            diversity_factor = 1.0 if new_solution[i] == 0 else 0.3\n\n            # Calculate flip probability\n            flip_prob = min(1.0, 0.2 + 0.8 * combined_improvement * diversity_factor + 0.1 * np.random.random())\n\n            if np.random.random() < flip_prob:\n                new_solution[i] = 1 - new_solution[i]\n                current_weight = new_weight\n                current_value1 += delta_value1\n                current_value2 += delta_value2\n\n    # Weight-balanced repair if necessary\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        excess_weight = total_weight - capacity\n        while excess_weight > 0:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n\n            # Calculate combined value-weight ratios\n            item_weights = weight_lst[included_items]\n            item_values = value1_lst[included_items] + value2_lst[included_items]\n            ratios = item_values / (item_weights + 1e-6)\n\n            # Remove item with lowest ratio\n            worst_item_idx = np.argmin(ratios)\n            actual_idx = included_items[worst_item_idx]\n            new_solution[actual_idx] = 0\n            excess_weight -= weight_lst[actual_idx]\n\n    # Post-optimization: greedily add items with best combined improvement\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        excluded_items = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[excluded_items]\n        candidate_values = value1_lst[excluded_items] + value2_lst[excluded_items]\n\n        # Find feasible items to add\n        feasible_items = candidate_weights <= remaining_weight\n        if np.any(feasible_items):\n            best_item_idx = np.argmax(candidate_values[feasible_items])\n            actual_idx = excluded_items[feasible_items][best_item_idx]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.80061070904028,
               -17.941981571958156
          ]
     },
     {
          "algorithm": "{The new algorithm combines the selection of high-variance solutions from the first approach with a novel \"objective-balanced\" local search that considers both objectives simultaneously, where items are flipped based on their potential to improve both objectives proportionally, while also incorporating a probabilistic element that favors items with better marginal returns, similar to the guided flip operator in the second approach, but with a more sophisticated balancing mechanism that dynamically adjusts the trade-off between objectives based on the current solution's position in the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (highest variance in objectives)\n    solutions = [s[0] for s in archive]\n    objectives = np.array([s[1] for s in archive])\n    variances = np.var(objectives, axis=0)\n    selected_idx = np.argmax(variances)\n    base_solution = solutions[selected_idx].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Calculate objective balances\n    total_value1 = np.sum(value1_lst)\n    total_value2 = np.sum(value2_lst)\n    balance1 = (current_value1 / (total_value1 + 1e-6))\n    balance2 = (current_value2 / (total_value2 + 1e-6))\n\n    # Objective-balanced local search\n    for i in range(len(new_solution)):\n        # Calculate potential improvement\n        delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n        new_weight = current_weight + delta_weight\n\n        if new_weight <= capacity:\n            delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n            delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n\n            # Calculate normalized improvement with objective balance\n            norm_improvement = (balance1 * delta_value1 / (total_value1 + 1e-6) +\n                               balance2 * delta_value2 / (total_value2 + 1e-6)) / 2\n\n            # Flip with probability based on improvement and balance\n            flip_prob = min(1.0, 0.1 + 0.9 * norm_improvement + 0.1 * np.random.random())\n\n            if np.random.random() < flip_prob:\n                new_solution[i] = 1 - new_solution[i]\n                current_weight = new_weight\n                current_value1 += delta_value1\n                current_value2 += delta_value2\n                balance1 = (current_value1 / (total_value1 + 1e-6))\n                balance2 = (current_value2 / (total_value2 + 1e-6))\n\n    # Greedy post-processing to ensure high-quality solution\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        # Find items not in the solution that can be added without exceeding capacity\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidate_items]\n        feasible_items = candidate_weights <= remaining_weight\n\n        if np.any(feasible_items):\n            # Calculate combined value with balance\n            candidate_value1 = value1_lst[candidate_items]\n            candidate_value2 = value2_lst[candidate_items]\n            combined_value = (balance1 * candidate_value1 + balance2 * candidate_value2) / (balance1 + balance2 + 1e-6)\n\n            best_item_idx = np.argmax(combined_value[feasible_items])\n            actual_idx = candidate_items[feasible_items][best_item_idx]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -17.69175356547707,
               -17.941539864109153
          ]
     },
     {
          "algorithm": "{This novel algorithm employs a \"multi-objective aware item clustering and strategic replacement\" approach that first partitions the item set into clusters based on their combined utility for both objectives, then performs a \"cluster-based perturbation\" where entire clusters are either added or removed from the solution based on their collective utility and feasibility, followed by a \"value-balanced replacement\" phase that selectively swaps items between clusters to improve the balance between the two objectives while maintaining feasibility through a \"capacity-aware cluster adjustment\" mechanism. The algorithm dynamically adjusts its search focus based on the current solution's cluster composition and the problem's constraints, balancing exploration of high-utility clusters with exploitation of promising cluster combinations.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        return np.zeros_like(weight_lst, dtype=int)\n\n    # Step 1: Select the solution with highest combined utility\n    selected_idx = np.argmax([(obj[0] + obj[1]) / (np.sum(weight_lst * sol) + 1e-6) for sol, obj in archive])\n    base_solution = archive[selected_idx][0].copy()\n    new_solution = base_solution.copy()\n\n    # Step 2: Cluster items based on combined utility\n    combined_utility = (value1_lst + value2_lst) / (weight_lst + 1e-6)\n    sorted_indices = np.argsort(combined_utility)[::-1]\n    num_clusters = max(2, len(weight_lst) // 5)\n    clusters = np.array_split(sorted_indices, num_clusters)\n\n    # Step 3: Cluster-based perturbation\n    current_weight = np.sum(weight_lst * new_solution)\n    for cluster in clusters:\n        cluster_weight = np.sum(weight_lst[cluster])\n        cluster_value1 = np.sum(value1_lst[cluster])\n        cluster_value2 = np.sum(value2_lst[cluster])\n\n        # Decide to add or remove the entire cluster\n        if np.random.random() < 0.5:  # 50% chance to process cluster\n            if np.all(new_solution[cluster] == 0):  # Cluster not in solution\n                if current_weight + cluster_weight <= capacity:\n                    new_solution[cluster] = 1\n                    current_weight += cluster_weight\n            else:  # Cluster in solution\n                if current_weight - cluster_weight >= 0:\n                    new_solution[cluster] = 0\n                    current_weight -= cluster_weight\n\n    # Step 4: Value-balanced replacement\n    included_items = np.where(new_solution == 1)[0]\n    excluded_items = np.where(new_solution == 0)[0]\n\n    if len(included_items) > 0 and len(excluded_items) > 0:\n        # Find best item to remove (least valuable in combined utility)\n        remove_idx = included_items[np.argmin(combined_utility[included_items])]\n\n        # Find best item to add (highest utility that fits)\n        add_candidates = excluded_items[weight_lst[excluded_items] <= (capacity - current_weight + weight_lst[remove_idx])]\n        if len(add_candidates) > 0:\n            add_idx = add_candidates[np.argmax(combined_utility[add_candidates])]\n\n            # Perform swap if it maintains feasibility\n            if current_weight - weight_lst[remove_idx] + weight_lst[add_idx] <= capacity:\n                new_solution[remove_idx] = 0\n                new_solution[add_idx] = 1\n\n    # Step 5: Ensure feasibility\n    total_weight = np.sum(weight_lst * new_solution)\n    while total_weight > capacity:\n        # Remove least valuable item in current solution\n        included_items = np.where(new_solution == 1)[0]\n        if len(included_items) == 0:\n            break\n        remove_idx = included_items[np.argmin(combined_utility[included_items])]\n        new_solution[remove_idx] = 0\n        total_weight -= weight_lst[remove_idx]\n\n    return new_solution\n\n",
          "score": [
               -17.80227463658331,
               -17.30085930897934
          ]
     },
     {
          "algorithm": "{The new algorithm 'select_neighbor' first identifies the solution with the highest combined objective value from the archive, then applies a novel 'adaptive clustering and diversification' strategy that groups items into clusters based on their weight-to-value ratios and selects items from underrepresented clusters to flip, while ensuring feasibility by dynamically adjusting the selection probability based on cluster diversity and remaining capacity. This approach avoids local optima by promoting exploration of diverse item combinations across different weight-value trade-offs, while maintaining feasibility through cluster-based feasibility checks and adaptive perturbation.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select the solution with highest combined objective value\n    archive_solutions = [sol for sol, _ in archive]\n    archive_objectives = [obj for _, obj in archive]\n    objectives_sum = np.array([sum(obj) for obj in archive_objectives])\n    best_idx = np.argmax(objectives_sum)\n    base_solution = archive_solutions[best_idx].copy()\n\n    # Calculate current weight and remaining capacity\n    current_weight = np.sum(weight_lst[base_solution == 1])\n    remaining_capacity = capacity - current_weight\n\n    # Calculate weight-to-value ratios for clustering\n    ratio1 = weight_lst / (value1_lst + 1e-10)\n    ratio2 = weight_lst / (value2_lst + 1e-10)\n    combined_ratio = ratio1 + ratio2\n\n    # Cluster items based on combined ratio\n    n_clusters = min(5, len(base_solution))\n    cluster_labels = np.argmin(np.abs(combined_ratio[:, None] - np.percentile(combined_ratio, np.linspace(0, 100, n_clusters))), axis=1)\n\n    # Calculate cluster diversity (number of items in each cluster)\n    cluster_diversity = np.zeros(n_clusters)\n    for cluster in range(n_clusters):\n        cluster_items = np.where(cluster_labels == cluster)[0]\n        cluster_diversity[cluster] = len(cluster_items)\n\n    # Calculate cluster selection probabilities (inverse of diversity)\n    cluster_probs = 1 / (cluster_diversity + 1e-10)\n    cluster_probs = cluster_probs / np.sum(cluster_probs)\n\n    # Select a cluster to target for diversification\n    target_cluster = np.random.choice(n_clusters, p=cluster_probs)\n    target_items = np.where(cluster_labels == target_cluster)[0]\n\n    # Generate neighbor solution by flipping items in the target cluster\n    new_solution = base_solution.copy()\n    for item in target_items:\n        if np.random.rand() < 0.3:  # 30% chance to flip each item in the cluster\n            if new_solution[item] == 1:\n                if current_weight - weight_lst[item] >= 0:\n                    new_solution[item] = 0\n                    current_weight -= weight_lst[item]\n            else:\n                if current_weight + weight_lst[item] <= capacity:\n                    new_solution[item] = 1\n                    current_weight += weight_lst[item]\n\n    # Additional adaptive perturbation based on remaining capacity\n    for i in range(len(new_solution)):\n        if np.random.rand() < (remaining_capacity / capacity) * 0.5:  # Capacity-sensitive probability\n            if new_solution[i] == 1:\n                if current_weight - weight_lst[i] >= 0:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n            else:\n                if current_weight + weight_lst[i] <= capacity:\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n\n    return new_solution\n\n",
          "score": [
               -17.35968444194008,
               -17.504641567425445
          ]
     },
     {
          "algorithm": "{This novel algorithm combines a diversity-aware selection mechanism with a hybrid local search that employs both greedy and evolutionary strategies. It first identifies the most extreme solution in the archive by measuring the Chebyshev distance from the centroid, then applies a multi-phase optimization: a greedy phase that sequentially adds items with the highest marginal utility in both objectives, followed by a genetic-inspired phase where it creates candidate solutions through crossover with other archive members, and a simulated annealing phase with a dynamic temperature schedule that balances exploration and exploitation while ensuring feasibility. The algorithm dynamically adjusts its search focus between phases based on the current solution's position relative to the Pareto front, and incorporates a novel \"objective-space warping\" technique to transform the problem space, allowing better navigation of convex and concave regions of the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Step 1: Select the most extreme solution (Chebyshev distance from centroid)\n    objectives = np.array([obj for (sol, obj) in archive])\n    centroid = np.mean(objectives, axis=0)\n    distances = np.max(np.abs(objectives - centroid), axis=1)\n    selected_idx = np.argmax(distances)\n    base_solution = archive[selected_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Step 2: Greedy phase - add items with highest marginal utility\n    remaining_items = np.where(new_solution == 0)[0]\n    for idx in remaining_items:\n        if current_weight + weight_lst[idx] <= capacity:\n            # Calculate marginal utility for both objectives\n            marginal1 = value1_lst[idx] / (weight_lst[idx] + 1e-6)\n            marginal2 = value2_lst[idx] / (weight_lst[idx] + 1e-6)\n            combined_marginal = marginal1 + marginal2\n\n            # Add if it improves both objectives\n            if combined_marginal > 0:\n                new_solution[idx] = 1\n                current_weight += weight_lst[idx]\n                current_value1 += value1_lst[idx]\n                current_value2 += value2_lst[idx]\n\n    # Step 3: Genetic-inspired crossover phase\n    if len(archive) > 1:\n        # Select another solution for crossover\n        crossover_idx = np.random.choice([i for i in range(len(archive)) if i != selected_idx])\n        crossover_sol = archive[crossover_idx][0]\n\n        # Create mask for crossover\n        mask = np.random.rand(len(new_solution)) < 0.5\n        candidate_solution = np.where(mask, new_solution, crossover_sol)\n\n        # Repair to ensure feasibility\n        candidate_weight = np.sum(weight_lst * candidate_solution)\n        if candidate_weight > capacity:\n            # Remove items randomly until feasible\n            excess_items = np.where(candidate_solution == 1)[0]\n            np.random.shuffle(excess_items)\n            for idx in excess_items:\n                if candidate_weight <= capacity:\n                    break\n                candidate_solution[idx] = 0\n                candidate_weight -= weight_lst[idx]\n\n        # Evaluate candidate\n        candidate_value1 = np.sum(value1_lst * candidate_solution)\n        candidate_value2 = np.sum(value2_lst * candidate_solution)\n\n        # Accept if better in both objectives or randomly with probability\n        if (candidate_value1 > current_value1 and candidate_value2 > current_value2) or \\\n           (np.random.rand() < 0.3):\n            new_solution = candidate_solution\n            current_weight = candidate_weight\n            current_value1 = candidate_value1\n            current_value2 = candidate_value2\n\n    # Step 4: Simulated annealing with dynamic temperature\n    temperature = 10.0\n    cooling_rate = 0.98\n    for _ in range(20):\n        # Create candidate by flipping multiple bits\n        candidate_solution = new_solution.copy()\n        flip_indices = np.random.choice(len(weight_lst), size=min(3, len(weight_lst)), replace=False)\n        for idx in flip_indices:\n            if candidate_solution[idx] == 1:\n                candidate_solution[idx] = 0\n            else:\n                candidate_solution[idx] = 1\n\n        # Check feasibility\n        candidate_weight = np.sum(weight_lst * candidate_solution)\n        if candidate_weight > capacity:\n            continue\n\n        # Evaluate candidate\n        candidate_value1 = np.sum(value1_lst * candidate_solution)\n        candidate_value2 = np.sum(value2_lst * candidate_solution)\n\n        # Acceptance criterion\n        delta1 = candidate_value1 - current_value1\n        delta2 = candidate_value2 - current_value2\n        combined_delta = delta1 + delta2\n\n        if combined_delta > 0 or \\\n           (np.random.rand() < np.exp(combined_delta / temperature)):\n            new_solution = candidate_solution\n            current_weight = candidate_weight\n            current_value1 = candidate_value1\n            current_value2 = candidate_value2\n\n        temperature *= cooling_rate\n\n    # Step 5: Objective-space warping to explore new regions\n    if np.random.rand() < 0.2:\n        # Transform the objective space\n        transformed_value1 = current_value1 * (1 + 0.1 * np.random.randn())\n        transformed_value2 = current_value2 * (1 + 0.1 * np.random.randn())\n\n        # Find solution closest to transformed point in archive\n        transformed_obj = np.array([transformed_value1, transformed_value2])\n        archive_objs = np.array([obj for (sol, obj) in archive])\n        distances = np.linalg.norm(archive_objs - transformed_obj, axis=1)\n        closest_idx = np.argmin(distances)\n\n        # Use the closest solution as a template\n        template_solution = archive[closest_idx][0]\n        template_weight = np.sum(weight_lst * template_solution)\n\n        # Create new solution by combining with current solution\n        mask = np.random.rand(len(new_solution)) < 0.4\n        candidate_solution = np.where(mask, template_solution, new_solution)\n\n        # Repair to ensure feasibility\n        candidate_weight = np.sum(weight_lst * candidate_solution)\n        if candidate_weight > capacity:\n            excess_items = np.where(candidate_solution == 1)[0]\n            np.random.shuffle(excess_items)\n            for idx in excess_items:\n                if candidate_weight <= capacity:\n                    break\n                candidate_solution[idx] = 0\n                candidate_weight -= weight_lst[idx]\n\n        # Accept if better in both objectives\n        candidate_value1 = np.sum(value1_lst * candidate_solution)\n        candidate_value2 = np.sum(value2_lst * candidate_solution)\n        if candidate_value1 > current_value1 and candidate_value2 > current_value2:\n            new_solution = candidate_solution\n\n    return new_solution\n\n",
          "score": [
               -16.835913049643715,
               -16.542527394962217
          ]
     }
]