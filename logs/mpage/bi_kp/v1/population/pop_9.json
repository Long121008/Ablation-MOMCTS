[
     {
          "algorithm": "{}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty.\")\n\n    # Select a solution with high potential for improvement (highest variance in objectives)\n    solutions = [s[0] for s in archive]\n    objectives = np.array([s[1] for s in archive])\n    variances = np.var(objectives, axis=0)\n    selected_idx = np.argmax(variances)\n    base_solution = solutions[selected_idx].copy()\n\n    # Generate a neighbor by randomly swapping items\n    new_solution = base_solution.copy()\n    n_items = len(new_solution)\n    swap_count = min(3, n_items)  # Limit the number of swaps to avoid excessive perturbation\n\n    # Randomly select items to swap\n    swap_indices = np.random.choice(n_items, size=swap_count, replace=False)\n    for idx in swap_indices:\n        new_solution[idx] = 1 - new_solution[idx]  # Flip the bit\n\n    # Check feasibility and repair if necessary\n    total_weight = np.sum(new_solution * weight_lst)\n    if total_weight > capacity:\n        # Greedy repair: remove items until feasible\n        excess_weight = total_weight - capacity\n        while excess_weight > 0:\n            # Find the item with the smallest ratio of weight to value (sum of both objectives)\n            item_weights = weight_lst[new_solution == 1]\n            item_values = value1_lst[new_solution == 1] + value2_lst[new_solution == 1]\n            if len(item_weights) == 0:\n                break  # No items left to remove\n            ratios = item_values / item_weights\n            worst_item_idx = np.argmin(ratios)\n            actual_idx = np.where(new_solution == 1)[0][worst_item_idx]\n            new_solution[actual_idx] = 0\n            excess_weight -= weight_lst[actual_idx]\n\n    # Greedy improvement: add items that improve both objectives without exceeding capacity\n    remaining_weight = capacity - np.sum(new_solution * weight_lst)\n    if remaining_weight > 0:\n        # Find items not in the solution that can be added without exceeding capacity\n        candidate_items = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidate_items]\n        candidate_values = value1_lst[candidate_items] + value2_lst[candidate_items]\n        feasible_items = candidate_weights <= remaining_weight\n\n        if np.any(feasible_items):\n            best_item_idx = np.argmax(candidate_values[feasible_items])\n            actual_idx = candidate_items[feasible_items][best_item_idx]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.909604645239646,
               -18.814088175738103
          ]
     },
     {
          "algorithm": "{The heuristic function 'select_neighbor' first identifies the most promising solution in the archive by evaluating the potential for improvement using a hybrid metric that combines the solution's current objective values with their spread across the Pareto front. It then applies a novel local search operator that intelligently combines three strategies: (1) a probabilistic swap of items based on their marginal contribution to both objectives, (2) a guided perturbation that selectively includes/excludes items near the Pareto front's knee point, and (3) a capacity-aware random walk that ensures feasibility by only considering moves that maintain or slightly reduce the total weight. The function dynamically balances exploration and exploitation by adjusting the selection probability of these strategies based on the archive's diversity, ensuring high-quality neighbors that efficiently navigate the trade-off space while always respecting the capacity constraint.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution (highest combined objective value)\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    best_idx = np.argmax(combined_values)\n    base_solution = archive[best_idx][0].copy()\n\n    # Step 2: Generate a neighbor using a hybrid local search\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n\n    # Strategy 1: Probabilistic swap based on marginal contribution\n    for _ in range(min(3, n_items // 2)):\n        candidates = np.where(new_solution == 1)[0]\n        if len(candidates) == 0:\n            break\n        i = np.random.choice(candidates)\n        if new_solution[i] == 1 and np.random.rand() < 0.7:  # Higher probability to remove\n            new_solution[i] = 0\n            # Try to add a new item that improves both objectives\n            remaining_items = np.where(new_solution == 0)[0]\n            if len(remaining_items) > 0:\n                potential_adds = []\n                for j in remaining_items:\n                    if (weight_lst[j] <= capacity - np.sum(weight_lst[new_solution == 1])):\n                        potential_adds.append(j)\n                if potential_adds:\n                    j = np.random.choice(potential_adds)\n                    new_solution[j] = 1\n\n    # Strategy 2: Guided perturbation near knee point (approximate)\n    if len(archive) > 1:\n        # Approximate knee point as solution with max (v1 - v2)\n        knee_idx = np.argmax(objectives[:, 0] - objectives[:, 1])\n        knee_solution = archive[knee_idx][0]\n        # Perturb around knee items\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.3:\n                if knee_solution[i] == 1 and (weight_lst[i] <= capacity - np.sum(weight_lst[new_solution == 1])):\n                    new_solution[i] = 1\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        # Strategy 3: Capacity-aware random walk\n        excess = current_weight - capacity\n        excess_items = np.where(new_solution == 1)[0]\n        np.random.shuffle(excess_items)\n        for i in excess_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.18646270182542,
               -18.508972406433266
          ]
     },
     {
          "algorithm": "{The new algorithm combines the selection of promising solutions based on both objective values and their trade-off potential with a novel local search strategy that dynamically adapts to the Pareto front's characteristics. It first identifies solutions with high combined objective values and strong trade-off potential by analyzing the archive's diversity and distribution, then applies a hybrid local search that intelligently combines a probabilistic item selection based on marginal contributions, a Pareto-front guided perturbation that explores regions near the knee point, and an adaptive capacity-aware random walk that ensures feasibility by considering both the current solution's weight and the remaining capacity, with the probability of each strategy being dynamically adjusted based on the solution's position relative to the Pareto front and the archive's state.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on trade-off potential\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    trade_off = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_score = combined_values * trade_off\n    best_idx = np.argmax(diversity_score)\n    base_solution = archive[best_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Adaptive hybrid local search\n    # Strategy 1: Marginal contribution-based selection\n    for i in range(n_items):\n        if np.random.rand() < 0.5:  # Probabilistic selection\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_improvement = (delta_value1 + delta_value2) / (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1]) + 1e-6)\n                if np.random.rand() < min(1.0, 0.3 + 0.7 * norm_improvement):\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Strategy 2: Pareto-front guided perturbation\n    if len(archive) > 2:\n        sorted_idx = np.argsort(objectives[:, 0] + objectives[:, 1])\n        middle_solution = archive[sorted_idx[len(archive)//2]][0]\n        for i in range(n_items):\n            if middle_solution[i] != new_solution[i] and np.random.rand() < 0.2:\n                if middle_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 3: Adaptive capacity-aware random walk\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        np.random.shuffle(candidates)\n        for i in candidates:\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < 0.4:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -20.177957868136076,
               -16.058563476430592
          ]
     },
     {
          "algorithm": "{The new algorithm combines the selection of promising solutions based on their potential for improvement with a novel local search strategy that dynamically adapts to the Pareto front's characteristics. It first identifies solutions with high combined objective values and strong trade-off potential by analyzing the archive's diversity and distribution, then applies a hybrid local search that intelligently combines a probabilistic item selection based on marginal contributions, a Pareto-front guided perturbation that explores regions near the knee point, and an adaptive capacity-aware random walk that ensures feasibility by considering both the current solution's weight and the remaining capacity, with the probability of each strategy being dynamically adjusted based on the solution's position relative to the Pareto front and the archive's state. Additionally, it incorporates a novel \"objective-balanced\" perturbation that selectively flips items based on their contribution to both objectives, a \"frontier-aware\" swap that prioritizes items near the Pareto frontier, and a \"capacity-sensitive\" mutation that ensures feasibility by only considering moves that maintain or slightly reduce the total weight, while dynamically balancing exploration and exploitation by adjusting the selection probability of these strategies based on the archive's diversity and the current solution's position relative to the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on combined objective values and trade-off potential\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    trade_off = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_score = combined_values * trade_off\n    best_idx = np.argmax(diversity_score)\n    base_solution = archive[best_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-balanced perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_improvement = (delta_value1 + delta_value2) / (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1]) + 1e-6)\n                if np.random.rand() < min(1.0, 0.4 + 0.6 * norm_improvement):\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware swap\n    if len(archive) > 2:\n        sorted_idx = np.argsort(objectives[:, 0] + objectives[:, 1])\n        middle_solution = archive[sorted_idx[len(archive)//2]][0]\n        for i in range(n_items):\n            if middle_solution[i] != new_solution[i] and np.random.rand() < 0.3:\n                if middle_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-sensitive mutation\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        np.random.shuffle(candidates)\n        for i in candidates:\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < 0.5:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.947542615525425,
               -16.70845019108186
          ]
     },
     {
          "algorithm": "{The new algorithm introduces a multi-phase evolutionary perturbation strategy that first selects solutions based on their normalized objective diversity and current weight utilization, then applies a four-stage transformation: (1) a probabilistic item inversion based on both objectives' marginal contributions weighted by their normalized objective distances, (2) a Pareto-aware item replacement that considers the solution's position relative to the extreme points of the Pareto front, (3) a dynamic capacity-aware perturbation that explores weight-sensitive regions while maintaining feasibility through an adaptive weight adjustment mechanism, and (4) a final greedy refinement phase that adds the most promising items that improve both objectives while respecting capacity constraints. The algorithm dynamically balances exploration and exploitation by adjusting the intensity of each transformation phase based on the solution's current position in the objective space and the archive's diversity, ensuring diverse and high-quality neighbors that efficiently navigate the trade-off space while always respecting capacity constraints.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    objectives = np.array([obj for (sol, obj) in archive])\n    n_items = len(weight_lst)\n\n    # Step 1: Select solution based on normalized diversity and weight utilization\n    max_values = objectives.max(axis=0)\n    min_values = objectives.min(axis=0)\n    diversity_scores = np.prod((objectives - min_values) / (max_values - min_values + 1e-6), axis=1)\n    current_weights = np.array([np.sum(weight_lst[sol[0] == 1]) for sol in archive])\n    weight_utilization = current_weights / capacity\n    selection_scores = diversity_scores * (1 - weight_utilization)\n    best_idx = np.argmax(selection_scores)\n    base_solution = archive[best_idx][0].copy()\n    new_solution = base_solution.copy()\n    current_weight = current_weights[best_idx]\n\n    # Step 2: Phase 1 - Probabilistic marginal contribution inversion\n    for i in range(n_items):\n        if np.random.rand() < 0.3:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_distance = np.sqrt((delta_value1 / (max_values[0] - min_values[0] + 1e-6))**2 +\n                                      (delta_value2 / (max_values[1] - min_values[1] + 1e-6))**2)\n                if np.random.rand() < min(1.0, 0.1 + 0.9 * norm_distance):\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Phase 2 - Pareto-aware item replacement\n    if len(archive) > 1:\n        extreme_idx = np.argmax(objectives[:, 0] - objectives[:, 1])\n        extreme_solution = archive[extreme_idx][0]\n        for i in range(n_items):\n            if extreme_solution[i] != new_solution[i] and np.random.rand() < 0.4:\n                if extreme_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Phase 3 - Adaptive capacity-aware perturbation\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = value1_lst[candidates] + value2_lst[candidates]\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            feasible_candidates = candidates[feasible]\n            np.random.shuffle(feasible_candidates)\n            for i in feasible_candidates:\n                if np.random.rand() < 0.6 * (1 - current_weight / capacity):\n                    new_solution[i] = 1\n                    remaining_capacity -= weight_lst[i]\n                    if remaining_capacity <= 0:\n                        break\n\n    # Step 5: Phase 4 - Greedy refinement\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[candidates]\n        candidate_values = (value1_lst[candidates] / (max_values[0] + 1e-6) +\n                           value2_lst[candidates] / (max_values[1] + 1e-6)) / 2\n        feasible = candidate_weights <= remaining_capacity\n        if np.any(feasible):\n            best_item = np.argmax(candidate_values[feasible])\n            actual_idx = candidates[feasible][best_item]\n            new_solution[actual_idx] = 1\n\n    # Ensure feasibility\n    current_weight = np.sum(weight_lst[new_solution == 1])\n    if current_weight > capacity:\n        excess_items = np.where(new_solution == 1)[0]\n        item_values = (value1_lst[excess_items] + value2_lst[excess_items]) / weight_lst[excess_items]\n        sorted_items = excess_items[np.argsort(item_values)]\n        excess = current_weight - capacity\n        for i in sorted_items:\n            if weight_lst[i] <= excess:\n                new_solution[i] = 0\n                excess -= weight_lst[i]\n                if excess <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -19.595826509324745,
               -17.803494672315733
          ]
     },
     {
          "algorithm": "{The new algorithm combines the selection of promising solutions based on both objective values and their trade-off potential with an innovative local search strategy that dynamically adapts to the Pareto front's characteristics. It first identifies solutions with high combined objective values and strong trade-off potential by analyzing the archive's diversity and distribution, then applies a hybrid local search that intelligently combines a probabilistic item selection based on marginal contributions, a Pareto-front guided perturbation that explores regions near the knee point, and an adaptive capacity-aware random walk that ensures feasibility by considering both the current solution's weight and the remaining capacity, with the probability of each strategy being dynamically adjusted based on the solution's position relative to the Pareto front and the archive's state. Additionally, it incorporates a novel \"objective-balanced\" perturbation that selectively flips items based on their contribution to both objectives, a \"frontier-aware\" swap that prioritizes items near the Pareto frontier, a \"capacity-sensitive\" mutation that ensures feasibility by only considering moves that maintain or slightly reduce the total weight, and a \"trade-off exploration\" strategy that dynamically balances exploration and exploitation by adjusting the selection probability of these strategies based on the archive's diversity and the current solution's position relative to the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on trade-off potential\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    trade_off = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_score = combined_values * trade_off\n    best_idx = np.argmax(diversity_score)\n    base_solution = archive[best_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-balanced perturbation\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_improvement = (delta_value1 + delta_value2) / (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1]) + 1e-6)\n                if np.random.rand() < min(1.0, 0.4 + 0.6 * norm_improvement):\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware swap\n    if len(archive) > 2:\n        sorted_idx = np.argsort(objectives[:, 0] + objectives[:, 1])\n        middle_solution = archive[sorted_idx[len(archive)//2]][0]\n        for i in range(n_items):\n            if middle_solution[i] != new_solution[i] and np.random.rand() < 0.3:\n                if middle_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-sensitive mutation\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        np.random.shuffle(candidates)\n        for i in candidates:\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < 0.5:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Step 5: Trade-off exploration\n    if np.random.rand() < 0.2:\n        knee_point = np.argmin(np.abs(objectives[:, 0] - objectives[:, 1]))\n        knee_solution = archive[knee_point][0]\n        for i in range(n_items):\n            if knee_solution[i] != new_solution[i] and np.random.rand() < 0.25:\n                if knee_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    return new_solution\n\n",
          "score": [
               -19.884969883685827,
               -16.87483320697015
          ]
     },
     {
          "algorithm": "{The new algorithm combines the selection of promising solutions based on their potential for improvement with a novel local search strategy that dynamically adapts to the Pareto front's characteristics. It first identifies solutions with high combined objective values and strong trade-off potential by analyzing the archive's diversity and distribution, then applies a hybrid local search that intelligently combines a probabilistic item selection based on marginal contributions, a Pareto-front guided perturbation that explores regions near the knee point, and an adaptive capacity-aware random walk that ensures feasibility by considering both the current solution's weight and the remaining capacity, with the probability of each strategy being dynamically adjusted based on the solution's position relative to the Pareto front and the archive's state. Additionally, it incorporates a novel \"objective-balanced\" perturbation that selectively flips items based on their contribution to both objectives, a \"frontier-aware\" swap that prioritizes items near the Pareto frontier, and a \"capacity-sensitive\" mutation that ensures feasibility by only considering moves that maintain or slightly reduce the total weight, while dynamically balancing exploration and exploitation by adjusting the selection probability of these strategies based on the archive's diversity and the current solution's position relative to the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on combined objective values and trade-off potential\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    trade_off = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_score = combined_values * trade_off\n    best_idx = np.argmax(diversity_score)\n    base_solution = archive[best_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-balanced perturbation with adaptive probability\n    for i in range(n_items):\n        if np.random.rand() < 0.6:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_improvement = (delta_value1 + delta_value2) / (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1]) + 1e-6)\n                prob = min(1.0, 0.3 + 0.7 * norm_improvement)\n                if np.random.rand() < prob:\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware swap with diversity consideration\n    if len(archive) > 2:\n        sorted_idx = np.argsort(objectives[:, 0] + objectives[:, 1])\n        middle_solution = archive[sorted_idx[len(archive)//2]][0]\n        for i in range(n_items):\n            if middle_solution[i] != new_solution[i] and np.random.rand() < 0.4:\n                if middle_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-sensitive mutation with neighborhood exploration\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        np.random.shuffle(candidates)\n        for i in candidates:\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < 0.6:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    return new_solution\n\n",
          "score": [
               -20.155008528462808,
               -16.602233713932996
          ]
     },
     {
          "algorithm": "{The new algorithm will combine the selection of high-potential solutions from the first approach with a novel \"adaptive objective balancing\" local search that dynamically adjusts the importance of each objective based on their current marginal contributions, while incorporating a \"diversity-aware\" flip mechanism that probabilistically explores both inclusion and exclusion of items with varying degrees of influence on the objectives. It will use a \"weight-constrained\" probabilistic selection process that prioritizes items with favorable trade-offs between objectives and weight, and will include a \"multi-phase\" repair mechanism that first removes items with the least combined value-weight ratio and then greedily adds items that provide the best balanced improvement in both objectives without exceeding capacity.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Select solution with highest adaptive objective balance score\n    solutions = [s[0] for s in archive]\n    objectives = np.array([s[1] for s in archive])\n\n    # Calculate adaptive weights based on current objective distribution\n    obj1_mean, obj2_mean = np.mean(objectives, axis=0)\n    obj1_std, obj2_std = np.std(objectives, axis=0)\n\n    adaptive_weights = np.array([obj2_std / (obj1_std + obj2_std + 1e-6), obj1_std / (obj1_std + obj2_std + 1e-6)])\n\n    # Calculate selection scores\n    selection_scores = []\n    for sol, obj in archive:\n        current_weight = np.sum(weight_lst * sol)\n        weighted_obj = adaptive_weights * np.array(obj)\n        normalized_score = np.sum(weighted_obj) / (current_weight + 1e-6)\n        selection_scores.append(normalized_score)\n\n    selected_idx = np.argmax(selection_scores)\n    base_solution = solutions[selected_idx].copy()\n\n    new_solution = base_solution.copy()\n    current_weight = np.sum(weight_lst * new_solution)\n    current_value1 = np.sum(value1_lst * new_solution)\n    current_value2 = np.sum(value2_lst * new_solution)\n\n    # Adaptive objective balancing local search\n    for i in range(len(new_solution)):\n        delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n        new_weight = current_weight + delta_weight\n\n        if new_weight <= capacity:\n            delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n            delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n\n            # Calculate weighted improvement\n            weighted_improvement = (adaptive_weights[0] * delta_value1 + adaptive_weights[1] * delta_value2) / (current_weight + 1e-6)\n\n            # Calculate diversity-aware flip probability\n            if new_solution[i] == 0:\n                # More aggressive for excluded items\n                flip_prob = min(1.0, 0.3 + 0.7 * weighted_improvement + 0.2 * np.random.random())\n            else:\n                # More conservative for included items\n                flip_prob = min(1.0, 0.1 + 0.4 * weighted_improvement + 0.1 * np.random.random())\n\n            if np.random.random() < flip_prob:\n                new_solution[i] = 1 - new_solution[i]\n                current_weight = new_weight\n                current_value1 += delta_value1\n                current_value2 += delta_value2\n\n    # Multi-phase repair mechanism\n    total_weight = np.sum(weight_lst * new_solution)\n    if total_weight > capacity:\n        # Phase 1: Remove items with least combined value-weight ratio\n        excess_weight = total_weight - capacity\n        while excess_weight > 0:\n            included_items = np.where(new_solution == 1)[0]\n            if len(included_items) == 0:\n                break\n\n            item_weights = weight_lst[included_items]\n            combined_values = adaptive_weights[0] * value1_lst[included_items] + adaptive_weights[1] * value2_lst[included_items]\n            ratios = combined_values / (item_weights + 1e-6)\n\n            worst_item_idx = np.argmin(ratios)\n            actual_idx = included_items[worst_item_idx]\n            new_solution[actual_idx] = 0\n            excess_weight -= weight_lst[actual_idx]\n\n    # Phase 2: Greedy addition of best balanced items\n    remaining_weight = capacity - np.sum(weight_lst * new_solution)\n    if remaining_weight > 0:\n        excluded_items = np.where(new_solution == 0)[0]\n        candidate_weights = weight_lst[excluded_items]\n        candidate_values = adaptive_weights[0] * value1_lst[excluded_items] + adaptive_weights[1] * value2_lst[excluded_items]\n\n        feasible_items = candidate_weights <= remaining_weight\n        if np.any(feasible_items):\n            best_item_idx = np.argmax(candidate_values[feasible_items])\n            actual_idx = excluded_items[feasible_items][best_item_idx]\n            new_solution[actual_idx] = 1\n\n    return new_solution\n\n",
          "score": [
               -18.87551729779102,
               -18.667650586901942
          ]
     },
     {
          "algorithm": "{The new algorithm combines the selection of promising solutions based on their objective trade-off potential with a novel local search strategy that dynamically adapts to the Pareto front's characteristics. It first identifies solutions with high combined objective values and strong trade-off potential by analyzing the archive's diversity and distribution, then applies a hybrid local search that intelligently combines a probabilistic item selection based on marginal contributions, a Pareto-front guided perturbation that explores regions near the knee point, and an adaptive capacity-aware random walk that ensures feasibility by considering both the current solution's weight and the remaining capacity, with the probability of each strategy being dynamically adjusted based on the solution's position relative to the Pareto front and the archive's state. Additionally, it incorporates a novel diversity-aware mutation that selectively introduces new items from underrepresented regions of the objective space, and a guided neighborhood exploration that prioritizes moves towards the most promising regions of the trade-off curve, ensuring both exploration of the solution space and exploitation of high-quality regions.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on trade-off potential and diversity\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    trade_off = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_score = combined_values * trade_off\n    best_idx = np.argmax(diversity_score)\n    base_solution = archive[best_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Hybrid local search with novel strategies\n    # Strategy 1: Marginal contribution-based selection with diversity awareness\n    for i in range(n_items):\n        if np.random.rand() < 0.5:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_improvement = (delta_value1 + delta_value2) / (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1]) + 1e-6)\n                diversity_factor = 1.0 / (1.0 + np.sum(np.abs(objectives[:, 0] - objectives[best_idx, 0]) + np.abs(objectives[:, 1] - objectives[best_idx, 1])))\n                if np.random.rand() < min(1.0, 0.3 + 0.7 * norm_improvement * diversity_factor):\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Strategy 2: Pareto-front guided perturbation with knee point approximation\n    if len(archive) > 2:\n        sorted_idx = np.argsort(objectives[:, 0] + objectives[:, 1])\n        middle_solution = archive[sorted_idx[len(archive)//2]][0]\n        knee_idx = np.argmax(objectives[:, 0] - objectives[:, 1])\n        knee_solution = archive[knee_idx][0]\n        for i in range(n_items):\n            if (middle_solution[i] != new_solution[i] or knee_solution[i] != new_solution[i]) and np.random.rand() < 0.2:\n                if (middle_solution[i] == 1 or knee_solution[i] == 1) and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Strategy 3: Adaptive capacity-aware random walk with diversity consideration\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        np.random.shuffle(candidates)\n        for i in candidates:\n            if weight_lst[i] <= remaining_capacity:\n                # Consider diversity in selection\n                if np.random.rand() < 0.4 * (1.0 / (1.0 + np.sum(np.abs(objectives[:, 0] - objectives[best_idx, 0]) + np.abs(objectives[:, 1] - objectives[best_idx, 1])))):\n                    new_solution[i] = 1\n                    remaining_capacity -= weight_lst[i]\n                    if remaining_capacity <= 0:\n                        break\n\n    # Step 4: Novel diversity-aware mutation\n    if np.random.rand() < 0.1:\n        # Select items from underrepresented regions\n        underrepresented = np.where(np.sum(objectives, axis=0) < np.mean(objectives, axis=0))[0]\n        if len(underrepresented) > 0:\n            i = np.random.choice(underrepresented)\n            if weight_lst[i] <= capacity - current_weight:\n                new_solution[i] = 1\n\n    return new_solution\n\n",
          "score": [
               -19.835392376333054,
               -15.857355104603634
          ]
     },
     {
          "algorithm": "{The new algorithm combines the selection of promising solutions based on their objective trade-off potential with a novel local search strategy that dynamically adapts to the Pareto front's characteristics. It first identifies solutions with high combined objective values and strong trade-off potential by analyzing the archive's diversity and distribution, then applies a hybrid local search that intelligently combines a probabilistic item selection based on marginal contributions, a Pareto-front guided perturbation that explores regions near the knee point, and an adaptive capacity-aware random walk that ensures feasibility by considering both the current solution's weight and the remaining capacity, with the probability of each strategy being dynamically adjusted based on the solution's position relative to the Pareto front and the archive's state. Additionally, it incorporates a novel \"objective-balanced\" perturbation that selectively flips items based on their contribution to both objectives, a \"frontier-aware\" swap that prioritizes items near the Pareto frontier, and a \"capacity-sensitive\" mutation that ensures feasibility by only considering moves that maintain or slightly reduce the total weight, while dynamically balancing exploration and exploitation by adjusting the selection probability of these strategies based on the archive's diversity and the current solution's position relative to the Pareto front.}",
          "function": "def select_neighbor(archive: List[Tuple[np.ndarray, Tuple[float, float]]], weight_lst: np.ndarray, value1_lst: np.ndarray, value2_lst: np.ndarray, capacity: float) -> np.ndarray:\n    \"\"\"\n    Select a promising solution from the archive and generate a neighbor solution from it.\n\n    Args:\n    archive: List of (solution, objective) pairs. Each solution is a binary numpy array (0/1) of item selections.\n             Each objective is a tuple of two float values (total value1, total value2).\n    weight_lst: Numpy array of shape (N, ), item weights.\n    value1_lst: Numpy array of shape (N, ), item values for objective 1.\n    value2_lst: Numpy array of shape (N, ), item values for objective 2.\n    capacity: Maximum allowed total weight.\n\n    Returns:\n    A new neighbor solution (numpy array).\n    \"\"\"\n    if not archive:\n        raise ValueError(\"Archive is empty\")\n\n    # Step 1: Select the most promising solution based on combined objective values and trade-off potential\n    objectives = np.array([obj for (sol, obj) in archive])\n    combined_values = objectives[:, 0] + objectives[:, 1]\n    trade_off = objectives[:, 0] / (objectives[:, 1] + 1e-6)\n    diversity_score = combined_values * trade_off\n    best_idx = np.argmax(diversity_score)\n    base_solution = archive[best_idx][0].copy()\n\n    new_solution = base_solution.copy()\n    n_items = len(weight_lst)\n    current_weight = np.sum(weight_lst[new_solution == 1])\n\n    # Step 2: Objective-balanced perturbation with adaptive probability\n    for i in range(n_items):\n        if np.random.rand() < 0.6:\n            delta_weight = weight_lst[i] * (1 - 2 * new_solution[i])\n            if current_weight + delta_weight <= capacity:\n                delta_value1 = value1_lst[i] * (1 - 2 * new_solution[i])\n                delta_value2 = value2_lst[i] * (1 - 2 * new_solution[i])\n                norm_improvement = (delta_value1 + delta_value2) / (np.sum(value1_lst[new_solution == 1]) + np.sum(value2_lst[new_solution == 1]) + 1e-6)\n                if np.random.rand() < min(1.0, 0.5 + 0.5 * norm_improvement):\n                    new_solution[i] = 1 - new_solution[i]\n                    current_weight += delta_weight\n\n    # Step 3: Frontier-aware swap with adaptive probability\n    if len(archive) > 2:\n        sorted_idx = np.argsort(objectives[:, 0] + objectives[:, 1])\n        middle_solution = archive[sorted_idx[len(archive)//2]][0]\n        for i in range(n_items):\n            if middle_solution[i] != new_solution[i] and np.random.rand() < 0.4:\n                if middle_solution[i] == 1 and (current_weight + weight_lst[i] <= capacity):\n                    new_solution[i] = 1\n                    current_weight += weight_lst[i]\n                elif new_solution[i] == 1:\n                    new_solution[i] = 0\n                    current_weight -= weight_lst[i]\n\n    # Step 4: Capacity-sensitive mutation with adaptive probability\n    remaining_capacity = capacity - current_weight\n    if remaining_capacity > 0:\n        candidates = np.where(new_solution == 0)[0]\n        np.random.shuffle(candidates)\n        for i in candidates:\n            if weight_lst[i] <= remaining_capacity and np.random.rand() < 0.6:\n                new_solution[i] = 1\n                remaining_capacity -= weight_lst[i]\n                if remaining_capacity <= 0:\n                    break\n\n    # Step 5: Novel diversity-aware mutation\n    if np.random.rand() < 0.2:\n        underrepresented = np.where(np.sum(objectives, axis=0) < np.mean(objectives, axis=0))[0]\n        if len(underrepresented) > 0:\n            i = np.random.choice(underrepresented)\n            if weight_lst[i] <= capacity - current_weight:\n                new_solution[i] = 1\n\n    return new_solution\n\n",
          "score": [
               -19.363488198730018,
               -17.290181888470755
          ]
     }
]